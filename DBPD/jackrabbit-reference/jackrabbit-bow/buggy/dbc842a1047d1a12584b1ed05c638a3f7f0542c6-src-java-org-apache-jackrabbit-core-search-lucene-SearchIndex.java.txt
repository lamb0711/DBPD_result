Speed up indexing using a volatile index with redo log.

git-svn-id: https://svn.apache.org/repos/asf/incubator/jackrabbit/trunk@156632 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.jackrabbit.core.state.NoSuchItemStateException;
+import org.apache.lucene.index.MultiReader;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.IndexSearcher;
+    /** The logger instance for this class */
+    /** Default name of the redo log file */
+    private static final String REDO_LOG = "redo.log";
+
-     * 512k default size
+     * Default merge size: 1000
-    //private static final long DEFAULT_MERGE_SIZE = 512 * 1024;
+    private static final long DEFAULT_MERGE_SIZE = 1000;
-    //private long mergeSize = DEFAULT_MERGE_SIZE;
+    /**
+     * The maximum number of entries in the redo log until the volatile index
+     * is merged into the persistent one.
+     */
+    private long mergeSize = DEFAULT_MERGE_SIZE;
+    /**
+     * The persistent index.
+     */
-    //private VolatileIndex volatileIndex;
+    /**
+     * The in-memory index.
+     */
+    private VolatileIndex volatileIndex;
+    /**
+     * The analyzer we use for indexing.
+     */
+    /**
+     * Internal namespace mappings.
+     */
+    /**
+     * Read-write lock to synchronize access on the index.
+     */
-        //volatileIndex = new VolatileIndex(analyzer);
+
+            // init volatile index
+            RedoLog redoLog = new RedoLog(new FileSystemResource(getFileSystem(), REDO_LOG));
+            if (redoLog.hasEntries()) {
+                log.warn("Found uncommitted redo log. Applying changes now...");
+                ItemStateManager itemMgr = getItemStateProvider();
+                // apply changes to persistent index
+                Iterator it = redoLog.getEntries().iterator();
+                while (it.hasNext()) {
+                    RedoLog.Entry entry = (RedoLog.Entry) it.next();
+                    if (entry.type == RedoLog.Entry.NODE_ADDED) {
+                        try {
+                            NodeState state = (NodeState) itemMgr.getItemState(new NodeId(entry.uuid));
+                            addNodePersistent(state);
+                        } catch (NoSuchItemStateException e) {
+                            // item does not exist anymore
+                        }
+                    } else {
+                        deleteNodePersistent(entry.uuid);
+                    }
+                }
+                log.warn("Redo changes applied.");
+                redoLog.clear();
+            }
+            volatileIndex = new VolatileIndex(analyzer, redoLog);
+            volatileIndex.setUseCompoundFile(false);
-            // FIXME: ??? do logging, simply return?
-            return;
+            throw new RepositoryException("Failed to aquire write lock.");
-            persistentIndex.addDocument(doc);
+            volatileIndex.addDocument(doc);
+            if (volatileIndex.getRedoLog().getSize() > mergeSize) {
+                log.info("Merging in-memory index");
+                persistentIndex.mergeIndex(volatileIndex);
+                // reset redo log
+                try {
+                    volatileIndex.getRedoLog().clear();
+                } catch (FileSystemException e) {
+                    log.error("Internal error: Unable to clear redo log.", e);
+                }
+                // create new volatile index
+                volatileIndex = new VolatileIndex(analyzer, volatileIndex.getRedoLog());
+                volatileIndex.setUseCompoundFile(false);
+            }
-
-        /*
-        volatileIndex.addDocument(doc);
-        if (volatileIndex.size() > mergeSize) {
-            persistentIndex.mergeIndex(volatileIndex);
-            // create new volatile index
-            volatileIndex = new VolatileIndex(analyzer);
-        }
-        */
-            // FIXME: ??? do logging, simply return?
-            return;
+            throw new IOException("Failed to aquire write lock.");
-            persistentIndex.removeDocument(idTerm);
+            // if the document cannot be deleted from the volatile index
+            // delete it from the persistent index.
+            if (volatileIndex.removeDocument(idTerm) == 0) {
+                persistentIndex.removeDocument(idTerm);
+            }
-        //volatileIndex.removeDocument(idTerm);
-        /*
+        log.info("Closing search index.");
-            persistentIndex.mergeIndex(volatileIndex);
+            if (volatileIndex.getRedoLog().hasEntries()) {
+                persistentIndex.mergeIndex(volatileIndex);
+                volatileIndex.getRedoLog().clear();
+            }
-            // FIXME do logging
+            log.error("Exception while closing search index.", e);
+        } catch (FileSystemException e) {
+            log.error("Exception while closing search index.", e);
-        */
-        log.info("Closing search index.");
+            MultiReader multiReader = new MultiReader(new IndexReader[]{ persistentIndex.getIndexReader(), volatileIndex.getIndexReader()});
-                hits = persistentIndex.getIndexSearcher().search(query,
-                        new Sort(sortFields));
+                hits = new IndexSearcher(multiReader).search(query, new Sort(sortFields));
-                hits = persistentIndex.getIndexSearcher().search(query);
+                hits = new IndexSearcher(multiReader).search(query);
-        addNode(node);
+        addNodePersistent(node);
+    /**
+     * Adds a node to the persistent index. This method will <b>not</b> aquire a
+     * write lock while writing!
+     * @param node the node to add.
+     * @throws IOException if an error occurs while writing to the index.
+     * @throws RepositoryException if any other error occurs
+     */
+    private void addNodePersistent(NodeState node)
+            throws IOException, RepositoryException {
+        Document doc = NodeIndexer.createDocument(node, getItemStateProvider(), nsMappings);
+        persistentIndex.addDocument(doc);
+    }
+
+    /**
+     * Removes a node from the persistent index. This method will <b>not</b>
+     * aquire a write lock while writing!
+     * @param uuid the uuid of the node to remove.
+     * @throws IOException if an error occurs while writing to the index.
+     */
+    private void deleteNodePersistent(String uuid) throws IOException {
+        Term idTerm = new Term(FieldNames.UUID, uuid);
+        persistentIndex.removeDocument(idTerm);
+    }
+
+
+    public void setRedoSize(int size) {
+        mergeSize = size;
+    }
