JCR-1093: Separate initial index creation from MultiIndex construction

git-svn-id: https://svn.apache.org/repos/asf/jackrabbit/trunk@570350 13f79535-47bb-0310-9956-ffa450edef68

-     * @param stateMgr shared item state manager
-     * @param rootId id of the root node
-               ItemStateManager stateMgr,
-               NodeId rootId,
-
-        try {
-            // open persistent indexes
-            for (int i = 0; i < indexNames.size(); i++) {
-                File sub = new File(indexDir, indexNames.getName(i));
-                // only open if it still exists
-                // it is possible that indexNames still contains a name for
-                // an index that has been deleted, but indexNames has not been
-                // written to disk.
-                if (!sub.exists()) {
-                    log.debug("index does not exist anymore: " + sub.getAbsolutePath());
-                    // move on to next index
-                    continue;
-                }
-                PersistentIndex index = new PersistentIndex(
-                        indexNames.getName(i), sub, false,
-                        handler.getTextAnalyzer(), cache, indexingQueue);
-                index.setMaxMergeDocs(handler.getMaxMergeDocs());
-                index.setMergeFactor(handler.getMergeFactor());
-                index.setMinMergeDocs(handler.getMinMergeDocs());
-                index.setMaxFieldLength(handler.getMaxFieldLength());
-                index.setUseCompoundFile(handler.getUseCompoundFile());
-                indexes.add(index);
-                merger.indexAdded(index.getName(), index.getNumDocuments());
+        // open persistent indexes
+        for (int i = 0; i < indexNames.size(); i++) {
+            File sub = new File(indexDir, indexNames.getName(i));
+            // only open if it still exists
+            // it is possible that indexNames still contains a name for
+            // an index that has been deleted, but indexNames has not been
+            // written to disk.
+            if (!sub.exists()) {
+                log.debug("index does not exist anymore: " + sub.getAbsolutePath());
+                // move on to next index
+                continue;
-
-            // init volatile index
-            resetVolatileIndex();
-
-            redoLogApplied = redoLog.hasEntries();
-
-            // run recovery
-            Recovery.run(this, redoLog);
-
-            // now that we are ready, start index merger
-            merger.start();
-
-            if (redoLogApplied) {
-                // wait for the index merge to finish pending jobs
-                try {
-                    merger.waitUntilIdle();
-                } catch (InterruptedException e) {
-                    // move on
-                }
-                flush();
-            }
-
-            // do an initial index if there are no indexes at all
-            if (indexNames.size() == 0) {
-                reindexing = true;
-                // traverse and index workspace
-                executeAndLog(new Start(Action.INTERNAL_TRANSACTION));
-                NodeState rootState = (NodeState) stateMgr.getItemState(rootId);
-                createIndex(rootState, stateMgr);
-                executeAndLog(new Commit(getTransactionId()));
-                reindexing = false;
-            }
-        } catch (Exception e) {
-            String msg = "Error reindexing workspace";
-            IOException ex = new IOException(msg);
-            ex.initCause(e);
-            throw ex;
+            PersistentIndex index = new PersistentIndex(
+                    indexNames.getName(i), sub, false,
+                    handler.getTextAnalyzer(), cache, indexingQueue);
+            index.setMaxMergeDocs(handler.getMaxMergeDocs());
+            index.setMergeFactor(handler.getMergeFactor());
+            index.setMinMergeDocs(handler.getMinMergeDocs());
+            index.setMaxFieldLength(handler.getMaxFieldLength());
+            index.setUseCompoundFile(handler.getUseCompoundFile());
+            indexes.add(index);
+            merger.indexAdded(index.getName(), index.getNumDocuments());
-        lastFlushTime = System.currentTimeMillis();
+        // init volatile index
+        resetVolatileIndex();
+
+        redoLogApplied = redoLog.hasEntries();
+
+        // run recovery
+        Recovery.run(this, redoLog);
+
+        // now that we are ready, start index merger
+        merger.start();
+
+        if (redoLogApplied) {
+            // wait for the index merge to finish pending jobs
+            try {
+                merger.waitUntilIdle();
+            } catch (InterruptedException e) {
+                // move on
+            }
+            flush();
+        }
+
-        FLUSH_TIMER.schedule(flushTask, 0, 1000);
+
+        if (indexNames.size() > 0) {
+            scheduleFlushTask();
+        }
+    }
+
+    /**
+     * Returns the number of documents in this index.
+     *
+     * @return the number of documents in this index.
+     * @throws IOException if an error occurs while reading from the index.
+     */
+    int numDocs() throws IOException {
+        if (indexNames.size() == 0) {
+            return volatileIndex.getNumDocuments();
+        } else {
+            IndexReader reader = getIndexReader();
+            try {
+                return reader.numDocs();
+            } finally {
+                reader.close();
+            }
+        }
+    }
+
+    /**
+     * Creates an initial index by traversing the node hierarchy starting at the
+     * node with <code>rootId</code>.
+     *
+     * @param stateMgr the item state manager.
+     * @param rootId   the id of the node from where to start.
+     * @throws IOException           if an error occurs while indexing the
+     *                               workspace.
+     * @throws IllegalStateException if this index is not empty.
+     */
+    void createInitialIndex(ItemStateManager stateMgr, NodeId rootId)
+            throws IOException {
+        // only do an initial index if there are no indexes at all
+        if (indexNames.size() == 0) {
+            reindexing = true;
+            try {
+                // traverse and index workspace
+                executeAndLog(new Start(Action.INTERNAL_TRANSACTION));
+                NodeState rootState = (NodeState) stateMgr.getItemState(rootId);
+                createIndex(rootState, stateMgr);
+                executeAndLog(new Commit(getTransactionId()));
+                scheduleFlushTask();
+            } catch (Exception e) {
+                String msg = "Error indexing workspace";
+                IOException ex = new IOException(msg);
+                ex.initCause(e);
+                throw ex;
+            } finally {
+                reindexing = false;
+            }
+        } else {
+            throw new IllegalStateException("Index already present");
+        }
-            if (reindexing) {
-                // do some cleanup right away when reindexing
-                attemptDelete();
-            } else {
+            if (!reindexing) {
+        if (reindexing) {
+            // do some cleanup right away when reindexing
+            attemptDelete();
+        }
+    private void scheduleFlushTask() {
+        lastFlushTime = System.currentTimeMillis();
+        FLUSH_TIMER.schedule(flushTask, 0, 1000);
+    }
+
