JCR-390: Move text extraction into a background thread

git-svn-id: https://svn.apache.org/repos/asf/jackrabbit/trunk@497067 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
-import javax.jcr.RepositoryException;
+import java.io.StringReader;
+import java.util.Enumeration;
+     * The indexing queue.
+     */
+    private IndexingQueue indexingQueue;
+
+    /**
-     * @param analyzer  the analyzer for text tokenizing.
-     * @param directory the underlying directory.
-     * @param cache     the document number cache if this index should use one;
-     *                  otherwise <code>cache</code> is <code>null</code>.
+     * @param analyzer      the analyzer for text tokenizing.
+     * @param directory     the underlying directory.
+     * @param cache         the document number cache if this index should use
+     *                      one; otherwise <code>cache</code> is
+     *                      <code>null</code>.
+     * @param indexingQueue the indexing queue.
-                  DocNumberCache cache) throws IOException {
+                  DocNumberCache cache,
+                  IndexingQueue indexingQueue) throws IOException {
+        this.indexingQueue = indexingQueue;
-     * Adds a node to this index and invalidates the shared reader.
+     * Adds a document to this index and invalidates the shared reader.
-     * @param nodeIndexer the node indexer of the node to add.
+     * @param doc the document to add.
-    void addNode(NodeIndexer nodeIndexer) throws IOException {
-        try {
-            getIndexWriter().addDocument(nodeIndexer.createDoc());
-        } catch (RepositoryException e) {
-            IOException iex = new IOException(e.getMessage());
-            iex.initCause(e);
-            throw iex;
-        }
+    void addDocument(Document doc) throws IOException {
+        // check if text extractor completed its work
+        doc = getFinishedDocument(doc);
+        getIndexWriter().addDocument(doc);
+    /**
+     * Returns a document that is finished with text extraction and is ready to
+     * be added to the index.
+     *
+     * @param doc the document to check.
+     * @return <code>doc</code> if it is finished already or a stripped down
+     *         copy of <code>doc</code> without text extractors.
+     * @throws IOException if the document cannot be added to the indexing
+     *                     queue.
+     */
+    private Document getFinishedDocument(Document doc) throws IOException {
+        if (!Util.isDocumentReady(doc)) {
+            Document copy = new Document();
+            for (Enumeration fields = doc.fields(); fields.hasMoreElements(); ) {
+                Field f = (Field) fields.nextElement();
+                Field field = null;
+                Field.TermVector tv;
+                if (f.isTermVectorStored()) {
+                    tv = Field.TermVector.YES;
+                } else {
+                    tv = Field.TermVector.NO;
+                }
+                Field.Store stored;
+                if (f.isStored()) {
+                    stored = Field.Store.YES;
+                } else {
+                    stored = Field.Store.NO;
+                }
+                Field.Index indexed;
+                if (!f.isIndexed()) {
+                    indexed = Field.Index.NO;
+                } else if (f.isTokenized()) {
+                    indexed = Field.Index.TOKENIZED;
+                } else {
+                    indexed = Field.Index.UN_TOKENIZED;
+                }
+                if (f.readerValue() != null) {
+                    // replace all readers with empty string reader
+                    field = new Field(f.name(), new StringReader(""), tv);
+                } else if (f.stringValue() != null) {
+                    field = new Field(f.name(), f.stringValue(),
+                            stored, indexed, tv);
+                } else if (f.isBinary()) {
+                    field = new Field(f.name(), f.binaryValue(), stored);
+                }
+                if (field != null) {
+                    copy.add(field);
+                }
+            }
+            // schedule the original document for later indexing
+            Document existing = indexingQueue.addDocument(doc);
+            if (existing != null) {
+                // the queue already contained a pending document for this
+                // node. -> dispose the document
+                Util.disposeDocument(existing);
+            }
+            // use the stripped down copy for now
+            doc = copy;
+        }
+        return doc;
+    }
+
