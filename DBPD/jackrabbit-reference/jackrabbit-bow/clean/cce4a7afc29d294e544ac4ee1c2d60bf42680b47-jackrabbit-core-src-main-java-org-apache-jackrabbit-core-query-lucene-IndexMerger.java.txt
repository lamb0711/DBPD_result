JCR-1818: Too many open files when merging large index segments

git-svn-id: https://svn.apache.org/repos/asf/jackrabbit/trunk@792109 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.commons.collections.Buffer;
-import org.apache.commons.collections.BufferUtils;
-import org.apache.commons.collections.buffer.UnboundedFifoBuffer;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.Semaphore;
-import EDU.oswego.cs.dl.util.concurrent.Sync;
-import EDU.oswego.cs.dl.util.concurrent.Mutex;
-
-class IndexMerger extends Thread implements IndexListener {
+class IndexMerger implements IndexListener {
-    private final Buffer mergeTasks = BufferUtils.blockingBuffer(new UnboundedFifoBuffer());
-
-    /**
-     * List of id <code>Term</code> that identify documents that were deleted
-     * while a merge was running.
-     */
-    private final List deletedDocuments = Collections.synchronizedList(new ArrayList());
+    private final BlockingQueue<Merge> mergeTasks = new LinkedBlockingQueue<Merge>();
-    private final List indexBuckets = new ArrayList();
+    private final List<IndexBucket> indexBuckets = new ArrayList<IndexBucket>();
-    private final Sync indexReplacement = new Mutex();
+    private final Semaphore indexReplacement;
-     * When released, indicates that this index merger is idle.
+     * List of merger threads that are currently busy.
-    private final Sync mergerIdle = new Mutex();
+    private final List<Worker> busyMergers = new ArrayList<Worker>();
+
+    /**
+     * List of merger threads.
+     */
+    private final List<Worker> workers = new ArrayList<Worker>();
+     * @param numWorkers the number of worker threads to use.
-    IndexMerger(MultiIndex multiIndex) {
+    IndexMerger(MultiIndex multiIndex, int numWorkers) {
-        setName("IndexMerger");
-        setDaemon(true);
-        try {
-            mergerIdle.acquire();
-        } catch (InterruptedException e) {
-            // will never happen, lock is free upon construction
-            throw new InternalError("Unable to acquire mutex after construction");
+        for (int i = 0; i < numWorkers; i++) {
+            Worker w = new Worker();
+            workers.add(w);
+            busyMergers.add(w);
+        }
+        this.indexReplacement = new Semaphore(workers.size());
+    }
+
+    /**
+     * Starts this index merger.
+     */
+    void start() {
+        for (Thread t : workers) {
+            t.start();
-            IndexBucket bucket = (IndexBucket) indexBuckets.get(indexBuckets.size() - 1);
-            for (int i = 0; i < indexBuckets.size(); i++) {
-                bucket = (IndexBucket) indexBuckets.get(i);
+            IndexBucket bucket = indexBuckets.get(indexBuckets.size() - 1);
+            for (IndexBucket indexBucket : indexBuckets) {
+                bucket = indexBucket;
-                List indexesToMerge = new ArrayList();
+                List<Index> indexesToMerge = new ArrayList<Index>();
-                for (Iterator it = bucket.iterator(); it.hasNext() && mergeDocs <= targetMergeDocs;) {
+                for (Iterator<Index> it = bucket.iterator(); it.hasNext() && mergeDocs <= targetMergeDocs;) {
-                    Index[] idxs = (Index[]) indexesToMerge.toArray(new Index[indexesToMerge.size()]);
+                    Index[] idxs = indexesToMerge.toArray(new Index[indexesToMerge.size()]);
-                    mergeTasks.add(new Merge(idxs));
-                    log.debug("merge queue now contains " + mergeTasks.size() + " tasks.");
+                    addMergeTask(new Merge(idxs));
+                    if (log.isDebugEnabled()) {
+                        log.debug("merge queue now contains " + mergeTasks.size() + " tasks.");
+                        int numBusy;
+                        synchronized (busyMergers) {
+                            numBusy = busyMergers.size();
+                        }
+                        log.debug("# of busy merge workers: " + numBusy);
+                    }
-        deletedDocuments.add(id);
+        synchronized (busyMergers) {
+            for (Worker w : busyMergers) {
+                w.documentDeleted(id);
+            }
+        }
-     * there will be no merge tasks pending anymore. The method returns immediately
-     * if there are currently no tasks pending at all.
+     * there will be no merge tasks pending anymore. The method returns
+     * immediately if there are currently no tasks pending at all.
+     *
+     * @throws InterruptedException if this thread is interrupted while waiting
+     *                              for the worker threads to become idle.
-        mergerIdle.acquire();
-        // and immediately release again
-        mergerIdle.release();
+        synchronized (busyMergers) {
+            while (!busyMergers.isEmpty()) {
+                busyMergers.wait();
+            }
+        }
-        // get mutex for index replacements
+        // get all permits for index replacements
-            indexReplacement.acquire();
+            indexReplacement.acquire(workers.size());
-            log.warn("Interrupted while acquiring index replacement sync: " + e);
+            log.warn("Interrupted while acquiring index replacement permits: " + e);
+        log.debug("merge queue size: " + mergeTasks.size());
-        mergeTasks.add(QUIT);
+        addMergeTask(QUIT);
-            // give the merger thread some time to quit,
-            // it is possible that the merger is busy working on a large index.
+            // give the merger threads some time to quit,
+            // it is possible that the mergers are busy working on a large index.
-            // on the MultiIndex because we hold the indexReplacement Sync.
-            this.join(500);
-            if (isAlive()) {
-                log.info("Unable to stop IndexMerger. Daemon is busy.");
-            } else {
-                log.debug("IndexMerger thread stopped");
+            // on the MultiIndex because we hold all indexReplacement permits.
+            for (Thread t : workers) {
+                t.join(500);
+                if (t.isAlive()) {
+                    log.info("Unable to stop IndexMerger.Worker. Daemon is busy.");
+                } else {
+                    log.debug("IndexMerger.Worker thread stopped");
+                }
-            log.debug("merge queue size: " + mergeTasks.size());
-            log.warn("Interrupted while waiting for IndexMerger thread to terminate.");
+            log.warn("Interrupted while waiting for IndexMerger threads to terminate.");
-    /**
-     * Implements the index merging.
-     */
-    public void run() {
-        for (;;) {
-            boolean isIdle = false;
-            if (mergeTasks.size() == 0) {
-                mergerIdle.release();
-                isIdle = true;
-            }
-            Merge task = (Merge) mergeTasks.remove();
-            if (task == QUIT) {
-                mergerIdle.release();
-                break;
-            }
-            if (isIdle) {
-                try {
-                    mergerIdle.acquire();
-                } catch (InterruptedException e) {
-                    Thread.interrupted();
-                    log.warn("Unable to acquire mergerIdle sync");
-                }
-            }
-
-            log.debug("accepted merge request");
-
-            // reset deleted documents
-            deletedDocuments.clear();
-
-            // get readers
-            String[] names = new String[task.indexes.length];
-            for (int i = 0; i < task.indexes.length; i++) {
-                names[i] = task.indexes[i].name;
-            }
-            try {
-                log.debug("create new index");
-                PersistentIndex index = multiIndex.getOrCreateIndex(null);
-                boolean success = false;
-                try {
-
-                    log.debug("get index readers from MultiIndex");
-                    IndexReader[] readers = multiIndex.getIndexReaders(names, this);
-                    try {
-                        // do the merge
-                        long time = System.currentTimeMillis();
-                        index.addIndexes(readers);
-                        time = System.currentTimeMillis() - time;
-                        int docCount = 0;
-                        for (int i = 0; i < readers.length; i++) {
-                            docCount += readers[i].numDocs();
-                        }
-                        log.info("merged " + docCount + " documents in " + time + " ms into " + index.getName() + ".");
-                    } finally {
-                        for (int i = 0; i < readers.length; i++) {
-                            try {
-                                Util.closeOrRelease(readers[i]);
-                            } catch (IOException e) {
-                                log.warn("Unable to close IndexReader: " + e);
-                            }
-                        }
-                    }
-
-                    // inform multi index
-                    // if we cannot get the sync immediately we have to quit
-                    if (!indexReplacement.attempt(0)) {
-                        log.debug("index merging canceled");
-                        break;
-                    }
-                    try {
-                        log.debug("replace indexes");
-                        multiIndex.replaceIndexes(names, index, deletedDocuments);
-                    } finally {
-                        indexReplacement.release();
-                    }
-
-                    success = true;
-
-                } finally {
-                    if (!success) {
-                        // delete index
-                        log.debug("deleting index " + index.getName());
-                        multiIndex.deleteIndex(index);
-                    }
-                }
-            } catch (Throwable e) {
-                log.error("Error while merging indexes: ", e);
-            }
-        }
-        log.info("IndexMerger terminated");
-    }
-
+     *
+     * @param mergeFactor the merge factor.
+     *
+     * @param minMergeDocs the min merge docs number.
+     *
+     * @param maxMergeDocs the max merge docs number.
+    private void addMergeTask(Merge task) {
+        for (;;) {
+            try {
+                mergeTasks.put(task);
+                break;
+            } catch (InterruptedException e) {
+                // try again
+                Thread.interrupted();
+            }
+        }
+    }
+
-    private static final class IndexBucket extends ArrayList {
+    private static final class IndexBucket extends ArrayList<Index> {
+
+        private static final long serialVersionUID = 2985514550083374904L;
+
+    private class Worker extends Thread implements IndexListener {
+
+        /**
+         * List of id <code>Term</code> that identify documents that were deleted
+         * while a merge was running.
+         */
+        private final List<Term> deletedDocuments = Collections.synchronizedList(new ArrayList<Term>());
+
+        public Worker() {
+            setName("IndexMerger.Worker");
+            setDaemon(true);
+        }
+
+        /**
+         * Implements the index merging.
+         */
+        public void run() {
+            for (;;) {
+                boolean isIdle = false;
+                if (mergeTasks.size() == 0) {
+                    synchronized (busyMergers) {
+                        busyMergers.remove(this);
+                        busyMergers.notifyAll();
+                    }
+                    isIdle = true;
+                }
+                Merge task;
+                for (;;) {
+                    try {
+                        task = mergeTasks.take();
+                        break;
+                    } catch (InterruptedException e) {
+                        // try again
+                        Thread.interrupted();
+                    }
+                }
+                if (task == QUIT) {
+                    synchronized (busyMergers) {
+                        busyMergers.remove(this);
+                    }
+                    // put back QUIT to signal other workers
+                    addMergeTask(task);
+                    break;
+                }
+                if (isIdle) {
+                    synchronized (busyMergers) {
+                        busyMergers.add(this);
+                    }
+                }
+
+                log.debug("accepted merge request");
+
+                // reset deleted documents
+                deletedDocuments.clear();
+
+                // get readers
+                String[] names = new String[task.indexes.length];
+                for (int i = 0; i < task.indexes.length; i++) {
+                    names[i] = task.indexes[i].name;
+                }
+                try {
+                    log.debug("create new index");
+                    PersistentIndex index = multiIndex.getOrCreateIndex(null);
+                    boolean success = false;
+                    try {
+
+                        log.debug("get index readers from MultiIndex");
+                        IndexReader[] readers = multiIndex.getIndexReaders(names, IndexMerger.this);
+                        try {
+                            // do the merge
+                            long time = System.currentTimeMillis();
+                            index.addIndexes(readers);
+                            time = System.currentTimeMillis() - time;
+                            int docCount = 0;
+                            for (IndexReader reader : readers) {
+                                docCount += reader.numDocs();
+                            }
+                            log.info("merged " + docCount + " documents in " + time + " ms into " + index.getName() + ".");
+                        } finally {
+                            for (IndexReader reader : readers) {
+                                try {
+                                    Util.closeOrRelease(reader);
+                                } catch (IOException e) {
+                                    log.warn("Unable to close IndexReader: " + e);
+                                }
+                            }
+                        }
+
+                        // inform multi index
+                        // if we cannot get the sync immediately we have to quit
+                        if (!indexReplacement.tryAcquire()) {
+                            log.debug("index merging canceled");
+                            break;
+                        }
+                        try {
+                            log.debug("replace indexes");
+                            multiIndex.replaceIndexes(names, index, deletedDocuments);
+                        } finally {
+                            indexReplacement.release();
+                        }
+
+                        success = true;
+
+                    } finally {
+                        if (!success) {
+                            // delete index
+                            log.debug("deleting index " + index.getName());
+                            multiIndex.deleteIndex(index);
+                        }
+                    }
+                } catch (Throwable e) {
+                    log.error("Error while merging indexes: ", e);
+                }
+            }
+            log.info("IndexMerger.Worker terminated");
+        }
+
+        /**
+         * @inheritDoc
+         */
+        public void documentDeleted(Term id) {
+            log.debug("document deleted: " + id.text());
+            deletedDocuments.add(id);
+        }
+    }
