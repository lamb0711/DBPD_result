JCR-907: Create HTML excerpt provider

git-svn-id: https://svn.apache.org/repos/asf/jackrabbit/trunk@537155 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.jackrabbit.core.NodeId;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermDocs;
-import org.apache.lucene.index.TermFreqVector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.Iterator;
- * <code>DefaultXMLExcerpt</code> implements an ExcerptProvider.
+ * <code>DefaultXMLExcerpt</code> creates an XML excerpt of a matching node.
+ * <br/>
+ * E.g. if you search for 'jackrabbit' and 'query' you may get the following
+ * result for a node:
+ * <pre>
+ * &lt;excerpt>
+ *     &lt;fragment>&lt;highlight>Jackrabbit&lt;/highlight> implements both the mandatory XPath and optional SQL &lt;highlight>query&lt;/highlight> syntax.&lt;/fragment>
+ *     &lt;fragment>Before parsing the XPath &lt;highlight>query&lt;/highlight> in &lt;highlight>Jackrabbit&lt;/highlight>, the statement is surrounded&lt;/fragment>
+ * &lt;/excerpt>
+ * </pre>
-class DefaultXMLExcerpt implements ExcerptProvider {
-
-    /**
-     * Logger instance for this class.
-     */
-    private static final Logger log = LoggerFactory.getLogger(DefaultXMLExcerpt.class);
-
-    /**
-     * The search index.
-     */
-    private SearchIndex index;
-
-    /**
-     * The current query.
-     */
-    private Query query;
-
-    /**
-     * Indicates whether the query is already rewritten.
-     */
-    private boolean rewritten = false;
+class DefaultXMLExcerpt extends AbstractExcerpt {
-    public void init(Query query, SearchIndex index) throws IOException {
-        this.index = index;
-        this.query = query;
-    }
-
-    /**
-     * {@inheritDoc}
-     */
-    public String getExcerpt(NodeId id, int maxFragments, int maxFragmentSize)
-            throws IOException {
-        IndexReader reader = index.getIndexReader();
-        try {
-            if (!rewritten) {
-                query = query.rewrite(reader);
-                rewritten = true;
-            }
-            Term idTerm = new Term(FieldNames.UUID, id.getUUID().toString());
-            TermDocs tDocs = reader.termDocs(idTerm);
-            int docNumber;
-            Document doc;
-            try {
-                if (tDocs.next()) {
-                    docNumber = tDocs.doc();
-                    doc = reader.document(docNumber);
-                } else {
-                    // node not found in index
-                    return null;
-                }
-            } finally {
-                tDocs.close();
-            }
-            Field[] fields = doc.getFields(FieldNames.FULLTEXT);
-            if (fields == null) {
-                log.debug("Fulltext field not stored, using {}",
-                        SimpleExcerptProvider.class.getName());
-                SimpleExcerptProvider exProvider = new SimpleExcerptProvider();
-                exProvider.init(query, index);
-                return exProvider.getExcerpt(id, maxFragments, maxFragmentSize);
-            }
-            StringBuffer text = new StringBuffer();
-            String separator = "";
-            for (int i = 0; i < fields.length; i++) {
-                text.append(separator);
-                text.append(fields[i].stringValue());
-                // this is a hack! in general multiple fields with the same
-                // name are handled properly, that is, offset and position is
-                // calculated correctly. there is one case however where
-                // the offset gets wrong:
-                // if a term text ends with characters that are considered noise
-                // then the offset of the next field will be off by the number
-                // of noise characters.
-                // therefore we delete noise characters at the end of the text.
-                // this process is required for all but the last field
-                if (i < fields.length - 1) {
-                    for (int j = text.length() - 1; j >= 0; j--) {
-                        if (Character.isLetterOrDigit(text.charAt(j))) {
-                            break;
-                        } else {
-                            text.deleteCharAt(j);
-                        }
-                    }
-                }
-                separator = " ";
-            }
-            TermFreqVector tfv = reader.getTermFreqVector(
-                    docNumber, FieldNames.FULLTEXT);
-            if (tfv instanceof TermPositionVector) {
-                return createExcerpt((TermPositionVector) tfv, text.toString(),
-                        maxFragments, maxFragmentSize);
-            } else {
-                log.debug("No TermPositionVector on Fulltext field, using {}",
-                        SimpleExcerptProvider.class.getName());
-                SimpleExcerptProvider exProvider = new SimpleExcerptProvider();
-                exProvider.init(query, index);
-                return exProvider.getExcerpt(id, maxFragments, maxFragmentSize);
-            }
-        } finally {
-            reader.close();
-        }
-    }
-
-    /**
-     * Creates an excerpt for the given <code>text</code> using token offset
-     * information provided by <code>tpv</code>.
-     *
-     * @param tpv             the term position vector for the fulltext field.
-     * @param text            the original text.
-     * @param maxFragments    the maximum number of fragments to create.
-     * @param maxFragmentSize the maximum number of characters in a fragment.
-     * @return the xml excerpt.
-     * @throws IOException if an error occurs while creating the excerpt.
-     */
-    private String createExcerpt(TermPositionVector tpv,
+    protected String createExcerpt(TermPositionVector tpv,
-
-        Set extractedTerms = new HashSet();
-        Set relevantTerms = new HashSet();
-        query.extractTerms(extractedTerms);
-        // only keep terms for fulltext fields
-        for (Iterator it = extractedTerms.iterator(); it.hasNext(); ) {
-            Term t = (Term) it.next();
-            if (t.field().equals(FieldNames.FULLTEXT)) {
-                relevantTerms.add(t);
-            } else {
-                int idx = t.field().indexOf(FieldNames.FULLTEXT_PREFIX);
-                if (idx != -1) {
-                    relevantTerms.add(new Term(FieldNames.FULLTEXT, t.text()));
-                }
-            }
-        }
-
-        return DefaultHighlighter.highlight(tpv, relevantTerms, text,
+        return DefaultHighlighter.highlight(tpv, getQueryTerms(), text,
