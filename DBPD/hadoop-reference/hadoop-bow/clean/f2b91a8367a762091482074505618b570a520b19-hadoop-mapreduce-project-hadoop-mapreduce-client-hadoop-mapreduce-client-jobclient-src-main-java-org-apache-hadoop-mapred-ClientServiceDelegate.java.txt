 MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68

-import java.net.UnknownHostException;
+import java.lang.reflect.Method;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
+import org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetCountersResponse;
+import org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetDiagnosticsResponse;
+import org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetJobReportResponse;
+import org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetTaskAttemptCompletionEventsResponse;
+import org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetTaskReportsResponse;
+import org.apache.hadoop.mapreduce.v2.api.records.Counters;
-import org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils;
-public class ClientServiceDelegate {
+class ClientServiceDelegate {
+  private static final NotRunningJob NOTSTARTEDJOB = 
+	  new NotRunningJob(JobState.NEW);
+  
+  private static final NotRunningJob FAILEDJOB = 
+	  new NotRunningJob(JobState.FAILED);
+  
+  private static final NotRunningJob KILLEDJOB = 
+	  new NotRunningJob(JobState.KILLED);
-  private Configuration conf;
-  private ApplicationId currentAppId;
-  private ApplicationState currentAppState = ApplicationState.NEW;
+  private final Configuration conf;
+  private final JobID jobId;
+  private final ApplicationId appId;
+  private final MRClientProtocol historyServerProxy;
+  private boolean forceRefresh;
-  private String serviceAddr = "";
-  private String serviceHttpAddr = "";
-  ClientServiceDelegate(Configuration conf, ResourceMgrDelegate rm) {
+  ClientServiceDelegate(Configuration conf, ResourceMgrDelegate rm, 
+      JobID jobId, MRClientProtocol historyServerProxy) {
+    this.jobId = jobId;
+    this.historyServerProxy = historyServerProxy;
+    this.appId = TypeConverter.toYarn(jobId).getAppId();
-  private MRClientProtocol getProxy(JobID jobId) throws YarnRemoteException {
-    return getProxy(TypeConverter.toYarn(jobId).getAppId(), false);
-  }
-
-  private MRClientProtocol getRefreshedProxy(JobID jobId) throws YarnRemoteException {
-    return getProxy(TypeConverter.toYarn(jobId).getAppId(), true);
-  }
-
-  private MRClientProtocol getProxy(ApplicationId appId, 
-      boolean forceRefresh) throws YarnRemoteException {
-    if (!appId.equals(currentAppId) || forceRefresh || realProxy == null) {
-      currentAppId = appId;
-      refreshProxy();
+  private MRClientProtocol getProxy() throws YarnRemoteException {
+    if (!forceRefresh && realProxy != null) {
+      return realProxy;
-    return realProxy;
-  }
-
-  private void refreshProxy() throws YarnRemoteException {
-    //TODO RM NPEs for unknown jobs. History may still be aware.
+      //TODO RM NPEs for unknown jobs. History may still be aware.
-    ApplicationReport application = rm.getApplicationReport(currentAppId);
+    ApplicationReport application = rm.getApplicationReport(appId);
+    String serviceAddr = null;
-          application = rm.getApplicationReport(currentAppId);
+          application = rm.getApplicationReport(appId);
-        serviceHttpAddr = application.getTrackingUrl();
-        currentAppState = application.getState();
+        LOG.info("Tracking Url of JOB is " + application.getTrackingUrl());
-        return;
+        return realProxy;
-        application = rm.getApplicationReport(currentAppId);
+        application = rm.getApplicationReport(appId);
-    currentAppState = application.getState();
-    if (currentAppState == ApplicationState.NEW) {
+    if (application.getState() == ApplicationState.NEW ||
+        application.getState() == ApplicationState.SUBMITTED) {
-      return;
+      return NOTSTARTEDJOB;
-    if (currentAppState == ApplicationState.SUCCEEDED
-        || currentAppState == ApplicationState.FAILED
-        || currentAppState == ApplicationState.KILLED) {
-      serviceAddr = conf.get(JHConfig.HS_BIND_ADDRESS,
-          JHConfig.DEFAULT_HS_BIND_ADDRESS);
+    if (application.getState() == ApplicationState.FAILED) {
+      realProxy = null;
+      return FAILEDJOB;
+    }
+    
+    if (application.getState() == ApplicationState.KILLED) {
+        realProxy = null;
+        return KILLEDJOB;
+      }
+    
+    //History server can serve a job only if application 
+    //succeeded.
+    if (application.getState() == ApplicationState.SUCCEEDED) {
-      try {
-        serviceHttpAddr = JobHistoryUtils.getHistoryUrl(conf, currentAppId);
-      } catch (UnknownHostException e) {
-        LOG.warn("Unable to get history url", e);
-        serviceHttpAddr = "UNKNOWN";
-      }
-      try {
-        instantiateHistoryProxy(serviceAddr);
-        return;
-      } catch (IOException e) {
-        throw new YarnException(e);
-      }
+      realProxy = historyServerProxy;
+    return realProxy;
-  private void instantiateHistoryProxy(final String serviceAddr)
-  throws IOException {
-    LOG.trace("Connecting to HistoryServer at: " + serviceAddr);
-    Configuration myConf = new Configuration(conf);
-    //TODO This should ideally be using it's own class (instead of ClientRMSecurityInfo)
-    myConf.setClass(YarnConfiguration.YARN_SECURITY_INFO,
-        ClientRMSecurityInfo.class, SecurityInfo.class);
-    YarnRPC rpc = YarnRPC.create(myConf);
-    realProxy = (MRClientProtocol) rpc.getProxy(MRClientProtocol.class,
-        NetUtils.createSocketAddr(serviceAddr), myConf);
-    LOG.trace("Connected to HistoryServer at: " + serviceAddr);
+  private synchronized Object invoke(String method, Class argClass, 
+      Object args) throws YarnRemoteException {
+    Method methodOb = null;
+    try {
+      methodOb = MRClientProtocol.class.getMethod(method, argClass);
+    } catch (SecurityException e) {
+      throw new YarnException(e);
+    } catch (NoSuchMethodException e) {
+      throw new YarnException("Method name mismatch", e);
+    }
+    while (true) {
+      try {
+        return methodOb.invoke(getProxy(), args);
+      } catch (YarnRemoteException yre) {
+        LOG.warn("Exception thrown by remote end.");
+        LOG.warn(RPCUtil.toString(yre));
+        throw yre;
+      } catch (Exception e) {
+        LOG.info("Failed to contact AM for job " + jobId + "  Will retry..");
+        LOG.debug("Failing to contact application master", e);
+        forceRefresh = true;
+      }
+    }
-  public org.apache.hadoop.mapreduce.Counters getJobCounters(JobID arg0) throws IOException,
+  org.apache.hadoop.mapreduce.Counters getJobCounters(JobID arg0) throws IOException,
-    try {
-      MRClientProtocol protocol = getProxy(arg0);
-      if (protocol == null) {
-        /* no AM to connect to, fake counters */
-        return new org.apache.hadoop.mapreduce.Counters();
-      }
-      return TypeConverter.fromYarn(protocol.getCounters(request).getCounters());
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      LOG.debug("Failing to contact application master", e);
-      try {
-        GetCountersRequest request = recordFactory.newRecordInstance(GetCountersRequest.class);
-        request.setJobId(jobID);
-        MRClientProtocol protocol = getRefreshedProxy(arg0);
-        if (protocol == null) {
-          /* no History to connect to, fake counters */
-          return new org.apache.hadoop.mapreduce.Counters();
-        }
-        return TypeConverter.fromYarn(protocol.getCounters(request).getCounters());
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
+      Counters cnt = ((GetCountersResponse) 
+          invoke("getCounters", GetCountersRequest.class, request)).getCounters();
+      return TypeConverter.fromYarn(cnt);
+      
-  public String getJobHistoryDir() throws IOException, InterruptedException {
-    return JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);
+  TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1, int arg2)
+      throws IOException, InterruptedException {
+    org.apache.hadoop.mapreduce.v2.api.records.JobId jobID = TypeConverter
+        .toYarn(arg0);
+    GetTaskAttemptCompletionEventsRequest request = recordFactory
+        .newRecordInstance(GetTaskAttemptCompletionEventsRequest.class);
+    request.setJobId(jobID);
+    request.setFromEventId(arg1);
+    request.setMaxEvents(arg2);
+    List<org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent> list = 
+      ((GetTaskAttemptCompletionEventsResponse) invoke(
+        "getTaskAttemptCompletionEvents", GetTaskAttemptCompletionEventsRequest.class, request)).
+        getCompletionEventList();
+    return TypeConverter
+        .fromYarn(list
+            .toArray(new org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent[0]));
-  public TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1,
-      int arg2) throws IOException, InterruptedException {
-    org.apache.hadoop.mapreduce.v2.api.records.JobId jobID = TypeConverter.toYarn(arg0);
-    List<org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent> list = null;
-    GetTaskAttemptCompletionEventsRequest request = recordFactory.newRecordInstance(GetTaskAttemptCompletionEventsRequest.class);
-    MRClientProtocol protocol;
-    try {
-      request.setJobId(jobID);
-      request.setFromEventId(arg1);
-      request.setMaxEvents(arg2);
-      protocol = getProxy(arg0);
-      /** This is hack to get around the issue of faking jobstatus while the AM
-       * is coming up.
-       */
-      if (protocol == null) {
-        return new TaskCompletionEvent[0];
-      }
-      list = getProxy(arg0).getTaskAttemptCompletionEvents(request).getCompletionEventList();
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      LOG.debug("Failed to contact application master ", e);
-      try {
-        request.setJobId(jobID);
-        request.setFromEventId(arg1);
-        request.setMaxEvents(arg2);
-        protocol = getRefreshedProxy(arg0);
-        if (protocol == null) {
-          return new TaskCompletionEvent[0];
-        }
-        list = protocol.getTaskAttemptCompletionEvents(request).getCompletionEventList();
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
-    return TypeConverter.fromYarn(
-        list.toArray(new org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent[0]));
-  }
+  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)
+      throws IOException, InterruptedException {
-  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID
-      arg0)
-  throws IOException,
-  InterruptedException {
-
-    List<String> list = null;
-    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID = TypeConverter.toYarn(arg0);
-    GetDiagnosticsRequest request = recordFactory.newRecordInstance(GetDiagnosticsRequest.class);
-    MRClientProtocol protocol;
-    try {
-      request.setTaskAttemptId(attemptID);
-      protocol = getProxy(arg0.getJobID());
-      if (protocol == null) {
-        return new String[0];
-      }
-      list = getProxy(arg0.getJobID()).getDiagnostics(request).getDiagnosticsList();
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      LOG.debug("Failed to contact application master ", e);
-      try {
-        protocol = getRefreshedProxy(arg0.getJobID());
-        if (protocol == null) {
-          return new String[0];
-        }
-        list = protocol.getDiagnostics(request).getDiagnosticsList();
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
+    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID = TypeConverter
+        .toYarn(arg0);
+    GetDiagnosticsRequest request = recordFactory
+        .newRecordInstance(GetDiagnosticsRequest.class);
+    request.setTaskAttemptId(attemptID);
+    List<String> list = ((GetDiagnosticsResponse) invoke("getDiagnostics",
+        GetDiagnosticsRequest.class, request)).getDiagnosticsList();
-  private JobStatus createFakeJobReport(ApplicationState state, 
-      org.apache.hadoop.mapreduce.v2.api.records.JobId jobId, String jobFile) {
-    JobReport jobreport = recordFactory.newRecordInstance(JobReport.class);
-    jobreport.setCleanupProgress(0);
-    jobreport.setFinishTime(0);
-    jobreport.setJobId(jobId);
-    jobreport.setMapProgress(0);
-    /** fix this, the start time should be fixed */
-    jobreport.setStartTime(0);
-    jobreport.setReduceProgress(0);
-    jobreport.setSetupProgress(0);
-
-    if (currentAppState == ApplicationState.NEW) {
-      /* the protocol wasnt instantiated because the applicaton wasnt launched
-       * return a fake report.
-       */
-      jobreport.setJobState(JobState.NEW);
-    } else if (currentAppState == ApplicationState.SUBMITTED) {
-      jobreport.setJobState(JobState.NEW);
-    } else if (currentAppState == ApplicationState.KILLED) {
-      jobreport.setJobState(JobState.KILLED);
-    } else if (currentAppState == ApplicationState.FAILED) {
-      jobreport.setJobState(JobState.FAILED);
-    }
-    return  TypeConverter.fromYarn(jobreport, jobFile, serviceHttpAddr);
-  }
-
-  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,
-  YarnRemoteException {
+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException,
+       YarnRemoteException {
-    JobReport report = null;
-    try {
-      request.setJobId(jobId);
-      protocol = getProxy(oldJobID);
-      
-      if (protocol == null) {
-        return createFakeJobReport(currentAppState, jobId, jobFile);
-      }
-      report = getProxy(oldJobID).getJobReport(request).getJobReport();
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch (Exception e) {
-      try {
-        request.setJobId(jobId);
-        protocol = getRefreshedProxy(oldJobID);
-        /* this is possible if an application that was running is killed */
-        if (protocol == null)  {
-          return createFakeJobReport(currentAppState, jobId, jobFile);
-        }
-        report = protocol.getJobReport(request).getJobReport();
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
-    return TypeConverter.fromYarn(report, jobFile, serviceHttpAddr);
+    request.setJobId(jobId);
+    JobReport  report = ((GetJobReportResponse) invoke("getJobReport", 
+        GetJobReportRequest.class, request)).getJobReport();
+    //TODO: add tracking url in JobReport
+    return TypeConverter.fromYarn(report, jobFile, "");
-  public org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(JobID jobID, TaskType taskType)
-  throws YarnRemoteException, YarnRemoteException {
-    List<org.apache.hadoop.mapreduce.v2.api.records.TaskReport> taskReports = null;
+  org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(JobID jobID, TaskType taskType)
+       throws YarnRemoteException, YarnRemoteException {
-    MRClientProtocol protocol = null;
-    try {
-      request.setJobId(nJobID);
-      request.setTaskType(TypeConverter.toYarn(taskType));
-      protocol = getProxy(jobID);
-      if (protocol == null) {
-        return new org.apache.hadoop.mapreduce.TaskReport[0];
-      }
-      taskReports = getProxy(jobID).getTaskReports(request).getTaskReportList();
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      LOG.debug("Failed to contact application master ", e);
-      try {
-        request.setJobId(nJobID);
-        request.setTaskType(TypeConverter.toYarn(taskType));
-        protocol = getRefreshedProxy(jobID);
-        if (protocol == null) {
-          return new org.apache.hadoop.mapreduce.TaskReport[0];
-        }
-        taskReports = protocol.getTaskReports(request).getTaskReportList();
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
+    
+    List<org.apache.hadoop.mapreduce.v2.api.records.TaskReport> taskReports = 
+      ((GetTaskReportsResponse) invoke("getTaskReports", GetTaskReportsRequest.class, 
+          request)).getTaskReportList();
+    
-  public boolean killTask(TaskAttemptID taskAttemptID, boolean fail)
-  throws YarnRemoteException {
+  boolean killTask(TaskAttemptID taskAttemptID, boolean fail)
+       throws YarnRemoteException {
-    = TypeConverter.toYarn(taskAttemptID);
-    KillTaskAttemptRequest killRequest = recordFactory.newRecordInstance(KillTaskAttemptRequest.class);
-    FailTaskAttemptRequest failRequest = recordFactory.newRecordInstance(FailTaskAttemptRequest.class);
-    MRClientProtocol protocol = getProxy(taskAttemptID.getJobID());
-    if (protocol == null) {
-      return false;
-    }
-    try {
-      if (fail) {
-        failRequest.setTaskAttemptId(attemptID);
-        getProxy(taskAttemptID.getJobID()).failTaskAttempt(failRequest);
-      } else {
-        killRequest.setTaskAttemptId(attemptID);
-        getProxy(taskAttemptID.getJobID()).killTaskAttempt(killRequest);
-      }
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      LOG.debug("Failed to contact application master ", e);
-      MRClientProtocol proxy = getRefreshedProxy(taskAttemptID.getJobID());
-      if (proxy == null) {
-        return false;
-      }
-      try {
-        if (fail) {
-          failRequest.setTaskAttemptId(attemptID);
-          proxy.failTaskAttempt(failRequest);
-        } else {
-          killRequest.setTaskAttemptId(attemptID);
-          proxy.killTaskAttempt(killRequest);
-        }
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
+      = TypeConverter.toYarn(taskAttemptID);
+    if (fail) {
+      FailTaskAttemptRequest failRequest = recordFactory.newRecordInstance(FailTaskAttemptRequest.class);
+      failRequest.setTaskAttemptId(attemptID);
+      invoke("failTaskAttempt", FailTaskAttemptRequest.class, failRequest);
+    } else {
+      KillTaskAttemptRequest killRequest = recordFactory.newRecordInstance(KillTaskAttemptRequest.class);
+      killRequest.setTaskAttemptId(attemptID);
+      invoke("killTaskAttempt", KillTaskAttemptRequest.class, killRequest);
-  public boolean killJob(JobID oldJobID)
-  throws YarnRemoteException {
+  boolean killJob(JobID oldJobID)
+       throws YarnRemoteException {
-    MRClientProtocol protocol = getProxy(oldJobID);
-    if (protocol == null) {
-      return false;
-    }
-    try {
-      killRequest.setJobId(jobId);
-      protocol.killJob(killRequest);
-      return true;
-    } catch(YarnRemoteException yre) {//thrown by remote server, no need to redirect
-      LOG.warn(RPCUtil.toString(yre));
-      throw yre;
-    } catch(Exception e) {
-      // Not really requied - if this is always the history context.
-      LOG.debug("Failed to contact application master ", e);
-      MRClientProtocol proxy = getRefreshedProxy(oldJobID);
-      if (proxy == null) {
-        return false;
-      }
-      try {
-        killRequest.setJobId(jobId);
-        protocol.killJob(killRequest);
-        return true;
-      } catch(YarnRemoteException yre) {
-        LOG.warn(RPCUtil.toString(yre));
-        throw yre;
-      }
-    }
+    killRequest.setJobId(jobId);
+    invoke("killJob", KillJobRequest.class, killRequest);
+    return true;
+
+    
