Revert "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen."

This reverts commit 064c8b25eca9bc825dc07a54d9147d65c9290a03.

-    final boolean splitLargeFile = options.splitLargeFile();
-
-    // When splitLargeFile is enabled, we don't randomize the copylist
-    // earlier, so we don't do the sorting here. For a file that has
-    // multiple entries due to split, we check here that their
-    // <chunkOffset, chunkLength> is continuous.
-    //
-    Path checkPath = splitLargeFile?
-        pathToListFile : DistCpUtils.sortListing(fs, config, pathToListFile);
+    Path sortedList = DistCpUtils.sortListing(fs, config, pathToListFile);
-                          config, SequenceFile.Reader.file(checkPath));
+                          config, SequenceFile.Reader.file(sortedList));
-      long lastChunkOffset = -1;
-      long lastChunkLength = -1;
-          if (!splitLargeFile) {
-            throw new DuplicateFileException("File " + lastFileStatus.getPath()
-                + " and " + currentFileStatus.getPath()
-                + " would cause duplicates. Aborting");
-          } else {
-            if (lastChunkOffset + lastChunkLength !=
-                currentFileStatus.getChunkOffset()) {
-              throw new InvalidInputException("File " + lastFileStatus.getPath()
-                  + " " + lastChunkOffset + "," + lastChunkLength
-                  + " and " + currentFileStatus.getPath()
-                  + " " + currentFileStatus.getChunkOffset() + ","
-                  + currentFileStatus.getChunkLength()
-                  + " are not continuous. Aborting");
-            }
-          }
+          throw new DuplicateFileException("File " + lastFileStatus.getPath() + " and " +
+              currentFileStatus.getPath() + " would cause duplicates. Aborting");
-
-        if (splitLargeFile) {
-          lastChunkOffset = lastFileStatus.getChunkOffset();
-          lastChunkLength = lastFileStatus.getChunkLength();
-        }
+
