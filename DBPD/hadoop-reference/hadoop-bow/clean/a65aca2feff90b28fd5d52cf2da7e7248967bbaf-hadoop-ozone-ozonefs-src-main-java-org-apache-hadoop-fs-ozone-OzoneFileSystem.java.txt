HDDS-922. Create isolated classloder to use ozonefs with any older hadoop versions. Contributed by Elek, Marton.

+import java.util.Iterator;
-import java.util.Iterator;
-
-import com.google.common.base.Preconditions;
-import org.apache.hadoop.hdds.conf.OzoneConfiguration;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.classification.InterfaceStability;
+import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.ozone.client.ObjectStore;
-import org.apache.hadoop.ozone.client.OzoneBucket;
-import org.apache.hadoop.ozone.client.OzoneClient;
-import org.apache.hadoop.ozone.client.OzoneClientFactory;
-import org.apache.hadoop.ozone.OzoneConfigKeys;
-import org.apache.hadoop.ozone.client.OzoneKey;
-import org.apache.hadoop.ozone.client.OzoneVolume;
-import org.apache.hadoop.hdds.client.ReplicationFactor;
-import org.apache.hadoop.hdds.client.ReplicationType;
-import org.apache.http.client.utils.URIBuilder;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdds.conf.OzoneConfiguration;
-import org.apache.hadoop.ozone.client.io.OzoneOutputStream;
+import com.google.common.base.Preconditions;
+import org.apache.commons.lang3.StringUtils;
+import static org.apache.hadoop.fs.ozone.Constants.LISTING_PAGE_SIZE;
-import static org.apache.hadoop.ozone.OzoneConsts.OZONE_URI_SCHEME;
-import static org.apache.hadoop.fs.ozone.Constants.LISTING_PAGE_SIZE;
+import static org.apache.hadoop.ozone.OzoneConsts.OZONE_URI_SCHEME;
+import org.apache.http.client.utils.URIBuilder;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
- *
+ * <p>
-  /** The Ozone client for connecting to Ozone server. */
-  private OzoneClient ozoneClient;
-  private ObjectStore objectStore;
-  private OzoneVolume volume;
-  private OzoneBucket bucket;
+  /**
+   * The Ozone client for connecting to Ozone server.
+   */
+
-  private ReplicationType replicationType;
-  private ReplicationFactor replicationFactor;
+
+  private OzoneClientAdapter adapter;
-    if(!(conf instanceof OzoneConfiguration)) {
-      setConf(new OzoneConfiguration(conf));
-    } else {
-      setConf(conf);
-    }
+    setConf(conf);
-      this.ozoneClient = OzoneClientFactory.getRpcClient(getConf());
-      objectStore = ozoneClient.getObjectStore();
-      this.volume = objectStore.getVolume(volumeStr);
-      this.bucket = volume.getBucket(bucketStr);
-      this.replicationType = ReplicationType.valueOf(
-          getConf().get(OzoneConfigKeys.OZONE_REPLICATION_TYPE,
-              OzoneConfigKeys.OZONE_REPLICATION_TYPE_DEFAULT));
-      this.replicationFactor = ReplicationFactor.valueOf(
-          getConf().getInt(OzoneConfigKeys.OZONE_REPLICATION,
-              OzoneConfigKeys.OZONE_REPLICATION_DEFAULT));
+
+      //isolated is the default for ozonefs-lib-legacy which includes the
+      // /ozonefs.txt, otherwise the default is false. It could be overridden.
+      boolean defaultValue =
+          OzoneFileSystem.class.getClassLoader().getResource("ozonefs.txt")
+              != null;
+
+      //Use string here instead of the constant as constant may not be available
+      //on the classpath of a hadoop 2.7
+      boolean isolatedClassloader =
+          conf.getBoolean("ozone.fs.isolated-classloader", defaultValue);
+
+      if (isolatedClassloader) {
+        this.adapter =
+            OzoneClientAdapterFactory.createAdapter(volumeStr, bucketStr);
+      } else {
+        OzoneConfiguration ozoneConfiguration;
+        if (conf instanceof OzoneConfiguration) {
+          ozoneConfiguration = (OzoneConfiguration) conf;
+        } else {
+          ozoneConfiguration = new OzoneConfiguration(conf);
+        }
+        this.adapter = new OzoneClientAdapterImpl(ozoneConfiguration,
+            volumeStr, bucketStr);
+      }
+
-              .makeQualified(this.uri, this.workingDir);
+          .makeQualified(this.uri, this.workingDir);
-      ozoneClient.close();
+      adapter.close();
-        new OzoneFSInputStream(bucket.readKey(key).getInputStream()));
+        new OzoneFSInputStream(adapter.createInputStream(key)));
-        deleteObject(key);
+        adapter.deleteObject(key);
-    OzoneOutputStream ozoneOutputStream =
-        bucket.createKey(key, 0, replicationType, replicationFactor,
-            new HashMap<>());
-        new OzoneFSOutputStream(ozoneOutputStream.getOutputStream()), null);
+        adapter.createKey(key), null);
-      Progressable progress) throws IOException {
+                                   Progressable progress) throws IOException {
-      bucket.renameKey(key, newKeyName);
+      adapter.renameKey(key, newKeyName);
-   *
+   * <p>
+
-        boolean succeed = deleteObject(key);
+        boolean succeed = adapter.deleteObject(key);
+   *
-      result = deleteObject(key);
+      result = adapter.deleteObject(key);
+   *
-      createDirectory(dirKey);
+      adapter.createDirectory(dirKey);
+   *
-    ListStatusIterator(Path f) throws IOException  {
+    ListStatusIterator(Path f) throws IOException {
+     *
-         // Key is a directory
+          // Key is a directory
+     *
+     *
+     *
-     * @return immediate child path of the input path f.
+   *
-        if (!createDirectory(dirKey)) {
+        if (!adapter.createDirectory(dirKey)) {
-          bucket.getCreationTime(), qualifiedPath);
+          adapter.getCreationTime(), qualifiedPath);
-    OzoneKey ozoneKey = getKeyInfo(key);
+    BasicKeyInfo ozoneKey = adapter.getKeyInfo(key);
+   *
-    OzoneKey ozoneKey = getKeyInfo(key);
-    if(ozoneKey != null) {
-      if (isDirectory(ozoneKey)) {
+    BasicKeyInfo ozoneKey = adapter.getKeyInfo(key);
+    if (ozoneKey != null) {
+      if (adapter.isDirectory(ozoneKey)) {
-    boolean hasChildren = bucket.listKeys(key).hasNext();
+    boolean hasChildren = adapter.hasNextKey(key);
-   * Helper method to fetch the key metadata info.
-   * @param key key whose metadata information needs to be fetched
-   * @return metadata info of the key
-   */
-  private OzoneKey getKeyInfo(String key) {
-    try {
-      return bucket.getKey(key);
-    } catch (IOException e) {
-      LOG.trace("Key:{} does not exist", key);
-      return null;
-    }
-  }
-
-  /**
-   * Helper method to check if an Ozone key is representing a directory.
-   * @param key key to be checked as a directory
-   * @return true if key is a directory, false otherwise
-   */
-  private boolean isDirectory(OzoneKey key) {
-    LOG.trace("key name:{} size:{}", key.getName(),
-        key.getDataSize());
-    return key.getName().endsWith(OZONE_URI_DELIMITER)
-        && (key.getDataSize() == 0);
-  }
-
-  /**
-   * Helper method to create an directory specified by key name in bucket.
-   * @param keyName key name to be created as directory
-   * @return true if the key is created, false otherwise
-   */
-  private boolean createDirectory(String keyName) {
-    try {
-      LOG.trace("creating dir for key:{}", keyName);
-      bucket.createKey(keyName, 0, replicationType, replicationFactor,
-          new HashMap<>()).close();
-      return true;
-    } catch (IOException ioe) {
-      LOG.error("create key failed for key:{}", keyName, ioe);
-      return false;
-    }
-  }
-
-  /**
-   * Helper method to delete an object specified by key name in bucket.
-   * @param keyName key name to be deleted
-   * @return true if the key is deleted, false otherwise
-   */
-  private boolean deleteObject(String keyName) {
-    LOG.trace("issuing delete for key" + keyName);
-    try {
-      bucket.deleteKey(keyName);
-      return true;
-    } catch (IOException ioe) {
-      LOG.error("delete key failed " + ioe.getMessage());
-      return false;
-    }
-  }
-
-  /**
-    Objects.requireNonNull(path, "Path can not be null!");
+    Objects.requireNonNull(path, "Path canf not be null!");
-   *  This class provides an interface to iterate through all the keys in the
-   *  bucket prefixed with the input path key and process them.
-   *
-   *  Each implementing class should define how the keys should be processed
-   *  through the processKey() function.
+   * This class provides an interface to iterate through all the keys in the
+   * bucket prefixed with the input path key and process them.
+   * <p>
+   * Each implementing class should define how the keys should be processed
+   * through the processKey() function.
-    private Iterator<? extends OzoneKey> keyIterator;
+    private Iterator<BasicKeyInfo> keyIterator;
-      keyIterator = bucket.listKeys(pathKey);
+      keyIterator = adapter.listKeys(pathKey);
+     *
+     *
-          OzoneKey key = keyIterator.next();
+          BasicKeyInfo key = keyIterator.next();
