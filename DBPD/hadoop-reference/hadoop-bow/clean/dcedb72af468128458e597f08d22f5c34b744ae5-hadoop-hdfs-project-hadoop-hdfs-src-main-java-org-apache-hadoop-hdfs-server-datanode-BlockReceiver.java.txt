Revert "HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao."

This reverts commit aeecfa24f4fb6af289920cbf8830c394e66bd78e.

+import java.io.FileDescriptor;
+import java.io.FileOutputStream;
+import java.io.OutputStream;
+import org.apache.hadoop.io.nativeio.NativeIO;
+  private OutputStream out = null; // to block file at local disk
+  private FileDescriptor outFd;
-      streams = replicaInfo.createStreams(isCreate, requestedChecksum,
-          datanodeSlowLogThresholdMs);
+      streams = replicaInfo.createStreams(isCreate, requestedChecksum);
+      this.out = streams.getDataOut();
+      if (out instanceof FileOutputStream) {
+        this.outFd = ((FileOutputStream)out).getFD();
+      } else {
+        LOG.warn("Could not get file descriptor for outputstream of class " +
+            out.getClass());
+      }
-    if (syncOnClose && (streams.getDataOut() != null || checksumOut != null)) {
+    if (syncOnClose && (out != null || checksumOut != null)) {
-      if (streams.getDataOut() != null) {
+      if (out != null) {
-        streams.flushDataOut();
+        out.flush();
-        streams.closeDataStream();
+        out.close();
+        out = null;
-      streams.close();
+      IOUtils.closeStream(out);
-    if (streams.getDataOut() != null) {
+    if (out != null) {
-      streams.flushDataOut();
+      out.flush();
-    if (checksumOut != null || streams.getDataOut() != null) {
+    if (checksumOut != null || out != null) {
-        datanode.metrics.incrFsyncCount();
+    	  datanode.metrics.incrFsyncCount();      
-          long duration = streams.writeToDisk(dataBuf.array(),
-              startByteToDisk, numBytesToDisk);
-
+          long begin = Time.monotonicNow();
+          out.write(dataBuf.array(), startByteToDisk, numBytesToDisk);
+          long duration = Time.monotonicNow() - begin;
+          if (duration > datanodeSlowLogThresholdMs) {
+            LOG.warn("Slow BlockReceiver write data to disk cost:" + duration
+                + "ms (threshold=" + datanodeSlowLogThresholdMs + "ms)");
+          }
-      if (streams.getOutFd() != null &&
+      if (outFd != null &&
-                block, streams, lastCacheManagementOffset,
+                block, outFd, lastCacheManagementOffset,
-            streams.syncFileRangeIfPossible(lastCacheManagementOffset,
+            NativeIO.POSIX.syncFileRangeIfPossible(outFd,
+                lastCacheManagementOffset,
-          streams.dropCacheBehindWrites(block.getBlockName(), 0, dropPos,
-              POSIX_FADV_DONTNEED);
+          NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(
+              block.getBlockName(), outFd, 0, dropPos, POSIX_FADV_DONTNEED);
-              IOUtils.closeStream(streams.getDataOut());
+              IOUtils.closeStream(out);
-    if (streams.getDataOut() != null) {
-      streams.flushDataOut();
+    if (out != null) {
+     out.flush();
-      instr.readDataFully(buf, 0, sizePartialChunk);
+      IOUtils.readFully(instr.getDataIn(), buf, 0, sizePartialChunk);
-      instr.readChecksumFully(crcbuf, 0, crcbuf.length);
+      IOUtils.readFully(instr.getChecksumIn(), crcbuf, 0, crcbuf.length);
