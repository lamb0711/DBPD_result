HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68

+import java.io.PrintWriter;
-abstract class InvalidateBlocks {
+class InvalidateBlocks {
+  private final DatanodeManager datanodeManager;
+
+  InvalidateBlocks(final DatanodeManager datanodeManager) {
+    this.datanodeManager = datanodeManager;
+  }
+
-  synchronized int numStorages() {
-    return node2blocks.size();
-  }
-
-  /**
-   * Polls up to <i>limit</i> blocks from the list of to-be-invalidated Blocks
-   * for a storage.
-   */
-  synchronized List<Block> pollNumBlocks(final String storageId, final int limit) {
-    final LightWeightHashSet<Block> set = node2blocks.get(storageId);
-    if (set == null) {
-      return null;
+  /** Print the contents to out. */
+  synchronized void dump(final PrintWriter out) {
+    final int size = node2blocks.values().size();
+    out.println("Metasave: Blocks " + numBlocks 
+        + " waiting deletion from " + size + " datanodes.");
+    if (size == 0) {
+      return;
-    List<Block> polledBlocks = set.pollN(limit);
-    // Remove the storage if the set is now empty
-    if (set.isEmpty()) {
-      remove(storageId);
+
+    for(Map.Entry<String,LightWeightHashSet<Block>> entry : node2blocks.entrySet()) {
+      final LightWeightHashSet<Block> blocks = entry.getValue();
+      if (blocks.size() > 0) {
+        out.println(datanodeManager.getDatanode(entry.getKey()));
+        out.println(blocks);
+      }
-    numBlocks -= polledBlocks.size();
-    return polledBlocks;
-  /**
-   * Return the set of to-be-invalidated blocks for a storage.
-   */
-  synchronized LightWeightHashSet<Block> getBlocks(String storageId) {
-    return node2blocks.get(storageId);
-  }
+  synchronized List<Block> invalidateWork(
+      final String storageId, final DatanodeDescriptor dn) {
+    final LightWeightHashSet<Block> set = node2blocks.get(storageId);
+    if (set == null) {
+      return null;
+    }
-  /**
-   * Schedules invalidation work associated with a storage at the corresponding
-   * datanode.
-   * @param storageId Storage of blocks to be invalidated
-   * @param dn Datanode where invalidation work will be scheduled
-   * @return List of blocks scheduled for invalidation at the datanode
-   */
-  abstract List<Block> invalidateWork(final String storageId,
-      final DatanodeDescriptor dn);
+    // # blocks that can be sent in one message is limited
+    final int limit = datanodeManager.blockInvalidateLimit;
+    final List<Block> toInvalidate = set.pollN(limit);
+
+    // If we send everything in this message, remove this node entry
+    if (set.isEmpty()) {
+      remove(storageId);
+    }
+
+    dn.addBlocksToBeInvalidated(toInvalidate);
+    numBlocks -= toInvalidate.size();
+    return toInvalidate;
+  }
