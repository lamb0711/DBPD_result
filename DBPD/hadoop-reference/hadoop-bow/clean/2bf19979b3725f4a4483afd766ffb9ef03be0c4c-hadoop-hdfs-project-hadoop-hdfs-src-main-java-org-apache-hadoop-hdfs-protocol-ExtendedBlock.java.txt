Merge trunk into auto-failover branch.

Needs a few tweaks to fix compilation - will do in followup commit. This is just a straight merge


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3042@1324567 13f79535-47bb-0310-9956-ffa450edef68

-import java.io.DataInput;
-import java.io.DataOutput;
-import java.io.IOException;
-
-import org.apache.hadoop.hdfs.DeprecatedUTF8;
-import org.apache.hadoop.io.Writable;
-import org.apache.hadoop.io.WritableFactories;
-import org.apache.hadoop.io.WritableFactory;
-public class ExtendedBlock implements Writable {
+public class ExtendedBlock {
-  static { // register a ctor
-    WritableFactories.setFactory(ExtendedBlock.class, new WritableFactory() {
-      public Writable newInstance() {
-        return new ExtendedBlock();
-      }
-    });
-  }
-
-  public void write(DataOutput out) throws IOException {
-    DeprecatedUTF8.writeString(out, poolId);
-    block.writeHelper(out);
-  }
-
-  public void readFields(DataInput in) throws IOException {
-    this.poolId = DeprecatedUTF8.readString(in);
-    block.readHelper(in);
-  }
-
-  // Write only the identifier part of the block
-  public void writeId(DataOutput out) throws IOException {
-    DeprecatedUTF8.writeString(out, poolId);
-    block.writeId(out);
-  }
-
-  // Read only the identifier part of the block
-  public void readId(DataInput in) throws IOException {
-    this.poolId = DeprecatedUTF8.readString(in);
-    block.readId(in);
-  }
-  
