merge the rest of trunk to branch HDFS-4949

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532967 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode;
+import org.apache.hadoop.yarn.util.YarnVersionInfo;
+  final private ResourceManager resourceManager;
-  final FiCaSchedulerNode schedulerNode;
-
+  
-      ResourceTrackerService resourceTrackerService, RMContext rmContext)
+      ResourceManager resourceManager)
-    this.resourceTrackerService = resourceTrackerService;
+    this.resourceTrackerService = resourceManager.getResourceTrackerService();
-
-    request.setNodeId(this.nodeId);
+    request.setNMVersion(YarnVersionInfo.getVersion());
-    this.schedulerNode = new FiCaSchedulerNode(rmContext.getRMNodes().get(
-        this.nodeId), false);
-   
-    // Sanity check
-    Assert.assertEquals(capability.getMemory(), 
-       schedulerNode.getAvailableResource().getMemory());
-    Assert.assertEquals(capability.getVirtualCores(), 
-        schedulerNode.getAvailableResource().getVirtualCores());
+    this.resourceManager = resourceManager;
+    resourceManager.getResourceScheduler().getNodeReport(this.nodeId);
-        schedulerNode.getAvailableResource().getMemory());
+        resourceManager.getResourceScheduler().getNodeReport(
+            this.nodeId).getAvailableResource().getMemory());
-        schedulerNode.getUsedResource().getMemory());
+        resourceManager.getResourceScheduler().getNodeReport(
+            this.nodeId).getUsedResource().getMemory());
-
-      List<Container> applicationContainers = containers.get(applicationId);
+      List<Container> applicationContainers = containers.get(containerID.getApplicationAttemptId()
+              .getApplicationId());
