HDDS-675. Add blocking buffer and use watchApi for flush/close in OzoneClient. Contributed by Shashikant Banerjee.

-
-
+import org.apache.hadoop.hdds.scm.XceiverClientAsyncReply;
+import org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
-
+import java.util.List;
+import java.util.ArrayList;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
-    .putBlock;
+    .putBlockAsync;
-    .writeChunk;
+    .writeChunkAsync;
+  public static final Logger LOG =
+      LoggerFactory.getLogger(ChunkOutputStream.class);
-  private ByteBuffer buffer;
+  private final long streamBufferFlushSize;
+  private final long streamBufferMaxSize;
+  private final long watchTimeout;
+  private ByteBuffer buffer;
+  // The IOException will be set by response handling thread in case there is an
+  // exception received in the response. If the exception is set, the next
+  // request will fail upfront.
+  private IOException ioException;
+  private ExecutorService responseExecutor;
+
+  // position of the buffer where the last flush was attempted
+  private int lastFlushPos;
+
+  // position of the buffer till which the flush was successfully
+  // acknowledged by all nodes in pipeline
+  private int lastSuccessfulFlushIndex;
+
+  // list to hold up all putBlock futures
+  private List<CompletableFuture<ContainerProtos.ContainerCommandResponseProto>>
+      futureList;
+  // list maintaining commit indexes for putBlocks
+  private List<Long> commitIndexList;
-   * @param blockID block ID
-   * @param key chunk key
+   * @param blockID              block ID
+   * @param key                  chunk key
-   * @param xceiverClient client to perform container calls
-   * @param traceID container protocol call args
-   * @param chunkSize chunk size
+   * @param xceiverClient        client to perform container calls
+   * @param traceID              container protocol call args
+   * @param chunkSize            chunk size
-       XceiverClientManager xceiverClientManager,
-       XceiverClientSpi xceiverClient, String traceID, int chunkSize) {
+      XceiverClientManager xceiverClientManager, XceiverClientSpi xceiverClient,
+      String traceID, int chunkSize, long streamBufferFlushSize,
+      long streamBufferMaxSize, long watchTimeout, ByteBuffer buffer) {
-    KeyValue keyValue = KeyValue.newBuilder()
-        .setKey("TYPE").setValue("KEY").build();
-    this.containerBlockData = BlockData.newBuilder()
-        .setBlockID(blockID.getDatanodeBlockIDProtobuf())
-        .addMetadata(keyValue);
+    KeyValue keyValue =
+        KeyValue.newBuilder().setKey("TYPE").setValue("KEY").build();
+    this.containerBlockData =
+        BlockData.newBuilder().setBlockID(blockID.getDatanodeBlockIDProtobuf())
+            .addMetadata(keyValue);
-    this.buffer = ByteBuffer.allocate(chunkSize);
-  }
+    this.streamBufferFlushSize = streamBufferFlushSize;
+    this.streamBufferMaxSize = streamBufferMaxSize;
+    this.watchTimeout = watchTimeout;
+    this.buffer = buffer;
+    this.ioException = null;
-  public ByteBuffer getBuffer() {
-    return buffer;
+    // A single thread executor handle the responses of async requests
+    responseExecutor = Executors.newSingleThreadExecutor();
+    commitIndexList = new ArrayList<>();
+    lastSuccessfulFlushIndex = 0;
+    futureList = new ArrayList<>();
+    lastFlushPos = 0;
+  public int getLastSuccessfulFlushIndex() {
+    return lastSuccessfulFlushIndex;
+  }
+
+
-    int rollbackPosition = buffer.position();
-    int rollbackLimit = buffer.limit();
-    buffer.put((byte)b);
-    if (buffer.position() == chunkSize) {
-      flushBufferToChunk(rollbackPosition, rollbackLimit);
-    }
+    byte[] buf = new byte[1];
+    buf[0] = (byte) b;
+    write(buf, 0, 1);
-  public void write(byte[] b, int off, int len)
-      throws IOException {
+  public void write(byte[] b, int off, int len) throws IOException {
-    if ((off < 0) || (off > b.length) || (len < 0) ||
-        ((off + len) > b.length) || ((off + len) < 0)) {
+    if ((off < 0) || (off > b.length) || (len < 0) || ((off + len) > b.length)
+        || ((off + len) < 0)) {
-      int writeLen = Math.min(chunkSize - buffer.position(), len);
-      int rollbackPosition = buffer.position();
-      int rollbackLimit = buffer.limit();
+      int writeLen;
+      writeLen = Math.min(chunkSize - buffer.position() % chunkSize, len);
-      if (buffer.position() == chunkSize) {
-        flushBufferToChunk(rollbackPosition, rollbackLimit);
+      if (buffer.position() % chunkSize == 0) {
+        int pos = buffer.position() - chunkSize;
+        int limit = buffer.position();
+        writeChunk(pos, limit);
+      if (buffer.position() >= streamBufferFlushSize
+          && buffer.position() % streamBufferFlushSize == 0) {
+
+        lastFlushPos = buffer.position();
+        futureList.add(handlePartialFlush());
+      }
+      if (buffer.position() >= streamBufferMaxSize
+          && buffer.position() % streamBufferMaxSize == 0) {
+        handleFullBuffer();
+      }
+    }
+  }
+
+  /**
+   * Will be called on the retryPath in case closedContainerException/
+   * TimeoutException.
+   * @param len length of data to write
+   * @throws IOException if error occured
+   */
+
+  // In this case, the data is already cached in the buffer.
+  public void writeOnRetry(int len) throws IOException {
+    if (len == 0) {
+      return;
+    }
+    int off = 0;
+    checkOpen();
+    while (len > 0) {
+      int writeLen;
+      writeLen = Math.min(chunkSize, len);
+      if (writeLen == chunkSize) {
+        int pos = off;
+        int limit = pos + chunkSize;
+        writeChunk(pos, limit);
+      }
+      off += writeLen;
+      len -= writeLen;
+      if (off % streamBufferFlushSize == 0) {
+        lastFlushPos = off;
+        futureList.add(handlePartialFlush());
+      }
+      if (off % streamBufferMaxSize == 0) {
+        handleFullBuffer();
+      }
+    }
+  }
+
+  private void handleResponse(
+      ContainerProtos.ContainerCommandResponseProto response,
+      XceiverClientAsyncReply asyncReply) {
+    validateResponse(response);
+    discardBuffer(asyncReply);
+  }
+
+  private void discardBuffer(XceiverClientAsyncReply asyncReply) {
+    if (!commitIndexList.isEmpty()) {
+      long index = commitIndexList.get(0);
+      if (checkIfBufferDiscardRequired(asyncReply, index)) {
+        updateFlushIndex();
+      }
+    }
+  }
+
+  /**
+   * just update the lastSuccessfulFlushIndex. Since we have allocated
+   * the buffer more than the streamBufferMaxSize, we can keep on writing
+   * to the buffer. In case of failure, we will read the data starting from
+   * lastSuccessfulFlushIndex.
+   */
+  private void updateFlushIndex() {
+    lastSuccessfulFlushIndex += streamBufferFlushSize;
+    LOG.debug("Discarding buffer till pos " + lastSuccessfulFlushIndex);
+    if (!commitIndexList.isEmpty()) {
+      commitIndexList.remove(0);
+      futureList.remove(0);
+    }
+
+  }
+  /**
+   * Check if the last commitIndex stored at the beginning of the
+   * commitIndexList is less than equal to current commitInfo indexes.
+   * If its true, the buffer has been successfully flushed till the
+   * last position where flush happened.
+   */
+  private boolean checkIfBufferDiscardRequired(
+      XceiverClientAsyncReply asyncReply, long commitIndex) {
+    if (asyncReply.getCommitInfos() != null) {
+      for (XceiverClientAsyncReply.CommitInfo info : asyncReply
+          .getCommitInfos()) {
+        if (info.getCommitIndex() < commitIndex) {
+          return false;
+        }
+      }
+    }
+    return true;
+  }
+
+  /**
+   * This is a blocking call.It will wait for the flush till the commit index
+   * at the head of the commitIndexList gets replicated to all or majority.
+   * @throws IOException
+   */
+  private void handleFullBuffer() throws IOException {
+    if (!commitIndexList.isEmpty()) {
+      watchForCommit(commitIndexList.get(0));
+    }
+  }
+
+  /**
+   * calls watchForCommit API of the Ratis Client. For Standalone client,
+   * it is a no op.
+   * @param commitIndex log index to watch for
+   * @throws IOException IOException in case watch gets timed out
+   */
+  private void watchForCommit(long commitIndex) throws IOException {
+    checkOpen();
+    Preconditions.checkState(!commitIndexList.isEmpty());
+    try {
+      xceiverClient.watchForCommit(commitIndex, watchTimeout);
+    } catch (TimeoutException | InterruptedException | ExecutionException e) {
+      LOG.warn("watchForCommit failed for index " + commitIndex, e);
+      throw new IOException(
+          "Unexpected Storage Container Exception: " + e.toString(), e);
+    }
+  }
+
+  private CompletableFuture<ContainerProtos.
+      ContainerCommandResponseProto> handlePartialFlush()
+      throws IOException {
+    String requestId =
+        traceID + ContainerProtos.Type.PutBlock + chunkIndex + blockID;
+    try {
+      XceiverClientAsyncReply asyncReply =
+          putBlockAsync(xceiverClient, containerBlockData.build(), requestId);
+      CompletableFuture<ContainerProtos.ContainerCommandResponseProto> future =
+          asyncReply.getResponse();
+
+      return future.thenApplyAsync(e -> {
+        handleResponse(e, asyncReply);
+        // if the ioException is not set, putBlock is successful
+        if (ioException == null) {
+          LOG.debug(
+              "Adding index " + asyncReply.getLogIndex() + " commitList size "
+                  + commitIndexList.size());
+          BlockID responseBlockID = BlockID.getFromProtobuf(
+              e.getPutBlock().getCommittedBlockLength().getBlockID());
+          Preconditions.checkState(blockID.getContainerBlockID()
+              .equals(responseBlockID.getContainerBlockID()));
+          // updates the bcsId of the block
+          blockID = responseBlockID;
+          long index = asyncReply.getLogIndex();
+          // for standalone protocol, logIndex will always be 0.
+          if (index != 0) {
+            commitIndexList.add(index);
+          } else {
+            updateFlushIndex();
+          }
+        }
+        return e;
+      }, responseExecutor);
+    } catch (IOException | InterruptedException | ExecutionException e) {
+      throw new IOException(
+          "Unexpected Storage Container Exception: " + e.toString(), e);
-    checkOpen();
-    if (buffer.position() > 0) {
-      int rollbackPosition = buffer.position();
-      int rollbackLimit = buffer.limit();
-      flushBufferToChunk(rollbackPosition, rollbackLimit);
+    if (xceiverClientManager != null && xceiverClient != null
+        && buffer != null) {
+      checkOpen();
+      if (buffer.position() > 0 && lastSuccessfulFlushIndex != buffer
+          .position()) {
+        try {
+
+          // flush the last chunk data residing on the buffer
+          if (buffer.position() % chunkSize > 0) {
+            int pos = buffer.position() - (buffer.position() % chunkSize);
+            writeChunk(pos, buffer.position());
+          }
+          if (lastFlushPos != buffer.position()) {
+            lastFlushPos = buffer.position();
+            handlePartialFlush();
+          }
+          CompletableFuture<Void> combinedFuture = CompletableFuture.allOf(
+              futureList.toArray(new CompletableFuture[futureList.size()]));
+          combinedFuture.get();
+          // just check again if the exception is hit while waiting for the
+          // futures to ensure flush has indeed succeeded
+          checkOpen();
+        } catch (InterruptedException | ExecutionException e) {
+          throw new IOException(
+              "Unexpected Storage Container Exception: " + e.toString(), e);
+        }
+      }
+  private void writeChunk(int pos, int limit) throws IOException {
+    // Please note : We are not flipping the slice when we write since
+    // the slices are pointing the buffer start and end as needed for
+    // the chunk write. Also please note, Duplicate does not create a
+    // copy of data, it only creates metadata that points to the data
+    // stream.
+    ByteBuffer chunk = buffer.duplicate();
+    chunk.position(pos);
+    chunk.limit(limit);
+    writeChunkToContainer(chunk);
+  }
+
-      if (buffer.position() > 0) {
-        writeChunkToContainer();
-      }
-        ContainerProtos.PutBlockResponseProto responseProto =
-            putBlock(xceiverClient, containerBlockData.build(), traceID);
-        BlockID responseBlockID = BlockID.getFromProtobuf(
-            responseProto.getCommittedBlockLength().getBlockID());
-        Preconditions.checkState(blockID.getContainerBlockID()
-            .equals(responseBlockID.getContainerBlockID()));
-        // updates the bcsId of the block
-        blockID = responseBlockID;
-      } catch (IOException e) {
+        if (buffer.position() > lastFlushPos) {
+          int pos = buffer.position() - (buffer.position() % chunkSize);
+          writeChunk(pos, buffer.position());
+          futureList.add(handlePartialFlush());
+        }
+        CompletableFuture<Void> combinedFuture = CompletableFuture.allOf(
+            futureList.toArray(new CompletableFuture[futureList.size()]));
+
+        // wait for all the transactions to complete
+        combinedFuture.get();
+
+        // irrespective of whether the commitIndexList is empty or not,
+        // ensure there is no exception set(For Standalone Protocol)
+        checkOpen();
+        if (!commitIndexList.isEmpty()) {
+          // wait for the last commit index in the commitIndexList to get
+          // committed to all or majority of nodes in case timeout happens.
+          long lastIndex = commitIndexList.get(commitIndexList.size() - 1);
+          LOG.debug(
+              "waiting for last flush Index " + lastIndex + " to catch up");
+          watchForCommit(lastIndex);
+          updateFlushIndex();
+        }
+      } catch (InterruptedException | ExecutionException e) {
+    // clear the buffer
+    buffer.clear();
+  }
+
+  private void validateResponse(
+      ContainerProtos.ContainerCommandResponseProto responseProto) {
+    try {
+      ContainerProtocolCalls.validateContainerResponse(responseProto);
+    } catch (StorageContainerException sce) {
+      ioException = new IOException(
+          "Unexpected Storage Container Exception: " + sce.toString(), sce);
+    }
-    xceiverClientManager.releaseClient(xceiverClient);
+    if (xceiverClientManager != null) {
+      xceiverClientManager.releaseClient(xceiverClient);
+    }
-    buffer = null;
+    if (futureList != null) {
+      futureList.clear();
+    }
+    futureList = null;
+    commitIndexList = null;
+    responseExecutor.shutdown();
-   * Checks if the stream is open.  If not, throws an exception.
+   * Checks if the stream is open or exception has occured.
+   * If not, throws an exception.
-    }
-  }
-
-  /**
-   * Attempts to flush buffered writes by writing a new chunk to the container.
-   * If successful, then clears the buffer to prepare to receive writes for a
-   * new chunk.
-   *
-   * @param rollbackPosition position to restore in buffer if write fails
-   * @param rollbackLimit limit to restore in buffer if write fails
-   * @throws IOException if there is an I/O error while performing the call
-   */
-  private void flushBufferToChunk(int rollbackPosition,
-      int rollbackLimit) throws IOException {
-    boolean success = false;
-    try {
-      writeChunkToContainer();
-      success = true;
-    } finally {
-      if (success) {
-        buffer.clear();
-      } else {
-        buffer.position(rollbackPosition);
-        buffer.limit(rollbackLimit);
-      }
+    } else if (ioException != null) {
+      throw ioException;
-  private void writeChunkToContainer() throws IOException {
-    buffer.flip();
-    ByteString data = ByteString.copyFrom(buffer);
-    ChunkInfo chunk = ChunkInfo
-        .newBuilder()
-        .setChunkName(
-            DigestUtils.md5Hex(key) + "_stream_"
-                + streamId + "_chunk_" + ++chunkIndex)
-        .setOffset(0)
-        .setLen(data.size())
-        .build();
+  private void writeChunkToContainer(ByteBuffer chunk) throws IOException {
+    int effectiveChunkSize = chunk.remaining();
+    ByteString data = ByteString.copyFrom(chunk);
+    ChunkInfo chunkInfo = ChunkInfo.newBuilder().setChunkName(
+        DigestUtils.md5Hex(key) + "_stream_" + streamId + "_chunk_"
+            + ++chunkIndex).setOffset(0).setLen(effectiveChunkSize).build();
+    // generate a unique requestId
+    String requestId =
+        traceID + ContainerProtos.Type.WriteChunk + chunkIndex + chunkInfo
+            .getChunkName();
-      writeChunk(xceiverClient, chunk, blockID, data, traceID);
-    } catch (IOException e) {
+      XceiverClientAsyncReply asyncReply =
+          writeChunkAsync(xceiverClient, chunkInfo, blockID, data, requestId);
+      CompletableFuture<ContainerProtos.ContainerCommandResponseProto> future =
+          asyncReply.getResponse();
+      future.thenApplyAsync(e -> {
+        handleResponse(e, asyncReply);
+        return e;
+      }, responseExecutor);
+    } catch (IOException | InterruptedException | ExecutionException e) {
-    containerBlockData.addChunks(chunk);
+    LOG.debug(
+        "writing chunk " + chunkInfo.getChunkName() + " blockID " + blockID
+            + " length " + chunk.remaining());
+    containerBlockData.addChunks(chunkInfo);
