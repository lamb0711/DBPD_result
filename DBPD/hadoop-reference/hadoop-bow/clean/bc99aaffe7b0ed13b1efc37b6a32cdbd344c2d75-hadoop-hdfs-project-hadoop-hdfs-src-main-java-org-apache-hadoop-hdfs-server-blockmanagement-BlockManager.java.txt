Revert "HDFS-8652. Track BlockInfo instead of Block in CorruptReplicasMap. Contributed by Jing Zhao."

This reverts commit d62b63d297bff12d93de560dd50ddd48743b851d.

+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_HA_NAMENODES_KEY_PREFIX;
-  private final Set<BlockInfo> postponedMisreplicatedBlocks = Sets.newHashSet();
+  private final Set<Block> postponedMisreplicatedBlocks = Sets.newHashSet();
-        conf.get(DFSConfigKeys.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY) != null;
+        conf.get(DFSConfigKeys.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY) == null
+            ? false : true;
-    return isBlockTokenEnabled() && blockTokenSecretManager.updateKeys(updateTime);
+    return isBlockTokenEnabled()? blockTokenSecretManager.updateKeys(updateTime)
+        : false;
-      for (BlockInfo block : neededReplications) {
+      for (Block block : neededReplications) {
-    for (BlockInfo block : postponedMisreplicatedBlocks) {
+    for (Block block : postponedMisreplicatedBlocks) {
-  private void dumpBlockMeta(BlockInfo block, PrintWriter out) {
-    List<DatanodeDescriptor> containingNodes = new ArrayList<>();
-    List<DatanodeStorageInfo> containingLiveReplicasNodes = new ArrayList<>();
+  private void dumpBlockMeta(Block block, PrintWriter out) {
+    List<DatanodeDescriptor> containingNodes =
+                                      new ArrayList<DatanodeDescriptor>();
+    List<DatanodeStorageInfo> containingLiveReplicasNodes =
+      new ArrayList<>();
-    // containingLiveReplicasNodes can include READ_ONLY_SHARED replicas which
-    // are not included in the numReplicas.liveReplicas() count
+    // containingLiveReplicasNodes can include READ_ONLY_SHARED replicas which are 
+    // not included in the numReplicas.liveReplicas() count
-
-    BlockCollection bc = block.getBlockCollection();
-    String fileName = (bc == null) ? "[orphaned]" : bc.getName();
-    out.print(fileName + ": ");
-
+    
+    if (block instanceof BlockInfo) {
+      BlockCollection bc = ((BlockInfo) block).getBlockCollection();
+      String fileName = (bc == null) ? "[orphaned]" : bc.getName();
+      out.print(fileName + ": ");
+    }
-    Collection<DatanodeDescriptor> corruptNodes =
-        corruptReplicas.getNodes(block);
+    Collection<DatanodeDescriptor> corruptNodes = 
+                                  corruptReplicas.getNodes(block);
-    long curPos = 0;
-    long blkSize;
+    long curPos = 0, blkSize = 0;
-   * Mark a replica (of a contiguous block) or an internal block (of a striped
-   * block group) as corrupt.
-   * @param b Indicating the reported bad block and the corresponding BlockInfo
-   *          stored in blocksMap.
+   * 
+   * @param b
+   * @throws IOException
-    corruptReplicas.addToCorruptReplicasMap(b.stored, node, b.reason,
+    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,
-      invalidateBlock(b, node, numberOfReplicas);
+      invalidateBlock(b, node);
-   * Invalidates the given block on the given datanode. Note that before this
-   * call we have already checked the current live replicas of the block and
-   * make sure it's safe to invalidate the replica.
-   *
-   * @return true if the replica was successfully invalidated and no longer
-   *         associated with the DataNode.
+   * Invalidates the given block on the given datanode.
+   * @return true if the block was successfully invalidated and no longer
+   * present in the BlocksMap
-  private boolean invalidateBlock(BlockToMarkCorrupt b, DatanodeInfo dn,
-      NumberReplicas nr) throws IOException {
+  private boolean invalidateBlock(BlockToMarkCorrupt b, DatanodeInfo dn
+      ) throws IOException {
+    NumberReplicas nr = countNodes(b.stored);
-      postponeBlock(b.stored);
+      postponeBlock(b.corrupted);
-    } else {
-      // we already checked the number of replicas in the caller of this
-      // function and we know there is at least one copy on a live node, so we
-      // can delete it.
+    } else if (nr.liveReplicas() >= 1) {
+      // If we have at least one copy on a live node, then we can delete it.
+    } else {
+      blockLog.info("BLOCK* invalidateBlocks: {} on {} is the only copy and" +
+          " was not deleted", b, dn);
+      return false;
+
-  private void postponeBlock(BlockInfo blk) {
+
+  private void postponeBlock(Block blk) {
-    BlockCollection bc;
+    BlockCollection bc = null;
-          for (DatanodeStorageInfo target : targets) {
+          for (int k = 0; k < targets.length; k++) {
-            targetList.append(target.getDatanodeDescriptor());
+            targetList.append(targets[k].getDatanodeDescriptor());
-      for (String nodeStr : nodes) {
-        DatanodeDescriptor node = datanodeManager.getDatanodeDescriptor(nodeStr);
+      for (int i = 0; i < nodes.size(); i++) {
+        DatanodeDescriptor node = datanodeManager.getDatanodeDescriptor(nodes.get(i));
-   DatanodeDescriptor chooseSourceDatanode(BlockInfo block,
+   DatanodeDescriptor chooseSourceDatanode(Block block,
-        for (BlockInfo timedOutItem : timedOutItems) {
+        for (int i = 0; i < timedOutItems.length; i++) {
-          BlockInfo bi = getStoredBlock(timedOutItem);
+          BlockInfo bi = getStoredBlock(timedOutItems[i]);
-          NumberReplicas num = countNodes(timedOutItem);
+          NumberReplicas num = countNodes(timedOutItems[i]);
-    DatanodeDescriptor node;
+    DatanodeDescriptor node = null;
-      Iterator<BlockInfo> it = postponedMisreplicatedBlocks.iterator();
+      Iterator<Block> it = postponedMisreplicatedBlocks.iterator();
-    BlockToMarkCorrupt b;
+    BlockToMarkCorrupt b = null;
-      invalidateCorruptReplicas(storedBlock, reportedBlock, num);
+      invalidateCorruptReplicas(storedBlock, reportedBlock);
-  private void invalidateCorruptReplicas(BlockInfo blk, Block reported,
-      NumberReplicas numberReplicas) {
+  private void invalidateCorruptReplicas(BlockInfo blk, Block reported) {
-    DatanodeDescriptor[] nodesCopy = nodes.toArray(
-        new DatanodeDescriptor[nodes.size()]);
+    DatanodeDescriptor[] nodesCopy = nodes.toArray(new DatanodeDescriptor[0]);
-            Reason.ANY), node, numberReplicas)) {
+            Reason.ANY), node)) {
+        return;
-        boolean removed = node.getPendingCached().remove(cblock);
+        boolean removed = false;
+        removed |= node.getPendingCached().remove(cblock);
-    for (DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {
+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {
-    return new NumberReplicas(live, decommissioned, decommissioning, corrupt,
-        excess, stale);
+    return new NumberReplicas(live, decommissioned, decommissioning, corrupt, excess, stale);
+        final BlockInfoUnderConstruction uc =
+            (BlockInfoUnderConstruction)b;
-  public void removeBlockFromMap(BlockInfo block) {
+  public int numCorruptReplicas(Block block) {
+    return corruptReplicas.numCorruptReplicas(block);
+  }
+
+  public void removeBlockFromMap(Block block) {
-  private void removeFromExcessReplicateMap(BlockInfo block) {
+  private void removeFromExcessReplicateMap(Block block) {
-  public Collection<DatanodeDescriptor> getCorruptReplicas(BlockInfo block) {
+  public Collection<DatanodeDescriptor> getCorruptReplicas(Block block) {
- public String getCorruptReason(BlockInfo block, DatanodeDescriptor node) {
+ public String getCorruptReason(Block block, DatanodeDescriptor node) {
-  }
+  };
