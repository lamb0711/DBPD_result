HADOOP-15320. Remove customized getFileBlockLocations for hadoop-azure and hadoop-azure-datalake. Contributed by Shanyu Zhao

-import org.apache.hadoop.fs.BlockLocation;
-  static final String AZURE_BLOCK_LOCATION_HOST_PROPERTY_NAME =
-      "fs.azure.block.location.impersonatedhost";
-  private static final String AZURE_BLOCK_LOCATION_HOST_DEFAULT =
-      "localhost";
-   * Return an array containing hostnames, offset and size of
-   * portions of the given file. For WASB we'll just lie and give
-   * fake hosts to make sure we get many splits in MR jobs.
-   */
-  @Override
-  public BlockLocation[] getFileBlockLocations(FileStatus file,
-      long start, long len) throws IOException {
-    if (file == null) {
-      return null;
-    }
-
-    if ((start < 0) || (len < 0)) {
-      throw new IllegalArgumentException("Invalid start or len parameter");
-    }
-
-    if (file.getLen() < start) {
-      return new BlockLocation[0];
-    }
-    final String blobLocationHost = getConf().get(
-        AZURE_BLOCK_LOCATION_HOST_PROPERTY_NAME,
-        AZURE_BLOCK_LOCATION_HOST_DEFAULT);
-    final String[] name = { blobLocationHost };
-    final String[] host = { blobLocationHost };
-    long blockSize = file.getBlockSize();
-    if (blockSize <= 0) {
-      throw new IllegalArgumentException(
-          "The block size for the given file is not a positive number: "
-              + blockSize);
-    }
-    int numberOfLocations = (int) (len / blockSize)
-        + ((len % blockSize == 0) ? 0 : 1);
-    BlockLocation[] locations = new BlockLocation[numberOfLocations];
-    for (int i = 0; i < locations.length; i++) {
-      long currentOffset = start + (i * blockSize);
-      long currentLength = Math.min(blockSize, start + len - currentOffset);
-      locations[i] = new BlockLocation(name, host, currentOffset, currentLength);
-    }
-    return locations;
-  }
-
-  /**
