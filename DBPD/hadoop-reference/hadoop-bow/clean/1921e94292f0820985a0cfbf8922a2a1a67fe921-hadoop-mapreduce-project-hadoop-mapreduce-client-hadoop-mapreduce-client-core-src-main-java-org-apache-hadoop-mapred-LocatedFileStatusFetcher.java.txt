HADOOP-16458. LocatedFileStatusFetcher.getFileStatuses failing intermittently with S3

Contributed by Steve Loughran.

Includes
-S3A glob scans don't bother trying to resolve symlinks
-stack traces don't get lost in getFileStatuses() when exceptions are wrapped
-debug level logging of what is up in Globber
-Contains HADOOP-13373. Add S3A implementation of FSMainOperationsBaseTest.
-ITestRestrictedReadAccess tests incomplete read access to files.

This adds a builder API for constructing globbers which other stores can use
so that they too can skip symlink resolution when not needed.

Change-Id: I23bcdb2783d6bd77cf168fdc165b1b4b334d91c7

+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+ * The thread count is determined from the value of
+ * "mapreduce.input.fileinputformat.list-status.num-threads" in the
+ * configuration.
+  public static final Logger LOG =
+      LoggerFactory.getLogger(LocatedFileStatusFetcher.class.getName());
-  private final List<IOException> invalidInputErrors = new LinkedList<IOException>();
+  private final List<IOException> invalidInputErrors = new LinkedList<>();
+   * Instantiate.
+   * The newApi switch is only used to configure what exception is raised
+   * on failure of {@link #getFileStatuses()}, it does not change the algorithm.
-   * @param recursive whether to traverse the patchs recursively
+   * @param recursive whether to traverse the paths recursively
-      boolean recursive, PathFilter inputFilter, boolean newApi) throws InterruptedException,
-      IOException {
+      boolean recursive, PathFilter inputFilter, boolean newApi)
+      throws InterruptedException, IOException {
+    LOG.debug("Instantiated LocatedFileStatusFetcher with {} threads",
+        numThreads);
-    resultQueue = new LinkedBlockingQueue<List<FileStatus>>();
+    resultQueue = new LinkedBlockingQueue<>();
-   * Start executing and return FileStatuses based on the parameters specified
+   * Start executing and return FileStatuses based on the parameters specified.
-   * @throws InterruptedException
-   * @throws IOException
+   * @throws InterruptedException interruption waiting for results.
+   * @throws IOException IO failure or other error.
+   * @throws InvalidInputException on an invalid input and the old API
+   * @throws org.apache.hadoop.mapreduce.lib.input.InvalidInputException on an
+   *         invalid input and the new API.
+      LOG.debug("Queuing scan of directory {}", p);
+      LOG.debug("Waiting scan completion");
+    // either the scan completed or an error was raised.
+    // in the case of an error shutting down the executor will interrupt all
+    // active threads, which can add noise to the logs.
+    LOG.debug("Scan complete: shutting down");
+      LOG.debug("Scan failed", this.unknownError);
-    if (this.invalidInputErrors.size() != 0) {
+    if (!this.invalidInputErrors.isEmpty()) {
+      LOG.debug("Invalid Input Errors raised");
+      for (IOException error : invalidInputErrors) {
+        LOG.debug("Error", error);
+      }
-   * are reported immediately
+   * are reported immediately.
-   * full exection queue
+   * full execution queue.
+    LOG.debug("Error", t);
-
+      LOG.debug("ProcessInputDirCallable {}", fileStatus);
-      private List<FileStatus> locatedFileStatuses = new LinkedList<FileStatus>();
-      private List<FileStatus> dirsNeedingRecursiveCalls = new LinkedList<FileStatus>();
+      private List<FileStatus> locatedFileStatuses = new LinkedList<>();
+      private List<FileStatus> dirsNeedingRecursiveCalls = new LinkedList<>();
-        if (result.locatedFileStatuses.size() != 0) {
+        if (!result.locatedFileStatuses.isEmpty()) {
-        if (result.dirsNeedingRecursiveCalls.size() != 0) {
+        if (!result.dirsNeedingRecursiveCalls.isEmpty()) {
+            LOG.debug("Queueing directory scan {}", fileStatus.getPath());
-  
+
+      LOG.debug("ProcessInitialInputPathCallable path {}", path);
-   * {@link ProcessInitialInputPathCallable}
+   * {@link ProcessInitialInputPathCallable}.
