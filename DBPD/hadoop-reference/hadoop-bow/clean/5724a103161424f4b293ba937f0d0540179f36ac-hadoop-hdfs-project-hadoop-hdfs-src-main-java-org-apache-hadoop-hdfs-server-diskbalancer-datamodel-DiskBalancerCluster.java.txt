HDFS-9469. DiskBalancer: Add Planner. (Contributed by Anu Engineer)

+import org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan;
+import org.apache.hadoop.hdfs.server.diskbalancer.planner.Planner;
+import org.apache.hadoop.hdfs.server.diskbalancer.planner.PlannerFactory;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
-        (thresholdPercent <= 100.0f),  "A percentage value expected.");
+        (thresholdPercent <= 100.0f), "A percentage value expected.");
+
+  /**
+   * Creates an Output directory for the cluster output.
+   *
+   * @throws IOException - On failure to create an new directory
+   */
+  public void createOutPutDirectory() throws IOException {
+    if (Files.exists(Paths.get(this.getOutput()))) {
+      LOG.fatal("An output directory already exists at this location. Path : " +
+          this.getOutput());
+      throw new IOException(
+          "An output directory already exists at this location. Path : " +
+              this.getOutput());
+    }
+
+    File f = new File(this.getOutput());
+    if (!f.mkdirs()) {
+      LOG.fatal("Unable to create the output directory. Path : " + this
+          .getOutput());
+      throw new IOException(
+          "Unable to create the output directory. Path : " + this.getOutput());
+    }
+    LOG.info("Output directory created. Path : " + this.getOutput());
+  }
+
+  /**
+   * Compute plan takes a node and constructs a planner that creates a plan that
+   * we would like to follow.
+   * <p/>
+   * This function creates a thread pool and executes a planner on each node
+   * that we are supposed to plan for. Each of these planners return a NodePlan
+   * that we can persist or schedule for execution with a diskBalancer
+   * Executor.
+   *
+   * @param thresholdPercent - in percentage
+   * @return list of NodePlans
+   */
+  public List<NodePlan> computePlan(float thresholdPercent) {
+    List<NodePlan> planList = new LinkedList<>();
+
+    if (nodesToProcess == null) {
+      LOG.warn("Nodes to process is null. No nodes processed.");
+      return planList;
+    }
+
+    int poolSize = computePoolSize(nodesToProcess.size());
+
+    ExecutorService executorService = Executors.newFixedThreadPool(poolSize);
+    List<Future<NodePlan>> futureList = new LinkedList<>();
+    for (int x = 0; x < nodesToProcess.size(); x++) {
+      final DiskBalancerDataNode node = nodesToProcess.get(x);
+      final Planner planner = PlannerFactory
+          .getPlanner(PlannerFactory.GREEDY_PLANNER, node,
+              thresholdPercent);
+      futureList.add(executorService.submit(new Callable<NodePlan>() {
+        @Override
+        public NodePlan call() throws Exception {
+          assert planner != null;
+          return planner.plan(node);
+        }
+      }));
+    }
+
+    for (Future<NodePlan> f : futureList) {
+      try {
+        planList.add(f.get());
+      } catch (InterruptedException e) {
+        LOG.error("Compute Node plan was cancelled or interrupted : ", e);
+      } catch (ExecutionException e) {
+        LOG.error("Unable to compute plan : ", e);
+      }
+    }
+    return planList;
+  }
+
+  /**
+   * Return the number of threads we should launch for this cluster.
+   * <p/>
+   * Here is the heuristic we are using.
+   * <p/>
+   * 1 thread per 100 nodes that we want to process. Minimum nodesToProcess
+   * threads in the pool. Maximum 100 threads in the pool.
+   * <p/>
+   * Generally return a rounded up multiple of 10.
+   *
+   * @return number
+   */
+  private int computePoolSize(int nodeCount) {
+
+    if (nodeCount < 10) {
+      return nodeCount;
+    }
+
+    int threadRatio = nodeCount / 100;
+    int modValue = threadRatio % 10;
+
+    if (((10 - modValue) + threadRatio) > 100) {
+      return 100;
+    } else {
+      return (10 - modValue) + threadRatio;
+    }
+  }
