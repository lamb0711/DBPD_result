HDFS-2140. Move Host2NodesMap to the blockmanagement package.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1146514 13f79535-47bb-0310-9956-ffa450edef68

+import java.io.IOException;
+
+import org.apache.hadoop.hdfs.protocol.DatanodeID;
+
+  private final Host2NodesMap host2DatanodeMap = new Host2NodesMap();
+
+  /** @return the datanode descriptor for the host. */
+  public DatanodeDescriptor getDatanodeByHost(final String host) {
+    return host2DatanodeMap.getDatanodeByHost(host);
+  }
+
+  /** Add a datanode. */
+  public void addDatanode(final DatanodeDescriptor node) {
+    // To keep host2DatanodeMap consistent with datanodeMap,
+    // remove  from host2DatanodeMap the datanodeDescriptor removed
+    // from datanodeMap before adding node to host2DatanodeMap.
+    synchronized (namesystem.datanodeMap) {
+      host2DatanodeMap.remove(
+          namesystem.datanodeMap.put(node.getStorageID(), node));
+    }
+    host2DatanodeMap.add(node);
+
+    if (LOG.isDebugEnabled()) {
+      LOG.debug(getClass().getSimpleName() + ".unprotectedAddDatanode: "
+          + "node " + node.getName() + " is added to datanodeMap.");
+    }
+  }
+
+  /** Physically remove node from datanodeMap. */
+  public void wipeDatanode(final DatanodeID node) throws IOException {
+    final String key = node.getStorageID();
+    synchronized (namesystem.datanodeMap) {
+      host2DatanodeMap.remove(namesystem.datanodeMap.remove(key));
+    }
+    if (LOG.isDebugEnabled()) {
+      LOG.debug(getClass().getSimpleName() + ".wipeDatanode("
+          + node.getName() + "): storage " + key 
+          + " is removed from datanodeMap.");
+    }
+  }
