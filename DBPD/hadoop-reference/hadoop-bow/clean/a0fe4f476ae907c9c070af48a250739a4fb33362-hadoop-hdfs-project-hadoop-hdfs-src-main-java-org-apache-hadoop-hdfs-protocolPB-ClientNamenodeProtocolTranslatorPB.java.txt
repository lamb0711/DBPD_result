Merge trunk into HA branch.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1213867 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DistributedUpgradeProgressResponseProto;
+import org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsResponseProto;
+import org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoResponseProto;
-      return PBHelper.convert(rpcProxy.getBlockLocations(null, req).getLocations());
+      GetBlockLocationsResponseProto resp = rpcProxy.getBlockLocations(null,
+          req);
+      return resp.hasLocations() ? 
+        PBHelper.convert(resp.getLocations()) : null;
-    AddBlockRequestProto req = AddBlockRequestProto.newBuilder().setSrc(src)
-        .setClientName(clientName).setPrevious(PBHelper.convert(previous))
-        .addAllExcludeNodes(Arrays.asList(PBHelper.convert(excludeNodes)))
-        .build();
+    AddBlockRequestProto.Builder builder = AddBlockRequestProto.newBuilder();
+    builder.setSrc(src)
+        .setClientName(clientName)
+        .addAllExcludeNodes(Arrays.asList(PBHelper.convert(excludeNodes)));
+    if (previous != null) {
+      builder.setPrevious(PBHelper.convert(previous));
+    }
-      return PBHelper.convert(rpcProxy.addBlock(null, req).getBlock());
+      return PBHelper.convert(rpcProxy.addBlock(null, builder.build()).getBlock());
-      return PBHelper.convert(
-          rpcProxy.distributedUpgradeProgress(null, req).getReport());
+      DistributedUpgradeProgressResponseProto res = rpcProxy
+          .distributedUpgradeProgress(null, req);
+      return res.hasReport() ? PBHelper.convert(res.getReport()) : null;
-      return PBHelper.convert(rpcProxy.getFileInfo(null, req).getFs());
+      GetFileInfoResponseProto res = rpcProxy.getFileInfo(null, req);
+      return res.hasFs() ? PBHelper.convert(res.getFs()) : null;
