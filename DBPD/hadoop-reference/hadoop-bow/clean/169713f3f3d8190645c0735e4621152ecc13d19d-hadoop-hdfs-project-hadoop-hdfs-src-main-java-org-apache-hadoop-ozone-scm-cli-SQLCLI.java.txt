HDFS-11788. Ozone : add DEBUG CLI support for nodepool db file. Contributed by Chen Liang

+import org.apache.hadoop.hdfs.DFSUtil;
+import org.apache.hadoop.hdfs.protocol.DatanodeID;
+import static org.apache.hadoop.ozone.OzoneConsts.NODEPOOL_DB;
+ *
+ * NOTE: user should use this CLI in an offline fashion. Namely, this should not
+ * be used to convert a levelDB that is currently being used by Ozone. Instead,
+ * this should be used to debug and diagnosis closed levelDB instances.
+ *
-  private static final String CREATE_CONTAINER_MACHINE =
+  private static final String CREATE_CONTAINER_MEMBERS =
-          "containerName INTEGER NOT NULL, " +
-          "datanodeUUID INTEGER NOT NULL," +
+          "containerName TEXT NOT NULL, " +
+          "datanodeUUID TEXT NOT NULL," +
+  // for nodepool.db
+  private static final String CREATE_NODE_POOL =
+      "CREATE TABLE nodePool (" +
+          "datanodeUUID TEXT NOT NULL," +
+          "poolName TEXT NOT NULL," +
+          "PRIMARY KEY(datanodeUUID, poolName))";
+  private static final String INSERT_NODE_POOL =
+      "INSERT INTO nodePool (datanodeUUID, poolName) " +
+          "VALUES (\"%s\", \"%s\")";
+  // and reuse CREATE_DATANODE_INFO and INSERT_DATANODE_INFO
+    } else if (dbName.toString().equals(NODEPOOL_DB)) {
+      LOG.info("Converting node pool DB");
+      convertNodePoolDB(dbPath, outPath);
-  private void closeDB(Connection conn) throws SQLException {
-    conn.close();
-  }
-
-    LevelDBStore dbStore = new LevelDBStore(dbFile, dbOptions);
+    try (LevelDBStore dbStore = new LevelDBStore(dbFile, dbOptions);
+         Connection conn = connectDB(outPath.toString())) {
+      executeSQL(conn, CREATE_CONTAINER_INFO);
+      executeSQL(conn, CREATE_CONTAINER_MEMBERS);
+      executeSQL(conn, CREATE_DATANODE_INFO);
-    Connection conn = connectDB(outPath.toString());
-    executeSQL(conn, CREATE_CONTAINER_INFO);
-    executeSQL(conn, CREATE_CONTAINER_MACHINE);
-    executeSQL(conn, CREATE_DATANODE_INFO);
-
-    DBIterator iter = dbStore.getIterator();
-    iter.seekToFirst();
-    HashSet<String> uuidChecked = new HashSet<>();
-    while(iter.hasNext()) {
-      Map.Entry<byte[], byte[]> entry = iter.next();
-      String containerName = new String(entry.getKey(), encoding);
-      Pipeline pipeline = Pipeline.parseFrom(entry.getValue());
-      insertContainerDB(conn, containerName, pipeline, uuidChecked);
+      DBIterator iter = dbStore.getIterator();
+      iter.seekToFirst();
+      HashSet<String> uuidChecked = new HashSet<>();
+      while (iter.hasNext()) {
+        Map.Entry<byte[], byte[]> entry = iter.next();
+        String containerName = new String(entry.getKey(), encoding);
+        Pipeline pipeline = Pipeline.parseFrom(entry.getValue());
+        insertContainerDB(conn, containerName, pipeline, uuidChecked);
+      }
-    closeDB(conn);
-    dbStore.close();
-    LevelDBStore dbStore = new LevelDBStore(dbFile, dbOptions);
+    try (LevelDBStore dbStore = new LevelDBStore(dbFile, dbOptions);
+         Connection conn = connectDB(outPath.toString())) {
+      executeSQL(conn, CREATE_BLOCK_CONTAINER);
-    Connection conn = connectDB(outPath.toString());
-    executeSQL(conn, CREATE_BLOCK_CONTAINER);
-
-    DBIterator iter = dbStore.getIterator();
-    iter.seekToFirst();
-    while (iter.hasNext()) {
-      Map.Entry<byte[], byte[]> entry = iter.next();
-      String blockKey = DFSUtilClient.bytes2String(entry.getKey());
-      String containerName = DFSUtilClient.bytes2String(entry.getValue());
-      String insertBlockContainer = String.format(
-          INSERT_BLOCK_CONTAINER, blockKey, containerName);
-      executeSQL(conn, insertBlockContainer);
+      DBIterator iter = dbStore.getIterator();
+      iter.seekToFirst();
+      while (iter.hasNext()) {
+        Map.Entry<byte[], byte[]> entry = iter.next();
+        String blockKey = DFSUtilClient.bytes2String(entry.getKey());
+        String containerName = DFSUtilClient.bytes2String(entry.getValue());
+        String insertBlockContainer = String.format(
+            INSERT_BLOCK_CONTAINER, blockKey, containerName);
+        executeSQL(conn, insertBlockContainer);
+      }
-    closeDB(conn);
-    dbStore.close();
+  }
+
+  /**
+   * Converts nodePool.db to sqlite. The schema of sql db:
+   * two tables, nodePool and datanodeInfo (the same datanode Info as for
+   * container.db).
+   *
+   * nodePool
+   * ---------------------------------------------------------
+   * datanodeUUID* | poolName*
+   * ---------------------------------------------------------
+   *
+   * datanodeInfo:
+   * ---------------------------------------------------------
+   * hostname | datanodeUUid* | xferPort | infoPort | ipcPort
+   * ---------------------------------------------------------
+   *
+   * --------------------------------
+   * | infoSecurePort | containerPort
+   * --------------------------------
+   *
+   * @param dbPath path to container db.
+   * @param outPath path to output sqlite
+   * @throws IOException throws exception.
+   */
+  private void convertNodePoolDB(Path dbPath, Path outPath) throws Exception {
+    LOG.info("Create table for sql node pool db.");
+    File dbFile = dbPath.toFile();
+    org.iq80.leveldb.Options dbOptions = new org.iq80.leveldb.Options();
+    try (LevelDBStore dbStore = new LevelDBStore(dbFile, dbOptions);
+         Connection conn = connectDB(outPath.toString())) {
+      executeSQL(conn, CREATE_NODE_POOL);
+      executeSQL(conn, CREATE_DATANODE_INFO);
+
+      DBIterator iter = dbStore.getIterator();
+      iter.seekToFirst();
+      while (iter.hasNext()) {
+        Map.Entry<byte[], byte[]> entry = iter.next();
+        DatanodeID nodeId = DatanodeID.getFromProtoBuf(
+            HdfsProtos.DatanodeIDProto.PARSER.parseFrom(entry.getKey()));
+        String blockPool = DFSUtil.bytes2String(entry.getValue());
+        insertNodePoolDB(conn, blockPool, nodeId);
+      }
+    }
+  }
+
+  private void insertNodePoolDB(Connection conn, String blockPool,
+      DatanodeID datanodeID) throws SQLException {
+    String insertNodePool = String.format(INSERT_NODE_POOL,
+        datanodeID.getDatanodeUuid(), blockPool);
+    executeSQL(conn, insertNodePool);
+
+    String insertDatanodeID = String.format(INSERT_DATANODE_INFO,
+        datanodeID.getHostName(), datanodeID.getDatanodeUuid(),
+        datanodeID.getIpAddr(), datanodeID.getXferPort(),
+        datanodeID.getInfoPort(), datanodeID.getIpcPort(),
+        datanodeID.getInfoSecurePort(), datanodeID.getContainerPort());
+    executeSQL(conn, insertDatanodeID);
