Revert "HDDS-1395. Key write fails with BlockOutputStream has been closed exception (#749)"

This reverts commit d525633619f83a76bcb4d73b444bbfe8e3ab594b.

-import org.apache.hadoop.hdds.scm.client.HddsClientUtils;
+import org.apache.hadoop.hdds.scm.storage.BufferPool;
+import org.apache.hadoop.ozone.OzoneConfigKeys;
+import org.apache.hadoop.ozone.client.OzoneClientUtils;
+import org.apache.hadoop.security.UserGroupInformation;
+import java.util.ArrayList;
+import java.util.ListIterator;
+  // array list's get(index) is O(1)
+  private final ArrayList<BlockOutputStreamEntry> streamEntries;
+  private int currentStreamIndex;
+  private final OzoneManagerProtocol omClient;
+  private final OmKeyArgs keyArgs;
+  private final long openID;
+  private final XceiverClientManager xceiverClientManager;
+  private final int chunkSize;
+  private final String requestID;
+  private final long streamBufferFlushSize;
+  private final long streamBufferMaxSize;
+  private final long watchTimeout;
+  private final long blockSize;
+  private final int bytesPerChecksum;
+  private final ChecksumType checksumType;
+  private final BufferPool bufferPool;
+  private OmMultipartCommitUploadPartInfo commitUploadPartInfo;
+  private ExcludeList excludeList;
-  private final BlockOutputStreamEntryPool blockOutputStreamEntryPool;
-
+  @SuppressWarnings("parameternumber")
+    streamEntries = new ArrayList<>();
+    omClient = null;
+    keyArgs = null;
+    openID = -1;
+    xceiverClientManager = null;
+    chunkSize = 0;
+    requestID = null;
-    this.retryPolicyMap = HddsClientUtils.getExceptionList()
+    streamBufferFlushSize = 0;
+    streamBufferMaxSize = 0;
+    bufferPool = new BufferPool(chunkSize, 1);
+    watchTimeout = 0;
+    blockSize = 0;
+    this.checksumType = ChecksumType.valueOf(
+        OzoneConfigKeys.OZONE_CLIENT_CHECKSUM_TYPE_DEFAULT);
+    this.bytesPerChecksum = OzoneConfigKeys
+        .OZONE_CLIENT_BYTES_PER_CHECKSUM_DEFAULT_BYTES; // Default is 1MB
+    this.retryPolicyMap = OzoneClientUtils.getExceptionList()
-    blockOutputStreamEntryPool = new BlockOutputStreamEntryPool();
-    return blockOutputStreamEntryPool.getStreamEntries();
+    return streamEntries;
-
-    return blockOutputStreamEntryPool.getXceiverClientManager();
+    return xceiverClientManager;
-  @VisibleForTesting
-  public List<OmKeyLocationInfo> getLocationInfoList() {
-    return blockOutputStreamEntryPool.getLocationInfoList();
+  public List<OmKeyLocationInfo> getLocationInfoList() throws IOException {
+    List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();
+    for (BlockOutputStreamEntry streamEntry : streamEntries) {
+      OmKeyLocationInfo info =
+          new OmKeyLocationInfo.Builder().setBlockID(streamEntry.getBlockID())
+              .setLength(streamEntry.getCurrentPosition()).setOffset(0)
+              .setToken(streamEntry.getToken())
+              .setPipeline(streamEntry.getPipeline())
+              .build();
+      LOG.debug("block written " + streamEntry.getBlockID() + ", length "
+          + streamEntry.getCurrentPosition() + " bcsID "
+          + streamEntry.getBlockID().getBlockCommitSequenceId());
+      locationInfoList.add(info);
+    }
+    return locationInfoList;
+    this.streamEntries = new ArrayList<>();
+    this.currentStreamIndex = 0;
+    this.omClient = omClient;
-    blockOutputStreamEntryPool =
-        new BlockOutputStreamEntryPool(omClient, chunkSize, requestId, factor,
-            type, bufferFlushSize, bufferMaxSize, size, watchTimeout,
-            checksumType, bytesPerChecksum, uploadID, partNumber, isMultipart,
-            info, xceiverClientManager, handler.getId());
-    this.retryPolicyMap = HddsClientUtils.getRetryPolicyByException(
+    this.keyArgs = new OmKeyArgs.Builder().setVolumeName(info.getVolumeName())
+        .setBucketName(info.getBucketName()).setKeyName(info.getKeyName())
+        .setType(type).setFactor(factor).setDataSize(info.getDataSize())
+        .setIsMultipartKey(isMultipart).setMultipartUploadID(
+            uploadID).setMultipartUploadPartNumber(partNumber)
+        .build();
+    this.openID = handler.getId();
+    this.xceiverClientManager = xceiverClientManager;
+    this.chunkSize = chunkSize;
+    this.requestID = requestId;
+    this.streamBufferFlushSize = bufferFlushSize;
+    this.streamBufferMaxSize = bufferMaxSize;
+    this.blockSize = size;
+    this.watchTimeout = watchTimeout;
+    this.bytesPerChecksum = bytesPerChecksum;
+    this.checksumType = checksumType;
+
+    Preconditions.checkState(chunkSize > 0);
+    Preconditions.checkState(streamBufferFlushSize > 0);
+    Preconditions.checkState(streamBufferMaxSize > 0);
+    Preconditions.checkState(blockSize > 0);
+    Preconditions.checkState(streamBufferFlushSize % chunkSize == 0);
+    Preconditions.checkState(streamBufferMaxSize % streamBufferFlushSize == 0);
+    Preconditions.checkState(blockSize % streamBufferMaxSize == 0);
+    this.bufferPool =
+        new BufferPool(chunkSize, (int)streamBufferMaxSize / chunkSize);
+    this.excludeList = new ExcludeList();
+    this.retryPolicyMap = OzoneClientUtils.getRetryPolicyByException(
-    blockOutputStreamEntryPool.addPreallocateBlocks(version, openVersion);
+    // server may return any number of blocks, (0 to any)
+    // only the blocks allocated in this open session (block createVersion
+    // equals to open session version)
+    for (OmKeyLocationInfo subKeyInfo : version.getLocationList()) {
+      if (subKeyInfo.getCreateVersion() == openVersion) {
+        addKeyLocationInfo(subKeyInfo);
+      }
+    }
+  }
+
+  private void addKeyLocationInfo(OmKeyLocationInfo subKeyInfo)
+      throws IOException {
+    Preconditions.checkNotNull(subKeyInfo.getPipeline());
+    UserGroupInformation.getCurrentUser().addToken(subKeyInfo.getToken());
+    BlockOutputStreamEntry.Builder builder =
+        new BlockOutputStreamEntry.Builder()
+            .setBlockID(subKeyInfo.getBlockID())
+            .setKey(keyArgs.getKeyName())
+            .setXceiverClientManager(xceiverClientManager)
+            .setPipeline(subKeyInfo.getPipeline())
+            .setRequestId(requestID)
+            .setChunkSize(chunkSize)
+            .setLength(subKeyInfo.getLength())
+            .setStreamBufferFlushSize(streamBufferFlushSize)
+            .setStreamBufferMaxSize(streamBufferMaxSize)
+            .setWatchTimeout(watchTimeout)
+            .setbufferPool(bufferPool)
+            .setChecksumType(checksumType)
+            .setBytesPerChecksum(bytesPerChecksum)
+            .setToken(subKeyInfo.getToken());
+    streamEntries.add(builder.build());
+  private long computeBufferData() {
+    return bufferPool.computeBufferData();
+  }
+
+    int succeededAllocates = 0;
-        BlockOutputStreamEntry current =
-            blockOutputStreamEntryPool.allocateBlockIfNeeded();
+        if (streamEntries.size() <= currentStreamIndex) {
+          Preconditions.checkNotNull(omClient);
+          // allocate a new block, if a exception happens, log an error and
+          // throw exception to the caller directly, and the write fails.
+          try {
+            allocateNewBlock(currentStreamIndex);
+            succeededAllocates += 1;
+          } catch (IOException ioe) {
+            LOG.error("Try to allocate more blocks for write failed, already "
+                + "allocated " + succeededAllocates
+                + " blocks for this write.");
+            throw ioe;
+          }
+        }
+        // in theory, this condition should never violate due the check above
+        // still do a sanity check.
+        Preconditions.checkArgument(currentStreamIndex < streamEntries.size());
+        BlockOutputStreamEntry current = streamEntries.get(currentStreamIndex);
+
-          Preconditions.checkState(!retry || len <= blockOutputStreamEntryPool
-              .getStreamBufferMaxSize());
+          Preconditions.checkState(!retry || len <= streamBufferMaxSize);
-          handleException(current, ioe);
+          handleException(current, currentStreamIndex, ioe);
+   * Discards the subsequent pre allocated blocks and removes the streamEntries
+   * from the streamEntries list for the container which is closed.
+   * @param containerID id of the closed container
+   * @param pipelineId id of the associated pipeline
+   * @param streamIndex index of the stream
+   */
+  private void discardPreallocatedBlocks(long containerID,
+      PipelineID pipelineId, int streamIndex) {
+    // streamIndex < streamEntries.size() signifies that, there are still
+    // pre allocated blocks available.
+
+    // This will be called only to discard the next subsequent unused blocks
+    // in the streamEntryList.
+    if (streamIndex < streamEntries.size()) {
+      ListIterator<BlockOutputStreamEntry> streamEntryIterator =
+          streamEntries.listIterator(streamIndex);
+      while (streamEntryIterator.hasNext()) {
+        BlockOutputStreamEntry streamEntry = streamEntryIterator.next();
+        Preconditions.checkArgument(streamEntry.getCurrentPosition() == 0);
+        if (((pipelineId != null && streamEntry.getPipeline().getId()
+            .equals(pipelineId)) || (containerID != -1
+            && streamEntry.getBlockID().getContainerID() == containerID))) {
+          streamEntryIterator.remove();
+        }
+      }
+    }
+  }
+
+  /**
+   * It might be possible that the blocks pre allocated might never get written
+   * while the stream gets closed normally. In such cases, it would be a good
+   * idea to trim down the locationInfoList by removing the unused blocks if any
+   * so as only the used block info gets updated on OzoneManager during close.
+   */
+  private void removeEmptyBlocks() {
+    if (currentStreamIndex < streamEntries.size()) {
+      ListIterator<BlockOutputStreamEntry> streamEntryIterator =
+          streamEntries.listIterator(currentStreamIndex);
+      while (streamEntryIterator.hasNext()) {
+        if (streamEntryIterator.next().getCurrentPosition() == 0) {
+          streamEntryIterator.remove();
+        }
+      }
+    }
+  }
+
+  private void cleanup() {
+    if (excludeList != null) {
+      excludeList.clear();
+      excludeList = null;
+    }
+    if (bufferPool != null) {
+      bufferPool.clearBufferPool();
+    }
+
+    if (streamEntries != null) {
+      streamEntries.clear();
+    }
+  }
+  /**
-   * datanode.
+   *    datanode.
-   * @param exception   actual exception that occurred
+   * @param streamIndex Index of the entry
+   * @param exception actual exception that occurred
-      IOException exception) throws IOException {
-    Throwable t = HddsClientUtils.checkForException(exception);
+      int streamIndex, IOException exception) throws IOException {
+    Throwable t = checkForException(exception);
-    long bufferedDataLen = blockOutputStreamEntryPool.computeBufferData();
-    LOG.debug(
-        "Encountered exception {}. The last committed block length is {}, "
+    long bufferedDataLen = computeBufferData();
+    LOG.warn("Encountered exception {}. The last committed block length is {}, "
-    Preconditions.checkArgument(
-        bufferedDataLen <= blockOutputStreamEntryPool.getStreamBufferMaxSize());
-    Preconditions.checkArgument(
-        offset - blockOutputStreamEntryPool.getKeyLength() == bufferedDataLen);
+    Preconditions.checkArgument(bufferedDataLen <= streamBufferMaxSize);
+    Preconditions.checkArgument(offset - getKeyLength() == bufferedDataLen);
-    ExcludeList excludeList = blockOutputStreamEntryPool.getExcludeList();
-    // discard all subsequent blocks the containers and pipelines which
+    // discard all sunsequent blocks the containers and pipelines which
-      blockOutputStreamEntryPool
-          .discardPreallocatedBlocks(streamEntry.getBlockID().getContainerID(),
-              null);
+      discardPreallocatedBlocks(streamEntry.getBlockID().getContainerID(), null,
+          streamIndex + 1);
-      // pipeline, just discard all the pre allocated blocks on this pipeline.
+      // pipeline, just discard all the preallocated blocks on this pipeline.
-      blockOutputStreamEntryPool
-          .discardPreallocatedBlocks(-1, pipelineId);
+      discardPreallocatedBlocks(-1, pipelineId, streamIndex + 1);
+      currentStreamIndex += 1;
+    if (totalSuccessfulFlushedData == 0) {
+      streamEntries.remove(streamIndex);
+      currentStreamIndex -= 1;
+    }
-    blockOutputStreamEntryPool.cleanup();
+    cleanup();
-    RetryPolicy retryPolicy = retryPolicyMap
-        .get(HddsClientUtils.checkForException(exception).getClass());
+    RetryPolicy retryPolicy =
+        retryPolicyMap.get(checkForException(exception).getClass());
-    LOG.trace("Retrying Write request. Already tried " + retryCount
-        + " time(s); retry policy is " + retryPolicy);
+    LOG.trace("Retrying Write request. Already tried "
+        + retryCount + " time(s); retry policy is " + retryPolicy);
-
+  public Throwable checkForException(IOException ioe) throws IOException {
+    Throwable t = ioe.getCause();
+    while (t != null) {
+      for (Class<? extends Exception> cls : OzoneClientUtils
+          .getExceptionList()) {
+        if (cls.isInstance(t)) {
+          return t;
+        }
+      }
+      t = t.getCause();
+    }
+    throw ioe;
+  }
+
+  private long getKeyLength() {
+    return streamEntries.stream().mapToLong(e -> e.getCurrentPosition())
+        .sum();
+  }
+
+  /**
+   * Contact OM to get a new block. Set the new block with the index (e.g.
+   * first block has index = 0, second has index = 1 etc.)
+   *
+   * The returned block is made to new BlockOutputStreamEntry to write.
+   *
+   * @param index the index of the block.
+   * @throws IOException
+   */
+  private void allocateNewBlock(int index) throws IOException {
+    OmKeyLocationInfo subKeyInfo =
+        omClient.allocateBlock(keyArgs, openID, excludeList);
+    addKeyLocationInfo(subKeyInfo);
+  }
+
-   *
-   *           outputStream.
+   *              outputStream.
-    if (blockOutputStreamEntryPool.isEmpty()) {
+    if (streamEntries.size() == 0) {
-        BlockOutputStreamEntry entry =
-            blockOutputStreamEntryPool.getCurrentStreamEntry();
+        int size = streamEntries.size();
+        int streamIndex =
+            currentStreamIndex >= size ? size - 1 : currentStreamIndex;
+        BlockOutputStreamEntry entry = streamEntries.get(streamIndex);
-              blockOutputStreamEntryPool.getExcludeList()
-                  .addDatanodes(failedServers);
+              excludeList.addDatanodes(failedServers);
+                currentStreamIndex++;
-            handleException(entry, ioe);
+            handleException(entry, streamIndex, ioe);
-      blockOutputStreamEntryPool.commitKey(offset);
+      if (keyArgs != null) {
+        // in test, this could be null
+        removeEmptyBlocks();
+        long length = getKeyLength();
+        Preconditions.checkArgument(offset == length);
+        keyArgs.setDataSize(length);
+        keyArgs.setLocationInfoList(getLocationInfoList());
+        // When the key is multipart upload part file upload, we should not
+        // commit the key, as this is not an actual key, this is a just a
+        // partial key of a large file.
+        if (keyArgs.getIsMultipartKey()) {
+          commitUploadPartInfo = omClient.commitMultipartUploadPart(keyArgs,
+              openID);
+        } else {
+          omClient.commitKey(keyArgs, openID);
+        }
+      } else {
+        LOG.warn("Closing KeyOutputStream, but key args is null");
+      }
-      blockOutputStreamEntryPool.cleanup();
+      cleanup();
-    return blockOutputStreamEntryPool.getCommitUploadPartInfo();
+    return commitUploadPartInfo;
-    return blockOutputStreamEntryPool.getExcludeList();
+    return excludeList;
+
-    public Builder setOmClient(OzoneManagerProtocol client) {
+    public Builder setOmClient(
+        OzoneManagerProtocol client) {
-    public Builder setChecksumType(ChecksumType cType) {
+    public Builder setChecksumType(ChecksumType cType){
-    public Builder setBytesPerChecksum(int bytes) {
+    public Builder setBytesPerChecksum(int bytes){
-    public KeyOutputStream build() {
-      return new KeyOutputStream(openHandler, xceiverManager, omClient,
-          chunkSize, requestID, factor, type, streamBufferFlushSize,
+    public KeyOutputStream build() throws IOException {
+      return new KeyOutputStream(openHandler, xceiverManager,
+          omClient, chunkSize, requestID, factor, type, streamBufferFlushSize,
-          ": " + FSExceptionMessages.STREAM_IS_CLOSED + " Key: "
-              + blockOutputStreamEntryPool.getKeyName());
+          ": " + FSExceptionMessages.STREAM_IS_CLOSED + " Key: " + keyArgs
+              .getKeyName());
