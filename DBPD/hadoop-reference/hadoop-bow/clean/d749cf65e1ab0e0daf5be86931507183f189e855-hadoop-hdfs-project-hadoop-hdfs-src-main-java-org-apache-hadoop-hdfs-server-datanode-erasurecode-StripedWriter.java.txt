HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.

-import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;
-import org.apache.hadoop.hdfs.server.protocol.BlockECReconstructionCommand.BlockECReconstructionInfo;
-  private long maxTargetLength;
-  StripedWriter(StripedReconstructor reconstructor,
-                DataNode datanode,
-                Configuration conf,
-                BlockECReconstructionInfo reconstructionInfo) {
+  StripedWriter(StripedReconstructor reconstructor, DataNode datanode,
+      Configuration conf, StripedReconstructionInfo stripedReconInfo) {
-    ErasureCodingPolicy ecPolicy = reconstructionInfo.getErasureCodingPolicy();
-    dataBlkNum = ecPolicy.getNumDataUnits();
-    parityBlkNum = ecPolicy.getNumParityUnits();
+    dataBlkNum = stripedReconInfo.getEcPolicy().getNumDataUnits();
+    parityBlkNum = stripedReconInfo.getEcPolicy().getNumParityUnits();
-    targets = reconstructionInfo.getTargetDnInfos();
-    targetStorageTypes = reconstructionInfo.getTargetStorageTypes();
+    this.targets = stripedReconInfo.getTargets();
+    assert targets != null;
+    this.targetStorageTypes = stripedReconInfo.getTargetStorageTypes();
+    assert targetStorageTypes != null;
-
-    maxTargetLength = 0L;
+    long maxTargetLength = 0L;
+    reconstructor.setMaxTargetLength(maxTargetLength);
-    int k = 0;
-  long getMaxTargetLength() {
-    return maxTargetLength;
-  }
-
