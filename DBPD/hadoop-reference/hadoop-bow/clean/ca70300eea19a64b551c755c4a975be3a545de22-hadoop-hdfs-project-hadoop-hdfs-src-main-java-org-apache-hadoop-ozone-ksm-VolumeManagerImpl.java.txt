HDFS-11775. Ozone: KSM: add createBucket. Contributed by Nandakumar Vadivelu.

-import org.apache.hadoop.ozone.OzoneConsts;
-import org.apache.hadoop.ozone.web.utils.OzoneUtils;
-import org.apache.hadoop.utils.LevelDBStore;
-import org.iq80.leveldb.Options;
-import org.iq80.leveldb.WriteBatch;
-import java.io.File;
+import java.util.AbstractMap;
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.Map;
-import static org.apache.hadoop.ozone.OzoneConsts.KSM_DB_NAME;
-import static org.apache.hadoop.ozone.ksm
-    .KSMConfigKeys.OZONE_KSM_DB_CACHE_SIZE_DEFAULT;
-import static org.apache.hadoop.ozone.ksm
-    .KSMConfigKeys.OZONE_KSM_DB_CACHE_SIZE_MB;
-  private final KeySpaceManager ksm;
-  private final LevelDBStore store;
-  private final ReadWriteLock lock;
+  private final MetadataManager metadataManager;
-  public VolumeManagerImpl(KeySpaceManager ksm, OzoneConfiguration conf)
-      throws IOException {
-    File metaDir = OzoneUtils.getScmMetadirPath(conf);
-    final int cacheSize = conf.getInt(OZONE_KSM_DB_CACHE_SIZE_MB,
-        OZONE_KSM_DB_CACHE_SIZE_DEFAULT);
-    Options options = new Options();
-    options.cacheSize(cacheSize * OzoneConsts.MB);
-    File ksmDBFile = new File(metaDir.getPath(), KSM_DB_NAME);
-    this.ksm = ksm;
-    this.store = new LevelDBStore(ksmDBFile, options);
-    lock = new ReentrantReadWriteLock();
+  public VolumeManagerImpl(MetadataManager metadataManager,
+      OzoneConfiguration conf) throws IOException {
+    this.metadataManager = metadataManager;
-  @Override
-  public void start() {
-  }
-
-  @Override
-  public void stop() throws IOException {
-    store.close();
-  }
-
-    lock.writeLock().lock();
-    WriteBatch batch = store.createWriteBatch();
+    metadataManager.writeLock().lock();
+    List<Map.Entry<byte[], byte[]>> batch = new LinkedList<>();
-      byte[] volumeName = store.get(DFSUtil.string2Bytes(args.getVolume()));
+      byte[] volumeName = metadataManager.
+          get(DFSUtil.string2Bytes(args.getVolume()));
-      byte[] volumeList  = store.get(DFSUtil.string2Bytes(dbUserName));
+      byte[] volumeList  = metadataManager
+          .get(DFSUtil.string2Bytes(dbUserName));
-      // Commit the volume information to leveldb
+      // Commit the volume information to metadataManager
-      batch.put(DFSUtil.string2Bytes(args.getVolume()),
-                                     volumeInfo.toByteArray());
+      batch.add(new AbstractMap.SimpleEntry<>(
+          DFSUtil.string2Bytes(args.getVolume()), volumeInfo.toByteArray()));
-      batch.put(DFSUtil.string2Bytes(dbUserName), newVolList.toByteArray());
-      store.commitWriteBatch(batch);
+      batch.add(new AbstractMap.SimpleEntry<>(
+          DFSUtil.string2Bytes(dbUserName), newVolList.toByteArray()));
+      metadataManager.batchPut(batch);
-      ksm.getMetrics().incNumVolumeCreateFails();
-      store.closeWriteBatch(batch);
-      lock.writeLock().unlock();
+      metadataManager.writeLock().unlock();
