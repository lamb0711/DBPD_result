HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.

+import java.util.List;
-import org.apache.hadoop.fs.StorageType;
-import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
+import org.apache.hadoop.hdfs.server.namenode.sps.StoragePolicySatisfier.DatanodeMap;
+import org.apache.hadoop.hdfs.server.namenode.sps.StoragePolicySatisfier.DatanodeWithStorage;
-  public NetworkTopology getNetworkTopology() {
-    return NetworkTopology.getInstance(service.getConf());
+  public NetworkTopology getNetworkTopology(DatanodeMap datanodeMap) {
+    // create network topology.
+    NetworkTopology cluster = NetworkTopology.getInstance(service.getConf());
+    List<DatanodeWithStorage> targets = datanodeMap.getTargets();
+    for (DatanodeWithStorage node : targets) {
+      cluster.add(node.getDatanodeInfo());
+    }
+    return cluster;
-  public boolean checkDNSpaceForScheduling(DatanodeInfo dn, StorageType type,
-      long estimatedSize) {
-    // TODO: Instead of calling namenode for checking the available space, it
-    // can be optimized by maintaining local cache of datanode storage report
-    // and do the computations. This local cache can be refreshed per file or
-    // periodic fashion.
-    try {
-      return nnc.getNNProtocolConnection().checkDNSpaceForScheduling(dn, type,
-          estimatedSize);
-    } catch (IOException e) {
-      LOG.warn("Verify the given datanode:{} is good and has "
-          + "estimated space in it.", dn, e);
-      return false;
-    }
-  }
-
-  @Override
