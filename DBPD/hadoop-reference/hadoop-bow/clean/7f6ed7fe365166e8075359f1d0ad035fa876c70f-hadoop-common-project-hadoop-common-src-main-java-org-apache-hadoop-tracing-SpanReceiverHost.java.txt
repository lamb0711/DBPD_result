HDFS-7055. Add tracing to DFSInputStream (cmccabe)

+import java.io.BufferedReader;
+import java.io.DataInputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.InputStreamReader;
+import java.util.UUID;
+import org.apache.hadoop.io.IOUtils;
- 
-    "hadoop.trace.spanreceiver.classes";
+    "hadoop.htrace.spanreceiver.classes";
+  private final static String LOCAL_FILE_SPAN_RECEIVER_PATH =
+      "hadoop.htrace.local-file-span-receiver.path";
+
+  private static String getUniqueLocalTraceFileName() {
+    String tmp = System.getProperty("java.io.tmpdir", "/tmp");
+    String nonce = null;
+    BufferedReader reader = null;
+    try {
+      // On Linux we can get a unique local file name by reading the process id
+      // out of /proc/self/stat.  (There isn't any portable way to get the
+      // process ID from Java.)
+      reader = new BufferedReader(
+          new InputStreamReader(new FileInputStream("/proc/self/stat")));
+      String line = reader.readLine();
+      nonce = line.split(" ")[0];
+    } catch (IOException e) {
+    } finally {
+      IOUtils.cleanup(LOG, reader);
+    }
+    if (nonce == null) {
+      // If we can't use the process ID, use a random nonce.
+      nonce = UUID.randomUUID().toString();
+    }
+    return new File(tmp, nonce).getAbsolutePath();
+  }
+
-   * "hadoop.trace.spanreceiver.classes" property and instantiates and registers
+   * "hadoop.htrace.spanreceiver.classes" property and instantiates and registers
+    // It's convenient to have each daemon log to a random trace file when
+    // testing.
+    if (config.get(LOCAL_FILE_SPAN_RECEIVER_PATH) == null) {
+      config.set(LOCAL_FILE_SPAN_RECEIVER_PATH,
+          getUniqueLocalTraceFileName());
+    }
+      if (!className.contains(".")) {
+        className = "org.htrace.impl." + className;
+      }
-      public static final String HTRACE_CONF_PREFIX = "hadoop.";
+      public static final String HTRACE_CONF_PREFIX = "hadoop.htrace.";
