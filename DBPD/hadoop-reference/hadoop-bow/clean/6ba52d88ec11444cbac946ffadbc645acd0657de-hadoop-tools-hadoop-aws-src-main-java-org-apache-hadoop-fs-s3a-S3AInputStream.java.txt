HADOOP-10714. AmazonS3Client.deleteObjects() need to be limited to 1000 entries per call. Contributed by Juan Yu.

+import org.apache.hadoop.fs.FSExceptionMessages;
+
-      throw new EOFException("Trying to seek to a negative offset " + pos);
+      throw new EOFException(FSExceptionMessages.NEGATIVE_SEEK
+          +" " + pos);
-      throw new EOFException("Trying to seek to an offset " + pos + 
-                             " past the end of the file");
+      throw new EOFException(
+          FSExceptionMessages.CANNOT_SEEK_PAST_EOF
+          + " " + pos);
-    LOG.info("Actually opening file " + key + " at pos " + pos);
+    LOG.debug("Actually opening file " + key + " at pos " + pos);
+    checkNotClosed();
+
-    LOG.info("Reopening " + this.key + " to seek to new offset " + (pos - this.pos));
+    LOG.debug(
+        "Reopening " + this.key + " to seek to new offset " + (pos - this.pos));
-    if (closed) {
-      throw new IOException("Stream closed");
-    }
+    checkNotClosed();
-  public synchronized int read(byte buf[], int off, int len) throws IOException {
-    if (closed) {
-      throw new IOException("Stream closed");
-    }
+  public synchronized int read(byte[] buf, int off, int len) throws IOException {
+    checkNotClosed();
+  private void checkNotClosed() throws IOException {
+    if (closed) {
+      throw new IOException(FSExceptionMessages.STREAM_IS_CLOSED);
+    }
+  }
+
-    if (closed) {
-      throw new IOException("Stream closed");
-    }
+    checkNotClosed();
+
