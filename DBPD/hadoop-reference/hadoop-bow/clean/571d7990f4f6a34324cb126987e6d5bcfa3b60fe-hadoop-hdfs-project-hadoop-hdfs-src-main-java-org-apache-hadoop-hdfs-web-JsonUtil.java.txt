Merge trunk into HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1196458 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.fs.FileChecksum;
-    m.put("className", e.getClass().getName());
+    m.put("exception", e.getClass().getSimpleName());
+    m.put("javaClassName", e.getClass().getName());
-    final String className = (String)m.get("className");
-    return new RemoteException(className, message);
+    final String javaClassName = (String)m.get("javaClassName");
+    return new RemoteException(javaClassName, message);
-  public static String toJsonString(final HdfsFileStatus status) {
+  public static String toJsonString(final HdfsFileStatus status,
+      boolean includeType) {
-    } else {
-      final Map<String, Object> m = new TreeMap<String, Object>();
-      m.put("localName", status.getLocalName());
-      m.put("isDir", status.isDir());
-      m.put("isSymlink", status.isSymlink());
-      if (status.isSymlink()) {
-        m.put("symlink", status.getSymlink());
-      }
-
-      m.put("len", status.getLen());
-      m.put("owner", status.getOwner());
-      m.put("group", status.getGroup());
-      m.put("permission", toString(status.getPermission()));
-      m.put("accessTime", status.getAccessTime());
-      m.put("modificationTime", status.getModificationTime());
-      m.put("blockSize", status.getBlockSize());
-      m.put("replication", status.getReplication());
-      return toJsonString(HdfsFileStatus.class, m);
+    final Map<String, Object> m = new TreeMap<String, Object>();
+    m.put("localName", status.getLocalName());
+    m.put("isDir", status.isDir());
+    m.put("isSymlink", status.isSymlink());
+    if (status.isSymlink()) {
+      m.put("symlink", status.getSymlink());
+    }
+
+    m.put("len", status.getLen());
+    m.put("owner", status.getOwner());
+    m.put("group", status.getGroup());
+    m.put("permission", toString(status.getPermission()));
+    m.put("accessTime", status.getAccessTime());
+    m.put("modificationTime", status.getModificationTime());
+    m.put("blockSize", status.getBlockSize());
+    m.put("replication", status.getReplication());
+    return includeType ? toJsonString(HdfsFileStatus.class, m) : 
+      JSON.toString(m);
-  public static HdfsFileStatus toFileStatus(final Map<?, ?> json) {
+  public static HdfsFileStatus toFileStatus(final Map<?, ?> json, boolean includesType) {
-    final Map<?, ?> m = (Map<?, ?>)json.get(HdfsFileStatus.class.getSimpleName());
+    final Map<?, ?> m = includesType ? 
+        (Map<?, ?>)json.get(HdfsFileStatus.class.getSimpleName()) : json;
-
+  
-        a[i] = toJsonMap(array.get(0));
+        a[i] = toJsonMap(array.get(i));
-    return toJsonString(MD5MD5CRC32FileChecksum.class, m);
+    return toJsonString(FileChecksum.class, m);
-    final Map<?, ?> m = (Map<?, ?>)json.get(
-        MD5MD5CRC32FileChecksum.class.getSimpleName());
+    final Map<?, ?> m = (Map<?, ?>)json.get(FileChecksum.class.getSimpleName());
