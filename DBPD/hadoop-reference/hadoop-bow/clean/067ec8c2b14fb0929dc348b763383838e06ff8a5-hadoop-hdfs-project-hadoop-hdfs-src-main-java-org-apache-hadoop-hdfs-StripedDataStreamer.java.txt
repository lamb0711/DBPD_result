HDFS-8838. Erasure Coding: Tolerate datanode failures in DFSStripedOutputStream when the data length is small. Contributed by Tsz Wo Nicholas Sze.

+import java.io.InterruptedIOException;
+import com.google.common.annotations.VisibleForTesting;
+
-    private final MultipleBlockingQueue<T> queue;
+    final MultipleBlockingQueue<T> queue;
-    T poll(final int i) throws IOException {
+    T poll(final int i) throws InterruptedIOException {
-            populate();
-            return queue.poll(i);
+            try {
+              populate();
+              return queue.poll(i);
+            } catch(IOException ioe) {
+              LOG.warn("Failed to populate, " + this, ioe);
+            }
-        try {
-          Thread.sleep(100);
-        } catch(InterruptedException ie) {
-          throw DFSUtil.toInterruptedIOException(
-              "Sleep interrupted during poll", ie);
-        }
+        sleep(100, "poll");
+  private static void sleep(long ms, String op) throws InterruptedIOException {
+    try {
+      Thread.sleep(ms);
+    } catch(InterruptedException ie) {
+      throw DFSUtil.toInterruptedIOException(
+          "Sleep interrupted during " + op, ie);
+    }
+  }
+
-  protected LocatedBlock locateFollowingBlock(final DatanodeInfo[] excludedNodes)
+  int getNumBlockWriteRetry() {
+    return 0;
+  }
+
+  @Override
+  LocatedBlock locateFollowingBlock(final DatanodeInfo[] excludedNodes)
-    final MultipleBlockingQueue<LocatedBlock> followingBlocks
-        = coordinator.getFollowingBlocks();
-    return new ConcurrentPoll<LocatedBlock>(followingBlocks) {
+    return new ConcurrentPoll<LocatedBlock>(coordinator.getFollowingBlocks()) {
-            followingBlocks.offer(i, blocks[i]);
+            queue.offer(i, blocks[i]);
+  @VisibleForTesting
+  LocatedBlock peekFollowingBlock() {
+    return coordinator.getFollowingBlocks().peek(index);
+  }
+
-    final MultipleBlockingQueue<LocatedBlock> newBlocks
-        = coordinator.getNewBlocks();
-    return new ConcurrentPoll<LocatedBlock>(newBlocks) {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("updateBlockForPipeline(), " + this);
+    }
+    return new ConcurrentPoll<LocatedBlock>(coordinator.getNewBlocks()) {
-            newBlocks.offer(i, lb);
+            queue.offer(i, lb);
-            final LocatedBlock lb = coordinator.getFollowingBlocks().peek(i);
-            lb.getBlock().setGenerationStamp(newGS);
+            final MultipleBlockingQueue<LocatedBlock> followingBlocks
+                = coordinator.getFollowingBlocks();
+            synchronized(followingBlocks) {
+              final LocatedBlock lb = followingBlocks.peek(i);
+              if (lb != null) {
+                lb.getBlock().setGenerationStamp(newGS);
+                si.getErrorState().reset();
+                continue;
+              }
+            }
+
+            //streamer i just have polled the block, sleep and retry.
+            sleep(100, "updateBlockForPipeline, " + this);
+            i--;
-    final MultipleBlockingQueue<ExtendedBlock> updateBlocks
-        = coordinator.getUpdateBlocks();
-    return new ConcurrentPoll<ExtendedBlock>(updateBlocks) {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("updatePipeline(newGS=" + newGS + "), " + this);
+    }
+    return new ConcurrentPoll<ExtendedBlock>(coordinator.getUpdateBlocks()) {
+        final MultipleBlockingQueue<LocatedBlock> followingBlocks
+            = coordinator.getFollowingBlocks();
-        final ExtendedBlock updated = callUpdatePipeline(bg, newBG);
-        for (int i = 0; i < NUM_DATA_BLOCKS + NUM_PARITY_BLOCKS; i++) {
-          StripedDataStreamer si = coordinator.getStripedDataStreamer(i);
-          if (si.isFailed()) {
-            continue; // skipping failed data streamer
+
+        final int n = NUM_DATA_BLOCKS + NUM_PARITY_BLOCKS;
+        final DatanodeInfo[] newNodes = new DatanodeInfo[n];
+        final String[] newStorageIDs = new String[n];
+        for (int i = 0; i < n; i++) {
+          final StripedDataStreamer si = coordinator.getStripedDataStreamer(i);
+          DatanodeInfo[] nodes = si.getNodes();
+          String[] storageIDs = si.getStorageIDs();
+          if (nodes == null || storageIDs == null) {
+            synchronized(followingBlocks) {
+              final LocatedBlock lb = followingBlocks.peek(i);
+              if (lb != null) {
+                nodes = lb.getLocations();
+                storageIDs = lb.getStorageIDs();
+              }
+            }
+          if (nodes != null && storageIDs != null) {
+            newNodes[i] = nodes[0];
+            newStorageIDs[i] = storageIDs[0];
+          } else {
+            //streamer i just have polled the block, sleep and retry.
+            sleep(100, "updatePipeline, " + this);
+            i--;
+          }
+        }
+        final ExtendedBlock updated = callUpdatePipeline(bg, newBG, newNodes,
+            newStorageIDs);
+
+        for (int i = 0; i < n; i++) {
+          final StripedDataStreamer si = coordinator.getStripedDataStreamer(i);
-          updateBlocks.offer(i, newBlock(bi, updated.getGenerationStamp()));
+          if (bi != null) {
+            queue.offer(i, newBlock(bi, updated.getGenerationStamp()));
+          } else if (!si.isFailed()) {
+            synchronized(followingBlocks) {
+              final LocatedBlock lb = followingBlocks.peek(i);
+              if (lb != null) {
+                lb.getBlock().setGenerationStamp(newGS);
+                si.getErrorState().reset();
+                continue;
+              }
+            }
+
+            //streamer i just have polled the block, sleep and retry.
+            sleep(100, "updatePipeline, " + this);
+            i--;
+          }
-    return "#" + index + ": failed? " + Boolean.toString(failed).charAt(0)
-        + ", " + super.toString();
+    return "#" + index + ": " + (failed? "failed, ": "") + super.toString();
