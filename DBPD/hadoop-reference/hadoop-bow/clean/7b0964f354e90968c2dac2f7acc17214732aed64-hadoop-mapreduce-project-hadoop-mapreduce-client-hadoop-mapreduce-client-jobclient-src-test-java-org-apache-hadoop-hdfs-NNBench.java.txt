MAPREDUCE-6363. [NNBench] Lease mismatch error when running with multiple mappers. Contributed by Vlad Sharanhovich and Bibin A Chundatt.

-import java.io.IOException;
-import java.util.Date;
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.IOException;
-import java.io.File;
-import java.io.BufferedReader;
-import java.util.StringTokenizer;
+import java.util.Date;
+import java.util.StringTokenizer;
-import org.apache.commons.logging.LogFactory;
-
+import org.apache.commons.logging.LogFactory;
-
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileStatus;
-
-import org.apache.hadoop.io.Text;
+import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.io.SequenceFile.CompressionType;
-
+import org.apache.hadoop.io.SequenceFile.CompressionType;
+import org.apache.hadoop.io.Text;
-import org.apache.hadoop.mapred.Mapper;
-import org.apache.hadoop.mapred.SequenceFileInputFormat;
-import org.apache.hadoop.mapred.MapReduceBase;
-import org.apache.hadoop.mapred.Reporter;
-import org.apache.hadoop.mapred.OutputCollector;
+import org.apache.hadoop.mapred.MapReduceBase;
+import org.apache.hadoop.mapred.Mapper;
+import org.apache.hadoop.mapred.OutputCollector;
+import org.apache.hadoop.mapred.Reporter;
+import org.apache.hadoop.mapred.SequenceFileInputFormat;
-        writer.append(new Text(strFileName), new LongWritable(0l));
+        writer.append(new Text(strFileName), new LongWritable(i));
-    Path reduceFile = new Path(new Path(baseDir, OUTPUT_DIR_NAME),
-            "part-00000");
-
-    DataInputStream in;
-    in = new DataInputStream(fs.open(reduceFile));
-
-    BufferedReader lines;
-    lines = new BufferedReader(new InputStreamReader(in));
+    Path reduceDir = new Path(baseDir, OUTPUT_DIR_NAME);
-    
-    String resultTPSLine1 = null;
-    String resultTPSLine2 = null;
-    String resultALLine1 = null;
-    String resultALLine2 = null;
-    
-    String line;
-    while((line = lines.readLine()) != null) {
-      StringTokenizer tokens = new StringTokenizer(line, " \t\n\r\f%;");
-      String attr = tokens.nextToken();
-      if (attr.endsWith(":totalTimeAL1")) {
-        totalTimeAL1 = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":totalTimeAL2")) {
-        totalTimeAL2 = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":totalTimeTPmS")) {
-        totalTimeTPmS = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":latemaps")) {
-        lateMaps = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":numOfExceptions")) {
-        numOfExceptions = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":successfulFileOps")) {
-        successfulFileOps = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":mapStartTimeTPmS")) {
-        mapStartTimeTPmS = Long.parseLong(tokens.nextToken());
-      } else if (attr.endsWith(":mapEndTimeTPmS")) {
-        mapEndTimeTPmS = Long.parseLong(tokens.nextToken());
+
+    FileStatus[] fss = fs.listStatus(reduceDir);
+    for (FileStatus status : fss) {
+
+      Path reduceFile = status.getPath();
+      DataInputStream in;
+      in = new DataInputStream(fs.open(reduceFile));
+
+      BufferedReader lines;
+      lines = new BufferedReader(new InputStreamReader(in));
+
+      String line;
+      while ((line = lines.readLine()) != null) {
+        StringTokenizer tokens = new StringTokenizer(line, " \t\n\r\f%;");
+        String attr = tokens.nextToken();
+        if (attr.endsWith(":totalTimeAL1")) {
+          totalTimeAL1 = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":totalTimeAL2")) {
+          totalTimeAL2 = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":totalTimeTPmS")) {
+          totalTimeTPmS = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":latemaps")) {
+          lateMaps = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":numOfExceptions")) {
+          numOfExceptions = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":successfulFileOps")) {
+          successfulFileOps = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":mapStartTimeTPmS")) {
+          mapStartTimeTPmS = Long.parseLong(tokens.nextToken());
+        } else if (attr.endsWith(":mapEndTimeTPmS")) {
+          mapEndTimeTPmS = Long.parseLong(tokens.nextToken());
+        }
+    String resultTPSLine1 = null;
+    String resultTPSLine2 = null;
+    String resultALLine1 = null;
+    String resultALLine2 = null;
+
+        String fileName = "file_" + value;
-          doCreateWriteOp("file_" + hostName + "_", reporter);
+          doCreateWriteOp(fileName, reporter);
-          doOpenReadOp("file_" + hostName + "_", reporter);
+          doOpenReadOp(fileName, reporter);
-          doRenameOp("file_" + hostName + "_", reporter);
+          doRenameOp(fileName, reporter);
-          doDeleteOp("file_" + hostName + "_", reporter);
+        } else {
+          throw new IllegalArgumentException(
+              "unsupported operation [" + op + "]");
-            LOG.info("Exception recorded in op: " +
-                    "Create/Write/Close");
- 
+            LOG.error("Exception recorded in op: Create/Write/Close, "
+                + "file: \"" + filePath + "\"", e);
-            LOG.info("Exception recorded in op: OpenRead " + e);
+            LOG.error("Exception recorded in op: OpenRead, " + "file: \""
+                + filePath + "\"", e);
-            LOG.info("Exception recorded in op: Rename");
-
+            LOG.error("Exception recorded in op: Rename, " + "file: \""
+                + filePath + "\"", e);
-            LOG.info("Exception in recorded op: Delete");
-
+            LOG.error("Exception recorded in op: Delete, " + "file: \""
+                + filePath + "\"", e);
