HDFS-11694. Block Storage: Add Support for 2 BlockIDBuffers and also for periodic flush of BlockIDBuffer. Contributed by Mukul Kumar Singh

-import java.io.FileOutputStream;
-import java.nio.ByteBuffer;
-import java.nio.channels.FileChannel;
-import java.nio.file.Paths;
-import static org.apache.hadoop.cblock.CBlockConfigKeys.DFS_CBLOCK_CACHE_BLOCK_BUFFER_SIZE;
-import static org.apache.hadoop.cblock.CBlockConfigKeys.DFS_CBLOCK_CACHE_BLOCK_BUFFER_SIZE_DEFAULT;
-
-   * Right now we have a single buffer and we block when we write it to
-   * the file.
-   */
-  private final ByteBuffer blockIDBuffer;
-
-  /**
-  private final int blockBufferSize;
-  private final static String DIRTY_LOG_PREFIX = "DirtyLog";
+  private final BlockBufferManager blockBufferManager;
+  public final static String DIRTY_LOG_PREFIX = "DirtyLog";
-    blockBufferSize = config.getInt(DFS_CBLOCK_CACHE_BLOCK_BUFFER_SIZE,
-        DFS_CBLOCK_CACHE_BLOCK_BUFFER_SIZE_DEFAULT) * (Long.SIZE / Byte.SIZE);
-    LOG.info("Cache: Block Size: {}", blockBufferSize);
-    blockIDBuffer = ByteBuffer.allocateDirect(blockBufferSize);
+    blockBufferManager = new BlockBufferManager(config, parentCache);
+    blockBufferManager.start();
-      parentCache.getTargetMetrics().incNumDirtyLogBlockUpdated();
-      blockIDBuffer.putLong(block.getBlockID());
-      if (blockIDBuffer.remaining() == 0) {
-        writeBlockBufferToFile(blockIDBuffer);
-      }
+      blockBufferManager.addToBlockBuffer(block.getBlockID());
-   * Write Block Buffer to file.
-   *
-   * @param blockBuffer - ByteBuffer
-   * @throws IOException
-   */
-  private synchronized void writeBlockBufferToFile(ByteBuffer blockBuffer)
-      throws IOException {
-    long startTime = Time.monotonicNow();
-    boolean append = false;
-    int bytesWritten = 0;
-
-    // If there is nothing written to blockId buffer,
-    // then skip flushing of blockId buffer
-    if (blockBuffer.position() == 0) {
-      return;
-    }
-
-    blockBuffer.flip();
-    String fileName =
-        String.format("%s.%s", DIRTY_LOG_PREFIX, Time.monotonicNow());
-    String log = Paths.get(parentCache.getDbPath().toString(), fileName)
-        .toString();
-
-    try {
-      FileChannel channel = new FileOutputStream(log, append).getChannel();
-      bytesWritten = channel.write(blockBuffer);
-    } catch (Exception ex) {
-      LOG.error("Unable to sync the Block map to disk -- This might cause a " +
-          "data loss or corruption", ex);
-      parentCache.getTargetMetrics().incNumFailedDirtyBlockFlushes();
-      throw ex;
-    } finally {
-      blockBuffer.clear();
-    }
-
-    parentCache.processDirtyMessage(fileName);
-    blockIDBuffer.clear();
-    long endTime = Time.monotonicNow();
-    if (parentCache.isTraceEnabled()) {
-      parentCache.getTracer().info(
-          "Task=DirtyBlockLogWrite,Time={} bytesWritten={}",
-          endTime - startTime, bytesWritten);
-    }
-
-    parentCache.getTargetMetrics().incNumBytesDirtyLogWritten(bytesWritten);
-    parentCache.getTargetMetrics().incNumBlockBufferFlush();
-    parentCache.getTargetMetrics()
-        .updateBlockBufferFlushLatency(endTime - startTime);
-    LOG.debug("Block buffer writer bytesWritten:{} Time:{}",
-        bytesWritten, endTime - startTime);
-  }
-
-  /**
-    try {
-      writeBlockBufferToFile(this.blockIDBuffer);
-    } catch (IOException e) {
-      LOG.error("Unable to sync the Block map to disk -- This might cause a " +
-          "data loss or corruption");
-    }
+    blockBufferManager.shutdown();
