HDFS-5050.  Add DataNode support for mlock and munlock  (contributed by Andrew Wang)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1517106 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.commons.io.IOUtils;
+  final FsDatasetCache cacheManager;
+    cacheManager = new FsDatasetCache(this);
+   * Returns the total cache used by the datanode (in bytes).
+   */
+  @Override // FSDatasetMBean
+  public long getCacheUsed() {
+    return cacheManager.getCacheUsed();
+  }
+
+  /**
+   * Returns the total cache capacity of the datanode (in bytes).
+   */
+  @Override // FSDatasetMBean
+  public long getCacheCapacity() {
+    return cacheManager.getCacheCapacity();
+  }
+
+  /**
+   * Returns the total amount of cache remaining (in bytes).
+   */
+  @Override // FSDatasetMBean
+  public long getCacheRemaining() {
+    return cacheManager.getCacheRemaining();
+  }
+
+  /**
+    // uncache the block
+    cacheManager.uncacheBlock(bpid, replicaInfo);
+  @Override // FsDatasetSpi
+  public BlockListAsLongs getCacheReport(String bpid) {
+    return new BlockListAsLongs(cacheManager.getCachedBlocks(bpid), null);
+  }
+
+      // Uncache the block synchronously
+      cacheManager.uncacheBlock(bpid, invalidBlks[i]);
+  synchronized boolean validToCache(String bpid, Block blk) {
+    ReplicaInfo info = volumeMap.get(bpid, blk);
+    if (info == null) {
+      LOG.warn("Failed to cache replica " + blk + ": ReplicaInfo not found.");
+      return false;
+    }
+    FsVolumeImpl volume = (FsVolumeImpl)info.getVolume();
+    if (volume == null) {
+      LOG.warn("Failed to cache replica " + blk + ": Volume not found.");
+      return false;
+    }
+    if (info.getState() != ReplicaState.FINALIZED) {
+      LOG.warn("Failed to cache replica " + blk + ": Replica is not"
+          + " finalized.");
+      return false;
+    }
+    return true;
+  }
+
+  /**
+   * Asynchronously attempts to cache a single block via {@link FsDatasetCache}.
+   */
+  private void cacheBlock(String bpid, Block blk) {
+    ReplicaInfo info;
+    FsVolumeImpl volume;
+    synchronized (this) {
+      if (!validToCache(bpid, blk)) {
+        return;
+      }
+      info = volumeMap.get(bpid, blk);
+      volume = (FsVolumeImpl)info.getVolume();
+    }
+    // Try to open block and meta streams
+    FileInputStream blockIn = null;
+    FileInputStream metaIn = null;
+    boolean success = false;
+    try {
+      ExtendedBlock extBlk = new ExtendedBlock(bpid, blk);
+      blockIn = (FileInputStream)getBlockInputStream(extBlk, 0);
+      metaIn = (FileInputStream)getMetaDataInputStream(extBlk)
+          .getWrappedStream();
+      success = true;
+    } catch (ClassCastException e) {
+      LOG.warn("Failed to cache replica " + blk + ": Underlying blocks"
+          + " are not backed by files.", e);
+    } catch (IOException e) {
+      LOG.warn("Failed to cache replica " + blk + ": IOException while"
+          + " trying to open block or meta files.", e);
+    }
+    if (!success) {
+      IOUtils.closeQuietly(blockIn);
+      IOUtils.closeQuietly(metaIn);
+      return;
+    }
+    cacheManager.cacheBlock(bpid, blk, volume, blockIn, metaIn);
+  }
+
+  @Override // FsDatasetSpi
+  public void cache(String bpid, Block[] cacheBlks) {
+    for (int i=0; i<cacheBlks.length; i++) {
+      cacheBlock(bpid, cacheBlks[i]);
+    }
+  }
+
+  @Override // FsDatasetSpi
+  public void uncache(String bpid, Block[] uncacheBlks) {
+    for (int i=0; i<uncacheBlks.length; i++) {
+      Block blk = uncacheBlks[i];
+      cacheManager.uncacheBlock(bpid, blk);
+    }
+  }
+
