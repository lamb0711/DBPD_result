HDFS-9624. DataNode start slowly due to the initial DU command operations. (Lin Yiqun via wang)

-import org.apache.hadoop.util.Time;
+import org.apache.hadoop.util.Timer;
-  private static final String DU_CACHE_FILE = "dfsUsed";
+  @VisibleForTesting
+  public static final String DU_CACHE_FILE = "dfsUsed";
+  private final long cachedDfsUsedCheckTime;
+  private final Timer timer;
+   * @param timer include methods for getting time
-      Configuration conf) throws IOException {
+      Configuration conf, Timer timer) throws IOException {
+    this.cachedDfsUsedCheckTime =
+        conf.getLong(
+            DFSConfigKeys.DFS_DN_CACHED_DFSUSED_CHECK_INTERVAL_MS,
+            DFSConfigKeys.DFS_DN_CACHED_DFSUSED_CHECK_INTERVAL_DEFAULT_MS);
+    this.timer = timer;
+
-   /**
-   * Read in the cached DU value and return it if it is less than 600 seconds
-   * old (DU update interval). Slight imprecision of dfsUsed is not critical
-   * and skipping DU can significantly shorten the startup time.
-   * If the cached value is not available or too old, -1 is returned.
+  /**
+   * Read in the cached DU value and return it if it is less than
+   * cachedDfsUsedCheckTime which is set by
+   * dfs.datanode.cached-dfsused.check.interval.ms parameter. Slight imprecision
+   * of dfsUsed is not critical and skipping DU can significantly shorten the
+   * startup time. If the cached value is not available or too old, -1 is
+   * returned.
-      if (mtime > 0 && (Time.now() - mtime < 600000L)) {
+      if (mtime > 0 && (timer.now() - mtime < cachedDfsUsedCheckTime)) {
-        out.write(Long.toString(used) + " " + Long.toString(Time.now()));
+        out.write(Long.toString(used) + " " + Long.toString(timer.now()));
-        if (sc.hasNextLong() && (sc.nextLong() > Time.now())) {
+        if (sc.hasNextLong() && (sc.nextLong() > timer.now())) {
