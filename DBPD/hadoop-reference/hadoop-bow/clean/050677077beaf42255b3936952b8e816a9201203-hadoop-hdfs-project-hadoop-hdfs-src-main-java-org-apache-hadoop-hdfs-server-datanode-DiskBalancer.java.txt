HDFS-9720. DiskBalancer : Add configuration parameters. Contributed by Anu Engineer.

-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import java.util.concurrent.atomic.AtomicBoolean;
+    this.bandwidth = conf.getInt(
+        DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_THRUPUT,
+        DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_THRUPUT_DEFAULT);
-   * @param bandwidth   - BytesPerSec to copy
-                         long bandwidth, boolean force)
-      throws DiskBalancerException {
+                         boolean force) throws DiskBalancerException {
-      NodePlan nodePlan =
-          verifyPlan(planID, planVersion, plan, bandwidth, force);
+      NodePlan nodePlan = verifyPlan(planID, planVersion, plan, force);
-      this.bandwidth = bandwidth;
-   * @param bandwidth   - Max disk bandwidth to use per second.
-                              long bandwidth, boolean force)
-      throws DiskBalancerException {
+                               boolean force) throws DiskBalancerException {
-      createWorkPlan(sourceVol, destVol, step.getBytesToMove());
+      createWorkPlan(sourceVol, destVol, step);
-   * @param bytesToMove - number of bytes to move
+   * @param step        - Move Step
-                              long bytesToMove) throws DiskBalancerException {
+                              Step step) throws DiskBalancerException {
-      throw new DiskBalancerException("Same source and destination",
-          DiskBalancerException.Result.INVALID_MOVE);
+      LOG.info("Disk Balancer - source & destination volumes are same.");
+      throw new DiskBalancerException("source and destination volumes are " +
+          "same.", DiskBalancerException.Result.INVALID_MOVE);
-
+    long bytesToMove = step.getBytesToMove();
+
+    // all these values can be zero, if so we will use
+    // values from configuration.
+    work.setBandwidth(step.getBandwidth());
+    work.setTolerancePercent(step.getTolerancePercent());
+    work.setMaxDiskErrors(step.getMaxDiskErrors());
-   * TODO : Add implementation for this class. This is here as a place holder so
-   * that Datanode can make calls into this class.
+    private long diskBandwidth;
+    private long blockTolerance;
+    private long maxDiskErrors;
-      // TODO : Read Config values.
+
+      this.diskBandwidth = conf.getLong(
+          DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_THRUPUT,
+          DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_THRUPUT_DEFAULT);
+
+      this.blockTolerance = conf.getLong(
+          DFSConfigKeys.DFS_DISK_BALANCER_BLOCK_TOLERANCE,
+          DFSConfigKeys.DFS_DISK_BALANCER_BLOCK_TOLERANCE_DEFAULT);
+
+      this.maxDiskErrors = conf.getLong(
+          DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_ERRORS,
+          DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_ERRORS_DEFAULT);
+
+      // Since these are user provided values make sure it is sane
+      // or ignore faulty values.
+      if (this.diskBandwidth <= 0) {
+        LOG.debug("Found 0 or less as max disk throughput, ignoring config " +
+            "value. value : " + diskBandwidth);
+        diskBandwidth =
+            DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_THRUPUT_DEFAULT;
+      }
+
+      if (this.blockTolerance <= 0) {
+        LOG.debug("Found 0 or less for block tolerance value, ignoring config" +
+            "value. value : " + blockTolerance);
+        blockTolerance =
+            DFSConfigKeys.DFS_DISK_BALANCER_BLOCK_TOLERANCE_DEFAULT;
+
+      }
+
+      if (this.maxDiskErrors < 0) {
+        LOG.debug("Found  less than 0 for maxDiskErrors value, ignoring " +
+            "config value. value : " + maxDiskErrors);
+        maxDiskErrors =
+            DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_ERRORS_DEFAULT;
+      }
