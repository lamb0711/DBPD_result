Merge remote-tracking branch 'apache/trunk' into HDFS-7285

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/Namesystem.java
	hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java

Change-Id: I8511c4d64b0959e79129febc179845a3892fedcc

- * thread-pool of Workers that loop on WorkRequest<T> inputQueue and for each
- * consumed WorkRequest Workers invoke WorkRequestProcessor.processItem()
- * and output resulting WorkReport<R> to the outputQueue.
+ * thread-pool of Workers that loop on WorkRequest{@literal <T>} inputQueue
+ * and for each consumed WorkRequest Workers invoke
+ * WorkRequestProcessor.processItem() and output resulting
+ * WorkReport{@literal <R>} to the outputQueue.
-   *  Add another worker that will consume WorkRequest<T> items from input
-   *  queue, process each item using supplied processor, and for every
-   *  processed item output WorkReport<R> to output queue.
+   *  Add another worker that will consume WorkRequest{@literal <T>} items
+   *  from input queue, process each item using supplied processor, and for
+   *  every processed item output WorkReport{@literal <R>} to output queue.
-   *  @param  WorkRequest<T> item to be processed.
+   *  @param  workRequest item to be processed.
-   *  @return  WorkReport<R> item returned by processor's processItem().
+   *  @return  item returned by processor's processItem().
-   *  @return  WorkReport<R> item returned by processor's processItem().
+   *  @return  item returned by processor's processItem().
