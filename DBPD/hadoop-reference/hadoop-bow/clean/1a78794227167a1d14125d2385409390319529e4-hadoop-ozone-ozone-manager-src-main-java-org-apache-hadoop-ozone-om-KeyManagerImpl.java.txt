HDDS-1624 : Refactor operations inside the bucket lock in OM key write. (#882)



+import org.apache.hadoop.utils.UniqueId;
-    long currentTime = Time.monotonicNowNanos();
+    long currentTime = UniqueId.next();
-    String openKey;
+    // NOTE size of a key is not a hard limit on anything, it is a value that
+    // client should expect, in terms of current size of key. If client sets
+    // a value, then this value is used, otherwise, we allocate a single
+    // block which is the current size, if read by the client.
+    final long size = args.getDataSize() >= 0 ?
+        args.getDataSize() : scmBlockSize;
+    final List<OmKeyLocationInfo> locations = new ArrayList<>();
+
+    ReplicationFactor factor = args.getFactor();
+    if (factor == null) {
+      factor = useRatis ? ReplicationFactor.THREE : ReplicationFactor.ONE;
+    }
+
+    ReplicationType type = args.getType();
+    if (type == null) {
+      type = useRatis ? ReplicationType.RATIS : ReplicationType.STAND_ALONE;
+    }
+
+    String dbKeyName = metadataManager.getOzoneKey(
+        args.getVolumeName(), args.getBucketName(), args.getKeyName());
-      // NOTE size of a key is not a hard limit on anything, it is a value that
-      // client should expect, in terms of current size of key. If client sets
-      // a value, then this value is used, otherwise, we allocate a single
-      // block which is the current size, if read by the client.
-      long size = args.getDataSize() >= 0 ? args.getDataSize() : scmBlockSize;
-      List<OmKeyLocationInfo> locations = new ArrayList<>();
-      if (args.getIsMultipartKey()) {
-        keyInfo = prepareMultipartKeyInfo(args, size, locations, encInfo);
-        //TODO args.getMetadata
-      } else {
-        keyInfo = prepareKeyInfo(args, size, locations, encInfo);
-      }
-
-      openVersion = keyInfo.getLatestVersionLocations().getVersion();
-      openKey = metadataManager.getOpenKey(
-          volumeName, bucketName, keyName, currentTime);
-      if (metadataManager.getOpenKeyTable().get(openKey) != null) {
-        // This should not happen. If this condition is satisfied, it means
-        // that we have generated a same openKeyId (i.e. currentTime) for two
-        // different client who are trying to write the same key at the same
-        // time. The chance of this happening is very, very minimal.
-
-        // Do we really need this check? Can we avoid this to gain some
-        // minor performance improvement?
-        LOG.warn("Cannot allocate key. The generated open key id is already" +
-            "used for the same key which is currently being written.");
-        throw new OMException("Cannot allocate key. Not able to get a valid" +
-            "open key id.", ResultCodes.KEY_ALLOCATION_ERROR);
-      }
-      LOG.debug("Key {} allocated in volume {} bucket {}",
-          keyName, volumeName, bucketName);
+      keyInfo = prepareKeyInfo(args, dbKeyName, size, locations, encInfo);
-
+    if (keyInfo == null) {
+      // the key does not exist, create a new object, the new blocks are the
+      // version 0
+      keyInfo = createKeyInfo(args, locations, factor, type, size, encInfo);
+    }
+    openVersion = keyInfo.getLatestVersionLocations().getVersion();
+    LOG.debug("Key {} allocated in volume {} bucket {}",
+        keyName, volumeName, bucketName);
-  private OmKeyInfo prepareKeyInfo(OmKeyArgs args, long size,
+  private OmKeyInfo prepareKeyInfo(
+      OmKeyArgs keyArgs, String dbKeyName, long size,
-    ReplicationFactor factor = args.getFactor();
-    ReplicationType type = args.getType();
-    OmKeyInfo keyInfo;
-    // If user does not specify a replication strategy or
-    // replication factor, OM will use defaults.
-    if (factor == null) {
-      factor = useRatis ? ReplicationFactor.THREE : ReplicationFactor.ONE;
-    }
-    if (type == null) {
-      type = useRatis ? ReplicationType.RATIS : ReplicationType.STAND_ALONE;
-    }
-    String objectKey = metadataManager.getOzoneKey(
-        args.getVolumeName(), args.getBucketName(), args.getKeyName());
-    keyInfo = metadataManager.getKeyTable().get(objectKey);
-    if (keyInfo != null) {
+    OmKeyInfo keyInfo = null;
+    if (keyArgs.getIsMultipartKey()) {
+      keyInfo = prepareMultipartKeyInfo(keyArgs, size, locations, encInfo);
+      //TODO args.getMetadata
+    } else if (metadataManager.getKeyTable().isExist(dbKeyName)) {
+      keyInfo = metadataManager.getKeyTable().get(dbKeyName);
-    } else {
-      // the key does not exist, create a new object, the new blocks are the
-      // version 0
-      keyInfo = createKeyInfo(args, locations, factor, type, size, encInfo);
-    metadataManager.getLock().acquireBucketLock(volumeName, bucketName);
+    List<OmKeyLocationInfo> locationInfoList = args.getLocationInfoList();
+    String objectKey = metadataManager
+        .getOzoneKey(volumeName, bucketName, keyName);
+    String openKey = metadataManager
+        .getOpenKey(volumeName, bucketName, keyName, clientID);
+    Preconditions.checkNotNull(locationInfoList);
+      metadataManager.getLock().acquireBucketLock(volumeName, bucketName);
-      String openKey = metadataManager.getOpenKey(volumeName, bucketName,
-          keyName, clientID);
-      String objectKey = metadataManager.getOzoneKey(
-          volumeName, bucketName, keyName);
-      List<OmKeyLocationInfo> locationInfoList = args.getLocationInfoList();
-      Preconditions.checkNotNull(locationInfoList);
