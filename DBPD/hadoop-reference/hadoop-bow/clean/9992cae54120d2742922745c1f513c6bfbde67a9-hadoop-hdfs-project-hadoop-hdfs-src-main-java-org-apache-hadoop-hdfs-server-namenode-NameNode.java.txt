Reverting the previous trunk merge since it added other unintended changes in addition


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1177127 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.hadoop.HadoopIllegalArgumentException;
+import org.apache.hadoop.hdfs.HDFSPolicyProvider;
+import org.apache.hadoop.hdfs.protocol.UnregisteredNodeException;
+import org.apache.hadoop.hdfs.server.common.IncorrectVersionException;
-import org.apache.hadoop.hdfs.server.namenode.ha.HAContext;
+import org.apache.hadoop.hdfs.server.protocol.NodeRegistration;
+import org.apache.hadoop.ipc.RPC;
+import org.apache.hadoop.ipc.Server;
+
+
+
-  protected final Configuration conf;
-  private final HAContext haContext;
-  protected InetSocketAddress getServiceRpcServerAddress(Configuration conf) {
+  protected InetSocketAddress getServiceRpcServerAddress(Configuration conf)
+    throws IOException {
-  protected InetSocketAddress getRpcServerAddress(Configuration conf) {
+  protected InetSocketAddress getRpcServerAddress(Configuration conf) throws IOException {
+    initializeGenericKeys(conf);
-    startCommonServices(conf);
+    activate(conf);
-  /** Start the services common to active and standby states */
-  private void startCommonServices(Configuration conf) throws IOException {
-    namesystem.startCommonServices(conf);
+  /**
+   * Activate name-node servers and threads.
+   */
+  void activate(Configuration conf) throws IOException {
+    if ((isRole(NamenodeRole.NAMENODE))
+        && (UserGroupInformation.isSecurityEnabled())) {
+      namesystem.activateSecretManager();
+    }
+    namesystem.activate(conf);
+    startHttpServer(conf);
+    startTrashEmptier(conf);
+    
+    
-      LOG.info(getRole() + " service server is up at: "
-          + rpcServer.getServiceRpcAddress());
+      LOG.info(getRole() + " service server is up at: " + rpcServer.getServiceRpcAddress()); 
-    startHttpServer(conf);
-  
-  private void stopCommonServices() {
-    if(namesystem != null) namesystem.close();
-    if(rpcServer != null) rpcServer.stop();
-    if (plugins != null) {
-      for (ServicePlugin p : plugins) {
-        try {
-          p.stop();
-        } catch (Throwable t) {
-          LOG.warn("ServicePlugin " + p + " could not be stopped", t);
-        }
-      }
-    }   
-    stopHttpServer();
-  }
-  
+
-  private void stopTrashEmptier() {
-    if (this.emptier != null) {
-      emptier.interrupt();
-      emptier = null;
-    }
-  }
-  
-  
-  private void stopHttpServer() {
-    try {
-      if (httpServer != null) httpServer.stop();
-    } catch (Exception e) {
-      LOG.error("Exception while stopping httpserver", e);
-    }
-  }
-   * @throws IOException on error
+   * @throws IOException
-      throws IOException {
-    this.conf = conf;
+      throws IOException { 
-    this.haContext = new NameNodeHAContext();
+    this.state = !haEnabled ? ACTIVE_STATE : STANDBY_STATE;
-      initializeGenericKeys(conf, getNameServiceId(conf));
-      if (!haEnabled) {
-        state = ACTIVE_STATE;
-      } else {
-        state = STANDBY_STATE;;
-      }
-      state.enterState(haContext);
-    } catch (ServiceFailedException e) {
-      this.stop();
-      throw new IOException("Service failed to start", e);
-    } catch (HadoopIllegalArgumentException e) {
-      this.stop();
-      throw e;
-      LOG.info("Caught interrupted exception " + ie);
-    try {
-      state.exitState(haContext);
-    } catch (ServiceFailedException e) {
-      LOG.info("Encountered exception while exiting state " + e);
+    if (plugins != null) {
+      for (ServicePlugin p : plugins) {
+        try {
+          p.stop();
+        } catch (Throwable t) {
+          LOG.warn("ServicePlugin " + p + " could not be stopped", t);
+        }
+      }
-    stopCommonServices();
+    try {
+      if (httpServer != null) httpServer.stop();
+    } catch (Exception e) {
+      LOG.error("Exception while stopping httpserver", e);
+    }
+    if(namesystem != null) namesystem.close();
+    if(emptier != null) emptier.interrupt();
+    if(rpcServer != null) rpcServer.stop();
-   * @param nameserviceId name service Id
-  public static void initializeGenericKeys(Configuration conf, String
-      nameserviceId) {
+  public static void initializeGenericKeys(Configuration conf) {
+    final String nameserviceId = DFSUtil.getNameServiceId(conf);
+    
-  /** 
-   * Get the name service Id for the node
-   * @return name service Id or null if federation is not configured
-   */
-  protected String getNameServiceId(Configuration conf) {
-    return DFSUtil.getNamenodeNameServiceId(conf);
-  }
-  
-    state.setState(haContext, ACTIVE_STATE);
+    state.setState(this, ACTIVE_STATE);
-    state.setState(haContext, STANDBY_STATE);
+    state.setState(this, STANDBY_STATE);
-    state.checkOperation(haContext, op);
+    state.checkOperation(this, op);
-  /**
-   * Class used as expose {@link NameNode} as context to {@link HAState}
-   */
-  private class NameNodeHAContext implements HAContext {
-    @Override
-    public void setState(HAState s) {
-      state = s;
-    }
-
-    @Override
-    public HAState getState() {
-      return state;
-    }
-
-    @Override
-    public void startActiveServices() throws IOException {
-      namesystem.startActiveServices();
-      startTrashEmptier(conf);
-    }
-
-    @Override
-    public void stopActiveServices() throws IOException {
-      namesystem.stopActiveServices();
-      stopTrashEmptier();
-    }
-
-    @Override
-    public void startStandbyServices() throws IOException {
-      // TODO:HA Start reading editlog from active
-    }
-
-    @Override
-    public void stopStandbyServices() throws IOException {
-      // TODO:HA Stop reading editlog from active
-    }
+  public synchronized HAState getState() {
+    return state;
+  }
+  
+  public synchronized void setState(final HAState s) {
+    state = s;
