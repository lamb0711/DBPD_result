Merge trunk into HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1196458 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
+    report.setContainerId(attemptInfo.getContainerId());
+    String []hostSplits = attemptInfo.getHostname().split(":");
+    if (hostSplits.length != 2) {
+      report.setNodeManagerHost("UNKNOWN");
+    } else {
+      report.setNodeManagerHost(hostSplits[0]);
+      report.setNodeManagerPort(Integer.parseInt(hostSplits[1]));
+    }
+    report.setNodeManagerHttpPort(attemptInfo.getHttpPort());
-    //TODO ContainerId needs to be part of some historyEvent to be able to 
-    //render the log directory.
-    ContainerId containerId = 
-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(
-            ContainerId.class);
-    containerId.setId(-1);
-    ApplicationAttemptId applicationAttemptId =
-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(
-            ApplicationAttemptId.class);
-    applicationAttemptId.setAttemptId(-1);
-    ApplicationId applicationId =
-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(
-            ApplicationId.class);
-    applicationId.setClusterTimestamp(-1);
-    applicationId.setId(-1);
-    applicationAttemptId.setApplicationId(applicationId);
-    containerId.setApplicationAttemptId(applicationAttemptId);
-    return containerId;
+    return attemptInfo.getContainerId();
-    // TODO Verify this is correct.
-    return attemptInfo.getTrackerName();
+    return attemptInfo.getHostname();
-    return attemptInfo.getHostname() + ":" + attemptInfo.getHttpPort();
+    return attemptInfo.getTrackerName() + ":" + attemptInfo.getHttpPort();
+  }
+  
+  @Override
+  public String getNodeRackName() {
+    return attemptInfo.getRackname();
