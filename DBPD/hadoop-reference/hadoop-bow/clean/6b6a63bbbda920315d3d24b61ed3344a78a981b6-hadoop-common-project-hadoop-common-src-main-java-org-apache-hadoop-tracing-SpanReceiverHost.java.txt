Merge commit '456e901a4c5c639267ee87b8e5f1319f256d20c2' (HDFS-6407. Add sorting and pagination in the datanode tab of the NN Web UI. Contributed by Haohui Mai.) into HDFS-7285-merge

-import java.io.BufferedReader;
-import java.io.DataInputStream;
-import java.io.EOFException;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.InputStreamReader;
-import java.util.UUID;
-import org.apache.commons.io.Charsets;
-import org.apache.hadoop.io.IOUtils;
-import org.apache.hadoop.tracing.TraceUtils;
-import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.htrace.impl.LocalFileSpanReceiver;
-    "spanreceiver.classes";
+      "spanreceiver.classes";
-  private static String getUniqueLocalTraceFileName() {
-    String tmp = System.getProperty("java.io.tmpdir", "/tmp");
-    String nonce = null;
-    BufferedReader reader = null;
-    try {
-      // On Linux we can get a unique local file name by reading the process id
-      // out of /proc/self/stat.  (There isn't any portable way to get the
-      // process ID from Java.)
-      reader = new BufferedReader(
-          new InputStreamReader(new FileInputStream("/proc/self/stat"),
-                                Charsets.UTF_8));
-      String line = reader.readLine();
-      if (line == null) {
-        throw new EOFException();
-      }
-      nonce = line.split(" ")[0];
-    } catch (IOException e) {
-    } finally {
-      IOUtils.cleanup(LOG, reader);
-    }
-    if (nonce == null) {
-      // If we can't use the process ID, use a random nonce.
-      nonce = UUID.randomUUID().toString();
-    }
-    return new File(tmp, nonce).getAbsolutePath();
-  }
-
-      String uniqueFile = getUniqueLocalTraceFileName();
+      String uniqueFile = LocalFileSpanReceiver.getUniqueLocalTraceFileName();
-    SpanReceiverInfo info[] = new SpanReceiverInfo[receivers.size()];
+    SpanReceiverInfo[] info = new SpanReceiverInfo[receivers.size()];
