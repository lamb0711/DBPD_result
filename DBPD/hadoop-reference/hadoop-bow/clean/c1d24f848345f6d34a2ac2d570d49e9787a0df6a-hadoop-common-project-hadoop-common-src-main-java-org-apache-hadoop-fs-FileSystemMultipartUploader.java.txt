HDFS-13713. Add specification of Multipart Upload API to FS specification, with contract tests.

Contributed by Ewan Higgs and Steve Loughran.

+import java.util.ArrayList;
+import java.util.Map;
+import java.util.UUID;
-import com.google.common.base.Preconditions;
-import org.apache.commons.lang3.tuple.Pair;
+import static org.apache.hadoop.io.IOUtils.cleanupWithLogger;
-
+    checkPutArguments(filePath, inputStream, partNumber, uploadId,
+        lengthInBytes);
-      org.apache.hadoop.io.IOUtils.cleanupWithLogger(LOG, inputStream);
+      cleanupWithLogger(LOG, inputStream);
+    String uuid = UUID.randomUUID().toString();
-            mergePaths(new Path("_multipart"),
+            mergePaths(new Path("_multipart_" + uuid),
-  public PathHandle complete(Path filePath,
-      List<Pair<Integer, PartHandle>> handles, UploadHandle multipartUploadId)
-      throws IOException {
+  public PathHandle complete(Path filePath, Map<Integer, PartHandle> handleMap,
+      UploadHandle multipartUploadId) throws IOException {
-    if (handles.isEmpty()) {
-      throw new IOException("Empty upload");
-    }
-    // If destination already exists, we believe we already completed it.
-    if (fs.exists(filePath)) {
-      return getPathHandle(filePath);
-    }
+    checkPartHandles(handleMap);
+    List<Map.Entry<Integer, PartHandle>> handles =
+        new ArrayList<>(handleMap.entrySet());
+    handles.sort(Comparator.comparingInt(Map.Entry::getKey));
-    handles.sort(Comparator.comparing(Pair::getKey));
-    Path collectorPath = createCollectorPath(filePath);
+    byte[] uploadIdByteArray = multipartUploadId.toByteArray();
+    Path collectorPath = new Path(new String(uploadIdByteArray, 0,
+        uploadIdByteArray.length, Charsets.UTF_8));
+
