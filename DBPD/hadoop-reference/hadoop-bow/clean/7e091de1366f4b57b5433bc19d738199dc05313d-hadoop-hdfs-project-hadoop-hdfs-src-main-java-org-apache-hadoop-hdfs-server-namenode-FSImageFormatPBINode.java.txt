HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.

-import org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.StripedBlocksFeature;
+      boolean isStriped = f.getIsStriped();
+      ECSchema schema = ErasureCodingSchemaManager.getSystemDefaultSchema();
-      BlockInfoContiguous[] blocks = null;
-      if (!f.hasStripedBlocks()) {
-        blocks = new BlockInfoContiguous[bp.size()];
-        for (int i = 0, e = bp.size(); i < e; ++i) {
-          blocks[i] = new BlockInfoContiguous(PBHelper.convert(bp.get(i)), replication);
+      if (isStriped) {
+        Preconditions.checkState(f.hasStripingCellSize());
+      }
+      BlockInfo[] blocks = new BlockInfo[bp.size()];
+      for (int i = 0; i < bp.size(); ++i) {
+        BlockProto b = bp.get(i);
+        if (isStriped) {
+          blocks[i] = new BlockInfoStriped(PBHelper.convert(b), schema,
+              (int)f.getStripingCellSize());
+        } else {
+          blocks[i] = new BlockInfoContiguous(PBHelper.convert(b),
+              replication);
-          (byte)f.getStoragePolicyID());
+          (byte)f.getStoragePolicyID(), isStriped);
-      
+
-      FileWithStripedBlocksFeature stripeFeature = null;
-      if (f.hasStripedBlocks()) {
-        // TODO: HDFS-7859
-        ECSchema schema = ErasureCodingSchemaManager.getSystemDefaultSchema();
-        stripeFeature = file.addStripedBlocksFeature();
-        if (bp.size() > 0) {
-          // if a striped file has block, the cellSize must exist in proto
-          final int cellSize = f.getStripedBlocks().getCellSize();
-          for (BlockProto b : bp) {
-            stripeFeature.addBlock(new BlockInfoStriped(PBHelper.convert(b),
-                schema, cellSize));
-          }
-        }
-      }
-
-        BlockInfo lastBlk = file.getLastBlock();
-        if (lastBlk != null) {
+        if (blocks.length > 0) {
+          BlockInfo lastBlk = file.getLastBlock();
-          if (stripeFeature != null) {
+          if (isStriped) {
-                striped.getSchema(), striped.getCellSize());
+                schema, (int)f.getStripingCellSize());
-          .setStoragePolicyID(file.getLocalStoragePolicyID());
+          .setStoragePolicyID(file.getLocalStoragePolicyID())
+          .setIsStriped(file.isStriped());
+      BlockInfo[] blocks = n.getBlocks();
-      BlockInfoContiguous[] cBlks = n.getContiguousBlocks();
-      if (cBlks != null) {
-        for (Block block : cBlks) {
+      if (blocks != null) {
+        for (Block block : n.getBlocks()) {
-      FileWithStripedBlocksFeature sb = n.getStripedBlocksFeature();
-      if (sb != null) {
-        StripedBlocksFeature.Builder builder =
-            StripedBlocksFeature.newBuilder();
-        BlockInfoStriped[] sblocks = sb.getBlocks();
-        if (sblocks != null && sblocks.length > 0) {
-          final int cellSize = sblocks[0].getCellSize();
-          for (BlockInfoStriped sblk : sblocks) {
-            assert cellSize == sblk.getCellSize();
-            b.addBlocks(PBHelper.convert(sblk));
-          }
-          builder.setCellSize(cellSize);
+      if (n.isStriped()) {
+        if (blocks != null && blocks.length > 0) {
+          BlockInfo firstBlock = blocks[0];
+          Preconditions.checkState(firstBlock.isStriped());
+          b.setStripingCellSize(((BlockInfoStriped)firstBlock).getCellSize());
+        } else {
+          b.setStripingCellSize(HdfsConstants.BLOCK_STRIPED_CELL_SIZE);
-        b.setStripedBlocks(builder.build());
