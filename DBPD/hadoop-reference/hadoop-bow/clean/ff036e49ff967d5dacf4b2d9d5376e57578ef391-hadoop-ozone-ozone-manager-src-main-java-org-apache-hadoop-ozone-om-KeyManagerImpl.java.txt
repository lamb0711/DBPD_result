HDDS-357. Use DBStore and TableStore for OzoneManager non-background service.
Contributed by Nandakumar.

-import org.apache.hadoop.ozone.OzoneConsts;
-import org.apache.hadoop.hdfs.DFSUtil;
-import org.apache.hadoop.ozone.om.helpers.OmKeyArgs;
-import org.apache.hadoop.ozone.common.BlockGroup;
-import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;
-import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;
-import org.apache.hadoop.ozone.om.exceptions.OMException;
-import org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes;
-import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfoGroup;
-import org.apache.hadoop.ozone.om.helpers.OpenKeySession;
-import org.apache.hadoop.ozone.protocol.proto
-    .OzoneManagerProtocolProtos.KeyInfo;
+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;
+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;
+import org.apache.hadoop.hdfs.DFSUtil;
+import org.apache.hadoop.ozone.OzoneConsts;
+import org.apache.hadoop.ozone.common.BlockGroup;
+import org.apache.hadoop.ozone.om.exceptions.OMException;
+import org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes;
+import org.apache.hadoop.ozone.om.helpers.OmKeyArgs;
+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;
+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;
+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfoGroup;
+import org.apache.hadoop.ozone.om.helpers.OpenKeySession;
+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyInfo;
-import org.apache.hadoop.utils.BatchOperation;
-import org.iq80.leveldb.DBException;
+import org.rocksdb.RocksDBException;
+import org.rocksdb.WriteBatch;
-import java.util.Random;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.DFS_CONTAINER_RATIS_ENABLED_DEFAULT;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.DFS_CONTAINER_RATIS_ENABLED_KEY;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.OZONE_KEY_PREALLOCATION_MAXSIZE;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.OZONE_KEY_PREALLOCATION_MAXSIZE_DEFAULT;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.OZONE_SCM_BLOCK_SIZE_DEFAULT;
-import static org.apache.hadoop.ozone
-    .OzoneConfigKeys.OZONE_SCM_BLOCK_SIZE_IN_MB;
-import org.apache.hadoop.hdds.protocol
-    .proto.HddsProtos.ReplicationType;
-import org.apache.hadoop.hdds.protocol
-    .proto.HddsProtos.ReplicationFactor;
-
+import static org.apache.hadoop.ozone.OzoneConfigKeys.DFS_CONTAINER_RATIS_ENABLED_DEFAULT;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.DFS_CONTAINER_RATIS_ENABLED_KEY;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_KEY_PREALLOCATION_MAXSIZE;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_KEY_PREALLOCATION_MAXSIZE_DEFAULT;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_SCM_BLOCK_SIZE_DEFAULT;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_SCM_BLOCK_SIZE_IN_MB;
-  private final Random random;
-                        OMMetadataManager metadataManager,
-                        OzoneConfiguration conf,
-                        String omId) {
+      OMMetadataManager metadataManager,
+      OzoneConfiguration conf,
+      String omId) {
-    random = new Random();
-
-    if(metadataManager.get(volumeKey) == null) {
+    if (metadataManager.getVolumeTable().get(volumeKey) == null) {
-    if(metadataManager.get(bucketKey) == null) {
+    if (metadataManager.getBucketTable().get(bucketKey) == null) {
-  public OmKeyLocationInfo allocateBlock(OmKeyArgs args, int clientID)
+  public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID)
-      String objectKey = metadataManager.getKeyWithDBPrefix(
-          volumeName, bucketName, keyName);
-      byte[] openKey = metadataManager.getOpenKeyNameBytes(objectKey, clientID);
-      byte[] keyData = metadataManager.get(openKey);
+      byte[] openKey = metadataManager.getOpenKeyBytes(
+          volumeName, bucketName, keyName, clientID);
+
+      byte[] keyData = metadataManager.getOpenKeyTable().get(openKey);
-        LOG.error("Allocate block for a key not in open status in meta store " +
-            objectKey + " with ID " + clientID);
+        LOG.error("Allocate block for a key not in open status in meta store" +
+            " /{}/{}/{} with ID {}", volumeName, bucketName, keyName, clientID);
-      metadataManager.put(openKey, keyInfo.getProtobuf().toByteArray());
+      metadataManager.getOpenKeyTable().put(openKey,
+          keyInfo.getProtobuf().toByteArray());
-    metadataManager.writeLock().lock();
+    validateBucket(volumeName, bucketName);
+
+    metadataManager.writeLock().lock();
+    long currentTime = Time.monotonicNowNanos();
-    if(factor == null) {
-      factor = useRatis ? ReplicationFactor.THREE: ReplicationFactor.ONE;
+    if (factor == null) {
+      factor = useRatis ? ReplicationFactor.THREE : ReplicationFactor.ONE;
-    if(type == null) {
+    if (type == null) {
-      validateBucket(volumeName, bucketName);
-      String objectKey = metadataManager.getKeyWithDBPrefix(
+      byte[] objectKey = metadataManager.getOzoneKeyBytes(
-      byte[] keyKey = metadataManager.getDBKeyBytes(
-          volumeName, bucketName, keyName);
-      byte[] value = metadataManager.get(keyKey);
+      byte[] value = metadataManager.getKeyTable().get(objectKey);
-        long currentTime = Time.now();
+
-      // Generate a random ID which is not already in meta db.
-      int id = -1;
-      // in general this should finish in a couple times at most. putting some
-      // arbitrary large number here to avoid dead loop.
-      for (int j = 0; j < 10000; j++) {
-        id = random.nextInt();
-        byte[] openKey = metadataManager.getOpenKeyNameBytes(objectKey, id);
-        if (metadataManager.get(openKey) == null) {
-          metadataManager.put(openKey, keyInfo.getProtobuf().toByteArray());
-          break;
-        }
+      byte[] openKey = metadataManager.getOpenKeyBytes(
+          volumeName, bucketName, keyName, currentTime);
+      if (metadataManager.getOpenKeyTable().get(openKey) != null) {
+        // This should not happen. If this condition is satisfied, it means
+        // that we have generated a same openKeyId (i.e. currentTime) for two
+        // different client who are trying to write the same key at the same
+        // time. The chance of this happening is very, very minimal.
+
+        // Do we really need this check? Can we avoid this to gain some
+        // minor performance improvement?
+        LOG.warn("Cannot allocate key. The generated open key id is already" +
+            "used for the same key which is currently being written.");
+        throw new OMException("Cannot allocate key. Not able to get a valid" +
+            "open key id.", OMException.ResultCodes.FAILED_KEY_ALLOCATION);
-      if (id == -1) {
-        throw new IOException("Failed to find a usable id for " + objectKey);
-      }
+      metadataManager.getOpenKeyTable().put(openKey,
+          keyInfo.getProtobuf().toByteArray());
-      return new OpenKeySession(id, keyInfo, openVersion);
+      return new OpenKeySession(currentTime, keyInfo, openVersion);
-      if (!(ex instanceof OMException)) {
-        LOG.error("Key open failed for volume:{} bucket:{} key:{}",
-            volumeName, bucketName, keyName, ex);
-      }
+      LOG.error("Key open failed for volume:{} bucket:{} key:{}",
+          volumeName, bucketName, keyName, ex);
-  public void commitKey(OmKeyArgs args, int clientID) throws IOException {
+  public void commitKey(OmKeyArgs args, long clientID) throws IOException {
-      String objectKey = metadataManager.getKeyWithDBPrefix(
+      byte[] openKey = metadataManager.getOpenKeyBytes(volumeName, bucketName,
+          keyName, clientID);
+      byte[] objectKey = metadataManager.getOzoneKeyBytes(
-      byte[] objectKeyBytes = metadataManager.getDBKeyBytes(volumeName,
-          bucketName, keyName);
-      byte[] openKey = metadataManager.getOpenKeyNameBytes(objectKey, clientID);
-      byte[] openKeyData = metadataManager.get(openKey);
+      byte[] openKeyData = metadataManager.getOpenKeyTable().get(openKey);
-            DFSUtil.bytes2String(openKey), ResultCodes.FAILED_KEY_NOT_FOUND);
+            DFSUtil.bytes2String(objectKey), ResultCodes.FAILED_KEY_NOT_FOUND);
+
-      BatchOperation batch = new BatchOperation();
-      batch.delete(openKey);
-      batch.put(objectKeyBytes, keyInfo.getProtobuf().toByteArray());
-      metadataManager.writeBatch(batch);
+      metadataManager.getStore().move(openKey, objectKey,
+          keyInfo.getProtobuf().toByteArray(),
+          metadataManager.getOpenKeyTable(),
+          metadataManager.getKeyTable());
-      byte[] keyKey = metadataManager.getDBKeyBytes(
+      byte[] keyBytes = metadataManager.getOzoneKeyBytes(
-      byte[] value = metadataManager.get(keyKey);
+      byte[] value = metadataManager.getKeyTable().get(keyBytes);
-    } catch (DBException ex) {
+    } catch (IOException ex) {
-      byte[] fromKey = metadataManager.getDBKeyBytes(
+      byte[] fromKey = metadataManager.getOzoneKeyBytes(
-      byte[] fromKeyValue = metadataManager.get(fromKey);
+      byte[] fromKeyValue = metadataManager.getKeyTable().get(fromKey);
+      // A rename is a no-op if the target and source name is same.
+      // TODO: Discuss if we need to throw?.
+      // TODO: Define the semantics of rename more clearly. Today this code
+      // will allow rename of a Key across volumes. This should *not* be
+      // allowed. The documentation of Ozone says that rename is permitted only
+      // within a volume.
+      if (fromKeyName.equals(toKeyName)) {
+        return;
+      }
+
-          metadataManager.getDBKeyBytes(volumeName, bucketName, toKeyName);
-      byte[] toKeyValue = metadataManager.get(toKey);
+          metadataManager.getOzoneKeyBytes(volumeName, bucketName, toKeyName);
+      byte[] toKeyValue = metadataManager.getKeyTable().get(toKey);
-      if (fromKeyName.equals(toKeyName)) {
-        return;
-      }
-      BatchOperation batch = new BatchOperation();
-      batch.delete(fromKey);
-      batch.put(toKey, newKeyInfo.getProtobuf().toByteArray());
-      metadataManager.writeBatch(batch);
-    } catch (DBException ex) {
+      try (WriteBatch batch = new WriteBatch()) {
+        batch.delete(metadataManager.getKeyTable().getHandle(), fromKey);
+        batch.put(metadataManager.getKeyTable().getHandle(), toKey,
+            newKeyInfo.getProtobuf().toByteArray());
+        metadataManager.getStore().write(batch);
+      }
+    } catch (RocksDBException | IOException ex) {
-      byte[] objectKey = metadataManager.getDBKeyBytes(
+      byte[] objectKey = metadataManager.getOzoneKeyBytes(
-      byte[] objectValue = metadataManager.get(objectKey);
+      byte[] objectValue = metadataManager.getKeyTable().get(objectKey);
-      byte[] deletingKey = metadataManager.getDeletedKeyName(objectKey);
-      BatchOperation batch = new BatchOperation();
-      batch.put(deletingKey, objectValue);
-      batch.delete(objectKey);
-      metadataManager.writeBatch(batch);
-    } catch (DBException ex) {
+      metadataManager.getStore().move(objectKey,
+          metadataManager.getKeyTable(),
+          metadataManager.getDeletedTable());
+    } catch (OMException ex) {
+      throw ex;
+    } catch (IOException ex) {
-                                  String startKey, String keyPrefix,
+      String startKey, String keyPrefix,
-    metadataManager.readLock().lock();
-    try {
-      return metadataManager.listKeys(volumeName, bucketName,
-          startKey, keyPrefix, maxKeys);
-    } finally {
-      metadataManager.readLock().unlock();
-    }
+    // We don't take a lock in this path, since we walk the
+    // underlying table using an iterator. That automatically creates a
+    // snapshot of the data, so we don't need these locks at a higher level
+    // when we iterate.
+    return metadataManager.listKeys(volumeName, bucketName,
+        startKey, keyPrefix, maxKeys);
-    metadataManager.readLock().lock();
-    try {
-      return metadataManager.getPendingDeletionKeys(count);
-    } finally {
-      metadataManager.readLock().unlock();
-    }
+    //TODO: Fix this in later patches.
+    return null;
-      throws IOException{
-    Preconditions.checkNotNull(objectKeyName);
-    if (!objectKeyName.startsWith(OzoneConsts.DELETING_KEY_PREFIX)) {
-      throw new IllegalArgumentException("Invalid key name,"
-          + " the name should be the key name with deleting prefix");
-    }
-
-    // Simply removes the entry from OM DB.
-    metadataManager.writeLock().lock();
-    try {
-      byte[] pendingDelKey = DFSUtil.string2Bytes(objectKeyName);
-      byte[] delKeyValue = metadataManager.get(pendingDelKey);
-      if (delKeyValue == null) {
-        throw new IOException("Failed to delete key " + objectKeyName
-            + " because it is not found in DB");
-      }
-      metadataManager.delete(pendingDelKey);
-    } finally {
-      metadataManager.writeLock().unlock();
-    }
+      throws IOException {
+    // TODO : Fix in later patches.
-    if (!objectKeyName.startsWith(OzoneConsts.OPEN_KEY_PREFIX)) {
-      throw new IllegalArgumentException("Invalid key name,"
-          + " the name should be the key name with open key prefix");
-    }
-
-    // Simply removes the entry from OM DB.
-    metadataManager.writeLock().lock();
-    try {
-      byte[] openKey = DFSUtil.string2Bytes(objectKeyName);
-      byte[] delKeyValue = metadataManager.get(openKey);
-      if (delKeyValue == null) {
-        throw new IOException("Failed to delete key " + objectKeyName
-            + " because it is not found in DB");
-      }
-      metadataManager.delete(openKey);
-    } finally {
-      metadataManager.writeLock().unlock();
-    }
+    // TODO: Fix this in later patches.
