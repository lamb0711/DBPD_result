Merging trunk to HDFS-1623 branch.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1179484 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.commons.lang.StringUtils;
-import org.apache.hadoop.yarn.api.records.ApplicationState;
+import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-  
+
-    
+
-  
+
-    for (TaskAttemptCompletionEvent newEvent 
+    for (TaskAttemptCompletionEvent newEvent
-  
+
-    org.apache.hadoop.mapreduce.Counters counters = 
+    org.apache.hadoop.mapreduce.Counters counters =
-        org.apache.hadoop.mapreduce.Counter c = 
-          counters.findCounter(yGrp.getName(), 
+        org.apache.hadoop.mapreduce.Counter c =
+          counters.findCounter(yGrp.getName(),
-  public static org.apache.hadoop.mapred.JobStatus fromYarn(
-      JobReport jobreport, String jobFile) {
+  public static JobStatus fromYarn(JobReport jobreport, String trackingUrl) {
-    org.apache.hadoop.mapred.JobStatus jobStatus =
-        new org.apache.hadoop.mapred.JobStatus(fromYarn(jobreport.getJobId()),
-            jobreport.getSetupProgress(), jobreport.getMapProgress(),
-            jobreport.getReduceProgress(), jobreport.getCleanupProgress(),
-            fromYarn(jobreport.getJobState()),
-            jobPriority, jobreport.getUser(), jobreport.getJobName(),
-            jobFile, jobreport.getTrackingUrl());
+    JobStatus jobStatus = new org.apache.hadoop.mapred.JobStatus(
+        fromYarn(jobreport.getJobId()), jobreport.getSetupProgress(), jobreport
+            .getMapProgress(), jobreport.getReduceProgress(), jobreport
+            .getCleanupProgress(), fromYarn(jobreport.getJobState()),
+        jobPriority, jobreport.getUser(), jobreport.getJobName(), jobreport
+            .getJobFile(), trackingUrl);
-  
+
-    org.apache.hadoop.mapreduce.QueueState qState = 
+    org.apache.hadoop.mapreduce.QueueState qState =
-  
+
-  
+
-    
-    TaskReport rep = new TaskReport(fromYarn(report.getTaskId()), 
+
+    TaskReport rep = new TaskReport(fromYarn(report.getTaskId()),
-    List<org.apache.hadoop.mapreduce.TaskAttemptID> runningAtts 
+    List<org.apache.hadoop.mapreduce.TaskAttemptID> runningAtts
-    for (org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId id 
+    for (org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId id
-  
+
-  
-  public static JobStatus.State fromYarn(ApplicationState state) {
+
+  public static JobStatus.State fromYarn(YarnApplicationState state) {
-    case SUCCEEDED:
+    case FINISHED:
-    TaskTrackerInfo taskTracker = 
+    TaskTrackerInfo taskTracker =
-          TypeConverter.fromYarn(application.getState()),
+          TypeConverter.fromYarn(application.getYarnApplicationState()),
-      org.apache.hadoop.mapreduce.JobID jobId = 
+      org.apache.hadoop.mapreduce.JobID jobId =
-  
-  public static QueueInfo fromYarn(org.apache.hadoop.yarn.api.records.QueueInfo 
+
+  public static QueueInfo fromYarn(org.apache.hadoop.yarn.api.records.QueueInfo
-  
+
-      
-      QueueAclsInfo acl = 
-        new QueueAclsInfo(aclInfo.getQueueName(), 
+
+      QueueAclsInfo acl =
+        new QueueAclsInfo(aclInfo.getQueueName(),
