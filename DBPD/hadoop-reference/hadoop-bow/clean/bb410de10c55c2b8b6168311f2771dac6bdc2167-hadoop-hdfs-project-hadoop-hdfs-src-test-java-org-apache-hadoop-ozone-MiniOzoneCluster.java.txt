HDFS-11184. Ozone: SCM: Make SCM use container protocol. Contributed by Anu Engineer.

- *     http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
+import com.google.common.base.Optional;
+import com.google.common.base.Preconditions;
+import com.google.common.base.Supplier;
+import org.apache.commons.io.FileUtils;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.hdfs.MiniDFSCluster;
+import org.apache.hadoop.ipc.Client;
+import org.apache.hadoop.ipc.RPC;
+import org.apache.hadoop.net.NetUtils;
+import org.apache.hadoop.ozone.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB;
+import org.apache.hadoop.ozone.protocolPB.StorageContainerLocationProtocolPB;
+import org.apache.hadoop.ozone.scm.StorageContainerManager;
+import org.apache.hadoop.ozone.scm.node.SCMNodeManager;
+import org.apache.hadoop.ozone.web.client.OzoneClient;
+import org.apache.hadoop.ozone.web.exceptions.OzoneException;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.test.GenericTestUtils;
+import org.apache.log4j.Level;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.net.URL;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.UUID;
-import com.google.common.base.Optional;
-import com.google.common.base.Preconditions;
-
-import com.google.common.base.Supplier;
-import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.hdfs.MiniDFSCluster;
-import org.apache.hadoop.hdfs.MiniDFSNNTopology;
-import org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType;
-import org.apache.hadoop.ipc.Client;
-import org.apache.hadoop.ipc.RPC;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.ozone.protocolPB.StorageContainerLocationProtocolPB;
-import org.apache.hadoop.ozone.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB;
-import org.apache.hadoop.ozone.storage.StorageContainerManager;
-import org.apache.hadoop.ozone.web.client.OzoneClient;
-import org.apache.hadoop.ozone.web.exceptions.OzoneException;
-import org.apache.hadoop.security.UserGroupInformation;
+import static org.junit.Assert.assertFalse;
- * running tests.  The cluster consists of a StorageContainerManager and
- * multiple DataNodes.  This class subclasses {@link MiniDFSCluster} for
- * convenient reuse of logic for starting DataNodes.  Unlike MiniDFSCluster, it
- * does not start a NameNode, because Ozone does not require a NameNode.
+ * running tests.  The cluster consists of a StorageContainerManager, Namenode
+ * and multiple DataNodes.  This class subclasses {@link MiniDFSCluster} for
+ * convenient reuse of logic for starting DataNodes.
-
-
+  private final Path tempPath;
-   * @param scm StorageContainerManager, already running
+   * @param scm     StorageContainerManager, already running
-        throws IOException {
+      throws IOException {
-  }
-
-  /**
-   * Builder for configuring the MiniOzoneCluster to run.
-   */
-  public static class Builder
-      extends org.apache.hadoop.hdfs.MiniDFSCluster.Builder {
-
-    private final OzoneConfiguration conf;
-    private Optional<String> ozoneHandlerType = Optional.absent();
-
-    /**
-     * Creates a new Builder.
-     *
-     * @param conf configuration
-     */
-    public Builder(OzoneConfiguration conf) {
-      super(conf);
-      this.conf = conf;
-      this.nnTopology(new MiniDFSNNTopology()); // No NameNode required
-    }
-
-    @Override
-    public Builder numDataNodes(int val) {
-      super.numDataNodes(val);
-      return this;
-    }
-
-    public Builder setHandlerType(String handler) {
-      ozoneHandlerType = Optional.of(handler);
-      return this;
-    }
-
-    @Override
-    public MiniOzoneCluster build() throws IOException {
-      if (!ozoneHandlerType.isPresent()) {
-        throw new IllegalArgumentException(
-            "The Ozone handler type must be specified.");
-      }
-
-      conf.setBoolean(OzoneConfigKeys.OZONE_ENABLED, true);
-      conf.setBoolean(OzoneConfigKeys.OZONE_TRACE_ENABLED_KEY, true);
-      conf.set(OzoneConfigKeys.OZONE_HANDLER_TYPE_KEY, ozoneHandlerType.get());
-      conf.set(OzoneConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, "127.0.0.1:0");
-      conf.set(OzoneConfigKeys.OZONE_SCM_DATANODE_ADDRESS_KEY, "127.0.0.1:0");
-      StorageContainerManager scm = new StorageContainerManager(conf);
-      scm.start();
-      MiniOzoneCluster cluster = new MiniOzoneCluster(this, scm);
-      try {
-        cluster.waitOzoneReady();
-      } catch(Exception e) {
-        // A workaround to propagate MiniOzoneCluster failures without
-        // changing the method signature (which would require cascading
-        // changes to hundreds of unrelated HDFS tests).
-        throw new IOException("Failed to start MiniOzoneCluster", e);
-      }
-      return cluster;
-    }
+    tempPath = Paths.get(builder.getPath(), builder.getRunID());
+    try {
+      FileUtils.deleteDirectory(tempPath.toFile());
+    } catch (IOException e) {
+      String errorMessage = "Cleaning up metadata directories failed." + e;
+      assertFalse(errorMessage, true);
+    }
-        address, UserGroupInformation.getCurrentUser(), conf,
-        NetUtils.getDefaultSocketFactory(conf), Client.getTimeout(conf)));
+            address, UserGroupInformation.getCurrentUser(), conf,
+            NetUtils.getDefaultSocketFactory(conf),
+            Client.getRpcTimeout(conf)));
-        final DatanodeInfo[] reports =
-            scm.getDatanodeReport(DatanodeReportType.LIVE);
-        if (reports.length >= numDataNodes) {
+        if (scm.getNodeCount(SCMNodeManager.NODESTATE.HEALTHY)
+            >= numDataNodes) {
-        LOG.info("Waiting for cluster to be ready. Got {} of {} DN reports.",
-            reports.length, numDataNodes);
+        LOG.info("Waiting for cluster to be ready. Got {} of {} DN Heartbeats.",
+            scm.getNodeCount(SCMNodeManager.NODESTATE.HEALTHY),
+            numDataNodes);
+        return false;
+      }
+    }, 1000, 5 * 60 * 1000); //wait for 5 mins.
+  }
+
+  /**
+   * Waits for SCM to be out of Chill Mode. Many tests can be run iff we are out
+   * of Chill mode.
+   *
+   * @throws TimeoutException
+   * @throws InterruptedException
+   */
+  public void waitTobeOutOfChillMode() throws TimeoutException,
+      InterruptedException {
+    GenericTestUtils.waitFor(new Supplier<Boolean>() {
+      @Override
+      public Boolean get() {
+        if (scm.getScmNodeManager().isOutOfNodeChillMode()) {
+          return true;
+        }
+        LOG.info("Waiting for cluster to be ready. No datanodes found");
+
+  /**
+   * Builder for configuring the MiniOzoneCluster to run.
+   */
+  public static class Builder
+      extends org.apache.hadoop.hdfs.MiniDFSCluster.Builder {
+
+    private final OzoneConfiguration conf;
+    private final int defaultHBSeconds = 1;
+    private final int defaultProcessorMs = 100;
+    private final String path;
+    private final UUID runID;
+    private Optional<String> ozoneHandlerType = Optional.absent();
+    private Optional<Boolean> enableTrace = Optional.of(true);
+    private Optional<Integer> hbSeconds = Optional.absent();
+    private Optional<Integer> hbProcessorInterval = Optional.absent();
+    private Optional<String> scmMetadataDir = Optional.absent();
+    private Boolean ozoneEnabled = true;
+    private Boolean waitForChillModeFinish = true;
+    private int containerWorkerThreadInterval = 1;
+
+    /**
+     * Creates a new Builder.
+     *
+     * @param conf configuration
+     */
+    public Builder(OzoneConfiguration conf) {
+      super(conf);
+      this.conf = conf;
+
+      // TODO : Remove this later, with SCM, NN and SCM can run together.
+      //this.nnTopology(new MiniDFSNNTopology()); // No NameNode required
+
+      URL p = conf.getClass().getResource("");
+      path = p.getPath().concat(MiniOzoneCluster.class.getSimpleName() + UUID
+          .randomUUID().toString());
+      runID = UUID.randomUUID();
+    }
+
+    @Override
+    public Builder numDataNodes(int val) {
+      super.numDataNodes(val);
+      return this;
+    }
+
+    public Builder setHandlerType(String handler) {
+      ozoneHandlerType = Optional.of(handler);
+      return this;
+    }
+
+    public Builder setTrace(Boolean trace) {
+      enableTrace = Optional.of(trace);
+      return this;
+    }
+
+    public Builder setSCMHBInterval(int seconds) {
+      hbSeconds = Optional.of(seconds);
+      return this;
+    }
+
+    public Builder setSCMHeartbeatProcessingInterval(int milliseconds) {
+      hbProcessorInterval = Optional.of(milliseconds);
+      return this;
+    }
+
+    public Builder setSCMMetadataDir(String scmMetadataDirPath) {
+      scmMetadataDir = Optional.of(scmMetadataDirPath);
+      return this;
+    }
+
+    public Builder disableOzone() {
+      ozoneEnabled = false;
+      return this;
+    }
+
+    public Builder doNotwaitTobeOutofChillMode() {
+      waitForChillModeFinish = false;
+      return this;
+    }
+
+    public Builder setSCMContainerWorkerThreadInterval(int intervalInSeconds) {
+      containerWorkerThreadInterval = intervalInSeconds;
+      return this;
+    }
+
+    public String getPath() {
+      return path;
+    }
+
+    public String getRunID() {
+      return runID.toString();
+    }
+
+    @Override
+    public MiniOzoneCluster build() throws IOException {
+
+
+      configureHandler();
+      configureTrace();
+      configureSCMheartbeat();
+      configScmMetadata();
+
+      conf.set(OzoneConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, "127.0.0.1:0");
+      conf.set(OzoneConfigKeys.OZONE_SCM_DATANODE_ADDRESS_KEY, "127.0.0.1:0");
+
+
+      StorageContainerManager scm = new StorageContainerManager(conf);
+      scm.start();
+      String addressString =  scm.getDatanodeRpcAddress().getHostString() +
+          ":" + scm.getDatanodeRpcAddress().getPort();
+      conf.setStrings(OzoneConfigKeys.OZONE_SCM_NAMES, addressString);
+
+      MiniOzoneCluster cluster = new MiniOzoneCluster(this, scm);
+      try {
+        cluster.waitOzoneReady();
+        if (waitForChillModeFinish) {
+          cluster.waitTobeOutOfChillMode();
+        }
+      } catch (Exception e) {
+        // A workaround to propagate MiniOzoneCluster failures without
+        // changing the method signature (which would require cascading
+        // changes to hundreds of unrelated HDFS tests).
+        throw new IOException("Failed to start MiniOzoneCluster", e);
+      }
+      return cluster;
+    }
+
+    private void configScmMetadata() throws IOException {
+
+
+      if (scmMetadataDir.isPresent()) {
+        // if user specifies a path in the test, it is assumed that user takes
+        // care of creating and cleaning up that directory after the tests.
+        conf.set(OzoneConfigKeys.OZONE_CONTAINER_METADATA_DIRS,
+            scmMetadataDir.get());
+        return;
+      }
+
+      // If user has not specified a path, create a UUID for this miniCluser
+      // and create SCM under that directory.
+      Path scmPath = Paths.get(path, runID.toString(), "scm");
+      Files.createDirectories(scmPath);
+      conf.set(OzoneConfigKeys.OZONE_CONTAINER_METADATA_DIRS, scmPath
+          .toString());
+
+      // TODO : Fix this, we need a more generic mechanism to map
+      // different datanode ID for different datanodes when we have lots of
+      // datanodes in the cluster.
+      conf.setStrings(OzoneConfigKeys.OZONE_SCM_DATANODE_ID,
+          scmPath.toString() + "/datanode.id");
+
+    }
+
+    private void configureHandler() {
+      conf.setBoolean(OzoneConfigKeys.OZONE_ENABLED, this.ozoneEnabled);
+      if (!ozoneHandlerType.isPresent()) {
+        throw new IllegalArgumentException(
+            "The Ozone handler type must be specified.");
+      }
+    }
+
+    private void configureTrace() {
+      if (enableTrace.isPresent()) {
+        conf.setBoolean(OzoneConfigKeys.OZONE_TRACE_ENABLED_KEY,
+            enableTrace.get());
+      }
+      GenericTestUtils.setLogLevel(org.apache.log4j.Logger.getRootLogger(),
+          Level.ALL);
+    }
+
+    private void configureSCMheartbeat() {
+      if (hbSeconds.isPresent()) {
+        conf.setInt(OzoneConfigKeys.OZONE_SCM_HEARTBEAT_INTERVAL_SECONDS,
+            hbSeconds.get());
+
+      } else {
+        conf.setInt(OzoneConfigKeys.OZONE_SCM_HEARTBEAT_INTERVAL_SECONDS,
+            defaultHBSeconds);
+      }
+
+      if (hbProcessorInterval.isPresent()) {
+        conf.setInt(OzoneConfigKeys.OZONE_SCM_HEARTBEAT_PROCESS_INTERVAL_MS,
+            hbProcessorInterval.get());
+      } else {
+        conf.setInt(OzoneConfigKeys.OZONE_SCM_HEARTBEAT_PROCESS_INTERVAL_MS,
+            defaultProcessorMs);
+      }
+
+    }
+  }
