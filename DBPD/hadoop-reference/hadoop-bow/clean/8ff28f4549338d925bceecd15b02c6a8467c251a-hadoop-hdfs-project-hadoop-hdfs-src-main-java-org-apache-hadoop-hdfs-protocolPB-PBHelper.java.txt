Merge trunk into HA branch.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1220616 13f79535-47bb-0310-9956-ffa450edef68

-    if (fs.hasLocations()) {
-      return new HdfsLocatedFileStatus(
-          fs.getLength(), fs.getFileType().equals(FileType.IS_DIR), 
-          fs.getBlockReplication(), fs.getBlocksize(),
-          fs.getModificationTime(), fs.getAccessTime(),
-          PBHelper.convert(fs.getPermission()), fs.getOwner(), fs.getGroup(), 
-          fs.getFileType().equals(FileType.IS_SYMLINK) ? 
-              fs.getSymlink().toByteArray() : null,
-          fs.getPath().toByteArray(),
-          PBHelper.convert(fs.hasLocations() ? fs.getLocations() : null));
-    }
-    return new HdfsFileStatus(
-      fs.getLength(), fs.getFileType().equals(FileType.IS_DIR), 
-      fs.getBlockReplication(), fs.getBlocksize(),
-      fs.getModificationTime(), fs.getAccessTime(),
-      PBHelper.convert(fs.getPermission()), fs.getOwner(), fs.getGroup(), 
-      fs.getFileType().equals(FileType.IS_SYMLINK) ? 
-          fs.getSymlink().toByteArray() : null,
-      fs.getPath().toByteArray());
+    return new HdfsLocatedFileStatus(
+        fs.getLength(), fs.getFileType().equals(FileType.IS_DIR), 
+        fs.getBlockReplication(), fs.getBlocksize(),
+        fs.getModificationTime(), fs.getAccessTime(),
+        PBHelper.convert(fs.getPermission()), fs.getOwner(), fs.getGroup(), 
+        fs.getFileType().equals(FileType.IS_SYMLINK) ? 
+            fs.getSymlink().toByteArray() : null,
+        fs.getPath().toByteArray(),
+        fs.hasLocations() ? PBHelper.convert(fs.getLocations()) : null);
-        partList.isEmpty() ? new HdfsFileStatus[0] 
+        partList.isEmpty() ? new HdfsLocatedFileStatus[0] 
-    return new CorruptFileBlocks((String[]) c.getFilesList().toArray(),
+    List<String> fileList = c.getFilesList();
+    return new CorruptFileBlocks(fileList.toArray(new String[fileList.size()]),
