YARN-5716. Add global scheduler interface definition and update CapacityScheduler to use it. Contributed by Wangda Tan

+import java.util.concurrent.atomic.AtomicInteger;
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.yarn.api.records.NodeLabel;
+import org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.PlacementSet;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.SchedulingPlacementSet;
+  // Not confirmed allocation resource, will be used to avoid too many proposal
+  // rejected because of duplicated allocation
+  private AtomicLong unconfirmedAllocatedMem = new AtomicLong();
+  private AtomicInteger unconfirmedAllocatedVcores = new AtomicInteger();
+
+      }
+      if (rmContainer.getState() == RMContainerState.NEW) {
-  public void resetSchedulingOpportunities(
-      SchedulerRequestKey schedulerKey, long currentTimeMs) {
-    try {
-      writeLock.lock();
-      lastScheduledContainer.put(schedulerKey, currentTimeMs);
-      schedulingOpportunities.setCount(schedulerKey, 0);
-    } finally {
-      writeLock.unlock();
-    }
-
+  public void resetSchedulingOpportunities(SchedulerRequestKey schedulerKey,
+      long currentTimeMs) {
+    lastScheduledContainer.put(schedulerKey, currentTimeMs);
+    schedulingOpportunities.setCount(schedulerKey, 0);
+    if (containerType == null || requestType == null) {
+      // Sanity check
+      return;
+    }
+
-    return SchedulerUtils.hasPendingResourceRequest(rc,
-        this.attemptResourceUsage, nodePartition, cluster,
-        schedulingMode);
+    // We need to consider unconfirmed allocations
+    if (schedulingMode == SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY) {
+      nodePartition = RMNodeLabelsManager.NO_LABEL;
+    }
+
+    Resource pending = attemptResourceUsage.getPending(nodePartition);
+
+    // TODO, need consider node partition here
+    // To avoid too many allocation-proposals rejected for non-default
+    // partition allocation
+    if (StringUtils.equals(nodePartition, RMNodeLabelsManager.NO_LABEL)) {
+      pending = Resources.subtract(pending, Resources
+          .createResource(unconfirmedAllocatedMem.get(),
+              unconfirmedAllocatedVcores.get()));
+    }
+
+    if (Resources.greaterThan(rc, cluster, pending, Resources.none())) {
+      return true;
+    }
+
+    return false;
+  public <N extends SchedulerNode> SchedulingPlacementSet<N> getSchedulingPlacementSet(
+      SchedulerRequestKey schedulerRequestKey) {
+    return appSchedulingInfo.getSchedulingPlacementSet(schedulerRequestKey);
+  }
+
+
+  public void incUnconfirmedRes(Resource res) {
+    unconfirmedAllocatedMem.addAndGet(res.getMemorySize());
+    unconfirmedAllocatedVcores.addAndGet(res.getVirtualCores());
+  }
+
+  public void decUnconfirmedRes(Resource res) {
+    unconfirmedAllocatedMem.addAndGet(-res.getMemorySize());
+    unconfirmedAllocatedVcores.addAndGet(-res.getVirtualCores());
+  }
+
