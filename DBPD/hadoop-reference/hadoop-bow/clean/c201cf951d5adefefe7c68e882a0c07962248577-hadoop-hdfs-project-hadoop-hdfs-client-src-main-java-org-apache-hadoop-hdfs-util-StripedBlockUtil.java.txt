HADOOP-12040. Adjust inputs order for the decode API in raw erasure coder. (Kai Zheng via yliu)

-        final int decodeIndex = convertIndex4Decode(i, dataBlkNum, parityBlkNum);
-        alignedStripe.chunks[i] = new StripingChunk(decodeInputs[decodeIndex]);
+        alignedStripe.chunks[i] = new StripingChunk(decodeInputs[i]);
-      int dataBlkNum, int parityBlkNum, AlignedStripe alignedStripe) {
+                                          AlignedStripe alignedStripe) {
-      final int decodeIndex = convertIndex4Decode(i, dataBlkNum, parityBlkNum);
-        chunk.copyTo(decodeInputs[decodeIndex]);
+        chunk.copyTo(decodeInputs[i]);
-        Arrays.fill(decodeInputs[decodeIndex], (byte) 0);
+        Arrays.fill(decodeInputs[i], (byte) 0);
-        decodeInputs[decodeIndex] = null;
+        decodeInputs[i] = null;
-   * Currently decoding requires parity chunks are before data chunks.
-   * The indices are opposite to what we store in NN. In future we may
-   * improve the decoding to make the indices order the same as in NN.
-   *
-   * @param index The index to convert
-   * @param dataBlkNum The number of data blocks
-   * @param parityBlkNum The number of parity blocks
-   * @return converted index
-   */
-  public static int convertIndex4Decode(int index, int dataBlkNum,
-      int parityBlkNum) {
-    return index < dataBlkNum ? index + parityBlkNum : index - dataBlkNum;
-  }
-
-  public static int convertDecodeIndexBack(int index, int dataBlkNum,
-      int parityBlkNum) {
-    return index < parityBlkNum ? index + dataBlkNum : index - parityBlkNum;
-  }
-
-  /**
-        decodeIndices[pos++] = convertIndex4Decode(i, dataBlkNum, parityBlkNum);
+        decodeIndices[pos++] = i;
-      int missingBlkIdx = convertDecodeIndexBack(decodeIndices[i],
-          dataBlkNum, parityBlkNum);
+      int missingBlkIdx = decodeIndices[i];
