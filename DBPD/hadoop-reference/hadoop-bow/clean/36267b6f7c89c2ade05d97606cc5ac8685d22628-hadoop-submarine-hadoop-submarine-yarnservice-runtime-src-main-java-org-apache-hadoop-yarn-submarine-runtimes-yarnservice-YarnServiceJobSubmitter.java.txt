SUBMARINE-52. [SUBMARINE-14] Generate Service spec + launch script for single-node PyTorch learning job. Contributed by Szilard Nemeth.

-import org.apache.hadoop.yarn.submarine.client.cli.param.RunJobParameters;
+import org.apache.hadoop.yarn.submarine.client.cli.param.ParametersHolder;
+import org.apache.hadoop.yarn.submarine.client.cli.param.runjob.PyTorchRunJobParameters;
+import org.apache.hadoop.yarn.submarine.client.cli.param.runjob.RunJobParameters;
+import org.apache.hadoop.yarn.submarine.client.cli.param.runjob.TensorFlowRunJobParameters;
+import org.apache.hadoop.yarn.submarine.client.cli.runjob.Framework;
-import org.apache.hadoop.yarn.submarine.runtimes.yarnservice.command.LaunchCommandFactory;
+import org.apache.hadoop.yarn.submarine.runtimes.yarnservice.command.PyTorchLaunchCommandFactory;
+import org.apache.hadoop.yarn.submarine.runtimes.yarnservice.command.TensorFlowLaunchCommandFactory;
+import org.apache.hadoop.yarn.submarine.runtimes.yarnservice.pytorch.PyTorchServiceSpec;
+import static org.apache.hadoop.yarn.submarine.client.cli.param.ParametersHolder.SUPPORTED_FRAMEWORKS_MESSAGE;
-  public ApplicationId submitJob(RunJobParameters parameters)
+  public ApplicationId submitJob(ParametersHolder paramsHolder)
+    Framework framework = paramsHolder.getFramework();
+    RunJobParameters parameters =
+        (RunJobParameters) paramsHolder.getParameters();
+
+    if (framework == Framework.TENSORFLOW) {
+      return submitTensorFlowJob((TensorFlowRunJobParameters) parameters);
+    } else if (framework == Framework.PYTORCH) {
+      return submitPyTorchJob((PyTorchRunJobParameters) parameters);
+    } else {
+      throw new UnsupportedOperationException(SUPPORTED_FRAMEWORKS_MESSAGE);
+    }
+  }
+
+  private ApplicationId submitTensorFlowJob(
+      TensorFlowRunJobParameters parameters) throws IOException, YarnException {
+    return submitJobInternal(serviceSpec);
+  }
+
+  private ApplicationId submitPyTorchJob(PyTorchRunJobParameters parameters)
+      throws IOException, YarnException {
+    FileSystemOperations fsOperations = new FileSystemOperations(clientContext);
+    HadoopEnvironmentSetup hadoopEnvSetup =
+        new HadoopEnvironmentSetup(clientContext, fsOperations);
+
+    Service serviceSpec = createPyTorchServiceSpec(parameters,
+        fsOperations, hadoopEnvSetup);
+    return submitJobInternal(serviceSpec);
+  }
+
+  private ApplicationId submitJobInternal(Service serviceSpec)
+      throws IOException, YarnException {
-    String appStatus=appAdminClient.getStatusString(serviceSpec.getName());
+    String appStatus = appAdminClient.getStatusString(serviceSpec.getName());
-  private Service createTensorFlowServiceSpec(RunJobParameters parameters,
+  private Service createTensorFlowServiceSpec(
+      TensorFlowRunJobParameters parameters,
-    LaunchCommandFactory launchCommandFactory =
-        new LaunchCommandFactory(hadoopEnvSetup, parameters,
+    TensorFlowLaunchCommandFactory launchCommandFactory =
+        new TensorFlowLaunchCommandFactory(hadoopEnvSetup, parameters,
+  private Service createPyTorchServiceSpec(PyTorchRunJobParameters parameters,
+      FileSystemOperations fsOperations, HadoopEnvironmentSetup hadoopEnvSetup)
+      throws IOException {
+    PyTorchLaunchCommandFactory launchCommandFactory =
+        new PyTorchLaunchCommandFactory(hadoopEnvSetup, parameters,
+            clientContext.getYarnConfig());
+    Localizer localizer = new Localizer(fsOperations,
+        clientContext.getRemoteDirectoryManager(), parameters);
+    PyTorchServiceSpec pyTorchServiceSpec = new PyTorchServiceSpec(
+        parameters, this.clientContext, fsOperations, launchCommandFactory,
+        localizer);
+
+    serviceWrapper = pyTorchServiceSpec.create();
+    return serviceWrapper.getService();
+  }
+
