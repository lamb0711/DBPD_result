HDDS-795. RocksDb specific classes leak from DBStore/Table interfaces. Contributed by  MÃ¡rton Elek.

-import com.google.common.base.Preconditions;
-import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;
-import org.apache.hadoop.hdds.conf.OzoneConfiguration;
-import org.apache.hadoop.ozone.om.exceptions.OMException;
-import org.apache.hadoop.ozone.protocol.proto
-    .OzoneManagerProtocolProtos.OzoneAclInfo;
-import org.apache.hadoop.ozone.protocol.proto
-    .OzoneManagerProtocolProtos.VolumeList;
-import org.apache.hadoop.ozone.protocol.proto
-    .OzoneManagerProtocolProtos.VolumeInfo;
-import org.apache.hadoop.hdds.protocol.proto.HddsProtos;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.utils.RocksDBStore;
-import org.rocksdb.RocksDBException;
-import org.rocksdb.WriteBatch;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.hadoop.ozone.om.OMConfigKeys
-    .OZONE_OM_USER_MAX_VOLUME_DEFAULT;
-import static org.apache.hadoop.ozone.om.OMConfigKeys
-    .OZONE_OM_USER_MAX_VOLUME;
+import org.apache.hadoop.hdds.conf.OzoneConfiguration;
+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;
+import org.apache.hadoop.ozone.om.exceptions.OMException;
+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;
+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OzoneAclInfo;
+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.VolumeInfo;
+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.VolumeList;
+import org.apache.hadoop.util.Time;
+import org.apache.hadoop.utils.RocksDBStore;
+import org.apache.hadoop.utils.db.BatchOperation;
+
+import com.google.common.base.Preconditions;
+import static org.apache.hadoop.ozone.om.OMConfigKeys.OZONE_OM_USER_MAX_VOLUME;
+import static org.apache.hadoop.ozone.om.OMConfigKeys.OZONE_OM_USER_MAX_VOLUME_DEFAULT;
+import org.rocksdb.RocksDBException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
-      WriteBatch batchOperation) throws RocksDBException, IOException {
+      BatchOperation batchOperation) throws IOException {
-    batchOperation.put(metadataManager.getUserTable().getHandle(),
+    metadataManager.getUserTable().putWithBatch(batchOperation,
-      WriteBatch batch) throws RocksDBException, IOException {
+      BatchOperation batch) throws RocksDBException, IOException {
-      batch.delete(metadataManager.getUserTable().getHandle(), dbUserKey);
+      metadataManager.getUserTable().deleteWithBatch(batch, dbUserKey);
-      batch.put(metadataManager.getUserTable().getHandle(),
+      metadataManager.getUserTable().putWithBatch(batch,
-      try(WriteBatch batch = new WriteBatch()) {
+      try (BatchOperation batch = metadataManager.getStore()
+          .initBatchOperation()) {
-        batch.put(metadataManager.getVolumeTable().getHandle(),
+        metadataManager.getVolumeTable().putWithBatch(batch,
-        metadataManager.getStore().write(batch);
+        metadataManager.getStore().commitBatchOperation(batch);
-    } catch (RocksDBException | IOException ex) {
+    } catch (IOException ex) {
-      }
-      if(ex instanceof RocksDBException) {
-        throw RocksDBStore.toIOException("Volume creation failed.",
-            (RocksDBException) ex);
-      try(WriteBatch batch = new WriteBatch()) {
+      try (BatchOperation batch = metadataManager.getStore()
+          .initBatchOperation()) {
-        batch.put(metadataManager.getVolumeTable().getHandle(),
+        metadataManager.getVolumeTable().putWithBatch(batch,
-        metadataManager.getStore().write(batch);
+        metadataManager.getStore().commitBatchOperation(batch);
-      try(WriteBatch batch = new WriteBatch()) {
+      try (BatchOperation batch = metadataManager.getStore()
+          .initBatchOperation()) {
-        batch.delete(metadataManager.getVolumeTable().getHandle(),
-            dbVolumeKey);
-        metadataManager.getStore().write(batch);
+        metadataManager.getVolumeTable().deleteWithBatch(batch, dbVolumeKey);
+        metadataManager.getStore().commitBatchOperation(batch);
