HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.

-import org.apache.hadoop.hdfs.DFSConfigKeys;
-import org.apache.hadoop.hdfs.DFSUtil;
+import org.apache.hadoop.hdfs.protocol.HdfsConstantsClient;
-import org.apache.hadoop.hdfs.server.namenode.SafeModeException;
-        DFSConfigKeys.DFS_WEBHDFS_USER_PATTERN_KEY,
-        DFSConfigKeys.DFS_WEBHDFS_USER_PATTERN_DEFAULT));
+        HdfsClientConfigKeys.DFS_WEBHDFS_USER_PATTERN_KEY,
+        HdfsClientConfigKeys.DFS_WEBHDFS_USER_PATTERN_DEFAULT));
-              SafeModeException.class);
+              HdfsConstantsClient.SAFEMODE_EXCEPTION_CLASS_NAME);
-        canRefreshDelegationToken = false; 
+        canRefreshDelegationToken = false;
-    return DFSConfigKeys.DFS_NAMENODE_HTTP_PORT_DEFAULT;
+    return HdfsClientConfigKeys.DFS_NAMENODE_HTTP_PORT_DEFAULT;
-  
+
-    if (!DFSUtil.isValidName(result)) {
-      throw new IllegalArgumentException("Invalid DFS directory name " + 
+    if (!DFSUtilClient.isValidName(result)) {
+      throw new IllegalArgumentException("Invalid DFS directory name " +
-   * 
+   *
-   * For an IOException which is not a RemoteException, return it. 
+   * For an IOException which is not a RemoteException, return it.
-  
+
-    List<Param<?,?>> authParams = Lists.newArrayList();    
+    List<Param<?,?>> authParams = Lists.newArrayList();
-     * 
+     *
-     * Step 1) Submit a Http request with neither auto-redirect nor data. 
+     * Step 1) Submit a Http request with neither auto-redirect nor data.
-     * 
+     *
-     * 
+     *
-      
+
-      }      
+      }
-        // to ensure the server/proxy knows this 
+        // to ensure the server/proxy knows this
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-  
+
-  
+
-  public void setXAttr(Path p, String name, byte[] value, 
+  public void setXAttr(Path p, String name, byte[] value,
-          XAttrCodec.encodeValue(value, XAttrCodec.HEX)), 
+          XAttrCodec.encodeValue(value, XAttrCodec.HEX)),
-      new FsPathRunner(op, p, new XAttrNameParam(name), 
+      new FsPathRunner(op, p, new XAttrNameParam(name),
-  
+
-    return new FsPathResponseRunner<byte[]>(op, p, new XAttrNameParam(name), 
+    return new FsPathResponseRunner<byte[]>(op, p, new XAttrNameParam(name),
-  
+
-    return new FsPathResponseRunner<Map<String, byte[]>>(op, p, 
+    return new FsPathResponseRunner<Map<String, byte[]>>(op, p,
-  
+
-  public Map<String, byte[]> getXAttrs(Path p, final List<String> names) 
+  public Map<String, byte[]> getXAttrs(Path p, final List<String> names)
-    Preconditions.checkArgument(names != null && !names.isEmpty(), 
+    Preconditions.checkArgument(names != null && !names.isEmpty(),
-    
+
-  
+
-  public Path createSnapshot(final Path path, final String snapshotName) 
+  public Path createSnapshot(final Path path, final String snapshotName)
-    return getConf().getLongBytes(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,
-        DFSConfigKeys.DFS_BLOCK_SIZE_DEFAULT);
+    return getConf().getLongBytes(HdfsClientConfigKeys.DFS_BLOCK_SIZE_KEY,
+        HdfsClientConfigKeys.DFS_BLOCK_SIZE_DEFAULT);
-    return (short)getConf().getInt(DFSConfigKeys.DFS_REPLICATION_KEY,
-        DFSConfigKeys.DFS_REPLICATION_DEFAULT);
+    return (short)getConf().getInt(HdfsClientConfigKeys.DFS_REPLICATION_KEY,
+        HdfsClientConfigKeys.DFS_REPLICATION_DEFAULT);
-    }  
+    }
-  
+
-  public BlockLocation[] getFileBlockLocations(final Path p, 
+  public BlockLocation[] getFileBlockLocations(final Path p,
-        return DFSUtil.locatedBlocks2Locations(
+        return DFSUtilClient.locatedBlocks2Locations(
-  
+
