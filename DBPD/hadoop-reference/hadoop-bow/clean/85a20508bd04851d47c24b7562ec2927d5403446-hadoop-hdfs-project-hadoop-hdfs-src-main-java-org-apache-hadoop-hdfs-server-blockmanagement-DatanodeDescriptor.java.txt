HDFS-10301. Interleaving processing of storages from repeated block reports causes false zombie storage detection, removes valid blocks. Contributed by Vinitha Gankidi.
-import java.util.BitSet;
-import org.apache.hadoop.hdfs.server.protocol.BlockReportContext;
-  private long curBlockReportId = 0;
-
-  private BitSet curBlockReportRpcsSeen = null;
-  public int updateBlockReportContext(BlockReportContext context) {
-    if (curBlockReportId != context.getReportId()) {
-      curBlockReportId = context.getReportId();
-      curBlockReportRpcsSeen = new BitSet(context.getTotalRpcs());
-    }
-    curBlockReportRpcsSeen.set(context.getCurRpc());
-    return curBlockReportRpcsSeen.cardinality();
-  }
-
-  public void clearBlockReportContext() {
-    curBlockReportId = 0;
-    curBlockReportRpcsSeen = null;
-  }
-
-  List<DatanodeStorageInfo> removeZombieStorages() {
+  List<DatanodeStorageInfo>
+      removeZombieStorages(Set<String> storageIDsInBlockReport) {
-        if (storageInfo.getLastBlockReportId() != curBlockReportId) {
-          LOG.info("{} had lastBlockReportId 0x{} but curBlockReportId = 0x{}",
-              storageInfo.getStorageID(),
-              Long.toHexString(storageInfo.getLastBlockReportId()),
-              Long.toHexString(curBlockReportId));
+        if (!storageIDsInBlockReport.contains(storageInfo.getStorageID())) {
-        storageInfo.setLastBlockReportId(0);
