svn merge --reintegrate https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832 for merging Heterogeneous Storage feature branch

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550363 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.Map;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeStorage;
+  // Changing this value may break some tests that assume it is 2.
+  public static final int DIRS_PER_DATANODE = 2;
+
-    LOG.info("starting cluster with " + 
-        builder.nnTopology.countNameNodes() + " namenodes.");
-    nameNodes = new NameNodeInfo[builder.nnTopology.countNameNodes()];
+    final int numNameNodes = builder.nnTopology.countNameNodes();
+    LOG.info("starting cluster: numNameNodes=" + numNameNodes
+        + ", numDataNodes=" + builder.numDataNodes);
+    nameNodes = new NameNodeInfo[numNameNodes];
-        File dir1 = getInstanceStorageDir(i, 0);
-        File dir2 = getInstanceStorageDir(i, 1);
-        dir1.mkdirs();
-        dir2.mkdirs();
-        if (!dir1.isDirectory() || !dir2.isDirectory()) { 
-          throw new IOException("Mkdirs failed to create directory for DataNode "
-                                + i + ": " + dir1 + " or " + dir2);
+        StringBuilder sb = new StringBuilder();
+        for (int j = 0; j < DIRS_PER_DATANODE; ++j) {
+          File dir = getInstanceStorageDir(i, j);
+          dir.mkdirs();
+          if (!dir.isDirectory()) {
+            throw new IOException("Mkdirs failed to create directory for DataNode " + dir);
+          }
+          sb.append((j > 0 ? "," : "") + fileAsURI(dir));
-        String dirs = fileAsURI(dir1) + "," + fileAsURI(dir2);
+        String dirs = sb.toString();
+      LOG.info("dnInfo.length != numDataNodes");
+        LOG.info("!dn.datanode.isDatanodeFullyStarted()");
+        LOG.info("dn.getCapacity() == 0");
+        LOG.info("DataNodeTestUtils.getFSDataset(dn.datanode) == null");
-  public Iterable<Block> getBlockReport(String bpid, int dataNodeIndex) {
+  public Map<DatanodeStorage, BlockListAsLongs> getBlockReport(String bpid, int dataNodeIndex) {
-    return DataNodeTestUtils.getFSDataset(dn).getBlockReport(bpid);
+    return DataNodeTestUtils.getFSDataset(dn).getBlockReports(bpid);
-  public Iterable<Block>[] getAllBlockReports(String bpid) {
+  public List<Map<DatanodeStorage, BlockListAsLongs>> getAllBlockReports(String bpid) {
-    Iterable<Block>[] result = new BlockListAsLongs[numDataNodes];
+    final List<Map<DatanodeStorage, BlockListAsLongs>> result
+        = new ArrayList<Map<DatanodeStorage, BlockListAsLongs>>(numDataNodes);
-     result[i] = getBlockReport(bpid, i);
+      result.add(getBlockReport(bpid, i));
