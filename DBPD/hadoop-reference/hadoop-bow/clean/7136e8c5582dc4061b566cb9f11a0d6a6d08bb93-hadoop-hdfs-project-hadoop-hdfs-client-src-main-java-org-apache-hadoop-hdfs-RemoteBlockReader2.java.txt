HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.

-  
+
-  public synchronized int read(byte[] buf, int off, int len) 
-                               throws IOException {
+  public synchronized int read(byte[] buf, int off, int len)
+      throws IOException {
-    if (curDataSlice == null || curDataSlice.remaining() == 0 && bytesNeededToFinish > 0) {
-      TraceScope scope = tracer.newScope(
-          "RemoteBlockReader2#readNextPacket(" + blockId + ")");
-      try {
+    if (curDataSlice == null ||
+        curDataSlice.remaining() == 0 && bytesNeededToFinish > 0) {
+      try (TraceScope ignored = tracer.newScope(
+          "RemoteBlockReader2#readNextPacket(" + blockId + ")")) {
-      } finally {
-        scope.close();
-    
+
-    
+
-    if (curDataSlice == null || curDataSlice.remaining() == 0 && bytesNeededToFinish > 0) {
-      TraceScope scope = tracer.newScope(
-          "RemoteBlockReader2#readNextPacket(" + blockId + ")");
-      try {
+    if (curDataSlice == null ||
+        (curDataSlice.remaining() == 0 && bytesNeededToFinish > 0)) {
+      try (TraceScope ignored = tracer.newScope(
+          "RemoteBlockReader2#readNextPacket(" + blockId + ")")) {
-      } finally {
-        scope.close();
-    
+
-         throw new IOException("BlockReader: error in packet header " +
-                               curHeader);
+      throw new IOException("BlockReader: error in packet header " +
+          curHeader);
-    
+
-        "checksum slice capacity=" + packetReceiver.getChecksumSlice().capacity() + 
-          " checksumsLen=" + checksumsLen;
-      
+          "checksum slice capacity=" +
+              packetReceiver.getChecksumSlice().capacity() +
+              " checksumsLen=" + checksumsLen;
+
-    }    
-    
+    }
+
-  
+
-      if (curDataSlice == null || curDataSlice.remaining() == 0 && bytesNeededToFinish > 0) {
+      if (curDataSlice == null ||
+          curDataSlice.remaining() == 0 && bytesNeededToFinish > 0) {
-       trailer.getDataLen() != 0) {
+        trailer.getDataLen() != 0) {
-                            trailer);
+          trailer);
-  protected RemoteBlockReader2(String file, String bpid, long blockId,
+  protected RemoteBlockReader2(String file, long blockId,
-  
+
-               peer.getRemoteAddressString() + ": " + e.getMessage());
+          peer.getRemoteAddressString() + ": " + e.getMessage());
-    
+
-      .setStatus(statusCode)
-      .build()
-      .writeDelimitedTo(out);
+        .setStatus(statusCode)
+        .build()
+        .writeDelimitedTo(out);
-  
+
-  
+
-                                     ExtendedBlock block,
-                                     Token<BlockTokenIdentifier> blockToken,
-                                     long startOffset, long len,
-                                     boolean verifyChecksum,
-                                     String clientName,
-                                     Peer peer, DatanodeID datanodeID,
-                                     PeerCache peerCache,
-                                     CachingStrategy cachingStrategy,
-                                     Tracer tracer) throws IOException {
+      ExtendedBlock block,
+      Token<BlockTokenIdentifier> blockToken,
+      long startOffset, long len,
+      boolean verifyChecksum,
+      String clientName,
+      Peer peer, DatanodeID datanodeID,
+      PeerCache peerCache,
+      CachingStrategy cachingStrategy,
+      Tracer tracer) throws IOException {
-          peer.getOutputStream()));
+        peer.getOutputStream()));
-      status.getReadOpChecksumInfo();
+        status.getReadOpChecksumInfo();
-                            firstChunkOffset + ") startOffset is " +
-                            startOffset + " for file " + file);
+          firstChunkOffset + ") startOffset is " +
+          startOffset + " for file " + file);
-    return new RemoteBlockReader2(file, block.getBlockPoolId(), block.getBlockId(),
-        checksum, verifyChecksum, startOffset, firstChunkOffset, len, peer,
-        datanodeID, peerCache, tracer);
+    return new RemoteBlockReader2(file, block.getBlockId(), checksum,
+        verifyChecksum, startOffset, firstChunkOffset, len, peer, datanodeID,
+        peerCache, tracer);
-      + ", self=" + peer.getLocalAddressString()
-      + ", remote=" + peer.getRemoteAddressString()
-      + ", for file " + file
-      + ", for pool " + block.getBlockPoolId()
-      + " block " + block.getBlockId() + "_" + block.getGenerationStamp();
+        + ", self=" + peer.getLocalAddressString()
+        + ", remote=" + peer.getRemoteAddressString()
+        + ", for file " + file
+        + ", for pool " + block.getBlockPoolId()
+        + " block " + block.getBlockId() + "_" + block.getGenerationStamp();
-  
+
-  public int available() throws IOException {
+  public int available() {
-  
+
-  
+
