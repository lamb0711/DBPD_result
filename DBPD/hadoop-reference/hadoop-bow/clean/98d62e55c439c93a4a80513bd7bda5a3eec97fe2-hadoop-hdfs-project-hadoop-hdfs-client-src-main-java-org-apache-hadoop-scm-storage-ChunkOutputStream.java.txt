Revert "HDFS-12794. Ozone: Parallelize ChunkOutputSream Writes to container. Contributed by Shashikant Banerjee."

This reverts commit 6ce5ec676164b84a9e2f8dc65b5f2199a141506d.

-import com.google.common.base.Preconditions;
+import static org.apache.hadoop.scm.storage.ContainerProtocolCalls.putKey;
+import static org.apache.hadoop.scm.storage.ContainerProtocolCalls.writeChunk;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.ByteBuffer;
+import java.util.UUID;
+
+
-import org.apache.commons.lang3.tuple.ImmutablePair;
-import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos;
-import org.apache.hadoop.util.Time;
-
-import java.io.IOException;
-import java.io.OutputStream;
-import java.nio.ByteBuffer;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.UUID;
-import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.ExecutionException;
-
-import static org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos
-    .Result.SUCCESS;
-import static org.apache.hadoop.scm.storage.ContainerProtocolCalls.putKey;
-import static org.apache.hadoop.scm.storage.ContainerProtocolCalls.writeChunk;
-
-  private final String streamId;
+  private final String streamId;
+  private int chunkIndex;
-  private int streamBufferSize;
-   * @param maxBufferSize -- Controls the maximum amount of memory that we need
-   * to allocate data buffering.
-      String traceID, int chunkSize, int maxBufferSize) {
+      String traceID, int chunkSize) {
-    this.streamBufferSize = maxBufferSize;
-
-    this.buffer = ByteBuffer.allocate(maxBufferSize);
+    this.buffer = ByteBuffer.allocate(chunkSize);
+    this.chunkIndex = 0;
-  /**
-   * {@inheritDoc}
-   */
-    byte[] c = new byte[1];
-    c[0] = (byte) b;
-    write(c, 0, 1);
+    int rollbackPosition = buffer.position();
+    int rollbackLimit = buffer.limit();
+    buffer.put((byte)b);
+    if (buffer.position() == chunkSize) {
+      flushBufferToChunk(rollbackPosition, rollbackLimit);
+    }
-  /**
-   * {@inheritDoc}
-   */
-    int rollbackPosition = buffer.position();
-    int rollbackLimit = buffer.limit();
-    try {
-      List<ImmutablePair<CompletableFuture<ContainerProtos
-              .ContainerCommandResponseProto>, ChunkInfo>>
-          writeFutures = writeInParallel(b, off, len);
-      // This is a rendezvous point for this function call, all chunk I/O
-      // for this block must complete before we can declare this call as
-      // complete.
-
-      // Wait until all the futures complete or throws an exception if any of
-      // the calls ended with an exception this call will throw.
-      // if futures is null, it means that we wrote the data to the buffer and
-      // returned.
-      if (writeFutures != null) {
-        CompletableFuture.allOf(writeFutures.toArray(new
-            CompletableFuture[writeFutures.size()])).join();
-
-        // Wrote this data, we will clear this buffer now.
-        buffer.clear();
+    while (len > 0) {
+      int writeLen = Math.min(chunkSize - buffer.position(), len);
+      int rollbackPosition = buffer.position();
+      int rollbackLimit = buffer.limit();
+      buffer.put(b, off, writeLen);
+      if (buffer.position() == chunkSize) {
+        flushBufferToChunk(rollbackPosition, rollbackLimit);
-    } catch (InterruptedException | ExecutionException e) {
-      buffer.position(rollbackPosition);
-      buffer.limit(rollbackLimit);
-      throw new IOException("Unexpected error in write. ", e);
+      off += writeLen;
+      len -= writeLen;
-  /**
-   * Write a given block into many small chunks in parallel.
-   *
-   * @param b
-   * @param off
-   * @param len
-   * @throws IOException
-   * @throws ExecutionException
-   * @throws InterruptedException
-   */
-  public List<ImmutablePair<CompletableFuture<ContainerProtos
-          .ContainerCommandResponseProto>, ChunkInfo>>
-      writeInParallel(byte[] b, int off, int len)
-      throws IOException, ExecutionException, InterruptedException {
-
-    Preconditions.checkArgument(len <= streamBufferSize,
-        "A chunk write cannot be " + "larger than max buffer size limit.");
-    long newBlockCount = len / chunkSize;
-    buffer.put(b, off, len);
-    List<ImmutablePair<CompletableFuture<ContainerProtos
-            .ContainerCommandResponseProto>, ChunkInfo>>
-        writeFutures = new LinkedList<>();
-
-    // We if must have at least a chunkSize of data ready to write, if so we
-    // will go ahead and start writing that data.
-    if (buffer.position() >= chunkSize) {
-      // Allocate new byte slices which will point to each chunk of data
-      // that we want to write. Divide the byte buffer into individual chunks
-      // each of length equals to chunkSize max where each chunk will be
-      // assigned a chunkId where, for each chunk the async write requests will
-      // be made and wait for all of them to return before the write call
-      // returns.
-      for (int chunkId = 0; chunkId < newBlockCount; chunkId++) {
-        // Please note : We are not flipping the slice when we write since
-        // the slices are pointing the buffer start and end as needed for
-        // the chunk write. Also please note, Duplicate does not create a
-        // copy of data, it only creates metadata that points to the data
-        // stream.
-        ByteBuffer chunk = buffer.duplicate();
-        Preconditions.checkState((chunkId * chunkSize) < buffer.limit(),
-            "Chunk offset cannot be beyond the limits of the buffer.");
-        chunk.position(chunkId * chunkSize);
-        // Min handles the case where the last block might be lesser than
-        // chunk Size.
-        chunk.limit(chunk.position() +
-            Math.min(chunkSize, chunk.remaining() - (chunkId * chunkSize)));
-
-        // Schedule all the writes, this is a non-block call which returns
-        // futures. We collect these futures and wait for all  of them to
-        // complete in the next line.
-        writeFutures.add(writeChunkToContainer(chunk, 0, chunkSize));
-      }
-      return writeFutures;
-    }
-    // Nothing to do , return null.
-    return null;
-  }
-
-      ByteBuffer chunk = buffer.duplicate();
-      try {
-
-        ImmutablePair<CompletableFuture<ContainerProtos
-            .ContainerCommandResponseProto>, ChunkInfo>
-            result = writeChunkToContainer(chunk, 0, chunkSize);
-        updateChunkInfo(result);
-        buffer.clear();
-      } catch (ExecutionException | InterruptedException e) {
-        buffer.position(rollbackPosition);
-        buffer.limit(rollbackLimit);
-        throw new IOException("Failure in flush", e);
-      }
+      flushBufferToChunk(rollbackPosition, rollbackLimit);
-          // This flip is needed since this is the real buffer to which we
-          // are writing and position will have moved each time we did a put.
-          buffer.flip();
-
-          // Call get immediately to make this call Synchronous.
-
-          ImmutablePair<CompletableFuture<ContainerProtos
-              .ContainerCommandResponseProto>, ChunkInfo>
-              result = writeChunkToContainer(buffer, 0, buffer.limit());
-          updateChunkInfo(result);
-          buffer.clear();
+          writeChunkToContainer();
-      } catch (IOException | InterruptedException | ExecutionException e) {
+      } catch (IOException e) {
-  private void updateChunkInfo(
-      ImmutablePair<
-          CompletableFuture<ContainerProtos.ContainerCommandResponseProto>,
-          ChunkInfo
-          > result) throws InterruptedException, ExecutionException {
-    // Wait for this call to complete.
-    ContainerProtos.ContainerCommandResponseProto response =
-        result.getLeft().get();
-
-    // If the write call to the chunk is successful, we need to add that
-    // chunk information to the containerKeyData.
-    // TODO: Clean up the garbage in case of failure.
-    if(response.getResult() == SUCCESS) {
-      ChunkInfo chunk = result.getRight();
-      containerKeyData.addChunks(chunk);
-    }
-  }
-
+   * Attempts to flush buffered writes by writing a new chunk to the container.
+   * If successful, then clears the buffer to prepare to receive writes for a
+   * new chunk.
+   *
+   * @param rollbackPosition position to restore in buffer if write fails
+   * @param rollbackLimit limit to restore in buffer if write fails
+   * @throws IOException if there is an I/O error while performing the call
+   */
+  private synchronized void flushBufferToChunk(int rollbackPosition,
+      int rollbackLimit) throws IOException {
+    boolean success = false;
+    try {
+      writeChunkToContainer();
+      success = true;
+    } finally {
+      if (success) {
+        buffer.clear();
+      } else {
+        buffer.position(rollbackPosition);
+        buffer.limit(rollbackLimit);
+      }
+    }
+  }
+
+  /**
-   * @param data -- Data to write.
-   * @param offset - offset to the data buffer
-   * @param len - Length in bytes
-   * @return Returns a Immutable pair -- A future object that will contian
-   * the result of the operation, and the chunkInfo that we wrote.
-   *
-   * @throws IOException
-   * @throws ExecutionException
-   * @throws InterruptedException
+   * @throws IOException if there is an I/O error while performing the call
-  private ImmutablePair<
-      CompletableFuture<ContainerProtos.ContainerCommandResponseProto>,
-      ChunkInfo>
-      writeChunkToContainer(ByteBuffer data, int offset, int len)
-      throws IOException, ExecutionException, InterruptedException {
-
-
-    ByteString dataString = ByteString.copyFrom(data);
-    ChunkInfo chunk = ChunkInfo.newBuilder().setChunkName(
+  private synchronized void writeChunkToContainer() throws IOException {
+    buffer.flip();
+    ByteString data = ByteString.copyFrom(buffer);
+    ChunkInfo chunk = ChunkInfo
+        .newBuilder()
+        .setChunkName(
-                + streamId + "_chunk_" + Time.monotonicNowNanos())
+                + streamId + "_chunk_" + ++chunkIndex)
-        .setLen(len)
+        .setLen(data.size())
-    CompletableFuture<ContainerProtos.ContainerCommandResponseProto> response =
-        writeChunk(xceiverClient, chunk, key, dataString, traceID);
-    return new ImmutablePair(response, chunk);
+    try {
+      writeChunk(xceiverClient, chunk, key, data, traceID);
+    } catch (IOException e) {
+      throw new IOException(
+          "Unexpected Storage Container Exception: " + e.toString(), e);
+    }
+    containerKeyData.addChunks(chunk);
