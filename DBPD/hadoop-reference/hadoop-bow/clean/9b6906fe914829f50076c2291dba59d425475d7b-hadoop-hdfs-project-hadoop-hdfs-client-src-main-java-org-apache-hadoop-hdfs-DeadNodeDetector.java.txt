HDFS-14651. DeadNodeDetector checks dead node periodically. Contributed by Lisheng Sun.

+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol;
+import org.apache.hadoop.hdfs.protocol.DatanodeLocalInfo;
+import org.apache.hadoop.hdfs.protocol.HdfsConstants;
+import org.apache.hadoop.util.Daemon;
+import org.apache.hadoop.util.Time;
+import java.util.Map;
+import java.util.Queue;
+import java.util.concurrent.ArrayBlockingQueue;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_DEAD_NODE_QUEUE_MAX_DEFAULT;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_DEAD_NODE_QUEUE_MAX_KEY;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_CONNECTION_TIMEOUT_MS_DEFAULT;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_CONNECTION_TIMEOUT_MS_KEY;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_INTERVAL_MS_DEFAULT;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_INTERVAL_MS_KEY;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_THREADS_DEFAULT;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_THREADS_KEY;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_RPC_THREADS_DEFAULT;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_DEAD_NODE_DETECTION_RPC_THREADS_KEY;
+import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_SOCKET_TIMEOUT_KEY;
+  private Configuration conf;
+
-  private final ConcurrentHashMap<String, DatanodeInfo> deadNodes;
+  private final Map<String, DatanodeInfo> deadNodes;
-  private final ConcurrentHashMap<DFSInputStream, HashSet<DatanodeInfo>>
+  private final Map<DFSInputStream, HashSet<DatanodeInfo>>
+   * Datanodes that is being probed.
+   */
+  private Map<String, DatanodeInfo> probeInProg =
+      new ConcurrentHashMap<String, DatanodeInfo>();
+
+  /**
+   * The last time when detect dead node.
+   */
+  private long lastDetectDeadTS = 0;
+
+  /**
+   * Interval time in milliseconds for probing dead node behavior.
+   */
+  private long deadNodeDetectInterval = 0;
+
+  /**
+   * The max queue size of probing dead node.
+   */
+  private int maxDeadNodesProbeQueueLen = 0;
+
+  /**
+   * Connection timeout for probing dead node in milliseconds.
+   */
+  private long probeConnectionTimeoutMs;
+
+  /**
+   * The dead node probe queue.
+   */
+  private Queue<DatanodeInfo> deadNodesProbeQueue;
+
+  /**
+   * The thread pool of probing dead node.
+   */
+  private ExecutorService probeDeadNodesThreadPool;
+
+  /**
+   * The scheduler thread of probing dead node.
+   */
+  private Thread probeDeadNodesSchedulerThr;
+
+  /**
+   * The thread pool of probing datanodes' rpc request. Sometimes the data node
+   * can hang and not respond to the client in a short time. And these node will
+   * filled with probe thread pool and block other normal node probing.
+   */
+  private ExecutorService rpcThreadPool;
+
+  private int socketTimeout;
+
+  /**
+   * The type of probe.
+   */
+  private enum ProbeType {
+    CHECK_DEAD
+  }
+
+  /**
-  public DeadNodeDetector(String name) {
+  public DeadNodeDetector(String name, Configuration conf) {
+    this.conf = new Configuration(conf);
+    deadNodeDetectInterval = conf.getLong(
+        DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_INTERVAL_MS_KEY,
+        DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_INTERVAL_MS_DEFAULT);
+    socketTimeout =
+        conf.getInt(DFS_CLIENT_SOCKET_TIMEOUT_KEY, HdfsConstants.READ_TIMEOUT);
+    maxDeadNodesProbeQueueLen =
+        conf.getInt(DFS_CLIENT_DEAD_NODE_DETECTION_DEAD_NODE_QUEUE_MAX_KEY,
+            DFS_CLIENT_DEAD_NODE_DETECTION_DEAD_NODE_QUEUE_MAX_DEFAULT);
+    probeConnectionTimeoutMs = conf.getLong(
+        DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_CONNECTION_TIMEOUT_MS_KEY,
+        DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_CONNECTION_TIMEOUT_MS_DEFAULT);
+
+    this.deadNodesProbeQueue =
+        new ArrayBlockingQueue<DatanodeInfo>(maxDeadNodesProbeQueueLen);
+
+    int deadNodeDetectDeadThreads =
+        conf.getInt(DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_THREADS_KEY,
+            DFS_CLIENT_DEAD_NODE_DETECTION_PROBE_DEAD_NODE_THREADS_DEFAULT);
+    int rpcThreads = conf.getInt(DFS_CLIENT_DEAD_NODE_DETECTION_RPC_THREADS_KEY,
+        DFS_CLIENT_DEAD_NODE_DETECTION_RPC_THREADS_DEFAULT);
+    probeDeadNodesThreadPool = Executors.newFixedThreadPool(
+        deadNodeDetectDeadThreads, new Daemon.DaemonFactory());
+    rpcThreadPool =
+        Executors.newFixedThreadPool(rpcThreads, new Daemon.DaemonFactory());
+
+    startProbeScheduler();
+
+      case CHECK_DEAD:
+        checkDeadNodes();
+        break;
+  /**
+   * Start probe dead node thread.
+   */
+  private void startProbeScheduler() {
+    probeDeadNodesSchedulerThr =
+            new Thread(new ProbeScheduler(this, ProbeType.CHECK_DEAD));
+    probeDeadNodesSchedulerThr.setDaemon(true);
+    probeDeadNodesSchedulerThr.start();
+  }
+
+  /**
+   * Prode datanode by probe byte.
+   */
+  private void scheduleProbe(ProbeType type) {
+    LOG.debug("Schedule probe datanode for probe type: {}.", type);
+    DatanodeInfo datanodeInfo = null;
+    if (type == ProbeType.CHECK_DEAD) {
+      while ((datanodeInfo = deadNodesProbeQueue.poll()) != null) {
+        if (probeInProg.containsKey(datanodeInfo.getDatanodeUuid())) {
+          LOG.debug("The datanode {} is already contained in probe queue, " +
+              "skip to add it.", datanodeInfo);
+          continue;
+        }
+        probeInProg.put(datanodeInfo.getDatanodeUuid(), datanodeInfo);
+        Probe probe = new Probe(this, datanodeInfo, ProbeType.CHECK_DEAD);
+        probeDeadNodesThreadPool.execute(probe);
+      }
+    }
+  }
+
+  /**
+   * Request the data node through rpc, and determine the data node status based
+   * on the returned result.
+   */
+  class Probe implements Runnable {
+    private DeadNodeDetector deadNodeDetector;
+    private DatanodeInfo datanodeInfo;
+    private ProbeType type;
+
+    Probe(DeadNodeDetector deadNodeDetector, DatanodeInfo datanodeInfo,
+        ProbeType type) {
+      this.deadNodeDetector = deadNodeDetector;
+      this.datanodeInfo = datanodeInfo;
+      this.type = type;
+    }
+
+    public DatanodeInfo getDatanodeInfo() {
+      return datanodeInfo;
+    }
+
+    public ProbeType getType() {
+      return type;
+    }
+
+    @Override
+    public void run() {
+      LOG.debug("Check node: {}, type: {}.", datanodeInfo, type);
+      try {
+        final ClientDatanodeProtocol proxy =
+            DFSUtilClient.createClientDatanodeProtocolProxy(datanodeInfo,
+                deadNodeDetector.conf, socketTimeout, true);
+
+        Future<DatanodeLocalInfo> future = rpcThreadPool.submit(new Callable() {
+          @Override
+          public DatanodeLocalInfo call() throws Exception {
+            return proxy.getDatanodeInfo();
+          }
+        });
+
+        try {
+          future.get(probeConnectionTimeoutMs, TimeUnit.MILLISECONDS);
+        } catch (TimeoutException e) {
+          LOG.error("Probe failed, datanode: {}, type: {}.", datanodeInfo, type,
+              e);
+          deadNodeDetector.probeCallBack(this, false);
+          return;
+        } finally {
+          future.cancel(true);
+        }
+        deadNodeDetector.probeCallBack(this, true);
+        return;
+      } catch (Exception e) {
+        LOG.error("Probe failed, datanode: {}, type: {}.", datanodeInfo, type,
+            e);
+      }
+
+      deadNodeDetector.probeCallBack(this, false);
+    }
+  }
+
+  /**
+   * Handle data node, according to probe result. When ProbeType is CHECK_DEAD,
+   * remove the datanode from DeadNodeDetector#deadNodes if probe success.
+   */
+  private void probeCallBack(Probe probe, boolean success) {
+    LOG.debug("Probe datanode: {} result: {}, type: {}",
+        probe.getDatanodeInfo(), success, probe.getType());
+    probeInProg.remove(probe.getDatanodeInfo().getDatanodeUuid());
+    if (success) {
+      if (probe.getType() == ProbeType.CHECK_DEAD) {
+        LOG.info("Remove the node out from dead node list: {}. ",
+            probe.getDatanodeInfo());
+        removeNodeFromDeadNode(probe.getDatanodeInfo());
+      }
+    }
+  }
+
+  /**
+   * Check dead node periodically.
+   */
+  private void checkDeadNodes() {
+    long ts = Time.monotonicNow();
+    if (ts - lastDetectDeadTS > deadNodeDetectInterval) {
+      Set<DatanodeInfo> datanodeInfos = clearAndGetDetectedDeadNodes();
+      for (DatanodeInfo datanodeInfo : datanodeInfos) {
+        LOG.debug("Add dead node to check: {}.", datanodeInfo);
+        if (!deadNodesProbeQueue.offer(datanodeInfo)) {
+          LOG.debug("Skip to add dead node {} to check " +
+              "since the probe queue is full.", datanodeInfo);
+          break;
+        }
+      }
+      lastDetectDeadTS = ts;
+    }
+
+    state = State.IDLE;
+  }
+
-    state = State.IDLE;
+    state = State.CHECK_DEAD;
-    state = State.IDLE;
+    state = State.CHECK_DEAD;
+  private void removeFromDead(DatanodeInfo datanodeInfo) {
+    deadNodes.remove(datanodeInfo.getDatanodeUuid());
+  }
+
+  public Queue<DatanodeInfo> getDeadNodesProbeQueue() {
+    return deadNodesProbeQueue;
+  }
+
+
+  /**
+   * Remove dead node from dfsInputStreamNodes#dfsInputStream and deadNodes.
+   */
+  public synchronized void removeNodeFromDeadNode(DatanodeInfo datanodeInfo) {
+    for (Map.Entry<DFSInputStream, HashSet<DatanodeInfo>> entry :
+            dfsInputStreamNodes.entrySet()) {
+      Set<DatanodeInfo> datanodeInfos = entry.getValue();
+      if (datanodeInfos.remove(datanodeInfo)) {
+        DFSInputStream dfsInputStream = entry.getKey();
+        dfsInputStream.removeFromLocalDeadNodes(datanodeInfo);
+      }
+    }
+
+    removeFromDead(datanodeInfo);
+  }
+
+  private static void probeSleep(long time) {
+    try {
+      Thread.sleep(time);
+    } catch (InterruptedException e) {
+      Thread.currentThread().interrupt();
+    }
+  }
+
+  /**
+   * Schedule probe data node.
+   */
+  static class ProbeScheduler implements Runnable {
+    private DeadNodeDetector deadNodeDetector;
+    private ProbeType type;
+
+    ProbeScheduler(DeadNodeDetector deadNodeDetector, ProbeType type) {
+      this.deadNodeDetector = deadNodeDetector;
+      this.type = type;
+    }
+
+    @Override
+    public void run() {
+      while (true) {
+        deadNodeDetector.scheduleProbe(type);
+        probeSleep(deadNodeDetector.deadNodeDetectInterval);
+      }
+    }
+  }
