HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.

-import org.apache.hadoop.fs.FileSystem;
-   * Number of times to retry creating a file when there are transient 
+   * Number of times to retry creating a file when there are transient
-  protected DFSPacket createPacket(int packetSize, int chunksPerPkt, long offsetInBlock,
-      long seqno, boolean lastPacketInBlock) throws InterruptedIOException {
+  protected DFSPacket createPacket(int packetSize, int chunksPerPkt,
+      long offsetInBlock, long seqno, boolean lastPacketInBlock)
+      throws InterruptedIOException {
-    for (int i = 0; i < currentNodes.length; i++) {
-      value[i] = currentNodes[i];
-    }
+    System.arraycopy(currentNodes, 0, value, 0, currentNodes.length);
-  private DFSOutputStream(DFSClient dfsClient, String src, Progressable progress,
-      HdfsFileStatus stat, DataChecksum checksum) throws IOException {
+  private DFSOutputStream(DFSClient dfsClient, String src,
+      Progressable progress, HdfsFileStatus stat, DataChecksum checksum) {
-    this.cachingStrategy = new AtomicReference<CachingStrategy>(
+    this.cachingStrategy = new AtomicReference<>(
-          + HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY + " (=" + bytesPerChecksum
-          + ") must divide block size (=" + blockSize + ").");
+          + HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY
+          + " (=" + bytesPerChecksum + ") must divide block size (=" +
+          blockSize + ").");
-  protected DFSOutputStream(DFSClient dfsClient, String src, HdfsFileStatus stat,
-      EnumSet<CreateFlag> flag, Progressable progress,
-      DataChecksum checksum, String[] favoredNodes, boolean createStreamer)
-      throws IOException {
+  protected DFSOutputStream(DFSClient dfsClient, String src,
+      HdfsFileStatus stat, EnumSet<CreateFlag> flag, Progressable progress,
+      DataChecksum checksum, String[] favoredNodes, boolean createStreamer) {
-    computePacketChunkSize(dfsClient.getConf().getWritePacketSize(), bytesPerChecksum);
+    computePacketChunkSize(dfsClient.getConf().getWritePacketSize(),
+        bytesPerChecksum);
-      short replication, long blockSize, Progressable progress, int buffersize,
+      short replication, long blockSize, Progressable progress,
-    TraceScope scope =
-        dfsClient.newPathTraceScope("newStreamForCreate", src);
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("newStreamForCreate", src)) {
-              new EnumSetWritable<CreateFlag>(flag), createParent, replication,
+              new EnumSetWritable<>(flag), createParent, replication,
-    } finally {
-      scope.close();
-      streamer = new DataStreamer(lastBlock, stat, dfsClient, src, progress, checksum,
-          cachingStrategy, byteArrayManager);
+      streamer = new DataStreamer(lastBlock, stat, dfsClient, src, progress,
+          checksum, cachingStrategy, byteArrayManager);
-      streamer = new DataStreamer(stat, lastBlock != null ? lastBlock.getBlock() : null,
-          dfsClient, src, progress, checksum, cachingStrategy, byteArrayManager,
-          favoredNodes);
+      streamer = new DataStreamer(stat,
+          lastBlock != null ? lastBlock.getBlock() : null, dfsClient, src,
+          progress, checksum, cachingStrategy, byteArrayManager, favoredNodes);
-      EnumSet<CreateFlag> flags, int bufferSize, Progressable progress,
-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,
-      String[] favoredNodes) throws IOException {
-    TraceScope scope =
-        dfsClient.newPathTraceScope("newStreamForAppend", src);
+      EnumSet<CreateFlag> flags, Progressable progress, LocatedBlock lastBlock,
+      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)
+      throws IOException {
-      throw new IOException("Not support appending to a striping layout file yet.");
+      throw new IOException(
+          "Not support appending to a striping layout file yet.");
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("newStreamForAppend", src)) {
-    } finally {
-      scope.close();
-   * it guarantees that flushed data become visible to new readers. 
-   * It is not guaranteed that data has been flushed to 
-   * persistent store on the datanode. 
+   * it guarantees that flushed data become visible to new readers.
+   * It is not guaranteed that data has been flushed to
+   * persistent store on the datanode.
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hflush", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hflush", src)) {
-    } finally {
-      scope.close();
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hsync", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
-    } finally {
-      scope.close();
-   * The expected semantics is all data have flushed out to all replicas 
-   * and all replicas have done posix fsync equivalent - ie the OS has 
+   * The expected semantics is all data have flushed out to all replicas
+   * and all replicas have done posix fsync equivalent - ie the OS has
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hsync", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
-    } finally {
-      scope.close();
-          DFSClient.LOG.warn("Unable to persist blocks in hflush for " + src, ioe);
-          // If we got an error here, it might be because some other thread called
-          // close before our hflush completed. In that case, we should throw an
-          // exception that the stream is closed.
+          DFSClient.LOG.warn("Unable to persist blocks in hflush for " + src,
+              ioe);
+          // If we got an error here, it might be because some other thread
+          // called close before our hflush completed. In that case, we should
+          // throw an exception that the stream is closed.
-          // If we aren't closed but failed to sync, we should expose that to the
-          // caller.
+          // If we aren't closed but failed to sync, we should expose that to
+          // the caller.
-      // This kind of error doesn't mean that the stream itself is broken - just the
-      // flushing thread got interrupted. So, we shouldn't close down the writer,
-      // but instead just propagate the error
+      // This kind of error doesn't mean that the stream itself is broken - just
+      // the flushing thread got interrupted. So, we shouldn't close down the
+      // writer, but instead just propagate the error
-   * Waits till all existing data is flushed and confirmations 
-   * received from datanodes. 
+   * Waits till all existing data is flushed and confirmations
+   * received from datanodes.
-   * Aborts this output stream and releases any system 
+   * Aborts this output stream and releases any system
-        + (dfsClient.getConf().getHdfsTimeout()/1000) + " seconds expired."));
+        + (dfsClient.getConf().getHdfsTimeout() / 1000) + " seconds expired."));
-   * Closes this output stream and releases any system 
+   * Closes this output stream and releases any system
-    TraceScope scope =
-        dfsClient.newPathTraceScope("DFSOutputStream#close", src);
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("DFSOutputStream#close", src)) {
-    } finally {
-      scope.close();
-      TraceScope scope = dfsClient.getTracer().newScope("completeFile");
-      try {
+      try (TraceScope ignored =
+               dfsClient.getTracer().newScope("completeFile")) {
-      } finally {
-        scope.close();
-    } catch (ClosedChannelException e) {
+    } catch (ClosedChannelException ignored) {
-  // should be called holding (this) lock since setTestFilename() may 
+  // should be called holding (this) lock since setTestFilename() may
-            String msg = "Unable to close file because dfsclient " +
-                          " was unable to contact the HDFS servers." +
-                          " clientRunning " + dfsClient.clientRunning +
-                          " hdfsTimeout " + hdfsTimeout;
-            DFSClient.LOG.info(msg);
-            throw new IOException(msg);
+          String msg = "Unable to close file because dfsclient " +
+              " was unable to contact the HDFS servers. clientRunning " +
+              dfsClient.clientRunning + " hdfsTimeout " + hdfsTimeout;
+          DFSClient.LOG.info(msg);
+          throw new IOException(msg);
-  static LocatedBlock addBlock(DatanodeInfo[] excludedNodes, DFSClient dfsClient,
-      String src, ExtendedBlock prevBlock, long fileId, String[] favoredNodes)
-      throws IOException {
+  static LocatedBlock addBlock(DatanodeInfo[] excludedNodes,
+      DFSClient dfsClient, String src, ExtendedBlock prevBlock, long fileId,
+      String[] favoredNodes) throws IOException {
-        if (NotReplicatedYetException.class.getName().equals(e.getClassName())) {
+        if (NotReplicatedYetException.class.getName()
+            .equals(e.getClassName())) {
