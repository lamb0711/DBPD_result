HDFS-9180. Update excluded DataNodes in DFSStripedOutputStream based on failures in data streamers. Contributed by Jing Zhao.

+    final int currentIndex = getCurrentIndex();
+    assert currentIndex == 0;
+        LOG.info("replacing previously failed streamer " + oldStreamer);
-        if (i == 0) {
+        if (i == currentIndex) {
+          this.currentPacket = null;
+  private DatanodeInfo[] getExcludedNodes() {
+    List<DatanodeInfo> excluded = new ArrayList<>();
+    for (StripedDataStreamer streamer : streamers) {
+      for (DatanodeInfo e : streamer.getExcludedNodes()) {
+        if (e != null) {
+          excluded.add(e);
+        }
+      }
+    }
+    return excluded.toArray(new DatanodeInfo[excluded.size()]);
+  }
+
+    DatanodeInfo[] excludedNodes = getExcludedNodes();
+    LOG.debug("Excluding DataNodes when allocating new block: "
+        + Arrays.asList(excludedNodes));
+
-    if (LOG.isDebugEnabled()) {
-      LOG.debug("Allocating new block group. The previous block group: "
-          + currentBlockGroup);
-    }
-
-    // TODO collect excludedNodes from all the data streamers
-    final LocatedBlock lb = addBlock(null, dfsClient, src, currentBlockGroup,
-        fileId, favoredNodes);
+    LOG.debug("Allocating new block group. The previous block group: "
+        + currentBlockGroup);
+    final LocatedBlock lb = addBlock(excludedNodes, dfsClient, src,
+        currentBlockGroup, fileId, favoredNodes);
-      if (si.isHealthy()) { // skipping failed data streamer
-        if (blocks[i] == null) {
-          // Set exception and close streamer as there is no block locations
-          // found for the parity block.
-          LOG.warn("Failed to get block location for parity block, index=" + i);
-          si.getLastException().set(
-              new IOException("Failed to get following block, i=" + i));
-          si.getErrorState().setInternalError();
-          si.close(true);
-        } else {
-          coordinator.getFollowingBlocks().offer(i, blocks[i]);
-        }
+      assert si.isHealthy();
+      if (blocks[i] == null) {
+        // Set exception and close streamer as there is no block locations
+        // found for the parity block.
+        LOG.warn("Failed to get block location for parity block, index=" + i);
+        si.getLastException().set(
+            new IOException("Failed to get following block, i=" + i));
+        si.getErrorState().setInternalError();
+        si.close(true);
+      } else {
+        coordinator.getFollowingBlocks().offer(i, blocks[i]);
-    final StripedDataStreamer current = getCurrentStreamer();
+    // note: the current streamer can be refreshed after allocating a new block
+    final StripedDataStreamer current = getCurrentStreamer();
-        // check failure state for all the streamers. Bump GS if necessary
-        checkStreamerFailures();
+          flushAllInternals();
+          checkStreamerFailures();
+        } else {
+          // check failure state for all the streamers. Bump GS if necessary
+          checkStreamerFailures();
+  /**
+   * @return whether the data streamer with the given index is streaming data.
+   * Note the streamer may not be in STREAMING stage if the block length is less
+   * than a stripe.
+   */
+  private boolean isStreamerWriting(int streamerIndex) {
+    final long length = currentBlockGroup == null ?
+        0 : currentBlockGroup.getNumBytes();
+    if (length == 0) {
+      return false;
+    }
+    if (streamerIndex >= numDataBlocks) {
+      return true;
+    }
+    final int numCells = (int) ((length - 1) / cellSize + 1);
+    return streamerIndex < numCells;
+  }
+
-    for (StripedDataStreamer streamer : streamers) {
-      if (streamer.isHealthy() &&
-          streamer.getStage() == BlockConstructionStage.DATA_STREAMING) {
+    for (int i = 0; i < numAllBlocks; i++) {
+      final StripedDataStreamer streamer = getStripedDataStreamer(i);
+      if (streamer.isHealthy() && isStreamerWriting(i)) {
+        Preconditions.checkState(
+            streamer.getStage() == BlockConstructionStage.DATA_STREAMING,
+            "streamer: " + streamer);
-    if (newFailed.size() > 0) {
-      // for healthy streamers, wait till all of them have fetched the new block
-      // and flushed out all the enqueued packets.
-      flushAllInternals();
+    if (newFailed.size() == 0) {
+      return;
-    // get all the current failed streamers after the flush
+
+    // for healthy streamers, wait till all of them have fetched the new block
+    // and flushed out all the enqueued packets.
+    flushAllInternals();
+    // recheck failed streamers again after the flush
+          LOG.info("close the slow stream " + streamer);
