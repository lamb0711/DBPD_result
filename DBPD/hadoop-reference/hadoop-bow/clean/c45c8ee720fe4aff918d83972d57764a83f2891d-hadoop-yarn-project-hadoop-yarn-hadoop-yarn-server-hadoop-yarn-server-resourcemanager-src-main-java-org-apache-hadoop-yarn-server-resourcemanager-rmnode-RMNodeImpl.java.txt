Complete commit of prior merge.

The previous merge accidentally only committed the hdfs project instead of common and MR
as well.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1463203 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.concurrent.ConcurrentLinkedQueue;
-import org.apache.hadoop.yarn.server.api.records.HeartbeatResponse;
+import org.apache.hadoop.yarn.server.api.protocolrecords.NodeHeartbeatResponse;
+import com.google.common.annotations.VisibleForTesting;
+
+  private final ConcurrentLinkedQueue<UpdatedContainerInfo> nodeUpdateQueue;
+  private volatile boolean nextHeartBeat = true;
+
-  private HeartbeatResponse latestHeartBeatResponse = recordFactory
-      .newRecordInstance(HeartbeatResponse.class);
+  private NodeHeartbeatResponse latestNodeHeartBeatResponse = recordFactory
+      .newRecordInstance(NodeHeartbeatResponse.class);
-    this.latestHeartBeatResponse.setResponseId(0);
+    this.latestNodeHeartBeatResponse.setResponseId(0);
+    this.nodeUpdateQueue = new ConcurrentLinkedQueue<UpdatedContainerInfo>();  
-  public HeartbeatResponse getLastHeartBeatResponse() {
+  public void updateNodeHeartbeatResponseForCleanup(NodeHeartbeatResponse response) {
+    this.writeLock.lock();
+
+    try {
+      response.addAllContainersToCleanup(
+          new ArrayList<ContainerId>(this.containersToClean));
+      response.addAllApplicationsToCleanup(this.finishedApplications);
+      this.containersToClean.clear();
+      this.finishedApplications.clear();
+    } finally {
+      this.writeLock.unlock();
+    }
+  };
+
+  @Override
+  public NodeHeartbeatResponse getLastNodeHeartBeatResponse() {
-      return this.latestHeartBeatResponse;
+      return this.latestNodeHeartBeatResponse;
+      rmNode.nodeUpdateQueue.clear();
-        rmNode.getLastHeartBeatResponse().setResponseId(0);
+        rmNode.getLastNodeHeartBeatResponse().setResponseId(0);
+      rmNode.nodeUpdateQueue.clear();
-      rmNode.latestHeartBeatResponse = statusEvent.getLatestResponse();
+      rmNode.latestNodeHeartBeatResponse = statusEvent.getLatestResponse();
+        LOG.info("Node " + rmNode.nodeId + " reported UNHEALTHY with details: "
+            + remoteNodeHealthStatus.getHealthReport());
+        rmNode.nodeUpdateQueue.clear();
-
-      rmNode.context.getDispatcher().getEventHandler().handle(
-          new NodeUpdateSchedulerEvent(rmNode, newlyLaunchedContainers, 
-              completedContainers));
+      if(newlyLaunchedContainers.size() != 0 
+          || completedContainers.size() != 0) {
+        rmNode.nodeUpdateQueue.add(new UpdatedContainerInfo
+            (newlyLaunchedContainers, completedContainers));
+      }
+      if(rmNode.nextHeartBeat) {
+        rmNode.nextHeartBeat = false;
+        rmNode.context.getDispatcher().getEventHandler().handle(
+            new NodeUpdateSchedulerEvent(rmNode));
+      }
-      // HeartBeat processing from our end is done, as node pulls the following
-      // lists before sending status-updates. Clear data-structures
-      // TODO: These lists could go to the NM multiple times, or never.
-      rmNode.containersToClean.clear();
-      rmNode.finishedApplications.clear();
-
-      rmNode.latestHeartBeatResponse = statusEvent.getLatestResponse();
+      rmNode.latestNodeHeartBeatResponse = statusEvent.getLatestResponse();
+
+  @Override
+  public List<UpdatedContainerInfo> pullContainerUpdates() {
+    List<UpdatedContainerInfo> latestContainerInfoList = 
+        new ArrayList<UpdatedContainerInfo>();
+    while(nodeUpdateQueue.peek() != null){
+      latestContainerInfoList.add(nodeUpdateQueue.poll());
+    }
+    this.nextHeartBeat = true;
+    return latestContainerInfoList;
+  }
+
+  @VisibleForTesting
+  public void setNextHeartBeat(boolean nextHeartBeat) {
+    this.nextHeartBeat = nextHeartBeat;
+  }
+  
+  @VisibleForTesting
+  public int getQueueSize() {
+    return nodeUpdateQueue.size();
+  }
