HDFS-10268. Ozone: end-to-end integration for create/get volumes, buckets and keys. Contributed by Chris Nauroth.

-import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.ContainerCommandRequestProto;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.ContainerCommandResponseProto;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.ContainerData;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.CreateContainerRequestProto;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.Result;
+import org.apache.hadoop.hdfs.ozone.protocol.proto.ContainerProtos.Type;
+import org.apache.hadoop.ozone.OzoneConfiguration;
+import org.apache.hadoop.ozone.container.common.helpers.Pipeline;
+import org.apache.hadoop.ozone.container.common.transport.client.XceiverClient;
+import org.apache.hadoop.ozone.container.common.transport.client.XceiverClientManager;
- * using the existing heartbeat messages.  StorageContainerManager tells clients
- * container locations by reporting that all registered nodes are a viable
- * location.  This will evolve from a stub to a full-fledged implementation
- * capable of partitioning the keyspace across multiple containers, with
- * appropriate distribution across nodes.
+ * using the existing heartbeat messages.  StorageContainerManager lazily
+ * initializes a single storage container to be served by those DataNodes.
+ * All subsequent requests for container locations will reply with that single
+ * pipeline, using all registered nodes.
+ *
+ * This will evolve from a stub to a full-fledged implementation capable of
+ * partitioning the keyspace across multiple containers, with appropriate
+ * distribution across nodes.
+  private final XceiverClientManager xceiverClientManager;
+  private Pipeline singlePipeline;
-  public StorageContainerManager(Configuration conf)
+  public StorageContainerManager(OzoneConfiguration conf)
+    xceiverClientManager = new XceiverClientManager(conf);
+    Pipeline pipeline = initSingleContainerPipeline();
-    String containerName = UUID.randomUUID().toString();
-      locatedContainers.add(new LocatedContainer(key, key, containerName,
-          locations, leader));
+      locatedContainers.add(new LocatedContainer(key, key,
+          pipeline.getContainerName(), locations, leader));
+   * Lazily initializes a single container pipeline using all registered
+   * DataNodes via a synchronous call to the container protocol.  This single
+   * container pipeline will be reused for container requests for the lifetime
+   * of this StorageContainerManager.
+   *
+   * @throws IOException if there is an I/O error
+   */
+  private synchronized Pipeline initSingleContainerPipeline()
+      throws IOException {
+    if (singlePipeline == null) {
+      List<DatanodeDescriptor> liveNodes = new ArrayList<DatanodeDescriptor>();
+      blockManager.getDatanodeManager().fetchDatanodes(liveNodes, null, false);
+      if (liveNodes.isEmpty()) {
+        throw new IOException("Storage container locations not found.");
+      }
+      Pipeline newPipeline = newPipelineFromNodes(liveNodes,
+          UUID.randomUUID().toString());
+      XceiverClient xceiverClient =
+          xceiverClientManager.acquireClient(newPipeline);
+      try {
+        ContainerData containerData = ContainerData
+            .newBuilder()
+            .setName(newPipeline.getContainerName())
+            .build();
+        CreateContainerRequestProto createContainerRequest =
+            CreateContainerRequestProto.newBuilder()
+            .setPipeline(newPipeline.getProtobufMessage())
+            .setContainerData(containerData)
+            .build();
+        ContainerCommandRequestProto request = ContainerCommandRequestProto
+            .newBuilder()
+            .setCmdType(Type.CreateContainer)
+            .setCreateContainer(createContainerRequest)
+            .build();
+        ContainerCommandResponseProto response = xceiverClient.sendCommand(
+            request);
+        Result result = response.getResult();
+        if (result != Result.SUCCESS) {
+          throw new IOException(
+              "Failed to initialize container due to result code: " + result);
+        }
+        singlePipeline = newPipeline;
+      } finally {
+        xceiverClientManager.releaseClient(xceiverClient);
+      }
+    }
+    return singlePipeline;
+  }
+
+  /**
+   * Translates a list of nodes, ordered such that the first is the leader, into
+   * a corresponding {@link Pipeline} object.
+   *
+   * @param nodes list of nodes
+   * @param containerName container name
+   * @return pipeline corresponding to nodes
+   */
+  private static Pipeline newPipelineFromNodes(List<DatanodeDescriptor> nodes,
+      String containerName) {
+    String leaderId = nodes.get(0).getDatanodeUuid();
+    Pipeline pipeline = new Pipeline(leaderId);
+    for (DatanodeDescriptor node : nodes) {
+      pipeline.addMember(node);
+    }
+    pipeline.setContainerName(containerName);
+    return pipeline;
+  }
+
+  /**
-  private static RPC.Server startRpcServer(Configuration conf,
+  private static RPC.Server startRpcServer(OzoneConfiguration conf,
-  private static InetSocketAddress updateListenAddress(Configuration conf,
+  private static InetSocketAddress updateListenAddress(OzoneConfiguration conf,
-        new Configuration());
+        new OzoneConfiguration());
