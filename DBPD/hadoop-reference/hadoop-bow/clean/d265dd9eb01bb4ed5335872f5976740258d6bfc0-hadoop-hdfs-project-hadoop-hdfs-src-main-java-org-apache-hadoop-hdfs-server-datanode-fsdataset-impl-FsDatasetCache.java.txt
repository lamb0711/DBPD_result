HDFS-6107. When a block cannot be cached due to limited space on the DataNode, it becomes uncacheable (cmccabe)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578508 13f79535-47bb-0310-9956-ffa450edef68

-      if (newUsedBytes < 0) {
-        LOG.warn("Failed to cache " + key + ": could not reserve " + length +
-            " more bytes in the cache: " +
-            DFSConfigKeys.DFS_DATANODE_MAX_LOCKED_MEMORY_KEY +
-            " of " + maxBytes + " exceeded.");
-        numBlocksFailedToCache.incrementAndGet();
-        return;
-      }
+      boolean reservedBytes = false;
+        if (newUsedBytes < 0) {
+          LOG.warn("Failed to cache " + key + ": could not reserve " + length +
+              " more bytes in the cache: " +
+              DFSConfigKeys.DFS_DATANODE_MAX_LOCKED_MEMORY_KEY +
+              " of " + maxBytes + " exceeded.");
+          return;
+        }
+        reservedBytes = true;
+        dataset.datanode.getMetrics().incrBlocksCached(1);
-          newUsedBytes = usedBytesCount.release(length);
+          if (reservedBytes) {
+            newUsedBytes = usedBytesCount.release(length);
+          }
+      dataset.datanode.getMetrics().incrBlocksUncached(1);
