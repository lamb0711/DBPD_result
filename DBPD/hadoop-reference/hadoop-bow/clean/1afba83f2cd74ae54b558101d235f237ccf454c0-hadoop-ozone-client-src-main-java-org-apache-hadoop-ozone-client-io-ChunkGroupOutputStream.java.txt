HDDS-870. Avoid creating block sized buffer in ChunkGroupOutputStream. Contributed by Shashikant Banerjee.

-  private ByteBuffer buffer;
+  private List<ByteBuffer> bufferList;
-    buffer = ByteBuffer.allocate(1);
+    bufferList = new ArrayList<>(1);
+    ByteBuffer buffer = ByteBuffer.allocate(1);
+    bufferList.add(buffer);
-
-    // This byteBuffer will be used to cache data until all the blockCommits
-    // (putBlock) gets replicated to all/majority servers. The idea here is to
-    // allocate the buffer of size blockSize so that as and when a chunk is
-    // is replicated to all servers, as a part of discarding the buffer, we
-    // don't necessarily need to run compaction(buffer.compact() on the buffer
-    // to actually discard the acknowledged data. Compaction is inefficient so
-    // it would be a better choice to avoid compaction on the happy I/O path.
-    this.buffer = ByteBuffer.allocate((int) blockSize);
+    this.bufferList = new ArrayList<>();
-        streamBufferMaxSize, watchTimeout, buffer, checksum));
-  }
-
-  @VisibleForTesting
-  public long getByteOffset() {
-    return getKeyLength();
+        streamBufferMaxSize, watchTimeout, bufferList, checksum));
-    handleWrite(b, off, len, false, buffer.position());
-  }
-
-  private void handleWrite(byte[] b, int off, int len, boolean retry,
-      int pos) throws IOException {
+    handleWrite(b, off, len, false);
+  }
+
+  private long computeBufferData() {
+    return bufferList.stream().mapToInt(value -> value.position())
+        .sum();
+  }
+
+  private void handleWrite(byte[] b, int off, long len, boolean retry)
+      throws IOException {
-    int initialPos;
-      int writeLen = Math.min(len, (int) current.getRemaining());
-      initialPos = pos < buffer.position() ? pos : buffer.position();
+
+      // length(len) will be in int range if the call is happening through
+      // write API of chunkOutputStream. Length can be in long range if it comes
+      // via Exception path.
+      int writeLen = Math.min((int)len, (int) current.getRemaining());
+      long currentPos = current.getWrittenDataLength();
-          // for the current iteration, current pos - initialPos gives the
+          // for the current iteration, totalDataWritten - currentPos gives the
-          writeLen = buffer.position() - initialPos;
+          writeLen = (int) (current.getWrittenDataLength() - currentPos);
+          LOG.debug("writeLen {}, total len {}", writeLen, len);
-    int lastSuccessfulFlushIndex = streamEntry.getLastSuccessfulFlushIndex();
-    int currentPos = buffer.position();
-
-    // In case of a failure, read the data from the position till the last
-    // acknowledgement happened.
-    if (lastSuccessfulFlushIndex > 0) {
-      buffer.position(lastSuccessfulFlushIndex);
-      buffer.limit(currentPos);
-      buffer.compact();
-    }
-
-    if (buffer.position() > 0) {
-      //set the correct length for the current stream
-      streamEntry.currentPosition = lastSuccessfulFlushIndex;
+    long totalSuccessfulFlushedData =
+        streamEntry.getTotalSuccessfulFlushedData();
+    //set the correct length for the current stream
+    streamEntry.currentPosition = totalSuccessfulFlushedData;
+    long bufferedDataLen = computeBufferData();
+    // just clean up the current stream.
+    streamEntry.cleanup();
+    if (bufferedDataLen > 0) {
-      handleWrite(buffer.array(), 0, buffer.position(), true,
-          lastSuccessfulFlushIndex);
+      handleWrite(null, 0, bufferedDataLen, true);
-
-    // just clean up the current stream.
-    streamEntry.cleanup();
-    if (lastSuccessfulFlushIndex == 0) {
+    if (totalSuccessfulFlushedData == 0) {
-    return streamEntries.parallelStream().mapToLong(e -> e.currentPosition)
+    return streamEntries.stream().mapToLong(e -> e.currentPosition)
-      if (buffer != null) {
-        buffer.clear();
+      if (bufferList != null) {
+        bufferList.stream().forEach(e -> e.clear());
-      buffer = null;
+      bufferList = null;
-    private ByteBuffer buffer;
+    private List<ByteBuffer> bufferList;
-        long watchTimeout, ByteBuffer buffer, Checksum checksum) {
+        long watchTimeout, List<ByteBuffer> bufferList, Checksum checksum) {
-      this.buffer = buffer;
+      this.bufferList = bufferList;
-      buffer = null;
+      bufferList = null;
-                streamBufferMaxSize, watchTimeout, buffer, checksum);
+                streamBufferMaxSize, watchTimeout, bufferList, checksum);
-    int getLastSuccessfulFlushIndex() throws IOException {
+    long getTotalSuccessfulFlushedData() throws IOException {
-        return out.getLastSuccessfulFlushIndex();
+        return out.getTotalSuccessfulFlushedData();
+      } else if (outputStream == null) {
+        // For a pre allocated block for which no write has been initiated,
+        // the OutputStream will be null here.
+        // In such cases, the default blockCommitSequenceId will be 0
+        return 0;
+      }
+      throw new IOException("Invalid Output Stream for Key: " + key);
+    }
+
+    long getWrittenDataLength() throws IOException {
+      if (this.outputStream instanceof ChunkOutputStream) {
+        ChunkOutputStream out = (ChunkOutputStream) this.outputStream;
+        return out.getWrittenDataLength();
-    void writeOnRetry(int len) throws IOException {
+    void writeOnRetry(long len) throws IOException {
