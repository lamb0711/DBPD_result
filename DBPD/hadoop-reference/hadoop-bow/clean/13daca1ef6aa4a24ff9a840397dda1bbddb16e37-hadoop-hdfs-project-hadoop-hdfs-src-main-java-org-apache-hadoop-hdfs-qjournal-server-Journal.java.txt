HDFS-3870. Add metrics to JournalNode. Contributed by Todd Lipcon.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1380980 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.concurrent.TimeUnit;
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Stopwatch;
+  private final String journalId;
+  
-  Journal(File logDir, StorageErrorReporter errorReporter) throws IOException {
+  private final JournalMetrics metrics;
+
+
+  Journal(File logDir, String journalId,
+      StorageErrorReporter errorReporter) throws IOException {
+    this.journalId = journalId;
+    
+    this.metrics = JournalMetrics.create(this);
+  
+  String getJournalId() {
+    return journalId;
+  }
+  
+  @VisibleForTesting
+  JournalMetrics getMetricsForTests() {
+    return metrics;
+  }
+    long lastTxnId = firstTxnId + numTxns - 1;
-      LOG.trace("Writing txid " + firstTxnId + "-" + (firstTxnId + numTxns - 1));
+      LOG.trace("Writing txid " + firstTxnId + "-" + lastTxnId);
+    Stopwatch sw = new Stopwatch();
+    sw.start();
+    sw.stop();
+    
+    metrics.addSync(sw.elapsedTime(TimeUnit.MICROSECONDS));
+    
+    if (committedTxnId.get() > lastTxnId) {
+      // This batch of edits has already been committed on a quorum of other
+      // nodes. So, we are in "catch up" mode. This gets its own metric.
+      metrics.batchesWrittenWhileLagging.incr(1);
+      metrics.currentLagTxns.set(committedTxnId.get() - lastTxnId);
+    } else {
+      metrics.currentLagTxns.set(0L);
+    }
+    
+    metrics.batchesWritten.incr(1);
+    metrics.bytesWritten.incr(records.length);
+    metrics.txnsWritten.incr(numTxns);
+    metrics.lastWrittenTxId.set(lastTxnId);
+    
