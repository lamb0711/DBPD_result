HADOOP-8140. dfs -getmerge should process its argments better (Daryn Sharp via bobby)


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1297771 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.shell.PathExceptions.PathIsDirectoryException;
+import org.apache.hadoop.io.IOUtils;
+    protected List<PathData> srcs = null;
-      CommandFormat cf = new CommandFormat(2, 3, "nl");
+      CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, "nl");
+      if (dst.exists && dst.stat.isDirectory()) {
+        throw new PathIsDirectoryException(dst.toString());
+      }
+      srcs = new LinkedList<PathData>();
+    protected void processArguments(LinkedList<PathData> items)
+    throws IOException {
+      super.processArguments(items);
+      if (exitCode != 0) { // check for error collecting paths
+        return;
+      }
+      FSDataOutputStream out = dst.fs.create(dst.path);
+      try {
+        FSDataInputStream in = null;
+        for (PathData src : srcs) {
+          try {
+            in = src.fs.open(src.path);
+            IOUtils.copyBytes(in, out, getConf(), false);
+            if (delimiter != null) {
+              out.write(delimiter.getBytes("UTF-8"));
+            }
+          } finally {
+            in.close();
+          }
+        }
+      } finally {
+        out.close();
+      }      
+    }
+ 
+    @Override
+    protected void processNonexistentPath(PathData item) throws IOException {
+      exitCode = 1; // flag that a path is bad
+      super.processNonexistentPath(item);
+    }
+
+    // this command is handled a bit differently than others.  the paths
+    // are batched up instead of actually being processed.  this avoids
+    // unnecessarily streaming into the merge file and then encountering
+    // a path error that should abort the merge
+    
+    @Override
-      FileUtil.copyMerge(src.fs, src.path,
-          dst.fs, dst.path, false, getConf(), delimiter);
+      // for directories, recurse one level to get its files, else skip it
+      if (src.stat.isDirectory()) {
+        if (getDepth() == 0) {
+          recursePath(src);
+        } // skip subdirs
+      } else {
+        srcs.add(src);
+      }

INS26 INS26 INS26 INS40 INS40 INS40 UPD40 INS23 INS31 INS31 INS83 INS74 INS59 UPD42 INS44 INS78 INS83 INS39 INS42 INS44 INS43 INS8 INS78 INS83 INS39 INS42 MOV44 INS43 INS8 INS43 INS43 INS42 INS33 INS25 INS21 INS74 INS42 INS21 INS25 INS60 INS54 INS42 INS43 INS42 INS42 INS21 INS21 INS42 INS42 INS25 INS42 INS42 MOV43 INS27 INS8 INS7 INS43 INS43 INS48 INS27 INS8 INS43 INS59 INS8 INS8 INS42 INS7 INS48 INS32 INS8 INS8 INS40 INS32 INS53 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS34 INS41 INS42 INS42 INS32 INS60 INS70 INS21 INS42 INS34 INS42 INS42 INS40 INS42 INS25 INS21 MOV43 INS40 INS40 INS42 INS14 INS74 UPD40 MOV40 INS42 UPD40 MOV40 INS43 INS59 INS44 INS42 INS8 INS32 INS27 INS8 INS32 INS43 INS32 INS43 INS43 INS42 INS42 INS33 INS43 INS42 INS54 INS42 INS42 INS32 INS34 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS8 INS8 INS42 INS32 INS21 INS21 INS25 INS21 INS42 INS42 INS7 INS32 INS27 INS8 INS32 INS42 INS32 INS42 INS42 INS42 INS42 MOV32 MOV9 INS42 INS33 INS21 INS42 INS42 UPD40 MOV40 INS42 UPD40 MOV40 INS32 INS42 INS42 INS32 INS42 INS42 INS45 DEL34 DEL42 DEL42 DEL42 DEL32 DEL21