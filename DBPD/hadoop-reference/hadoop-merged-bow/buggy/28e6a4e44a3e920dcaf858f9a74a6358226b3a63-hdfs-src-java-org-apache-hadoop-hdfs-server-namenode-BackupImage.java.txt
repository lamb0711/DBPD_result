HDFS-1073. Redesign the NameNode's storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68

-import java.io.File;
-import java.net.URI;
-import java.util.Collection;
-import java.util.zip.CheckedInputStream;
-import org.apache.hadoop.hdfs.protocol.LayoutVersion;
-import org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdfs.server.common.InconsistentFSStateException;
-import org.apache.hadoop.hdfs.server.common.InconsistentFSStateException;
-import static org.apache.hadoop.hdfs.server.common.Util.now;
-import org.apache.hadoop.hdfs.server.namenode.FSImage;
-import org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream;
-import org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeDirType;
-import org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeFile;
-import org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration;
-import org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol;
-import org.apache.hadoop.io.LongWritable;
+import org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.LogLoadPlan;
+import org.apache.hadoop.io.IOUtils;
+import org.apache.hadoop.util.StringUtils;
+
+import com.google.common.base.Preconditions;
-  // Names of the journal spool directory and the spool file
-  private static final String STORAGE_JSPOOL_DIR = "jspool";
-  private static final String STORAGE_JSPOOL_FILE =
-    NNStorage.NameNodeFile.EDITS_NEW.getName();
-
-  private EditLogBackupInputStream backupInputStream;
-
-  /** Is journal spooling in progress */
-  volatile JSpoolState jsState;
-
-  static enum JSpoolState {
-    OFF,
-    INPROGRESS,
-    WAIT;
+  private EditLogBackupInputStream backupInputStream =
+    new EditLogBackupInputStream("Data from remote NameNode");
+  
+  /**
+   * Current state of the BackupNode. The BackupNode's state
+   * transitions are as follows:
+   * 
+   * Initial: DROP_UNTIL_NEXT_ROLL
+   * - Transitions to JOURNAL_ONLY the next time the log rolls
+   * - Transitions to IN_SYNC in convergeJournalSpool
+   * - Transitions back to JOURNAL_ONLY if the log rolls while
+   *   stopApplyingOnNextRoll is true.
+   */
+  volatile BNState bnState;
+  static enum BNState {
+    /**
+     * Edits from the NN should be dropped. On the next log roll,
+     * transition to JOURNAL_ONLY state
+     */
+    DROP_UNTIL_NEXT_ROLL,
+    /**
+     * Edits from the NN should be written to the local edits log
+     * but not applied to the namespace.
+     */
+    JOURNAL_ONLY,
+    /**
+     * Edits should be written to the local edits log and applied
+     * to the local namespace.
+     */
+    IN_SYNC;
+   * Flag to indicate that the next time the NN rolls, the BN
+   * should transition from to JOURNAL_ONLY state.
+   * {@see #freezeNamespaceAtNextRoll()}
-  BackupImage() {
-    super();
+  private boolean stopApplyingEditsOnNextRoll = false;
+
+  /**
+   * Construct a backup image.
+   * @param conf Configuration
+   * @throws IOException if storage cannot be initialised.
+   */
+  BackupImage(Configuration conf) throws IOException {
+    super(conf);
-    jsState = JSpoolState.OFF;
+    bnState = BNState.DROP_UNTIL_NEXT_ROLL;
+    editLog.initJournals();
-   * @param imageDirs list of image directories as URI.
-   * @param editsDirs list of edits directories URI.
-  void recoverCreateRead(Collection<URI> imageDirs,
-                         Collection<URI> editsDirs) throws IOException {
-    storage.setStorageDirectories(imageDirs, editsDirs);
-    storage.setCheckpointTime(0L);
+  void recoverCreateRead() throws IOException {
-   * Reset storage directories.
-   * <p>
-   * Unlock the storage.
-   * Rename <code>current</code> to <code>lastcheckpoint.tmp</code>
-   * and recreate empty <code>current</code>.
-   * @throws IOException
-   */
-  synchronized void reset() throws IOException {
-    // reset NameSpace tree
-    FSDirectory fsDir = getFSNamesystem().dir;
-    fsDir.reset();
-
-    // unlock, close and rename storage directories
-    storage.unlockAll();
-    // recover from unsuccessful checkpoint if necessary
-    recoverCreateRead(storage.getImageDirectories(),
-                      storage.getEditsDirectories());
-    // rename and recreate
-    for (Iterator<StorageDirectory> it = storage.dirIterator(); it.hasNext();) {
-      StorageDirectory sd = it.next();
-      // rename current to lastcheckpoint.tmp
-      storage.moveCurrent(sd);
-    }
-  }
-
-  /**
-   * Load checkpoint from local files only if the memory state is empty.<br>
-   * Set new checkpoint time received from the name-node.<br>
-   * Move <code>lastcheckpoint.tmp</code> to <code>previous.checkpoint</code>.
-   * @throws IOException
-   */
-  void loadCheckpoint(CheckpointSignature sig) throws IOException {
-    // load current image and journal if it is not in memory already
-    if(!editLog.isOpen())
-      editLog.open();
-
-    FSDirectory fsDir = getFSNamesystem().dir;
-    if(fsDir.isEmpty()) {
-      Iterator<StorageDirectory> itImage
-        = storage.dirIterator(NameNodeDirType.IMAGE);
-      Iterator<StorageDirectory> itEdits
-        = storage.dirIterator(NameNodeDirType.EDITS);
-      if(!itImage.hasNext() || ! itEdits.hasNext())
-        throw new IOException("Could not locate checkpoint directories");
-      StorageDirectory sdName = itImage.next();
-      StorageDirectory sdEdits = itEdits.next();
-      getFSDirectoryRootLock().writeLock();
-      try { // load image under rootDir lock
-        loadFSImage(NNStorage.getStorageFile(sdName, NameNodeFile.IMAGE));
-      } finally {
-        getFSDirectoryRootLock().writeUnlock();
-      }
-      loadFSEdits(sdEdits);
-    }
-
-    // set storage fields
-    storage.setStorageInfo(sig);
-    storage.setImageDigest(sig.imageDigest);
-    storage.setCheckpointTime(sig.checkpointTime);
-  }
-
-  /**
-    saveNamespace(false);
-  }
-
-  private FSDirectory getFSDirectoryRootLock() {
-    return getFSNamesystem().dir;
-  }
-
-  static File getJSpoolDir(StorageDirectory sd) {
-    return new File(sd.getRoot(), STORAGE_JSPOOL_DIR);
-  }
-
-  static File getJSpoolFile(StorageDirectory sd) {
-    return new File(getJSpoolDir(sd), STORAGE_JSPOOL_FILE);
+    saveNamespace();
-   * Journal writer journals new meta-data state.
-   * <ol>
-   * <li> If Journal Spool state is OFF then journal records (edits)
-   * are applied directly to meta-data state in memory and are written
-   * to the edits file(s).</li>
-   * <li> If Journal Spool state is INPROGRESS then records are only
-   * written to edits.new file, which is called Spooling.</li>
-   * <li> Journal Spool state WAIT blocks journaling until the
-   * Journal Spool reader finalizes merging of the spooled data and
-   * switches to applying journal to memory.</li>
-   * </ol>
-   * @param length length of data.
+   * Receive a batch of edits from the NameNode.
+   * 
+   * Depending on bnState, different actions are taken. See
+   * {@link BackupImage.BNState}
+   * 
+   * @param firstTxId first txid in batch
+   * @param numTxns number of transactions
-  synchronized void journal(int length, byte[] data) throws IOException {
-    assert backupInputStream.length() == 0 : "backup input stream is not empty";
-    try {
-      switch(jsState) {
-        case WAIT:
-        case OFF:
-          // wait until spooling is off
-          waitSpoolEnd();
-          // update NameSpace in memory
-          backupInputStream.setBytes(data);
-          FSEditLogLoader logLoader = new FSEditLogLoader(namesystem);
-          int logVersion = storage.getLayoutVersion();
-          BufferedInputStream bin = new BufferedInputStream(backupInputStream);
-          DataInputStream in = new DataInputStream(bin);
-          Checksum checksum = null;
-          if (LayoutVersion.supports(Feature.EDITS_CHESKUM, logVersion)) {
-            checksum = FSEditLog.getChecksum();
-            in = new DataInputStream(new CheckedInputStream(bin, checksum));
-          }
-          logLoader.loadEditRecords(logVersion, in, checksum, true);
-          getFSNamesystem().dir.updateCountForINodeWithQuota(); // inefficient!
-          break;
-        case INPROGRESS:
-          break;
-      }
-      // write to files
-      editLog.logEdit(length, data);
-      editLog.logSync();
-    } finally {
-      backupInputStream.clear();
+  synchronized void journal(long firstTxId, int numTxns, byte[] data) throws IOException {
+    if (LOG.isTraceEnabled()) {
+      LOG.trace("Got journal, " +
+          "state = " + bnState +
+          "; firstTxId = " + firstTxId +
+          "; numTxns = " + numTxns);
-  }
-
-  private synchronized void waitSpoolEnd() {
-    while(jsState == JSpoolState.WAIT) {
-      try {
-        wait();
-      } catch (InterruptedException  e) {}
-    }
-    // now spooling should be off, verifying just in case
-    assert jsState == JSpoolState.OFF : "Unexpected JSpool state: " + jsState;
-  }
-
-  /**
-   * Start journal spool.
-   * Switch to writing into edits.new instead of edits.
-   *
-   * edits.new for spooling is in separate directory "spool" rather than in
-   * "current" because the two directories should be independent.
-   * While spooling a checkpoint can happen and current will first
-   * move to lastcheckpoint.tmp and then to previous.checkpoint
-   * spool/edits.new will remain in place during that.
-   */
-  synchronized void startJournalSpool(NamenodeRegistration nnReg)
-  throws IOException {
-    switch(jsState) {
-      case OFF:
-        break;
-      case INPROGRESS:
+    
+    switch(bnState) {
+      case DROP_UNTIL_NEXT_ROLL:
-      case WAIT:
-        waitSpoolEnd();
+
+      case IN_SYNC:
+        // update NameSpace in memory
+        applyEdits(firstTxId, numTxns, data);
+        break;
+      
+      case JOURNAL_ONLY:
+        break;
+      
+      default:
+        throw new AssertionError("Unhandled state: " + bnState);
-
-    // create journal spool directories
-    for (Iterator<StorageDirectory> it
-           = storage.dirIterator(NameNodeDirType.EDITS); it.hasNext();) {
-      StorageDirectory sd = it.next();
-      File jsDir = getJSpoolDir(sd);
-      if (!jsDir.exists() && !jsDir.mkdirs()) {
-        throw new IOException("Mkdirs failed to create "
-                              + jsDir.getCanonicalPath());
-      }
-      // create edit file if missing
-      File eFile = storage.getEditFile(sd);
-      if(!eFile.exists()) {
-        editLog.createEditLogFile(eFile);
-      }
-    }
-
-    if(!editLog.isOpen())
-      editLog.open();
-
-    // create streams pointing to the journal spool files
-    // subsequent journal records will go directly to the spool
-    editLog.divertFileStreams(STORAGE_JSPOOL_DIR + "/" + STORAGE_JSPOOL_FILE);
-    setCheckpointState(CheckpointStates.ROLLED_EDITS);
-
-    // set up spooling
-    if(backupInputStream == null)
-      backupInputStream = new EditLogBackupInputStream(nnReg.getAddress());
-    jsState = JSpoolState.INPROGRESS;
+    
+    // write to BN's local edit log.
+    logEditsLocally(firstTxId, numTxns, data);
-  synchronized void setCheckpointTime(int length, byte[] data)
-  throws IOException {
+  /**
+   * Write the batch of edits to the local copy of the edit logs.
+   */
+  private void logEditsLocally(long firstTxId, int numTxns, byte[] data) {
+    long expectedTxId = editLog.getLastWrittenTxId() + 1;
+    Preconditions.checkState(firstTxId == expectedTxId,
+        "received txid batch starting at %s but expected txn %s",
+        firstTxId, expectedTxId);
+    editLog.setNextTxId(firstTxId + numTxns - 1);
+    editLog.logEdit(data.length, data);
+    editLog.logSync();
+  }
+
+  /**
+   * Apply the batch of edits to the local namespace.
+   */
+  private synchronized void applyEdits(long firstTxId, int numTxns, byte[] data)
+      throws IOException {
+    Preconditions.checkArgument(firstTxId == lastAppliedTxId + 1,
+        "Received txn batch starting at %s but expected %s",
+        firstTxId, lastAppliedTxId + 1);
-      // unpack new checkpoint time
+      if (LOG.isTraceEnabled()) {
+        LOG.debug("data:" + StringUtils.byteToHexString(data));
+      }
-      DataInputStream in = backupInputStream.getDataInputStream();
-      byte op = in.readByte();
-      assert op == NamenodeProtocol.JA_CHECKPOINT_TIME;
-      LongWritable lw = new LongWritable();
-      lw.readFields(in);
-      storage.setCheckpointTimeInStorage(lw.get());
+      FSEditLogLoader logLoader = new FSEditLogLoader(namesystem);
+      int logVersion = storage.getLayoutVersion();
+      BufferedInputStream bin = new BufferedInputStream(backupInputStream);
+      DataInputStream in = new DataInputStream(bin);
+      Checksum checksum = FSEditLog.getChecksum();
+      int numLoaded = logLoader.loadEditRecords(logVersion, in, checksum, true,
+                                lastAppliedTxId + 1);
+      if (numLoaded != numTxns) {
+        throw new IOException("Batch of txns starting at txnid " +
+            firstTxId + " was supposed to contain " + numTxns +
+            " transactions but only was able to apply " + numLoaded);
+      }
+      lastAppliedTxId += numTxns;
+      
+      getFSNamesystem().dir.updateCountForINodeWithQuota(); // inefficient!
-   * Merge Journal Spool to memory.<p>
-   * Journal Spool reader reads journal records from edits.new.
-   * When it reaches the end of the file it sets {@link JSpoolState} to WAIT.
-   * This blocks journaling (see {@link #journal(int,byte[])}.
-   * The reader
-   * <ul>
-   * <li> reads remaining journal records if any,</li>
-   * <li> renames edits.new to edits,</li>
-   * <li> sets {@link JSpoolState} to OFF,</li>
-   * <li> and notifies the journaling thread.</li>
-   * </ul>
-   * Journaling resumes with applying new journal records to the memory state,
-   * and writing them into edits file(s).
+   * Transition the BackupNode from JOURNAL_ONLY state to IN_SYNC state.
+   * This is done by repeated invocations of tryConvergeJournalSpool until
+   * we are caught up to the latest in-progress edits file.
-    Iterator<StorageDirectory> itEdits
-      = storage.dirIterator(NameNodeDirType.EDITS);
-    if(! itEdits.hasNext())
-      throw new IOException("Could not locate checkpoint directories");
-    StorageDirectory sdEdits = itEdits.next();
-    int numEdits = 0;
-    File jSpoolFile = getJSpoolFile(sdEdits);
-    long startTime = now();
-    if(jSpoolFile.exists()) {
-      // load edits.new
-      EditLogFileInputStream edits = new EditLogFileInputStream(jSpoolFile);
-      BufferedInputStream bin = new BufferedInputStream(edits);
-      DataInputStream in = new DataInputStream(bin);
-      FSEditLogLoader logLoader = new FSEditLogLoader(namesystem);
-      int logVersion = logLoader.readLogVersion(in);
-      Checksum checksum = null;
-      if (LayoutVersion.supports(Feature.EDITS_CHESKUM, logVersion)) {
-        checksum = FSEditLog.getChecksum();
-        in = new DataInputStream(new CheckedInputStream(bin, checksum));
-      }
-      numEdits += logLoader.loadEditRecords(logVersion, in, checksum, false);
+    Preconditions.checkState(bnState == BNState.JOURNAL_ONLY,
+        "bad state: %s", bnState);
-      // first time reached the end of spool
-      jsState = JSpoolState.WAIT;
-      numEdits += logLoader.loadEditRecords(logVersion,
-                                            in, checksum, true);
-      getFSNamesystem().dir.updateCountForINodeWithQuota();
-      edits.close();
+    while (!tryConvergeJournalSpool()) {
+      ;
+    assert bnState == BNState.IN_SYNC;
+  }
+  
+  private boolean tryConvergeJournalSpool() throws IOException {
+    Preconditions.checkState(bnState == BNState.JOURNAL_ONLY,
+        "bad state: %s", bnState);
+    
+    // This section is unsynchronized so we can continue to apply
+    // ahead of where we're reading, concurrently. Since the state
+    // is JOURNAL_ONLY at this point, we know that lastAppliedTxId
+    // doesn't change, and curSegmentTxId only increases
-    FSImage.LOG.info("Edits file " + jSpoolFile.getCanonicalPath()
-        + " of size " + jSpoolFile.length() + " edits # " + numEdits
-        + " loaded in " + (now()-startTime)/1000 + " seconds.");
+    while (lastAppliedTxId < editLog.getCurSegmentTxId() - 1) {
+      long target = editLog.getCurSegmentTxId();
+      LOG.info("Loading edits into backupnode to try to catch up from txid "
+          + lastAppliedTxId + " to " + target);
+      FSImageTransactionalStorageInspector inspector =
+        new FSImageTransactionalStorageInspector();
+      
+      storage.inspectStorageDirs(inspector);
+      LogLoadPlan logLoadPlan = inspector.createLogLoadPlan(lastAppliedTxId,
+          target - 1);
+  
+      logLoadPlan.doRecovery();
+      loadEdits(logLoadPlan.getEditsFiles());
+    }
+    
+    // now, need to load the in-progress file
+    synchronized (this) {
+      if (lastAppliedTxId != editLog.getCurSegmentTxId() - 1) {
+        LOG.debug("Logs rolled while catching up to current segment");
+        return false; // drop lock and try again to load local logs
+      }
+      
+      EditLogInputStream stream = getEditLog().getInProgressFileInputStream();
+      try {
+        long remainingTxns = getEditLog().getLastWrittenTxId() - lastAppliedTxId;
+        
+        LOG.info("Going to finish converging with remaining " + remainingTxns
+            + " txns from in-progress stream " + stream);
+        
+        FSEditLogLoader loader = new FSEditLogLoader(namesystem);
+        int numLoaded = loader.loadFSEdits(stream, lastAppliedTxId + 1);
+        lastAppliedTxId += numLoaded;
+        assert numLoaded == remainingTxns :
+          "expected to load " + remainingTxns + " but loaded " +
+          numLoaded + " from " + stream;
+      } finally {
+        IOUtils.closeStream(stream);
+      }
-    // rename spool edits.new to edits making it in sync with the active node
-    // subsequent journal records will go directly to edits
-    editLog.revertFileStreams(STORAGE_JSPOOL_DIR + "/" + STORAGE_JSPOOL_FILE);
+      LOG.info("Successfully synced BackupNode with NameNode at txnid " +
+          lastAppliedTxId);
+      setState(BNState.IN_SYNC);
+    }
+    return true;
+  }
-    // write version file
-    resetVersion(false, storage.getImageDigest());
+  /**
+   * Transition edit log to a new state, logging as necessary.
+   */
+  private synchronized void setState(BNState newState) {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("State transition " + bnState + " -> " + newState,
+          new Exception("trace"));
+    }
+    bnState = newState;
+  }
-    // wake up journal writer
-    synchronized(this) {
-      jsState = JSpoolState.OFF;
+  /**
+   * Receive a notification that the NameNode has begun a new edit log.
+   * This causes the BN to also start the new edit log in its local
+   * directories.
+   */
+  synchronized void namenodeStartedLogSegment(long txid)
+      throws IOException {
+    LOG.info("NameNode started a new log segment at txid " + txid);
+    if (editLog.isOpen()) {
+      if (editLog.getLastWrittenTxId() == txid - 1) {
+        // We are in sync with the NN, so end and finalize the current segment
+        editLog.endCurrentLogSegment(false);
+      } else {
+        // We appear to have missed some transactions -- the NN probably
+        // lost contact with us temporarily. So, mark the current segment
+        // as aborted.
+        LOG.warn("NN started new log segment at txid " + txid +
+            ", but BN had only written up to txid " +
+            editLog.getLastWrittenTxId() +
+            "in the log segment starting at " + 
+        		editLog.getCurSegmentTxId() + ". Aborting this " +
+        		"log segment.");
+        editLog.abortCurrentLogSegment();
+      }
+    }
+    editLog.setNextTxId(txid);
+    editLog.startLogSegment(txid, false);
+    if (bnState == BNState.DROP_UNTIL_NEXT_ROLL) {
+      setState(BNState.JOURNAL_ONLY);
+    }
+    
+    if (stopApplyingEditsOnNextRoll) {
+      if (bnState == BNState.IN_SYNC) {
+        LOG.info("Stopped applying edits to prepare for checkpoint.");
+        setState(BNState.JOURNAL_ONLY);
+      }
+      stopApplyingEditsOnNextRoll = false;
+  }
-    // Rename lastcheckpoint.tmp to previous.checkpoint
-    for (Iterator<StorageDirectory> it = storage.dirIterator(); it.hasNext();) {
-      StorageDirectory sd = it.next();
-      storage.moveLastCheckpoint(sd);
+  /**
+   * Request that the next time the BN receives a log roll, it should
+   * stop applying the edits log to the local namespace. This is
+   * typically followed on by a call to {@link #waitUntilNamespaceFrozen()}
+   */
+  synchronized void freezeNamespaceAtNextRoll() {
+    stopApplyingEditsOnNextRoll = true;
+  }
+
+  /**
+   * After {@link #freezeNamespaceAtNextRoll()} has been called, wait until
+   * the BN receives notification of the next log roll.
+   */
+  synchronized void waitUntilNamespaceFrozen() throws IOException {
+    if (bnState != BNState.IN_SYNC) return;
+
+    LOG.info("Waiting until the NameNode rolls its edit logs in order " +
+        "to freeze the BackupNode namespace.");
+    while (bnState == BNState.IN_SYNC) {
+      Preconditions.checkState(stopApplyingEditsOnNextRoll,
+        "If still in sync, we should still have the flag set to " +
+        "freeze at next roll");
+      try {
+        wait();
+      } catch (InterruptedException ie) {
+        LOG.warn("Interrupted waiting for namespace to freeze", ie);
+        throw new IOException(ie);
+      }
+    LOG.info("BackupNode namespace frozen.");
+  }
+
+  /**
+   * Override close() so that we don't finalize edit logs.
+   */
+  @Override
+  public synchronized void close() throws IOException {
+    editLog.abortCurrentLogSegment();
+    storage.close();

MOV26 MOV31 UPD40 UPD40 UPD40 UPD40 UPD40 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 UPD43 UPD42 INS29 INS83 INS39 INS59 INS44 MOV43 UPD42 INS44 INS44 MOV44 INS43 INS8 MOV29 INS83 MOV39 UPD42 MOV42 MOV44 INS44 INS44 INS8 INS83 UPD42 INS44 INS29 INS39 INS42 MOV43 INS8 UPD83 MOV83 UPD39 MOV39 UPD42 MOV42 MOV43 INS8 MOV29 INS83 INS83 MOV39 UPD42 MOV42 INS44 INS8 INS29 INS83 INS39 INS42 INS44 MOV43 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 MOV43 INS8 INS29 INS78 INS83 INS83 INS39 INS42 MOV43 INS8 INS14 UPD42 UPD42 INS29 UPD42 INS29 UPD42 INS29 UPD42 INS65 INS42 INS9 INS65 INS65 INS65 INS43 INS42 INS21 UPD65 INS65 MOV65 MOV65 MOV65 INS39 INS42 INS39 INS42 INS42 INS25 INS50 MOV21 INS39 INS42 INS39 INS42 INS5 INS42 MOV60 INS21 MOV21 MOV21 MOV21 INS39 INS42 UPD42 INS21 INS65 INS21 INS61 MOV6 INS21 INS61 INS51 INS41 INS43 INS42 INS25 INS21 INS65 INS39 INS42 INS21 INS25 MOV21 MOV21 INS25 INS25 INS65 MOV21 INS65 INS25 INS21 MOV61 INS21 INS65 INS42 INS21 MOV21 MOV43 INS45 INS66 INS66 INS66 INS66 UPD66 INS66 INS66 INS65 INS65 INS65 INS66 INS66 INS65 INS66 INS42 INS66 INS42 INS66 INS42 INS42 INS32 UPD66 UPD66 INS65 UPD42 INS66 INS42 INS66 INS32 INS8 INS42 INS49 INS41 INS49 INS21 INS10 INS49 INS10 INS49 INS53 UPD66 INS39 INS85 INS39 INS32 UPD66 INS32 INS66 INS66 INS66 INS32 INS38 INS8 INS32 INS27 INS8 INS52 INS8 INS9 UPD66 UPD42 MOV42 INS32 INS8 INS7 INS66 INS66 INS66 INS32 MOV32 INS8 INS32 INS32 INS27 INS8 INS42 INS8 INS66 INS66 INS66 INS65 INS66 INS65 INS66 INS66 INS27 INS41 INS32 INS32 INS66 INS32 INS42 INS66 INS66 INS66 INS66 INS66 INS66 INS66 UPD42 UPD40 INS42 INS42 INS40 UPD42 MOV42 UPD42 MOV42 MOV21 INS42 INS42 INS32 INS42 INS14 UPD42 UPD42 UPD42 INS42 UPD42 INS27 INS42 UPD42 MOV42 INS27 INS45 INS42 INS42 UPD42 UPD42 MOV42 INS27 INS42 UPD42 INS40 UPD42 INS42 INS42 INS27 INS45 INS42 INS27 INS25 MOV21 MOV60 MOV60 MOV60 MOV60 INS60 INS60 INS25 INS21 MOV21 UPD42 MOV42 UPD42 MOV42 INS27 INS45 INS42 INS32 INS20 UPD42 UPD40 INS42 INS42 INS27 INS45 INS42 INS42 INS27 INS60 INS21 MOV60 INS21 MOV60 INS21 MOV21 INS25 INS60 INS54 MOV21 MOV21 INS42 INS42 INS21 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS27 INS25 INS42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 MOV9 INS42 INS40 MOV21 INS25 INS21 MOV21 INS68 UPD42 INS9 INS68 INS42 INS40 UPD42 MOV42 UPD42 MOV42 INS27 UPD42 UPD40 INS21 UPD42 MOV42 UPD42 MOV42 INS45 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 MOV42 INS42 INS42 UPD42 MOV42 INS43 INS27 INS32 INS34 INS42 INS42 INS27 INS34 INS42 INS27 INS42 INS34 MOV32 MOV8 MOV43 INS59 INS39 INS59 INS27 INS8 INS7 INS42 INS40 UPD42 MOV42 INS42 INS40 INS32 INS34 INS39 INS59 INS32 UPD43 INS32 UPD43 INS32 INS27 INS8 INS43 INS59 INS8 INS8 INS32 INS45 INS42 INS27 INS8 INS8 INS27 INS8 INS7 INS42 INS42 INS45 INS45 INS32 UPD42 UPD42 MOV42 INS27 UPD42 MOV42 INS45 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS34 UPD42 UPD42 INS42 MOV32 INS42 INS32 INS42 INS42 INS53 INS42 INS42 INS42 INS42 UPD42 MOV42 MOV32 UPD42 MOV42 UPD42 MOV42 INS27 UPD42 UPD42 INS14 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 UPD42 INS32 INS42 INS27 MOV21 INS41 UPD42 MOV42 INS42 INS32 INS60 MOV21 MOV60 MOV60 INS21 INS6 MOV21 UPD42 UPD42 INS27 UPD42 INS40 UPD42 MOV42 UPD42 MOV42 INS27 INS14 INS32 INS27 INS21 INS21 MOV21 UPD42 INS40 INS42 INS40 MOV21 MOV21 INS42 INS9 INS42 INS42 INS42 INS27 INS27 INS42 INS45 INS42 INS45 INS42 INS32 MOV42 MOV42 MOV42 MOV42 MOV42 MOV9 INS27 INS14 UPD42 UPD42 INS45 INS42 INS45 INS42 INS43 UPD42 UPD42 UPD42 INS27 UPD42 MOV42 UPD42 MOV42 INS32 INS34 INS9 INS32 UPD42 MOV42 INS39 INS59 UPD43 UPD39 INS7 MOV27 INS27 INS45 INS42 INS45 INS42 INS45 INS42 UPD43 MOV43 UPD45 MOV45 INS42 INS42 INS42 INS34 INS32 INS32 INS32 INS45 INS45 UPD42 INS21 INS53 INS45 INS45 INS42 INS42 INS27 INS42 INS34 MOV43 INS27 INS42 INS42 INS34 MOV42 UPD42 MOV42 UPD42 UPD42 INS45 UPD42 MOV42 INS42 INS27 UPD42 INS42 INS27 UPD42 UPD42 INS14 UPD42 INS42 INS42 UPD42 INS42 INS45 INS42 INS45 INS42 INS45 INS42 UPD42 UPD42 UPD42 UPD42 INS42 INS42 INS9 INS42 INS42 INS27 UPD42 MOV42 UPD42 MOV42 INS42 INS45 UPD42 INS40 INS32 INS14 INS45 INS32 INS45 INS42 INS45 INS42 INS45 INS42 MOV32 INS42 INS45 INS42 INS45 INS42 INS43 INS42 UPD42 INS42 UPD42 INS27 INS45 INS42 INS45 INS32 INS45 INS32 INS45 INS45 INS42 INS42 INS45 INS42 INS43 INS42 INS42 INS42 INS42 INS32 UPD42 INS42 INS42 INS34 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 UPD42 MOV42 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL40 DEL26 DEL83 DEL83 DEL83 DEL42 DEL43 DEL42 DEL45 DEL59 DEL23 DEL83 DEL83 DEL83 DEL42 DEL43 DEL42 DEL40 DEL42 DEL32 DEL59 DEL23 DEL42 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL34 DEL32 DEL21 DEL42 DEL42 DEL32 DEL38 DEL42 DEL42 DEL32 DEL21 DEL25 DEL42 DEL43 DEL42 DEL42 DEL32 DEL42 DEL22 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL40 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL38 DEL42 DEL42 DEL32 DEL38 DEL27 DEL45 DEL14 DEL53 DEL25 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL32 DEL42 DEL32 DEL21 DEL8 DEL42 DEL32 DEL42 DEL32 DEL21 DEL8 DEL54 DEL8 DEL25 DEL42 DEL42 DEL32 DEL21 DEL42 DEL40 DEL32 DEL21 DEL42 DEL42 DEL40 DEL32 DEL21 DEL8 DEL31 DEL9 DEL66 DEL66 DEL66 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL42 DEL32 DEL42 DEL22 DEL59 DEL60 DEL32 DEL21 DEL42 DEL42 DEL32 DEL21 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL32 DEL59 DEL58 DEL42 DEL42 DEL32 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL8 DEL24 DEL8 DEL66 DEL66 DEL42 DEL65 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL40 DEL32 DEL42 DEL42 DEL40 DEL32 DEL83 DEL42 DEL43 DEL42 DEL42 DEL32 DEL42 DEL22 DEL41 DEL8 DEL31 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL32 DEL42 DEL14 DEL41 DEL8 DEL31 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL42 DEL32 DEL42 DEL14 DEL41 DEL8 DEL31 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL42 DEL66 DEL65 DEL40 DEL42 DEL42 DEL7 DEL21 DEL42 DEL42 DEL43 DEL42 DEL43 DEL42 DEL42 DEL14 DEL14 DEL7 DEL42 DEL42 DEL49 DEL42 DEL49 DEL42 DEL32 DEL21 DEL42 DEL33 DEL59 DEL60 DEL25 DEL32 DEL21 DEL10 DEL42 DEL49 DEL10 DEL50 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL45 DEL42 DEL27 DEL40 DEL42 DEL42 DEL32 DEL42 DEL45 DEL42 DEL27 DEL42 DEL42 DEL42 DEL42 DEL32 DEL40 DEL42 DEL42 DEL32 DEL42 DEL66 DEL66 DEL66 DEL42 DEL65 DEL66 DEL66 DEL42 DEL39 DEL69 DEL39 DEL85 DEL5 DEL69 DEL68 DEL65 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL42 DEL65 DEL66 DEL66 DEL66 DEL66 DEL42 DEL32 DEL7 DEL42 DEL42 DEL43 DEL42 DEL43 DEL42 DEL42 DEL14 DEL14 DEL7 DEL42 DEL42 DEL42 DEL32 DEL7 DEL42 DEL32 DEL42 DEL22 DEL40 DEL45 DEL42 DEL42 DEL32 DEL45 DEL42 DEL42 DEL32 DEL45 DEL42 DEL45 DEL42 DEL32 DEL42 DEL27 DEL36 DEL34 DEL27 DEL27 DEL45 DEL27 DEL42 DEL42 DEL45 DEL42 DEL27 DEL40 DEL42 DEL83 DEL83 DEL39 DEL42 DEL8 DEL31 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL65 DEL29 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL49 DEL10 DEL42 DEL49 DEL41 DEL42 DEL49 DEL42 DEL32 DEL21 DEL50 DEL42 DEL43 DEL42 DEL43 DEL74 DEL59 DEL58 DEL32 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL32 DEL38 DEL42 DEL32 DEL38 DEL27 DEL45 DEL42 DEL32 DEL27 DEL14 DEL53 DEL8 DEL25 DEL32 DEL38 DEL8 DEL25 DEL8 DEL24 DEL38 DEL32 DEL21 DEL25 DEL42 DEL40 DEL32 DEL21 DEL42 DEL33 DEL27 DEL42 DEL32 DEL14 DEL7 DEL21 DEL25 DEL42 DEL40 DEL7 DEL21 DEL8 DEL31 DEL83 DEL39 DEL42 DEL39 DEL42 DEL44 DEL34 DEL27 DEL45 DEL6 DEL6 DEL42 DEL43 DEL42 DEL42 DEL43 DEL14 DEL59 DEL60 DEL8 DEL8 DEL54 DEL8 DEL31 DEL43 DEL42 DEL43 DEL74 DEL42 DEL40 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL38 DEL14 DEL53 DEL25 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL39 DEL42 DEL32 DEL59 DEL60 DEL42 DEL32 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL39 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL43 DEL42 DEL33 DEL59 DEL60 DEL40 DEL42 DEL32 DEL8 DEL25 DEL42 DEL40 DEL7 DEL21 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL9 DEL32 DEL7 DEL21 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL42 DEL9 DEL42 DEL42 DEL32 DEL32 DEL21 DEL52 DEL8 DEL51 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL32 DEL59 DEL58 DEL32 DEL42 DEL43 DEL42 DEL32 DEL59 DEL60 DEL8 DEL24 DEL8 DEL31