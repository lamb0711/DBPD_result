HDFS-7411. Change decommission logic to throttle by blocks rather
than nodes in each interval. Contributed by Andrew Wang

+import java.util.AbstractList;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Queue;
+import java.util.TreeMap;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Preconditions;
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
-import org.apache.hadoop.classification.InterfaceStability;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hdfs.DFSConfigKeys;
+import org.apache.hadoop.hdfs.protocol.Block;
+import org.apache.hadoop.hdfs.protocol.DatanodeID;
+import org.apache.hadoop.hdfs.util.CyclicIteration;
+import org.apache.hadoop.util.ChunkedArrayList;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.hadoop.util.Time.now;
- * Manage node decommissioning.
+ * Manages datanode decommissioning. A background monitor thread 
+ * periodically checks the status of datanodes that are in-progress of 
+ * decommissioning.
+ * <p/>
+ * A datanode can be decommissioned in a few situations:
+ * <ul>
+ * <li>If a DN is dead, it is decommissioned immediately.</li>
+ * <li>If a DN is alive, it is decommissioned after all of its blocks 
+ * are sufficiently replicated. Merely under-replicated blocks do not 
+ * block decommissioning as long as they are above a replication 
+ * threshold.</li>
+ * </ul>
+ * In the second case, the datanode transitions to a 
+ * decommission-in-progress state and is tracked by the monitor thread. The 
+ * monitor periodically scans through the list of insufficiently replicated
+ * blocks on these datanodes to 
+ * determine if they can be decommissioned. The monitor also prunes this list 
+ * as blocks become replicated, so monitor scans will become more efficient 
+ * over time.
+ * <p/>
+ * Decommission-in-progress nodes that become dead do not progress to 
+ * decommissioned until they become live again. This prevents potential 
+ * durability loss for singly-replicated blocks (see HDFS-6791).
+ * <p/>
+ * This class depends on the FSNamesystem lock for synchronization.
-@InterfaceStability.Evolving
-class DecommissionManager {
-  static final Log LOG = LogFactory.getLog(DecommissionManager.class);
+public class DecommissionManager {
+  private static final Logger LOG = LoggerFactory.getLogger(DecommissionManager
+      .class);
-  private final BlockManager blockmanager;
+  private final BlockManager blockManager;
+  private final HeartbeatManager hbManager;
+  private final ScheduledExecutorService executor;
+
+  /**
+   * Map containing the decommission-in-progress datanodes that are being
+   * tracked so they can be be marked as decommissioned.
+   * <p/>
+   * This holds a set of references to the under-replicated blocks on the DN at
+   * the time the DN is added to the map, i.e. the blocks that are preventing
+   * the node from being marked as decommissioned. During a monitor tick, this
+   * list is pruned as blocks becomes replicated.
+   * <p/>
+   * Note also that the reference to the list of under-replicated blocks 
+   * will be null on initial add
+   * <p/>
+   * However, this map can become out-of-date since it is not updated by block
+   * reports or other events. Before being finally marking as decommissioned,
+   * another check is done with the actual block map.
+   */
+  private final TreeMap<DatanodeDescriptor, AbstractList<BlockInfoContiguous>>
+      decomNodeBlocks;
+
+  /**
+   * Tracking a node in decomNodeBlocks consumes additional memory. To limit
+   * the impact on NN memory consumption, we limit the number of nodes in 
+   * decomNodeBlocks. Additional nodes wait in pendingNodes.
+   */
+  private final Queue<DatanodeDescriptor> pendingNodes;
+
+  private Monitor monitor = null;
-      final BlockManager blockmanager) {
+      final BlockManager blockManager, final HeartbeatManager hbManager) {
-    this.blockmanager = blockmanager;
+    this.blockManager = blockManager;
+    this.hbManager = hbManager;
+
+    executor = Executors.newScheduledThreadPool(1,
+        new ThreadFactoryBuilder().setNameFormat("DecommissionMonitor-%d")
+            .setDaemon(true).build());
+    decomNodeBlocks = new TreeMap<>();
+    pendingNodes = new LinkedList<>();
-  /** Periodically check decommission status. */
-  class Monitor implements Runnable {
-    /** recheckInterval is how often namenode checks
-     *  if a node has finished decommission
-     */
-    private final long recheckInterval;
-    /** The number of decommission nodes to check for each interval */
-    private final int numNodesPerCheck;
-    /** firstkey can be initialized to anything. */
-    private String firstkey = "";
+  /**
+   * Start the decommission monitor thread.
+   * @param conf
+   */
+  void activate(Configuration conf) {
+    final int intervalSecs =
+        conf.getInt(DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY,
+            DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_DEFAULT);
+    checkArgument(intervalSecs >= 0, "Cannot set a negative " +
+        "value for " + DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY);
-    Monitor(int recheckIntervalInSecond, int numNodesPerCheck) {
-      this.recheckInterval = recheckIntervalInSecond * 1000L;
+    // By default, the new configuration key overrides the deprecated one.
+    // No # node limit is set.
+    int blocksPerInterval = conf.getInt(
+        DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_KEY,
+        DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_DEFAULT);
+    int nodesPerInterval = Integer.MAX_VALUE;
+
+    // If the expected key isn't present and the deprecated one is, 
+    // use the deprecated one into the new one. This overrides the 
+    // default.
+    //
+    // Also print a deprecation warning.
+    final String deprecatedKey =
+        "dfs.namenode.decommission.nodes.per.interval";
+    final String strNodes = conf.get(deprecatedKey);
+    if (strNodes != null) {
+      nodesPerInterval = Integer.parseInt(strNodes);
+      blocksPerInterval = Integer.MAX_VALUE;
+      LOG.warn("Using deprecated configuration key {} value of {}.",
+          deprecatedKey, nodesPerInterval); 
+      LOG.warn("Please update your configuration to use {} instead.", 
+          DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_KEY);
+    }
+    checkArgument(blocksPerInterval > 0,
+        "Must set a positive value for "
+        + DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_BLOCKS_PER_INTERVAL_KEY);
+
+    final int maxConcurrentTrackedNodes = conf.getInt(
+        DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES,
+        DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES_DEFAULT);
+    checkArgument(maxConcurrentTrackedNodes >= 0, "Cannot set a negative " +
+        "value for "
+        + DFSConfigKeys.DFS_NAMENODE_DECOMMISSION_MAX_CONCURRENT_TRACKED_NODES);
+
+    monitor = new Monitor(blocksPerInterval, 
+        nodesPerInterval, maxConcurrentTrackedNodes);
+    executor.scheduleAtFixedRate(monitor, intervalSecs, intervalSecs,
+        TimeUnit.SECONDS);
+
+    LOG.debug("Activating DecommissionManager with interval {} seconds, " +
+            "{} max blocks per interval, {} max nodes per interval, " +
+            "{} max concurrently tracked nodes.", intervalSecs,
+        blocksPerInterval, nodesPerInterval, maxConcurrentTrackedNodes);
+  }
+
+  /**
+   * Stop the decommission monitor thread, waiting briefly for it to terminate.
+   */
+  void close() {
+    executor.shutdownNow();
+    try {
+      executor.awaitTermination(3000, TimeUnit.MILLISECONDS);
+    } catch (InterruptedException e) {}
+  }
+
+  /**
+   * Start decommissioning the specified datanode. 
+   * @param node
+   */
+  @VisibleForTesting
+  public void startDecommission(DatanodeDescriptor node) {
+    if (!node.isDecommissionInProgress()) {
+      if (!node.isAlive) {
+        LOG.info("Dead node {} is decommissioned immediately.", node);
+        node.setDecommissioned();
+      } else if (!node.isDecommissioned()) {
+        for (DatanodeStorageInfo storage : node.getStorageInfos()) {
+          LOG.info("Starting decommission of {} {} with {} blocks", 
+              node, storage, storage.numBlocks());
+        }
+        // Update DN stats maintained by HeartbeatManager
+        hbManager.startDecommission(node);
+        node.decommissioningStatus.setStartTime(now());
+        pendingNodes.add(node);
+      }
+    } else {
+      LOG.trace("startDecommission: Node {} is already decommission in "
+              + "progress, nothing to do.", node);
+    }
+  }
+
+  /**
+   * Stop decommissioning the specified datanode. 
+   * @param node
+   */
+  void stopDecommission(DatanodeDescriptor node) {
+    if (node.isDecommissionInProgress() || node.isDecommissioned()) {
+      LOG.info("Stopping decommissioning of node {}", node);
+      // Update DN stats maintained by HeartbeatManager
+      hbManager.stopDecommission(node);
+      // Over-replicated blocks will be detected and processed when 
+      // the dead node comes back and send in its full block report.
+      if (node.isAlive) {
+        blockManager.processOverReplicatedBlocksOnReCommission(node);
+      }
+      // Remove from tracking in DecommissionManager
+      pendingNodes.remove(node);
+      decomNodeBlocks.remove(node);
+    } else {
+      LOG.trace("stopDecommission: Node {} is not decommission in progress " +
+          "or decommissioned, nothing to do.", node);
+    }
+  }
+
+  private void setDecommissioned(DatanodeDescriptor dn) {
+    dn.setDecommissioned();
+    LOG.info("Decommissioning complete for node {}", dn);
+  }
+
+  /**
+   * Checks whether a block is sufficiently replicated for decommissioning.
+   * Full-strength replication is not always necessary, hence "sufficient".
+   * @return true if sufficient, else false.
+   */
+  private boolean isSufficientlyReplicated(BlockInfoContiguous block, 
+      BlockCollection bc,
+      NumberReplicas numberReplicas) {
+    final int numExpected = bc.getBlockReplication();
+    final int numLive = numberReplicas.liveReplicas();
+    if (!blockManager.isNeededReplication(block, numExpected, numLive)) {
+      // Block doesn't need replication. Skip.
+      LOG.trace("Block {} does not need replication.", block);
+      return true;
+    }
+
+    // Block is under-replicated
+    LOG.trace("Block {} numExpected={}, numLive={}", block, numExpected, 
+        numLive);
+    if (numExpected > numLive) {
+      if (bc.isUnderConstruction() && block.equals(bc.getLastBlock())) {
+        // Can decom a UC block as long as there will still be minReplicas
+        if (numLive >= blockManager.minReplication) {
+          LOG.trace("UC block {} sufficiently-replicated since numLive ({}) "
+              + ">= minR ({})", block, numLive, blockManager.minReplication);
+          return true;
+        } else {
+          LOG.trace("UC block {} insufficiently-replicated since numLive "
+              + "({}) < minR ({})", block, numLive,
+              blockManager.minReplication);
+        }
+      } else {
+        // Can decom a non-UC as long as the default replication is met
+        if (numLive >= blockManager.defaultReplication) {
+          return true;
+        }
+      }
+    }
+    return false;
+  }
+
+  private static void logBlockReplicationInfo(Block block, BlockCollection bc,
+      DatanodeDescriptor srcNode, NumberReplicas num,
+      Iterable<DatanodeStorageInfo> storages) {
+    int curReplicas = num.liveReplicas();
+    int curExpectedReplicas = bc.getBlockReplication();
+    StringBuilder nodeList = new StringBuilder();
+    for (DatanodeStorageInfo storage : storages) {
+      final DatanodeDescriptor node = storage.getDatanodeDescriptor();
+      nodeList.append(node);
+      nodeList.append(" ");
+    }
+    LOG.info("Block: " + block + ", Expected Replicas: "
+        + curExpectedReplicas + ", live replicas: " + curReplicas
+        + ", corrupt replicas: " + num.corruptReplicas()
+        + ", decommissioned replicas: " + num.decommissionedReplicas()
+        + ", excess replicas: " + num.excessReplicas()
+        + ", Is Open File: " + bc.isUnderConstruction()
+        + ", Datanodes having this block: " + nodeList + ", Current Datanode: "
+        + srcNode + ", Is current datanode decommissioning: "
+        + srcNode.isDecommissionInProgress());
+  }
+
+  @VisibleForTesting
+  public int getNumPendingNodes() {
+    return pendingNodes.size();
+  }
+
+  @VisibleForTesting
+  public int getNumTrackedNodes() {
+    return decomNodeBlocks.size();
+  }
+
+  @VisibleForTesting
+  public int getNumNodesChecked() {
+    return monitor.numNodesChecked;
+  }
+
+  /**
+   * Checks to see if DNs have finished decommissioning.
+   * <p/>
+   * Since this is done while holding the namesystem lock, 
+   * the amount of work per monitor tick is limited.
+   */
+  private class Monitor implements Runnable {
+    /**
+     * The maximum number of blocks to check per tick.
+     */
+    private final int numBlocksPerCheck;
+    /**
+     * The maximum number of nodes to check per tick.
+     */
+    private final int numNodesPerCheck;
+    /**
+     * The maximum number of nodes to track in decomNodeBlocks. A value of 0
+     * means no limit.
+     */
+    private final int maxConcurrentTrackedNodes;
+    /**
+     * The number of blocks that have been checked on this tick.
+     */
+    private int numBlocksChecked = 0;
+    /**
+     * The number of nodes that have been checked on this tick. Used for 
+     * testing.
+     */
+    private int numNodesChecked = 0;
+    /**
+     * The last datanode in decomNodeBlocks that we've processed
+     */
+    private DatanodeDescriptor iterkey = new DatanodeDescriptor(new 
+        DatanodeID("", "", "", 0, 0, 0, 0));
+
+    Monitor(int numBlocksPerCheck, int numNodesPerCheck, int 
+        maxConcurrentTrackedNodes) {
+      this.numBlocksPerCheck = numBlocksPerCheck;
+      this.maxConcurrentTrackedNodes = maxConcurrentTrackedNodes;
+    }
+
+    private boolean exceededNumBlocksPerCheck() {
+      LOG.trace("Processed {} blocks so far this tick", numBlocksChecked);
+      return numBlocksChecked >= numBlocksPerCheck;
+    }
+
+    @Deprecated
+    private boolean exceededNumNodesPerCheck() {
+      LOG.trace("Processed {} nodes so far this tick", numNodesChecked);
+      return numNodesChecked >= numNodesPerCheck;
+    }
+
+    @Override
+    public void run() {
+      if (!namesystem.isRunning()) {
+        LOG.info("Namesystem is not running, skipping decommissioning checks"
+            + ".");
+        return;
+      }
+      // Reset the checked count at beginning of each iteration
+      numBlocksChecked = 0;
+      numNodesChecked = 0;
+      // Check decom progress
+      namesystem.writeLock();
+      try {
+        processPendingNodes();
+        check();
+      } finally {
+        namesystem.writeUnlock();
+      }
+      if (numBlocksChecked + numNodesChecked > 0) {
+        LOG.info("Checked {} blocks and {} nodes this tick", numBlocksChecked,
+            numNodesChecked);
+      }
-     * Check decommission status of numNodesPerCheck nodes
-     * for every recheckInterval milliseconds.
+     * Pop datanodes off the pending list and into decomNodeBlocks, 
+     * subject to the maxConcurrentTrackedNodes limit.
-    @Override
-    public void run() {
-      for(; namesystem.isRunning(); ) {
-        namesystem.writeLock();
-        try {
-          check();
-        } finally {
-          namesystem.writeUnlock();
-        }
-  
-        try {
-          Thread.sleep(recheckInterval);
-        } catch (InterruptedException ie) {
-          LOG.warn(this.getClass().getSimpleName() + " interrupted: " + ie);
-        }
+    private void processPendingNodes() {
+      while (!pendingNodes.isEmpty() &&
+          (maxConcurrentTrackedNodes == 0 ||
+           decomNodeBlocks.size() < maxConcurrentTrackedNodes)) {
+        decomNodeBlocks.put(pendingNodes.poll(), null);
-    
-    private void check() {
-      final DatanodeManager dm = blockmanager.getDatanodeManager();
-      int count = 0;
-      for(Map.Entry<String, DatanodeDescriptor> entry
-          : dm.getDatanodeCyclicIteration(firstkey)) {
-        final DatanodeDescriptor d = entry.getValue();
-        firstkey = entry.getKey();
-        if (d.isDecommissionInProgress()) {
-          try {
-            dm.checkDecommissionState(d);
-          } catch(Exception e) {
-            LOG.warn("entry=" + entry, e);
-          }
-          if (++count == numNodesPerCheck) {
-            return;
-          }
+    private void check() {
+      final Iterator<Map.Entry<DatanodeDescriptor, AbstractList<BlockInfoContiguous>>>
+          it = new CyclicIteration<>(decomNodeBlocks, iterkey).iterator();
+      final LinkedList<DatanodeDescriptor> toRemove = new LinkedList<>();
+
+      while (it.hasNext()
+          && !exceededNumBlocksPerCheck()
+          && !exceededNumNodesPerCheck()) {
+        numNodesChecked++;
+        final Map.Entry<DatanodeDescriptor, AbstractList<BlockInfoContiguous>>
+            entry = it.next();
+        final DatanodeDescriptor dn = entry.getKey();
+        AbstractList<BlockInfoContiguous> blocks = entry.getValue();
+        boolean fullScan = false;
+        if (blocks == null) {
+          // This is a newly added datanode, run through its list to schedule 
+          // under-replicated blocks for replication and collect the blocks 
+          // that are insufficiently replicated for further tracking
+          LOG.debug("Newly-added node {}, doing full scan to find " +
+              "insufficiently-replicated blocks.", dn);
+          blocks = handleInsufficientlyReplicated(dn);
+          decomNodeBlocks.put(dn, blocks);
+          fullScan = true;
+        } else {
+          // This is a known datanode, check if its # of insufficiently 
+          // replicated blocks has dropped to zero and if it can be decommed
+          LOG.debug("Processing decommission-in-progress node {}", dn);
+          pruneSufficientlyReplicated(dn, blocks);
+        if (blocks.size() == 0) {
+          if (!fullScan) {
+            // If we didn't just do a full scan, need to re-check with the 
+            // full block map.
+            //
+            // We've replicated all the known insufficiently replicated 
+            // blocks. Re-check with the full block map before finally 
+            // marking the datanode as decommissioned 
+            LOG.debug("Node {} has finished replicating current set of "
+                + "blocks, checking with the full block map.", dn);
+            blocks = handleInsufficientlyReplicated(dn);
+            decomNodeBlocks.put(dn, blocks);
+          }
+          // If the full scan is clean AND the node liveness is okay, 
+          // we can finally mark as decommissioned.
+          final boolean isHealthy =
+              blockManager.isNodeHealthyForDecommission(dn);
+          if (blocks.size() == 0 && isHealthy) {
+            setDecommissioned(dn);
+            toRemove.add(dn);
+            LOG.debug("Node {} is sufficiently replicated and healthy, "
+                + "marked as decommissioned.", dn);
+          } else {
+            if (LOG.isDebugEnabled()) {
+              StringBuilder b = new StringBuilder("Node {} ");
+              if (isHealthy) {
+                b.append("is ");
+              } else {
+                b.append("isn't ");
+              }
+              b.append("healthy and still needs to replicate {} more blocks," +
+                  " decommissioning is still in progress.");
+              LOG.debug(b.toString(), dn, blocks.size());
+            }
+          }
+        } else {
+          LOG.debug("Node {} still has {} blocks to replicate "
+                  + "before it is a candidate to finish decommissioning.",
+              dn, blocks.size());
+        }
+        iterkey = dn;
+      }
+      // Remove the datanodes that are decommissioned
+      for (DatanodeDescriptor dn : toRemove) {
+        Preconditions.checkState(dn.isDecommissioned(),
+            "Removing a node that is not yet decommissioned!");
+        decomNodeBlocks.remove(dn);
+
+    /**
+     * Removes sufficiently replicated blocks from the block list of a 
+     * datanode.
+     */
+    private void pruneSufficientlyReplicated(final DatanodeDescriptor datanode,
+        AbstractList<BlockInfoContiguous> blocks) {
+      processBlocksForDecomInternal(datanode, blocks.iterator(), null, true);
+    }
+
+    /**
+     * Returns a list of blocks on a datanode that are insufficiently 
+     * replicated, i.e. are under-replicated enough to prevent decommission.
+     * <p/>
+     * As part of this, it also schedules replication work for 
+     * any under-replicated blocks.
+     *
+     * @param datanode
+     * @return List of insufficiently replicated blocks 
+     */
+    private AbstractList<BlockInfoContiguous> handleInsufficientlyReplicated(
+        final DatanodeDescriptor datanode) {
+      AbstractList<BlockInfoContiguous> insufficient = new ChunkedArrayList<>();
+      processBlocksForDecomInternal(datanode, datanode.getBlockIterator(),
+          insufficient, false);
+      return insufficient;
+    }
+
+    /**
+     * Used while checking if decommission-in-progress datanodes can be marked
+     * as decommissioned. Combines shared logic of 
+     * pruneSufficientlyReplicated and handleInsufficientlyReplicated.
+     *
+     * @param datanode                    Datanode
+     * @param it                          Iterator over the blocks on the
+     *                                    datanode
+     * @param insufficientlyReplicated    Return parameter. If it's not null,
+     *                                    will contain the insufficiently
+     *                                    replicated-blocks from the list.
+     * @param pruneSufficientlyReplicated whether to remove sufficiently
+     *                                    replicated blocks from the iterator
+     * @return true if there are under-replicated blocks in the provided block
+     * iterator, else false.
+     */
+    private void processBlocksForDecomInternal(
+        final DatanodeDescriptor datanode,
+        final Iterator<BlockInfoContiguous> it,
+        final List<BlockInfoContiguous> insufficientlyReplicated,
+        boolean pruneSufficientlyReplicated) {
+      boolean firstReplicationLog = true;
+      int underReplicatedBlocks = 0;
+      int decommissionOnlyReplicas = 0;
+      int underReplicatedInOpenFiles = 0;
+      while (it.hasNext()) {
+        numBlocksChecked++;
+        final BlockInfoContiguous block = it.next();
+        // Remove the block from the list if it's no longer in the block map,
+        // e.g. the containing file has been deleted
+        if (blockManager.blocksMap.getStoredBlock(block) == null) {
+          LOG.trace("Removing unknown block {}", block);
+          it.remove();
+          continue;
+        }
+        BlockCollection bc = blockManager.blocksMap.getBlockCollection(block);
+        if (bc == null) {
+          // Orphan block, will be invalidated eventually. Skip.
+          continue;
+        }
+
+        final NumberReplicas num = blockManager.countNodes(block);
+        final int liveReplicas = num.liveReplicas();
+        final int curReplicas = liveReplicas;
+
+        // Schedule under-replicated blocks for replication if not already
+        // pending
+        if (blockManager.isNeededReplication(block, bc.getBlockReplication(),
+            liveReplicas)) {
+          if (!blockManager.neededReplications.contains(block) &&
+              blockManager.pendingReplications.getNumReplicas(block) == 0 &&
+              namesystem.isPopulatingReplQueues()) {
+            // Process these blocks only when active NN is out of safe mode.
+            blockManager.neededReplications.add(block,
+                curReplicas,
+                num.decommissionedReplicas(),
+                bc.getBlockReplication());
+          }
+        }
+
+        // Even if the block is under-replicated, 
+        // it doesn't block decommission if it's sufficiently replicated 
+        if (isSufficientlyReplicated(block, bc, num)) {
+          if (pruneSufficientlyReplicated) {
+            it.remove();
+          }
+          continue;
+        }
+
+        // We've found an insufficiently replicated block.
+        if (insufficientlyReplicated != null) {
+          insufficientlyReplicated.add(block);
+        }
+        // Log if this is our first time through
+        if (firstReplicationLog) {
+          logBlockReplicationInfo(block, bc, datanode, num,
+              blockManager.blocksMap.getStorages(block));
+          firstReplicationLog = false;
+        }
+        // Update various counts
+        underReplicatedBlocks++;
+        if (bc.isUnderConstruction()) {
+          underReplicatedInOpenFiles++;
+        }
+        if ((curReplicas == 0) && (num.decommissionedReplicas() > 0)) {
+          decommissionOnlyReplicas++;
+        }
+      }
+
+      datanode.decommissioningStatus.set(underReplicatedBlocks,
+          decommissionOnlyReplicas,
+          underReplicatedInOpenFiles);
+    }
+  }
+
+  @VisibleForTesting
+  void runMonitor() throws ExecutionException, InterruptedException {
+    Future f = executor.submit(monitor);
+    f.get();

MOV26 MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 UPD40 INS83 INS23 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS83 UPD43 INS83 INS83 INS43 INS59 INS83 INS83 INS43 INS59 INS29 INS83 INS83 INS74 INS59 INS29 INS83 INS83 INS74 INS59 INS83 INS43 INS59 INS44 INS29 INS39 INS42 INS44 INS8 INS29 INS39 INS42 INS8 INS29 INS78 INS83 INS39 INS42 INS44 INS8 INS29 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS44 INS8 INS83 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS83 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS78 INS39 INS42 INS43 INS43 INS8 INS66 INS66 UPD66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 UPD42 UPD42 INS42 INS42 INS42 INS42 INS65 INS43 INS43 INS74 INS42 INS65 INS43 MOV43 INS42 INS42 INS42 INS33 UPD42 INS83 INS43 INS42 INS21 INS21 INS21 INS21 INS65 INS65 INS43 INS42 INS60 INS21 INS60 INS60 INS60 INS60 INS25 INS21 INS60 INS21 INS21 INS21 INS21 INS65 INS21 INS54 INS65 INS65 INS42 INS43 INS42 INS25 INS65 INS65 INS43 INS42 INS25 INS43 INS42 INS21 INS21 INS65 INS65 INS43 INS42 INS43 INS42 INS43 INS42 INS60 INS60 INS25 INS21 INS25 INS41 INS43 INS42 INS43 INS42 INS43 INS42 INS43 INS42 INS74 INS42 INS60 INS60 INS60 INS70 INS21 INS42 INS41 INS42 INS41 INS42 INS41 UPD39 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS39 INS59 INS29 INS83 INS39 INS59 MOV43 INS44 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 MOV78 INS83 INS39 INS42 INS8 UPD83 UPD42 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS8 INS29 INS83 INS74 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS8 INS42 INS42 INS42 INS60 INS21 UPD42 UPD42 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS43 INS43 INS66 INS66 INS66 INS42 INS42 INS7 INS7 INS7 INS7 INS66 INS42 INS42 INS83 INS39 INS59 INS32 INS39 INS59 INS39 INS59 INS83 MOV43 INS59 INS83 MOV43 INS59 INS27 INS8 INS32 INS83 INS39 INS59 INS32 INS7 INS32 INS32 INS66 INS32 INS8 INS12 INS66 INS42 INS42 INS38 INS8 INS8 INS66 INS42 INS42 INS27 INS8 INS8 INS42 INS32 INS32 INS66 INS66 INS66 INS42 INS42 INS42 INS83 INS39 INS59 INS83 INS39 INS59 INS38 INS8 INS32 INS27 INS8 INS9 INS42 INS42 INS42 INS42 INS43 INS43 INS39 INS59 INS39 INS59 INS43 INS59 INS44 INS42 INS8 INS32 INS32 INS32 INS40 UPD66 INS66 INS66 INS66 UPD42 INS65 INS42 INS65 INS42 INS34 INS65 INS42 INS34 UPD42 INS14 UPD42 INS39 INS42 INS21 INS21 INS41 INS42 INS21 INS41 INS25 INS21 INS21 MOV21 MOV54 INS25 INS61 INS61 INS70 INS65 INS83 INS43 INS42 INS74 INS42 INS21 INS65 INS65 INS65 INS43 INS43 INS83 INS43 INS42 INS60 INS21 INS41 INS65 INS65 INS65 INS65 INS65 INS65 INS83 INS43 INS42 INS83 INS74 INS42 INS83 INS74 INS42 INS39 INS42 INS60 INS60 INS60 INS60 INS61 INS21 INS43 INS59 INS32 INS42 INS42 UPD42 INS22 INS42 INS42 INS32 INS42 INS14 INS42 INS14 INS42 INS32 INS42 INS27 INS27 INS42 INS32 INS42 INS40 INS42 INS45 INS42 INS32 INS42 INS33 INS21 INS21 INS21 INS21 INS42 INS27 INS27 INS42 INS32 INS42 INS27 INS27 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS21 MOV44 INS8 INS32 INS25 INS21 INS32 INS32 INS21 INS21 INS25 INS21 INS21 INS21 INS42 INS42 INS42 INS42 INS45 INS42 INS42 INS32 INS42 INS32 INS32 INS21 INS41 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS25 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS14 INS43 INS42 INS60 INS21 INS21 INS42 INS42 INS27 INS42 INS42 INS42 INS42 UPD66 UPD66 INS66 INS66 INS66 INS66 INS66 UPD66 INS43 INS14 INS7 INS32 INS27 INS32 INS27 INS38 INS8 INS7 INS7 INS27 INS8 UPD66 UPD66 INS27 INS8 INS74 INS83 INS74 INS27 INS8 INS44 INS42 INS8 INS66 INS66 INS42 INS43 INS43 INS32 INS66 INS66 INS66 INS66 INS66 INS42 INS66 INS42 INS42 INS42 INS74 INS59 INS32 INS42 INS66 INS66 INS66 INS42 INS66 INS42 INS66 INS66 INS42 INS66 INS66 INS66 INS42 INS66 INS66 INS66 INS66 INS42 INS43 INS43 INS43 INS43 INS39 INS59 INS39 INS59 INS39 INS59 INS39 INS59 INS32 INS8 INS32 INS42 INS42 INS32 INS42 INS42 UPD42 INS52 INS42 INS42 INS42 INS34 INS32 INS74 INS74 INS42 INS42 INS40 INS40 INS42 INS34 INS45 INS45 INS40 INS42 INS42 INS40 INS40 INS42 INS42 INS42 INS7 INS7 INS32 INS32 INS42 INS34 INS45 INS40 INS42 INS42 INS40 INS40 INS42 INS34 INS45 INS45 INS40 INS43 INS42 INS42 INS42 INS45 INS45 INS45 INS32 UPD42 INS42 INS42 INS38 INS8 INS25 INS32 INS42 INS42 INS42 INS42 INS32 INS32 INS40 INS8 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS9 INS27 INS8 INS8 INS42 INS42 INS42 INS42 INS43 INS42 INS83 INS43 INS59 INS32 INS32 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS32 INS45 INS32 INS45 INS32 INS45 INS32 INS45 INS42 INS45 INS42 INS45 INS32 INS42 INS43 INS45 INS45 INS45 INS34 INS34 INS34 INS34 INS42 INS22 INS42 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS45 INS42 INS42 INS42 MOV32 INS21 INS41 INS42 INS34 INS42 INS34 INS21 INS27 INS34 INS21 INS38 INS36 MOV21 INS43 INS74 UPD42 INS43 INS43 INS42 INS14 INS32 INS38 INS38 INS21 INS60 INS60 MOV60 INS60 INS25 MOV25 INS21 INS43 INS42 INS21 INS21 INS42 INS42 INS42 INS42 INS32 INS33 INS9 INS43 INS43 INS42 INS14 INS42 INS42 INS32 INS42 INS9 INS42 INS42 INS42 INS42 INS42 INS9 INS42 INS34 INS42 INS34 INS42 INS34 INS42 INS42 INS21 INS60 INS25 INS60 INS25 INS60 INS60 INS60 INS25 INS25 INS25 INS25 INS21 INS25 INS25 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS43 INS43 INS42 INS32 INS42 INS40 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS45 INS40 INS42 INS42 INS42 INS34 INS40 INS40 INS21 INS21 INS38 INS8 INS42 INS42 INS27 INS42 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS45 INS42 INS32 INS32 INS25 INS25 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS52 INS42 INS32 INS32 INS42 INS42 INS32 INS32 INS27 INS42 MOV43 INS43 INS74 INS14 UPD42 INS42 INS42 INS74 INS42 INS42 INS32 INS32 INS37 INS83 INS74 INS59 INS83 INS43 INS59 INS74 INS39 INS59 INS27 INS8 INS8 INS27 INS8 INS7 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS74 INS42 INS42 INS37 INS83 INS43 INS59 INS27 INS8 INS43 INS59 INS27 INS8 INS83 INS43 INS59 INS83 INS39 INS59 INS83 INS39 INS59 INS32 INS8 INS32 INS8 INS27 INS8 INS42 INS8 INS37 INS32 INS8 INS27 INS8 INS32 INS42 INS9 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS32 INS70 INS21 INS21 INS21 INS45 INS45 INS32 INS45 INS45 INS42 INS42 INS42 INS42 INS32 INS27 INS8 INS8 INS27 INS8 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS45 INS42 INS42 UPD42 MOV42 INS42 INS27 INS27 UPD42 UPD42 INS32 INS33 UPD42 MOV42 INS43 INS43 INS74 INS42 INS42 INS43 INS42 INS42 INS42 INS43 INS43 INS74 INS42 INS32 INS42 INS42 MOV32 INS43 INS43 UPD42 INS42 INS9 INS42 INS33 INS21 INS21 INS21 MOV21 INS21 INS21 INS32 INS34 INS25 INS60 INS25 INS21 INS42 INS42 INS42 INS42 INS32 INS45 INS42 INS42 INS42 INS43 INS42 INS42 INS42 INS32 INS32 INS33 INS21 INS21 INS18 INS42 INS42 INS32 INS42 INS33 INS18 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS25 INS42 INS42 INS42 INS42 INS25 INS18 INS42 INS33 INS21 INS21 INS21 INS42 INS42 INS42 INS21 INS36 INS36 INS21 INS14 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS44 INS32 INS8 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS21 INS41 INS21 INS42 INS40 INS41 INS45 INS45 INS42 INS34 INS32 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS43 INS42 INS40 INS42 INS43 INS43 INS42 INS42 INS42 INS42 INS32 INS7 INS32 INS32 INS32 UPD42 MOV42 UPD42 MOV42 INS38 INS8 INS83 INS39 INS59 INS27 INS8 INS8 INS32 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS42 INS32 INS32 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS8 INS42 INS8 INS32 INS32 INS7 INS37 INS27 INS27 INS37 INS43 INS43 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS40 INS42 INS32 INS42 INS42 INS42 INS32 INS9 INS32 INS9 INS42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS32 UPD42 MOV42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 INS9 INS42 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS21 INS21 MOV21 INS42 INS32 INS27 INS42 INS21 INS21 MOV21 INS25 INS42 INS42 INS27 INS42 INS32 INS42 INS42 INS45 INS42 INS42 INS42 INS27 INS32 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS9 INS42 INS42 INS34 INS32 INS34 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS27 INS42 INS42 INS40 INS42 INS42 INS27 INS42 INS42 INS40 INS45 INS45 INS42 INS42 INS32 INS7 INS42 INS42 INS42 INS32 INS34 INS32 INS32 INS32 INS8 INS45 INS45 INS42 INS42 INS38 INS27 INS42 INS42 INS32 INS32 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS42 INS42 INS32 INS45 INS45 INS45 INS45 INS42 INS42 INS27 INS42 INS42 INS32 UPD42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 UPD42 INS42 INS42 INS60 MOV25 INS21 INS21 INS32 INS32 INS34 INS40 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS45 INS45 INS42 INS42 INS45 UPD45 INS43 INS59 INS42 INS8 INS32 INS32 INS40 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS14 INS21 INS21 INS42 INS42 INS27 INS42 INS42 INS32 INS42 INS32 INS43 INS45 INS32 INS32 INS45 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS42 INS42 INS45 DEL40 DEL78 DEL66 DEL45 DEL42 DEL34 DEL27 DEL52 DEL32 DEL32 DEL45 DEL42 DEL27 DEL42 DEL32 DEL21 DEL8 DEL8 DEL12 DEL54 DEL8 DEL24 DEL8 DEL43 DEL42 DEL39 DEL42 DEL34 DEL83 DEL32 DEL42 DEL42 DEL38 DEL42 DEL27 DEL41 DEL8 DEL42 DEL43 DEL42 DEL44 DEL8 DEL12 DEL54 DEL74 DEL42 DEL44 DEL32 DEL8 DEL70