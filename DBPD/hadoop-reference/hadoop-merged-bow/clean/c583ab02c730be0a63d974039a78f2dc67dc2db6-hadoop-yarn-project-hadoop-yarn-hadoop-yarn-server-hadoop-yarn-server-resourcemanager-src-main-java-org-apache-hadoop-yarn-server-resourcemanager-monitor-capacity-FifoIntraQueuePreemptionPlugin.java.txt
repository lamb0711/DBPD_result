YARN-2113. Add cross-user preemption within CapacityScheduler's leaf-queue. (Sunil G via wangda)

Change-Id: I9b19f69788068be05b3295247cdd7b972f8a573c

+import java.util.ArrayList;
+import java.util.List;
+import org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.IntraQueuePreemptionOrderPolicy;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceUsage;
+  public Collection<FiCaSchedulerApp> getPreemptableApps(String queueName,
+      String partition) {
+    TempQueuePerPartition tq = context.getQueueByPartition(queueName,
+        partition);
+
+    List<FiCaSchedulerApp> apps = new ArrayList<FiCaSchedulerApp>();
+    for (TempAppPerPartition tmpApp : tq.getApps()) {
+      // If a lower priority app was not selected to get preempted, mark such
+      // apps out from preemption candidate selection.
+      if (Resources.equals(tmpApp.getActuallyToBePreempted(),
+          Resources.none())) {
+        continue;
+      }
+
+      apps.add(tmpApp.app);
+    }
+    return apps;
+  }
+
+  @Override
-      Resource partitionBasedResource, TempQueuePerPartition tq,
+      TempQueuePerPartition tq,
-    TAPriorityComparator taComparator = new TAPriorityComparator();
-    PriorityQueue<TempAppPerPartition> orderedByPriority =
-        createTempAppForResCalculation(tq.partition, apps, taComparator);
+    PriorityQueue<TempAppPerPartition> orderedByPriority = createTempAppForResCalculation(
+        tq, apps, clusterResource, perUserAMUsed);
-    TreeSet<TempAppPerPartition> orderedApps =
-        calculateIdealAssignedResourcePerApp(clusterResource,
-            partitionBasedResource, tq, selectedCandidates,
-            queueReassignableResource, orderedByPriority, perUserAMUsed);
+    TreeSet<TempAppPerPartition> orderedApps = calculateIdealAssignedResourcePerApp(
+        clusterResource, tq, selectedCandidates, queueReassignableResource,
+        orderedByPriority);
-        preemptionLimit);
+        Resources.clone(preemptionLimit));
-        (TreeSet<TempAppPerPartition>) tq.getApps());
+        (TreeSet<TempAppPerPartition>) orderedApps, tq.getUsersPerPartition(),
+        context.getIntraQueuePreemptionOrderPolicy());
-      Resources.subtractFrom(preemtableFromApp, tmpApp.selected);
-      Resources.subtractFrom(preemtableFromApp, tmpApp.getAMUsed());
+      Resources.subtractFromNonNegative(preemtableFromApp, tmpApp.selected);
+      Resources.subtractFromNonNegative(preemtableFromApp, tmpApp.getAMUsed());
-          preemptionLimit);
+          Resources.clone(preemptionLimit));
-      preemptionLimit = Resources.subtract(preemptionLimit,
+      preemptionLimit = Resources.subtractFromNonNegative(preemptionLimit,
-   * @param partitionBasedResource resource per partition
-   * @param perUserAMUsed AM used resource
-      Resource clusterResource, Resource partitionBasedResource,
-      TempQueuePerPartition tq,
+      Resource clusterResource, TempQueuePerPartition tq,
-      PriorityQueue<TempAppPerPartition> orderedByPriority,
-      Map<String, Resource> perUserAMUsed) {
+      PriorityQueue<TempAppPerPartition> orderedByPriority) {
-    Map<String, Resource> userIdealAssignedMapping = new HashMap<>();
-
-    Map<String, Resource> preCalculatedUserLimit =
-        new HashMap<String, Resource>();
+    Map<String, TempUserPerPartition> usersPerPartition = tq.getUsersPerPartition();
-          queueReassignableResource, Resources.none())) {
+          queueReassignableResource, Resources.none())
+          || Resources.isAnyMajorResourceZero(rc, queueReassignableResource)) {
-      Resource userLimitResource = preCalculatedUserLimit.get(userName);
-
-      // Verify whether we already calculated headroom for this user.
-      if (userLimitResource == null) {
-        userLimitResource = Resources.clone(
-            tq.leafQueue.getResourceLimitForAllUsers(userName, clusterResource,
-                partition, SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY));
-
-        Resource amUsed = perUserAMUsed.get(userName);
-        if (null == amUsed) {
-          amUsed = Resources.createResource(0, 0);
-        }
-
-        // Real AM used need not have to be considered for user-limit as well.
-        userLimitResource = Resources.subtract(userLimitResource, amUsed);
-        if (LOG.isDebugEnabled()) {
-          LOG.debug("Userlimit for user '" + userName + "' is :"
-              + userLimitResource + ", and amUsed is:" + amUsed);
-        }
-
-        preCalculatedUserLimit.put(userName, userLimitResource);
-      }
-
-      Resource idealAssignedForUser = userIdealAssignedMapping.get(userName);
-
-      if (idealAssignedForUser == null) {
-        idealAssignedForUser = Resources.createResource(0, 0);
-        userIdealAssignedMapping.put(userName, idealAssignedForUser);
-      }
+      TempUserPerPartition tmpUser = usersPerPartition.get(userName);
+      Resource userLimitResource = tmpUser.getUserLimit();
+      Resource idealAssignedForUser = tmpUser.idealAssigned;
-      getAlreadySelectedPreemptionCandidatesResource(selectedCandidates,
-          tmpApp, partition);
+      getAlreadySelectedPreemptionCandidatesResource(selectedCandidates, tmpApp,
+          tmpUser, partition);
-        appIdealAssigned = Resources.min(rc, clusterResource, appIdealAssigned,
+        Resource idealAssigned = Resources.min(rc, clusterResource,
+            appIdealAssigned,
-            clusterResource, queueReassignableResource, appIdealAssigned));
+            clusterResource, queueReassignableResource, idealAssigned));
-      Resources.subtractFrom(queueReassignableResource, tmpApp.idealAssigned);
+      Resources.subtractFromNonNegative(queueReassignableResource,
+          tmpApp.idealAssigned);
-      TempAppPerPartition tmpApp, String partition) {
+      TempAppPerPartition tmpApp, TempUserPerPartition tmpUser,
+      String partition) {
+        Resources.addTo(tmpUser.selected, cont.getAllocatedResource());
-      String partition, Collection<FiCaSchedulerApp> apps,
-      TAPriorityComparator taComparator) {
+      TempQueuePerPartition tq, Collection<FiCaSchedulerApp> apps,
+      Resource clusterResource,
+      Map<String, Resource> perUserAMUsed) {
+    TAPriorityComparator taComparator = new TAPriorityComparator();
+    String partition = tq.partition;
+    Map<String, TempUserPerPartition> usersPerPartition = tq
+        .getUsersPerPartition();
+
+
+      // Create a TempUserPerPartition structure to hold more information
+      // regarding each user's entities such as UserLimit etc. This could
+      // be kept in a user to TempUserPerPartition map for further reference.
+      String userName = app.getUser();
+      if (!usersPerPartition.containsKey(userName)) {
+        ResourceUsage userResourceUsage = tq.leafQueue.getUser(userName)
+            .getResourceUsage();
+
+        TempUserPerPartition tmpUser = new TempUserPerPartition(
+            tq.leafQueue.getUser(userName), tq.queueName,
+            Resources.clone(userResourceUsage.getUsed(partition)),
+            Resources.clone(perUserAMUsed.get(userName)),
+            Resources.clone(userResourceUsage.getReserved(partition)),
+            Resources.none());
+
+        Resource userLimitResource = Resources.clone(
+            tq.leafQueue.getResourceLimitForAllUsers(userName, clusterResource,
+                partition, SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY));
+
+        // Real AM used need not have to be considered for user-limit as well.
+        userLimitResource = Resources.subtract(userLimitResource,
+            tmpUser.amUsed);
+        tmpUser.setUserLimit(userLimitResource);
+
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("TempUser:" + tmpUser);
+        }
+
+        tmpUser.idealAssigned = Resources.createResource(0, 0);
+        tq.addUserPerPartition(userName, tmpUser);
+      }
-   * same priority level. Such cases will be validated out.
+   * same priority level. Such cases will be validated out. But if the demand is
+   * from an app of different user, force to preempt resources even if apps are
+   * at same priority.
-      TreeSet<TempAppPerPartition> appsOrderedfromLowerPriority) {
+      TreeSet<TempAppPerPartition> orderedApps,
+      Map<String, TempUserPerPartition> usersPerPartition,
+      IntraQueuePreemptionOrderPolicy intraQueuePreemptionOrder) {
-    TempAppPerPartition[] apps = appsOrderedfromLowerPriority
-        .toArray(new TempAppPerPartition[appsOrderedfromLowerPriority.size()]);
+    TempAppPerPartition[] apps = orderedApps
+        .toArray(new TempAppPerPartition[orderedApps.size()]);
-    int lPriority = 0;
-    int hPriority = apps.length - 1;
+    for (int hPriority = apps.length - 1; hPriority >= 0; hPriority--) {
-    while (lPriority < hPriority
-        && !apps[lPriority].equals(apps[hPriority])
-        && apps[lPriority].getPriority() < apps[hPriority].getPriority()) {
-      Resource toPreemptFromOther = apps[hPriority]
-          .getToBePreemptFromOther();
-      Resource actuallyToPreempt = apps[lPriority].getActuallyToBePreempted();
-      Resource delta = Resources.subtract(apps[lPriority].toBePreempted,
-          actuallyToPreempt);
+      // Check whether high priority app with demand needs resource from other
+      // user.
+      if (Resources.greaterThan(rc, cluster,
+          apps[hPriority].getToBePreemptFromOther(), Resources.none())) {
-      if (Resources.greaterThan(rc, cluster, delta, Resources.none())) {
-        Resource toPreempt = Resources.min(rc, cluster,
-            toPreemptFromOther, delta);
+        // Given we have a demand from a high priority app, we can do a reverse
+        // scan from lower priority apps to select resources.
+        // Since idealAssigned of each app has considered user-limit, this logic
+        // will provide eventual consistency w.r.t user-limit as well.
+        for (int lPriority = 0; lPriority < apps.length; lPriority++) {
-        apps[hPriority].setToBePreemptFromOther(
-            Resources.subtract(toPreemptFromOther, toPreempt));
-        apps[lPriority].setActuallyToBePreempted(
-            Resources.add(actuallyToPreempt, toPreempt));
-      }
+          // Check whether app with demand needs resource from other user.
+          if (Resources.greaterThan(rc, cluster, apps[lPriority].toBePreempted,
+              Resources.none())) {
-      if (Resources.lessThanOrEqual(rc, cluster,
-          apps[lPriority].toBePreempted,
-          apps[lPriority].getActuallyToBePreempted())) {
-        lPriority++;
-        continue;
-      }
+            // If apps are of same user, and priority is same, then skip.
+            if ((apps[hPriority].getUser().equals(apps[lPriority].getUser()))
+                && (apps[lPriority].getPriority() >= apps[hPriority]
+                    .getPriority())) {
+              continue;
+            }
-      if (Resources.equals(apps[hPriority].getToBePreemptFromOther(),
-          Resources.none())) {
-        hPriority--;
-        continue;
+            if (Resources.lessThanOrEqual(rc, cluster,
+                apps[lPriority].toBePreempted,
+                apps[lPriority].getActuallyToBePreempted())
+                || Resources.equals(apps[hPriority].getToBePreemptFromOther(),
+                    Resources.none())) {
+              continue;
+            }
+
+            // Ideally if any application has a higher priority, then it can
+            // force to preempt any lower priority app from any user. However
+            // if admin enforces user-limit over priority, preemption module
+            // will not choose lower priority apps from usre's who are not yet
+            // met its user-limit.
+            TempUserPerPartition tmpUser = usersPerPartition
+                .get(apps[lPriority].getUser());
+            if ((!apps[hPriority].getUser().equals(apps[lPriority].getUser()))
+                && (!tmpUser.isUserLimitReached(rc, cluster))
+                && (intraQueuePreemptionOrder
+                    .equals(IntraQueuePreemptionOrderPolicy.USERLIMIT_FIRST))) {
+              continue;
+            }
+
+            Resource toPreemptFromOther = apps[hPriority]
+                .getToBePreemptFromOther();
+            Resource actuallyToPreempt = apps[lPriority]
+                .getActuallyToBePreempted();
+
+            // A lower priority app could offer more resource to preempt, if
+            // multiple higher priority/under served users needs resources.
+            // After one iteration, we need to ensure that actuallyToPreempt is
+            // subtracted from the resource to preempt.
+            Resource preemptableFromLowerPriorityApp = Resources
+                .subtract(apps[lPriority].toBePreempted, actuallyToPreempt);
+
+            // In case of user-limit preemption, when app's are from different
+            // user and of same priority, we will do user-limit preemption if
+            // there is a demand from under UL quota app.
+            // However this under UL quota app's demand may be more.
+            // Still we should ensure that we are not doing over preemption such
+            // that only a maximum of (user's used - UL quota) could be
+            // preempted.
+            if ((!apps[hPriority].getUser().equals(apps[lPriority].getUser()))
+                && (apps[lPriority].getPriority() == apps[hPriority]
+                    .getPriority())
+                && tmpUser.isUserLimitReached(rc, cluster)) {
+
+              Resource deltaULQuota = Resources
+                  .subtract(tmpUser.getUsedDeductAM(), tmpUser.selected);
+              Resources.subtractFrom(deltaULQuota, tmpUser.getUserLimit());
+
+              if (tmpUser.isPreemptionQuotaForULDeltaDone()) {
+                deltaULQuota = Resources.createResource(0, 0);
+              }
+
+              if (Resources.lessThan(rc, cluster, deltaULQuota,
+                  preemptableFromLowerPriorityApp)) {
+                tmpUser.updatePreemptionQuotaForULDeltaAsDone(true);
+                preemptableFromLowerPriorityApp = deltaULQuota;
+              }
+            }
+
+            if (Resources.greaterThan(rc, cluster,
+                preemptableFromLowerPriorityApp, Resources.none())) {
+              Resource toPreempt = Resources.min(rc, cluster,
+                  toPreemptFromOther, preemptableFromLowerPriorityApp);
+
+              apps[hPriority].setToBePreemptFromOther(
+                  Resources.subtract(toPreemptFromOther, toPreempt));
+              apps[lPriority].setActuallyToBePreempted(
+                  Resources.add(actuallyToPreempt, toPreempt));
+            }
+          }
+        }
+
+
+  @Override
+  public boolean skipContainerBasedOnIntraQueuePolicy(FiCaSchedulerApp app,
+      Resource clusterResource, Resource usedResource, RMContainer c) {
+    // Ensure below checks
+    // 1. This check must be done only when preemption order is USERLIMIT_FIRST
+    // 2. By selecting container "c", check whether this user's resource usage
+    // is going below its user-limit.
+    // 3. Used resource of user must be always greater than user-limit to
+    // skip some containers as per this check. If used resource is under user
+    // limit, then these containers of this user has to be preempted as demand
+    // might be due to high priority apps running in same user.
+    String partition = context.getScheduler()
+        .getSchedulerNode(c.getAllocatedNode()).getPartition();
+    TempQueuePerPartition tq = context.getQueueByPartition(app.getQueueName(),
+        partition);
+    TempUserPerPartition tmpUser = tq.getUsersPerPartition().get(app.getUser());
+
+    // Given user is not present, skip the check.
+    if (tmpUser == null) {
+      return false;
+    }
+
+    // For ideal resource computations, user-limit got saved by subtracting am
+    // used resource in TempUser. Hence it has to be added back here for
+    // complete check.
+    Resource userLimit = Resources.add(tmpUser.getUserLimit(), tmpUser.amUsed);
+
+    return Resources.lessThanOrEqual(rc, clusterResource,
+        Resources.subtract(usedResource, c.getAllocatedResource()), userLimit)
+        && context.getIntraQueuePreemptionOrderPolicy()
+            .equals(IntraQueuePreemptionOrderPolicy.USERLIMIT_FIRST);
+  }

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS31 MOV44 INS31 INS78 INS83 INS74 INS42 INS44 MOV44 INS8 MOV60 INS44 INS44 MOV44 INS44 INS44 INS78 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS8 INS42 INS43 INS43 INS43 INS42 INS60 INS60 INS70 INS41 INS43 INS42 UPD43 UPD42 INS43 INS42 MOV60 INS60 INS60 UPD42 INS74 INS42 INS43 INS42 INS24 INS42 INS43 INS42 INS43 INS42 MOV43 INS42 INS43 INS42 INS60 INS60 INS60 INS25 INS60 INS41 INS42 INS42 INS42 INS43 INS59 INS74 INS59 INS44 MOV32 INS8 INS42 MOV74 UPD74 INS42 UPD42 INS42 INS43 INS59 INS74 INS59 INS43 MOV43 INS43 INS42 MOV5 INS58 INS27 MOV37 INS8 INS42 INS42 INS42 INS43 INS59 INS43 INS59 INS43 INS59 INS27 INS8 MOV43 INS59 INS27 INS42 INS42 INS32 INS43 INS43 INS42 INS14 INS43 INS42 INS25 INS21 INS32 INS32 INS32 MOV43 MOV43 UPD43 UPD42 INS32 INS60 INS42 INS42 INS40 MOV43 MOV43 INS43 INS42 INS32 INS60 INS25 INS42 INS42 INS39 MOV59 INS42 INS34 INS25 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS33 INS41 INS42 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS74 INS42 INS32 INS8 INS32 INS42 UPD42 INS42 INS42 INS42 MOV42 MOV74 INS42 INS42 INS42 INS42 INS42 UPD42 INS42 INS42 INS27 INS43 MOV43 INS59 INS42 INS42 INS42 INS43 INS59 INS38 INS8 UPD42 INS32 INS8 INS32 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS32 INS9 INS42 INS42 INS32 INS40 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS40 INS43 INS43 INS42 INS42 INS32 INS32 INS18 INS42 INS42 INS40 UPD42 UPD42 MOV32 INS32 INS42 UPD42 INS42 INS32 INS40 INS42 INS60 UPD42 INS21 INS42 INS42 INS32 INS32 INS60 INS60 INS60 INS21 INS21 INS25 MOV21 INS21 MOV5 INS42 INS42 INS42 INS42 MOV32 MOV42 MOV32 INS24 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 UPD42 INS42 INS42 INS42 INS42 UPD42 UPD42 MOV42 UPD42 MOV42 MOV43 INS59 INS32 INS42 INS42 INS42 INS42 INS42 INS43 INS59 INS43 INS59 MOV43 INS59 INS7 INS32 MOV32 INS8 INS32 UPD42 UPD42 INS58 INS27 MOV37 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV42 INS42 MOV32 INS42 INS42 INS40 INS32 INS42 INS42 INS32 INS42 INS42 INS14 INS42 MOV32 INS42 INS32 INS42 INS42 INS42 INS21 INS40 INS42 INS42 INS42 INS42 INS39 MOV59 MOV42 INS40 INS25 INS42 INS42 INS32 INS42 INS43 INS32 INS40 INS32 INS32 INS32 INS32 INS42 INS42 INS42 INS40 INS32 INS32 MOV8 MOV25 MOV25 UPD42 INS40 INS42 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS32 INS42 INS42 MOV32 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS22 INS32 INS25 INS60 INS25 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS42 MOV2 INS42 INS42 INS42 INS27 INS8 INS27 INS43 INS59 INS27 INS8 INS27 INS8 INS36 INS36 INS18 MOV32 MOV32 INS42 INS42 INS32 INS36 INS36 INS36 INS18 UPD42 INS36 INS36 INS32 INS60 INS21 MOV25 INS25 UPD42 INS32 INS32 UPD27 MOV27 INS42 INS42 INS42 INS32 INS38 INS38 INS32 INS38 INS27 INS42 INS42 INS42 INS42 MOV43 INS59 INS32 INS32 INS32 MOV8 INS42 INS42 MOV43 INS32 INS42 INS32 INS2 INS42 INS42 INS42 INS2 INS42 INS32 INS32 INS42 INS42 INS40 INS32 INS32 INS32 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS2 INS42 INS2 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS32 MOV42 INS32 INS2 INS42 MOV2 UPD42 MOV42 MOV42 UPD42 MOV42 INS32 INS40 INS42 INS42 INS32 INS7 UPD42 INS42 INS42 INS42 INS42 INS2 INS42 INS2 INS42 INS2 INS42 INS2 INS42 INS42 INS42 INS42 INS42 UPD42 INS42 INS42 INS9 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 DEL42 DEL44 DEL40 DEL42 DEL42 DEL42 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL44 DEL42 DEL43 DEL74 DEL14 DEL74 DEL42 DEL42 DEL43 DEL74 DEL14 DEL59 DEL60 DEL42 DEL33 DEL27 DEL42 DEL7 DEL21 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL45 DEL42 DEL45 DEL42 DEL45 DEL42 DEL27 DEL32 DEL21 DEL8 DEL25 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL42 DEL42 DEL42 DEL32 DEL42 DEL33 DEL27 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL42 DEL7 DEL21 DEL42 DEL21 DEL33 DEL42 DEL27 DEL18 DEL39 DEL60 DEL39 DEL60 DEL42 DEL27 DEL38 DEL27 DEL27 DEL61