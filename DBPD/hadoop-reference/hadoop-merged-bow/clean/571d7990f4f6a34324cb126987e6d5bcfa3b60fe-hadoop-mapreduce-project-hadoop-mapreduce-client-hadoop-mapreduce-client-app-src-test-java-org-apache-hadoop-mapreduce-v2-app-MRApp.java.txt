Merge trunk into HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1196458 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.mapreduce.JobID;
+import org.apache.hadoop.mapreduce.OutputCommitter;
+import org.apache.hadoop.mapreduce.TypeConverter;
+import org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent;
+import org.apache.hadoop.yarn.util.BuilderUtils;
+  
+  public static String NM_HOST = "localhost";
+  public static int NM_PORT = 1234;
+  public static int NM_HTTP_PORT = 9999;
+  
+  private static ContainerId getContainerId(ApplicationId applicationId,
+      int startCount) {
+    ApplicationAttemptId appAttemptId =
+        getApplicationAttemptId(applicationId, startCount);
+    ContainerId containerId =
+        BuilderUtils.newContainerId(appAttemptId, startCount);
+    return containerId;
+  }
-    super(getApplicationAttemptId(applicationId, startCount));
+    super(getApplicationAttemptId(applicationId, startCount), getContainerId(
+        applicationId, startCount), NM_HOST, NM_PORT, NM_HTTP_PORT, System
+        .currentTimeMillis());
-    Job newJob = new TestJob(conf, getAppID(), getDispatcher().getEventHandler(),
-                             getTaskAttemptListener(), getContext().getClock(),
-                             currentUser.getUserName());
+    Job newJob = new TestJob(getJobId(), getAttemptID(), conf, 
+    		getDispatcher().getEventHandler(),
+            getTaskAttemptListener(), getContext().getClock(),
+            getCommitter(), isNewApiCommitter(),
+            currentUser.getUserName());
-      public void register(TaskAttemptId attemptID, 
+      public void registerLaunchedTask(TaskAttemptId attemptID, 
+      @Override
+      public void registerPendingTask(WrappedJvmID jvmID) {
+      }
+
+    //We are running locally so set the shuffle port to -1 
+    int shufflePort = -1;
+
+    @SuppressWarnings("unchecked")
-        //We are running locally so set the shuffle port to -1 
-                -1)
-            );
+                shufflePort));
-        Container container = recordFactory.newRecordInstance(Container.class);
-        container.setId(cId);
-        container.setNodeId(recordFactory.newRecordInstance(NodeId.class));
-        container.getNodeId().setHost("dummy");
-        container.getNodeId().setPort(1234);
-        container.setContainerToken(null);
-        container.setNodeHttpAddress("localhost:9999");
+        NodeId nodeId = BuilderUtils.newNodeId(NM_HOST, NM_PORT);
+        Container container = BuilderUtils.newContainer(cId, nodeId,
+            NM_HOST + ":" + NM_HTTP_PORT, null, null, null);
+        JobID id = TypeConverter.fromYarn(applicationId);
+        JobId jobId = TypeConverter.toYarn(id);
+        getContext().getEventHandler().handle(new JobHistoryEvent(jobId, 
+            new NormalizedResourceEvent(
+                org.apache.hadoop.mapreduce.TaskType.REDUCE,
+            100)));
+        getContext().getEventHandler().handle(new JobHistoryEvent(jobId, 
+            new NormalizedResourceEvent(
+                org.apache.hadoop.mapreduce.TaskType.MAP,
+            100)));
-                container));
+                container, null));
-    public TestJob(Configuration conf, ApplicationId applicationId,
-        EventHandler eventHandler, TaskAttemptListener taskAttemptListener,
-        Clock clock, String user) {
-      super(getApplicationAttemptId(applicationId, getStartCount()), 
+    public TestJob(JobId jobId, ApplicationAttemptId applicationAttemptId,
+        Configuration conf, EventHandler eventHandler,
+        TaskAttemptListener taskAttemptListener, Clock clock,
+        OutputCommitter committer, boolean newApiCommitter, String user) {
+      super(jobId, getApplicationAttemptId(applicationId, getStartCount()),
-          new JobTokenSecretManager(), new Credentials(), clock, 
-          getCompletedTaskFromPreviousRun(), metrics, user);
+          new JobTokenSecretManager(), new Credentials(), clock,
+          getCompletedTaskFromPreviousRun(), metrics, committer,
+          newApiCommitter, user, System.currentTimeMillis(), getAllAMInfos());

INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS23 INS23 INS23 INS31 INS83 INS83 INS43 INS59 INS83 INS83 INS39 INS59 INS83 INS83 INS39 INS59 INS83 INS83 INS43 INS42 MOV44 INS44 INS8 INS23 INS42 INS42 INS45 INS42 INS34 INS42 INS34 INS42 INS39 INS42 INS60 INS60 INS41 INS39 INS59 INS79 INS44 INS44 INS44 INS44 INS43 INS59 INS43 INS59 INS42 INS32 INS42 INS42 INS42 INS32 INS42 MOV38 INS42 INS45 INS43 INS42 INS43 INS42 INS43 INS42 INS39 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 MOV32 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS32 INS31 INS42 INS42 INS42 INS42 INS42 UPD42 INS42 UPD42 INS78 INS83 INS39 INS42 INS44 INS8 INS42 INS43 INS42 INS42 INS60 INS60 INS60 INS21 INS42 MOV43 MOV43 INS59 INS43 INS59 INS43 INS59 INS32 UPD42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS14 INS32 UPD42 MOV42 INS14 UPD42 UPD42 INS42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS27 INS33 INS33 INS33 UPD42 MOV42 UPD42 MOV42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS32 UPD42 INS43 INS42 INS14 INS32 UPD42 MOV42 INS43 INS42 INS14 INS33 INS42 INS45 INS42 UPD42 MOV42 INS42 INS43 INS40 INS34 UPD42 MOV42 INS42 INS43 INS40 INS34 INS42 INS42 DEL42 DEL43 DEL57 DEL32 DEL21 DEL42 DEL42 DEL57 DEL32 DEL32 DEL21 DEL32 DEL45 DEL32 DEL21 DEL42 DEL34 DEL33 DEL32 DEL21 DEL42 DEL45 DEL32 DEL21