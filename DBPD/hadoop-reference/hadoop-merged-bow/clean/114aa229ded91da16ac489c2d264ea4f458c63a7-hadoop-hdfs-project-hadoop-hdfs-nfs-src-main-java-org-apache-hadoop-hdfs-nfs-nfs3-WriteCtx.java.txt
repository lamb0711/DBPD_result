Merging r1525409 through r1525758 from trunk to branch HDFS-2832

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1525759 13f79535-47bb-0310-9956-ffa450edef68

+import com.google.common.base.Preconditions;
+
-  private byte[] data;
+  private volatile byte[] data;
-  private DataState dataState;
+  /** 
+   * Data belonging to the same {@link OpenFileCtx} may be dumped to a file. 
+   * After being dumped to the file, the corresponding {@link WriteCtx} records 
+   * the dump file and the offset.  
+   */
+  private RandomAccessFile raf;
+  private long dumpFileOffset;
+  
+  private volatile DataState dataState;
-
-  private RandomAccessFile raf;
-  private long dumpFileOffset;
-  // Return the dumped data size
-  public long dumpData(FileOutputStream dumpOut, RandomAccessFile raf)
+  /** 
+   * Writing the data into a local file. After the writing, if 
+   * {@link #dataState} is still ALLOW_DUMP, set {@link #data} to null and set 
+   * {@link #dataState} to DUMPED.
+   */
+  long dumpData(FileOutputStream dumpOut, RandomAccessFile raf)
-    data = null;
-    dataState = DataState.DUMPED;
-    return count;
+    // it is possible that while we dump the data, the data is also being
+    // written back to HDFS. After dump, if the writing back has not finished
+    // yet, we change its flag to DUMPED and set the data to null. Otherwise
+    // this WriteCtx instance should have been removed from the buffer.
+    if (dataState == DataState.ALLOW_DUMP) {
+      synchronized (this) {
+        if (dataState == DataState.ALLOW_DUMP) {
+          data = null;
+          dataState = DataState.DUMPED;
+          return count;
+        }
+      }
+    }
+    return 0;
-  public FileHandle getHandle() {
+  FileHandle getHandle() {
-  public long getOffset() {
+  long getOffset() {
-  public int getCount() {
+  int getCount() {
-  public WriteStableHow getStableHow() {
+  WriteStableHow getStableHow() {
-  public byte[] getData() throws IOException {
+  byte[] getData() throws IOException {
-      if (data == null) {
-        throw new IOException("Data is not dumpted but has null:" + this);
-      }
-    } else {
-      // read back
-      if (data != null) {
-        throw new IOException("Data is dumpted but not null");
-      }
-      data = new byte[count];
-      raf.seek(dumpFileOffset);
-      int size = raf.read(data, 0, count);
-      if (size != count) {
-        throw new IOException("Data count is " + count + ", but read back "
-            + size + "bytes");
+      synchronized (this) {
+        if (dataState != DataState.DUMPED) {
+          Preconditions.checkState(data != null);
+          return data;
+        }
+    // read back from dumped file
+    this.loadData();
+  private void loadData() throws IOException {
+    Preconditions.checkState(data == null);
+    data = new byte[count];
+    raf.seek(dumpFileOffset);
+    int size = raf.read(data, 0, count);
+    if (size != count) {
+      throw new IOException("Data count is " + count + ", but read back "
+          + size + "bytes");
+    }
+  }
+

INS26 MOV23 MOV23 INS40 INS31 INS83 INS29 INS83 INS29 MOV5 INS42 MOV43 INS8 UPD83 INS39 UPD42 MOV8 INS65 INS65 INS25 INS41 INS25 INS21 INS41 INS21 INS66 INS65 INS66 INS66 INS65 INS66 INS66 INS66 INS65 INS66 INS65 INS66 INS65 INS66 INS27 INS8 INS34 INS27 INS8 INS32 INS42 INS32 INS42 INS42 INS67 INS67 INS67 INS42 INS40 INS51 INS42 INS40 INS51 INS52 INS42 INS42 INS42 MOV27 INS42 INS42 INS42 INS52 INS8 INS52 INS8 INS25 INS25 INS27 INS8 MOV27 INS8 INS42 INS40 MOV21 MOV21 MOV41 INS21 MOV41 INS32 INS42 INS42 MOV27 DEL83 DEL83 DEL83 DEL83 DEL83 DEL45 DEL14 DEL53 DEL8 DEL25 DEL42 DEL43 DEL45 DEL52 DEL27 DEL14 DEL53 DEL8 DEL25 DEL8 DEL25 DEL8