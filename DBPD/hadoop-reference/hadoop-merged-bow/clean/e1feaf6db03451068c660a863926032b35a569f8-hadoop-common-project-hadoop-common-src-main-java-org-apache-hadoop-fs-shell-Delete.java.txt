HADOOP-12358. Add -safely flag to rm to prompt when deleting many files. Contributed by Xiaoyu Yao.

+import org.apache.hadoop.fs.ContentSummary;
+import org.apache.hadoop.util.ToolRunner;
+
+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.HADOOP_SHELL_SAFELY_DELETE_LIMIT_NUM_FILES;
+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.HADOOP_SHELL_SAFELY_DELETE_LIMIT_NUM_FILES_DEFAULT;
- * Classes that delete paths
+ * Classes that delete paths.
-    public static final String USAGE = "[-f] [-r|-R] [-skipTrash] <src> ...";
+    public static final String USAGE = "[-f] [-r|-R] [-skipTrash] " +
+        "[-safely] <src> ...";
-      "Delete all files that match the specified file pattern. " +
-      "Equivalent to the Unix command \"rm <src>\"\n" +
-      "-skipTrash: option bypasses trash, if enabled, and immediately " +
-      "deletes <src>\n" +
-      "-f: If the file does not exist, do not display a diagnostic " +
-      "message or modify the exit status to reflect an error.\n" +
-      "-[rR]:  Recursively deletes directories";
+        "Delete all files that match the specified file pattern. " +
+            "Equivalent to the Unix command \"rm <src>\"\n" +
+            "-f: If the file does not exist, do not display a diagnostic " +
+            "message or modify the exit status to reflect an error.\n" +
+            "-[rR]:  Recursively deletes directories.\n" +
+            "-skipTrash: option bypasses trash, if enabled, and immediately " +
+            "deletes <src>.\n" +
+            "-safely: option requires safety confirmationï¼Œif enabled, " +
+            "requires confirmation before deleting large directory with more " +
+            "than <hadoop.shell.delete.limit.num.files> files. Delay is " +
+            "expected when walking over large directory recursively to count " +
+            "the number of files to be deleted before the confirmation.\n";
-    
+    private boolean safeDelete = false;
+
-          1, Integer.MAX_VALUE, "f", "r", "R", "skipTrash");
+          1, Integer.MAX_VALUE, "f", "r", "R", "skipTrash", "safely");
+      safeDelete = cf.getOpt("safely");
-      if (moveToTrash(item)) {
+      if (moveToTrash(item) || !canBeSafelyDeleted(item)) {
+    private boolean canBeSafelyDeleted(PathData item)
+        throws IOException {
+      boolean shouldDelete = true;
+      if (safeDelete) {
+        final long deleteLimit = getConf().getLong(
+            HADOOP_SHELL_SAFELY_DELETE_LIMIT_NUM_FILES,
+            HADOOP_SHELL_SAFELY_DELETE_LIMIT_NUM_FILES_DEFAULT);
+        if (deleteLimit > 0) {
+          ContentSummary cs = item.fs.getContentSummary(item.path);
+          final long numFiles = cs.getFileCount();
+          if (numFiles > deleteLimit) {
+            if (!ToolRunner.confirmPrompt("Proceed deleting " + numFiles +
+                " files?")) {
+              System.err.println("Delete aborted at user request.\n");
+              shouldDelete = false;
+            }
+          }
+        }
+      }
+      return shouldDelete;
+    }
+
-	  }
+          }

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS23 INS31 UPD66 MOV43 MOV43 INS83 INS39 INS59 INS83 INS39 INS42 INS44 INS43 INS8 INS27 INS42 INS9 INS21 INS43 INS42 INS42 INS60 INS25 INS41 INS45 INS45 INS45 INS45 INS45 UPD45 UPD45 UPD45 INS45 UPD45 INS45 MOV43 INS7 INS27 INS42 INS39 INS59 INS42 INS8 INS42 INS42 INS32 MOV32 INS38 INS42 INS9 INS60 INS25 MOV43 INS45 INS42 INS42 INS45 INS32 INS83 INS39 INS59 INS27 INS8 INS42 INS42 INS42 INS32 INS42 INS34 INS60 INS60 INS25 INS32 INS42 INS42 INS42 INS43 INS59 INS83 INS39 INS59 INS27 INS8 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS25 INS40 INS42 INS40 INS42 INS42 INS38 INS8 INS32 INS21 INS21 INS42 INS42 INS27 INS32 INS7 INS45 INS42 INS45 INS40 INS42 INS45 INS42 INS9 DEL45