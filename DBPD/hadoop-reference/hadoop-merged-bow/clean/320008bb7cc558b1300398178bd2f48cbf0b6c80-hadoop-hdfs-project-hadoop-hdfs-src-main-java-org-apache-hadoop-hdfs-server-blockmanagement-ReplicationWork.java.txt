HDFS-14720. DataNode shouldn't report block as bad block if the block length is Long.MAX_VALUE. Contributed by  hemanthboyina.

+import org.apache.hadoop.hdfs.server.protocol.BlockCommand;
-      DatanodeStorageInfo[] chosenTargets = blockplacement.chooseTarget(
-          getSrcPath(), getAdditionalReplRequired(), getSrcNodes()[0],
-          getLiveReplicaStorages(), false, excludedNodes, getBlockSize(),
-          storagePolicySuite.getPolicy(getStoragePolicyID()), null);
+      DatanodeStorageInfo[] chosenTargets = null;
+      // HDFS-14720 If the block is deleted, the block size will become
+      // BlockCommand.NO_ACK (LONG.MAX_VALUE) . This kind of block we don't need
+      // to send for replication or reconstruction
+      if (getBlock().getNumBytes() != BlockCommand.NO_ACK) {
+        chosenTargets = blockplacement.chooseTarget(getSrcPath(),
+            getAdditionalReplRequired(), getSrcNodes()[0],
+            getLiveReplicaStorages(), false, excludedNodes, getBlockSize(),
+            storagePolicySuite.getPolicy(getStoragePolicyID()), null);
+      }

INS26 INS40 INS25 INS27 INS8 INS33 INS32 INS40 INS21 INS32 INS42 INS7 INS42 INS42 MOV32