merge from trunk r1598430

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1598435 13f79535-47bb-0310-9956-ffa450edef68

-import java.io.BufferedInputStream;
-import java.io.InputStream;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.tools.mapred.CopyMapper.FileAction;
+  private FileAction action;
-  public RetriableFileCopyCommand(String description) {
+  public RetriableFileCopyCommand(String description, FileAction action) {
+    this.action = action;
+   * @param action We should overwrite the target file or append new data to it.
-  public RetriableFileCopyCommand(boolean skipCrc, String description) {
-    this(description);
+  public RetriableFileCopyCommand(boolean skipCrc, String description,
+      FileAction action) {
+    this(description, action);
-                      Mapper.Context context,
-                      EnumSet<FileAttribute> fileAttributes)
-          throws IOException {
-
-    Path tmpTargetPath = getTmpFile(target, context);
+      Mapper.Context context, EnumSet<FileAttribute> fileAttributes)
+      throws IOException {
+    final boolean toAppend = action == FileAction.APPEND;
+    Path targetPath = toAppend ? target : getTmpFile(target, context);
-        LOG.debug("Tmp-file path: " + tmpTargetPath);
+        LOG.debug("Target file path: " + targetPath);
-      long bytesRead = copyToTmpFile(tmpTargetPath, targetFS, sourceFileStatus,
-          context, fileAttributes, sourceChecksum);
+      final long offset = action == FileAction.APPEND ? targetFS.getFileStatus(
+          target).getLen() : 0;
+      long bytesRead = copyToFile(targetPath, targetFS, sourceFileStatus,
+          offset, context, fileAttributes, sourceChecksum);
-      compareFileLengths(sourceFileStatus, tmpTargetPath, configuration,
-          bytesRead);
+      compareFileLengths(sourceFileStatus, targetPath, configuration, bytesRead
+          + offset);
-            targetFS, tmpTargetPath);
+            targetFS, targetPath);
-      promoteTmpToTarget(tmpTargetPath, target, targetFS);
+      // it's not append case, thus we first write to a temporary file, rename
+      // it to the target path.
+      if (!toAppend) {
+        promoteTmpToTarget(targetPath, target, targetFS);
+      }
-
-      if (targetFS.exists(tmpTargetPath))
-        targetFS.delete(tmpTargetPath, false);
+      // note that for append case, it is possible that we append partial data
+      // and then fail. In that case, for the next retry, we either reuse the
+      // partial appended data if it is good or we overwrite the whole file
+      if (!toAppend && targetFS.exists(targetPath)) {
+        targetFS.delete(targetPath, false);
+      }
-  private long copyToTmpFile(Path tmpTargetPath, FileSystem targetFS,
-      FileStatus sourceFileStatus, Mapper.Context context,
+  private long copyToFile(Path targetPath, FileSystem targetFS,
+      FileStatus sourceFileStatus, long sourceOffset, Mapper.Context context,
-    OutputStream outStream = new BufferedOutputStream(
-        targetFS.create(tmpTargetPath, permission,
-            EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE), BUFFER_SIZE,
-            getReplicationFactor(fileAttributes, sourceFileStatus, targetFS,
-                tmpTargetPath),
-            getBlockSize(fileAttributes, sourceFileStatus, targetFS,
-                tmpTargetPath),
-            context, getChecksumOpt(fileAttributes, sourceChecksum)));
-    return copyBytes(sourceFileStatus, outStream, BUFFER_SIZE, context);
+    final OutputStream outStream;
+    if (action == FileAction.OVERWRITE) {
+      final short repl = getReplicationFactor(fileAttributes, sourceFileStatus,
+          targetFS, targetPath);
+      final long blockSize = getBlockSize(fileAttributes, sourceFileStatus,
+          targetFS, targetPath);
+      FSDataOutputStream out = targetFS.create(targetPath, permission,
+          EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),
+          BUFFER_SIZE, repl, blockSize, context,
+          getChecksumOpt(fileAttributes, sourceChecksum));
+      outStream = new BufferedOutputStream(out);
+    } else {
+      outStream = new BufferedOutputStream(targetFS.append(targetPath,
+          BUFFER_SIZE));
+    }
+    return copyBytes(sourceFileStatus, sourceOffset, outStream, BUFFER_SIZE,
+        context);
-                                  Configuration configuration, long bytesRead)
+                                  Configuration configuration, long targetLen)
-    if (fs.getFileStatus(sourcePath).getLen() != bytesRead)
+    if (fs.getFileStatus(sourcePath).getLen() != targetLen)
-  long copyBytes(FileStatus sourceFileStatus, OutputStream outStream,
-                         int bufferSize, Mapper.Context context)
+  long copyBytes(FileStatus sourceFileStatus, long sourceOffset,
+      OutputStream outStream, int bufferSize, Mapper.Context context)
-      int bytesRead = readBytes(inStream, buf);
+      int bytesRead = readBytes(inStream, buf, sourceOffset);
+        if (action == FileAction.APPEND) {
+          sourceOffset += bytesRead;
+        }
-        bytesRead = inStream.read(buf);
+        bytesRead = readBytes(inStream, buf, sourceOffset);
-
-  private static int readBytes(InputStream inStream, byte buf[])
-          throws IOException {
+  private static int readBytes(ThrottledInputStream inStream, byte buf[],
+      long position) throws IOException {
-      return inStream.read(buf);
-    }
-    catch (IOException e) {
+      if (position == 0) {
+        return inStream.read(buf);
+      } else {
+        return inStream.read(position, buf, 0, buf.length);
+      }
+    } catch (IOException e) {
-  private static ThrottledInputStream getInputStream(Path path, Configuration conf)
-          throws IOException {
+  private static ThrottledInputStream getInputStream(Path path,
+      Configuration conf) throws IOException {
-      return new ThrottledInputStream(new BufferedInputStream(fs.open(path)),
-              bandwidthMB * 1024 * 1024);
+      FSDataInputStream in = fs.open(path);
+      return new ThrottledInputStream(in, bandwidthMB * 1024 * 1024);

MOV26 MOV26 INS26 UPD40 UPD40 INS40 INS23 INS83 INS43 INS59 INS44 INS44 UPD42 INS44 INS44 INS44 INS42 INS42 INS43 INS42 INS21 INS65 INS43 INS42 INS60 UPD42 INS39 INS42 INS60 INS25 UPD42 INS39 INS42 UPD43 INS39 INS42 INS42 INS7 INS42 INS66 INS42 INS42 INS83 INS39 INS59 INS83 MOV43 INS59 INS27 INS8 INS8 UPD42 INS8 INS22 INS42 INS42 INS27 UPD42 INS16 INS60 INS25 MOV42 INS42 INS40 INS60 INS60 INS60 INS21 INS21 INS42 UPD42 INS25 INS60 INS52 INS42 INS42 INS40 INS42 INS42 MOV32 INS83 INS39 INS59 INS38 INS8 INS27 INS8 INS83 INS39 INS59 INS83 INS39 INS59 INS43 INS59 INS7 INS7 INS27 MOV8 INS8 INS43 INS59 INS42 INS16 UPD42 INS27 INS42 MOV21 INS38 INS32 INS21 INS42 INS32 INS42 INS32 INS42 INS42 INS32 INS42 INS14 INS42 INS14 INS25 INS42 INS34 INS41 INS42 INS42 MOV32 INS42 INS27 INS32 INS34 UPD42 UPD42 INS42 INS42 INS42 INS42 MOV42 MOV42 UPD42 MOV42 MOV32 MOV42 MOV42 MOV42 MOV42 UPD42 MOV42 MOV42 MOV42 MOV42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 MOV32 INS42 INS42 INS42 MOV42 MOV32 MOV43 INS42 INS43 INS32 INS42 INS27 INS8 INS32 INS42 INS40 INS32 INS42 UPD42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS21 INS42 INS42 INS42 INS42 INS34 INS40 UPD45 UPD42 INS42 INS42 INS42 INS7 UPD42 UPD42 INS42 INS42 INS42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL32 DEL14 DEL59 DEL60 DEL42 DEL43 DEL14