HDFS-5000. DataNode configuration should allow specifying storage type

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1517417 13f79535-47bb-0310-9956-ffa450edef68

-  private AbstractList<File> dataDirs;
+  private AbstractList<StorageLocation> dataDirs;
-   * Create the DataNode given a configuration and an array of dataDirs.
-   * 'dataDirs' is where the blocks are stored.
-   */
-  DataNode(final Configuration conf, 
-           final AbstractList<File> dataDirs) throws IOException {
-    this(conf, dataDirs, null);
-  }
-  
-  /**
-  DataNode(final Configuration conf, 
-           final AbstractList<File> dataDirs,
+  DataNode(final Configuration conf,
+           final AbstractList<StorageLocation> dataDirs,
-                     AbstractList<File> dataDirs,
+                     AbstractList<StorageLocation> dataDirs,
-   * @param nsInfo the handshake response from the NN.
+   * @param bpos block pool to initialize and register with the NameNode.
-    Collection<URI> dataDirs = getStorageDirs(conf);
+    Collection<StorageLocation> dataLocations = getStorageLocations(conf);
-    return makeInstance(dataDirs, conf, resources);
+    return makeInstance(dataLocations, conf, resources);
-  static Collection<URI> getStorageDirs(Configuration conf) {
-    Collection<String> dirNames =
-      conf.getTrimmedStringCollection(DFS_DATANODE_DATA_DIR_KEY);
-    return Util.stringCollectionAsURIs(dirNames);
+  static Collection<StorageLocation> parseStorageLocations(
+      Collection<String> rawLocations) {
+    List<StorageLocation> locations =
+        new ArrayList<StorageLocation>(rawLocations.size());
+
+    for(String locationString : rawLocations) {
+      StorageLocation location;
+      try {
+        location = StorageLocation.parse(locationString);
+      } catch (IOException ioe) {
+        LOG.error("Failed to parse storage location " + locationString);
+        continue;
+      } catch (IllegalArgumentException iae) {
+        LOG.error(iae.toString());
+        continue;
+      }
+
+      locations.add(location);
+    }
+
+    return locations;
+  }
+
+  static Collection<StorageLocation> getStorageLocations(Configuration conf) {
+    return parseStorageLocations(
+        conf.getTrimmedStringCollection(DFS_DATANODE_DATA_DIR_KEY));
-  static DataNode makeInstance(Collection<URI> dataDirs, Configuration conf,
-      SecureResources resources) throws IOException {
+  static DataNode makeInstance(Collection<StorageLocation> dataDirs,
+      Configuration conf, SecureResources resources) throws IOException {
-    ArrayList<File> dirs =
-        getDataDirsFromURIs(dataDirs, localFS, dataNodeDiskChecker);
+    ArrayList<StorageLocation> locations =
+        checkStorageLocations(dataDirs, localFS, dataNodeDiskChecker);
-    assert dirs.size() > 0 : "number of data directories should be > 0";
-    return new DataNode(conf, dirs, resources);
+    assert locations.size() > 0 : "number of data directories should be > 0";
+    return new DataNode(conf, locations, resources);
-  static ArrayList<File> getDataDirsFromURIs(Collection<URI> dataDirs,
+  static ArrayList<StorageLocation> checkStorageLocations(
+      Collection<StorageLocation> dataDirs,
-    ArrayList<File> dirs = new ArrayList<File>();
+    ArrayList<StorageLocation> locations = new ArrayList<StorageLocation>();
-    for (URI dirURI : dataDirs) {
-      if (!"file".equalsIgnoreCase(dirURI.getScheme())) {
-        LOG.warn("Unsupported URI schema in " + dirURI + ". Ignoring ...");
-        invalidDirs.append("\"").append(dirURI).append("\" ");
-        continue;
-      }
-      // drop any (illegal) authority in the URI for backwards compatibility
-      File dir = new File(dirURI.getPath());
+    for (StorageLocation location : dataDirs) {
-        dataNodeDiskChecker.checkDir(localFS, new Path(dir.toURI()));
-        dirs.add(dir);
+        dataNodeDiskChecker.checkDir(localFS, new Path(location.getUri()));
+        locations.add(location);
-            + dir + " : ", ioe);
-        invalidDirs.append("\"").append(dir.getCanonicalPath()).append("\" ");
+            + location.getFile() + " : ", ioe);
+        invalidDirs.append("\"").append(location.getFile().getCanonicalPath()).append("\" ");
-    if (dirs.size() == 0) {
+    if (locations.size() == 0) {
-    return dirs;
+    return locations;

INS31 INS31 INS31 UPD74 MOV44 INS83 UPD74 MOV74 UPD42 MOV42 MOV44 INS8 INS83 INS74 INS42 MOV44 INS8 INS44 INS83 UPD74 MOV74 INS42 MOV44 MOV44 MOV44 MOV43 INS8 UPD43 UPD74 UPD74 UPD43 MOV74 INS42 INS60 INS70 INS41 INS43 INS43 INS41 INS74 INS42 UPD43 UPD74 INS60 MOV60 INS70 MOV25 MOV41 UPD42 UPD43 UPD43 UPD42 UPD66 INS74 UPD42 INS74 INS59 INS44 INS42 INS8 INS42 UPD42 MOV42 INS42 INS32 MOV43 INS43 INS74 UPD42 UPD43 UPD74 MOV74 INS59 INS44 INS42 INS8 UPD42 UPD42 UPD42 INS43 INS43 UPD42 UPD42 INS43 INS43 INS42 INS14 INS43 INS42 MOV60 INS54 INS21 INS42 MOV32 INS42 INS42 MOV43 INS43 UPD42 UPD42 UPD42 UPD43 INS42 INS14 INS43 INS42 MOV54 INS42 INS42 UPD42 UPD42 MOV42 INS42 INS74 INS32 UPD42 MOV42 INS43 INS8 INS12 INS12 INS32 INS42 INS42 UPD42 UPD42 UPD42 UPD74 MOV74 UPD42 MOV42 UPD42 UPD43 MOV43 UPD43 MOV43 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 INS21 INS44 INS8 INS44 INS8 INS42 INS42 INS42 UPD43 UPD42 UPD42 INS7 INS43 INS42 MOV21 INS18 INS43 INS42 MOV21 MOV18 UPD42 INS42 INS32 INS42 INS42 INS32 UPD42 UPD42 INS42 INS42 UPD42 MOV42 UPD42 UPD42 MOV42 UPD42 MOV42 INS32 UPD45 UPD42 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 INS32 INS42 INS42 INS32 UPD42 MOV42 INS42 DEL66 DEL66 DEL65 DEL29 DEL43 DEL42 DEL42 DEL33 DEL17 DEL8 DEL31 DEL83 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL74 DEL14 DEL45 DEL45 DEL32 DEL32 DEL42 DEL45 DEL32 DEL83 DEL74 DEL42 DEL42 DEL59 DEL60 DEL42 DEL32 DEL41 DEL8 DEL31 DEL42 DEL83 DEL42 DEL42 DEL43 DEL74 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL42 DEL45 DEL42 DEL42 DEL32 DEL32 DEL38 DEL8 DEL25 DEL43 DEL42 DEL43 DEL42 DEL42 DEL32 DEL14 DEL59 DEL60 DEL8 DEL70 DEL8 DEL31