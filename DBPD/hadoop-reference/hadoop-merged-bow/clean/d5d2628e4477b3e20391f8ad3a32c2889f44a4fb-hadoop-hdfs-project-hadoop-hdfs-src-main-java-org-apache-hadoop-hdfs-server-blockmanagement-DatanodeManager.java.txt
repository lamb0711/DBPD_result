Merge r1360400 through r1399945 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1399950 13f79535-47bb-0310-9956-ffa450edef68

-import static org.apache.hadoop.hdfs.server.common.Util.now;
+import static org.apache.hadoop.util.Time.now;
+import java.util.Comparator;
-import org.apache.hadoop.hdfs.server.common.Util;
+import org.apache.hadoop.util.Time;
+import com.google.common.base.Preconditions;
-
+  private Daemon decommissionthread = null;
+  /** Whether or not to check stale DataNodes for read/write */
+  private final boolean checkForStaleDataNodes;
+
+  /** The interval for judging stale DataNodes for read/write */
+  private final long staleInterval;
+  
+  /** Whether or not to avoid using stale DataNodes for writing */
+  private volatile boolean avoidStaleDataNodesForWrite;
+  
+  /** The number of stale DataNodes */
+  private volatile int numStaleNodes;
+  
-  DatanodeManager(final BlockManager blockManager,
-      final Namesystem namesystem, final Configuration conf
-      ) throws IOException {
+  DatanodeManager(final BlockManager blockManager, final Namesystem namesystem,
+      final Configuration conf) throws IOException {
-    networktopology = (NetworkTopology) ReflectionUtils.newInstance(
-        networkTopologyClass, conf);
+    networktopology = ReflectionUtils.newInstance(networkTopologyClass, conf);
+    
+    checkForStaleDataNodes = conf.getBoolean(
+        DFSConfigKeys.DFS_NAMENODE_CHECK_STALE_DATANODE_KEY,
+        DFSConfigKeys.DFS_NAMENODE_CHECK_STALE_DATANODE_DEFAULT);
+
+    staleInterval = getStaleIntervalFromConf(conf, heartbeatExpireInterval);
+    avoidStaleDataNodesForWrite = getAvoidStaleForWriteFromConf(conf,
+        checkForStaleDataNodes);
-
-  private Daemon decommissionthread = null;
-
+  
+  private static long getStaleIntervalFromConf(Configuration conf,
+      long heartbeatExpireInterval) {
+    long staleInterval = conf.getLong(
+        DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY, 
+        DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_INTERVAL_DEFAULT);
+    Preconditions.checkArgument(staleInterval > 0,
+        DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY +
+        " = '" + staleInterval + "' is invalid. " +
+        "It should be a positive non-zero value.");
+    
+    final long heartbeatIntervalSeconds = conf.getLong(
+        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,
+        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_DEFAULT);
+    // The stale interval value cannot be smaller than 
+    // 3 times of heartbeat interval 
+    final long minStaleInterval = conf.getInt(
+        DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_KEY,
+        DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_DEFAULT)
+        * heartbeatIntervalSeconds * 1000;
+    if (staleInterval < minStaleInterval) {
+      LOG.warn("The given interval for marking stale datanode = "
+          + staleInterval + ", which is less than "
+          + DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_DEFAULT
+          + " heartbeat intervals. This may cause too frequent changes of " 
+          + "stale states of DataNodes since a heartbeat msg may be missing " 
+          + "due to temporary short-term failures. Reset stale interval to " 
+          + minStaleInterval + ".");
+      staleInterval = minStaleInterval;
+    }
+    if (staleInterval > heartbeatExpireInterval) {
+      LOG.warn("The given interval for marking stale datanode = "
+          + staleInterval + ", which is larger than heartbeat expire interval "
+          + heartbeatExpireInterval + ".");
+    }
+    return staleInterval;
+  }
+  
+  static boolean getAvoidStaleForWriteFromConf(Configuration conf,
+      boolean checkForStale) {
+    boolean avoid = conf.getBoolean(
+        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY,
+        DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_DEFAULT);
+    boolean avoidStaleDataNodesForWrite = checkForStale && avoid;
+    if (!checkForStale && avoid) {
+      LOG.warn("Cannot set "
+          + DFSConfigKeys.DFS_NAMENODE_CHECK_STALE_DATANODE_KEY
+          + " as false while setting "
+          + DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY
+          + " as true.");
+    }
+    return avoidStaleDataNodesForWrite;
+  }
+  
-    if (decommissionthread != null) decommissionthread.interrupt();
+    if (decommissionthread != null) {
+      decommissionthread.interrupt();
+      try {
+        decommissionthread.join(3000);
+      } catch (InterruptedException e) {
+      }
+    }
+    
+    Comparator<DatanodeInfo> comparator = checkForStaleDataNodes ? 
+        new DFSUtil.DecomStaleComparator(staleInterval) : 
+        DFSUtil.DECOM_COMPARATOR;
+        
-      
-      // Move decommissioned datanodes to the bottom
-      Arrays.sort(b.getLocations(), DFSUtil.DECOM_COMPARATOR);
+      // Move decommissioned/stale datanodes to the bottom
+      Arrays.sort(b.getLocations(), comparator);
-
+  
-            (Util.now() - heartbeatExpireInterval));
+            (Time.now() - heartbeatExpireInterval));
-  private void checkDecommissioning(DatanodeDescriptor nodeReg, String ipAddr) { 
+  private void checkDecommissioning(DatanodeDescriptor nodeReg) { 
-    DatanodeDescriptor nodeN = getDatanodeByHost(nodeReg.getXferAddr());
+    DatanodeDescriptor nodeN = host2DatanodeMap.getDatanodeByXferAddr(
+        nodeReg.getIpAddr(), nodeReg.getXferPort());
-      checkDecommissioning(nodeS, dnAddress);
+      checkDecommissioning(nodeS);
-    checkDecommissioning(nodeDescr, dnAddress);
+    checkDecommissioning(nodeDescr);
-  private void refreshDatanodes() throws IOException {
+  private void refreshDatanodes() {
+  
+  /* Getter and Setter for stale DataNodes related attributes */
+  
+  /**
+   * @return whether or not to avoid writing to stale datanodes
+   */
+  public boolean isAvoidingStaleDataNodesForWrite() {
+    return avoidStaleDataNodesForWrite;
+  }
+  /**
+   * Set the value of {@link DatanodeManager#avoidStaleDataNodesForWrite}. 
+   * The HeartbeatManager disable avoidStaleDataNodesForWrite when more than
+   * half of the DataNodes are marked as stale.
+   * 
+   * @param avoidStaleDataNodesForWrite
+   *          The value to set to
+   *          {@link DatanodeManager#avoidStaleDataNodesForWrite}
+   */
+  void setAvoidStaleDataNodesForWrite(boolean avoidStaleDataNodesForWrite) {
+    this.avoidStaleDataNodesForWrite = avoidStaleDataNodesForWrite;
+  }
+
+  /**
+   * @return Whether or not to check stale DataNodes for R/W
+   */
+  boolean isCheckingForStaleDataNodes() {
+    return checkForStaleDataNodes;
+  }
+  
+  /**
+   * @return The time interval used to mark DataNodes as stale.
+   */
+  long getStaleInterval() {
+    return staleInterval;
+  }
+
+  /**
+   * Set the number of current stale DataNodes. The HeartbeatManager got this
+   * number based on DataNodes' heartbeats.
+   * 
+   * @param numStaleNodes
+   *          The number of stale DataNodes to be set.
+   */
+  void setNumStaleNodes(int numStaleNodes) {
+    this.numStaleNodes = numStaleNodes;
+  }
+  
+  /**
+   * @return Return the current number of stale DataNodes (detected by
+   * HeartbeatManager). 
+   */
+  public int getNumStaleNodes() {
+    return this.numStaleNodes;
+  }
-  private void setDatanodeDead(DatanodeDescriptor node) throws IOException {
+  private void setDatanodeDead(DatanodeDescriptor node) {

MOV26 INS26 INS26 MOV23 UPD40 INS40 UPD40 INS40 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS83 INS39 INS59 INS83 INS83 INS39 INS42 INS44 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS39 INS42 INS44 INS8 INS29 INS39 INS42 INS8 INS29 INS39 INS42 INS8 INS29 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS8 INS65 INS42 INS65 INS42 INS65 INS42 INS65 INS42 INS21 INS21 INS21 INS43 INS42 INS39 INS42 INS60 INS21 INS60 INS60 INS25 INS25 INS41 INS43 INS42 INS39 INS42 INS60 INS60 INS25 INS41 INS60 INS65 INS41 INS65 INS65 INS39 INS42 INS21 INS65 INS41 INS65 INS41 INS65 INS65 INS39 INS42 INS21 INS65 INS41 INS66 INS66 INS66 INS66 INS7 INS7 INS7 INS42 INS39 INS59 INS32 INS83 INS39 INS59 INS83 INS39 INS59 INS27 INS8 INS27 INS8 INS42 INS42 INS39 INS59 INS39 INS59 INS27 INS8 INS42 INS8 INS74 INS59 INS66 INS42 INS66 INS65 INS66 INS66 INS66 INS42 INS66 INS65 INS7 INS66 INS42 INS66 INS42 INS66 INS66 INS42 INS66 INS7 INS66 INS66 INS22 MOV32 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS42 INS27 INS27 INS42 INS32 INS42 INS27 INS42 INS42 INS21 INS21 INS42 INS42 INS21 INS42 INS32 INS42 INS27 INS38 INS42 INS21 MOV21 INS54 INS43 INS43 INS42 INS16 INS67 INS67 INS22 INS42 INS22 INS42 INS52 INS42 INS42 INS42 INS40 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS40 INS42 INS34 INS40 INS45 INS42 INS45 INS45 INS42 INS42 INS40 INS40 INS32 INS42 INS34 INS32 INS7 INS32 INS42 INS42 INS40 INS40 INS42 INS42 INS42 INS32 INS8 INS12 INS42 INS42 INS42 INS14 INS40 INS42 UPD42 INS32 INS42 INS42 INS42 INS42 INS52 INS42 INS52 INS42 INS42 INS42 INS40 INS40 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS27 INS21 INS44 INS8 INS43 INS42 INS42 UPD42 INS42 INS42 INS45 INS42 INS45 INS40 INS45 INS45 INS45 INS42 INS45 INS45 INS42 INS45 INS42 INS45 INS45 INS40 INS45 INS40 INS45 INS32 INS43 INS42 INS40 INS42 INS42 INS34 INS42 UPD42 DEL42 DEL43 DEL11 DEL40 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL43 DEL42 DEL43