Merge r1360400 through r1399945 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1399950 13f79535-47bb-0310-9956-ffa450edef68

+import static com.google.common.base.Preconditions.checkArgument;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.PrintStream;
+import org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferEncryptor;
+import org.apache.hadoop.hdfs.protocol.datatransfer.IOStreamPair;
-import org.apache.hadoop.hdfs.server.common.Util;
+import org.apache.hadoop.util.Time;
-import static com.google.common.base.Preconditions.checkArgument;
+  private static final String USAGE = "Usage: java "
+      + Balancer.class.getSimpleName()
+      + "\n\t[-policy <policy>]\tthe balancing policy: "
+      + BalancingPolicy.Node.INSTANCE.getName() + " or "
+      + BalancingPolicy.Pool.INSTANCE.getName()
+      + "\n\t[-threshold <threshold>]\tPercentage of disk capacity";
+  
-        out = new DataOutputStream( new BufferedOutputStream(
-            sock.getOutputStream(), HdfsConstants.IO_FILE_BUFFER_SIZE));
+        
+        OutputStream unbufOut = sock.getOutputStream();
+        InputStream unbufIn = sock.getInputStream();
+        if (nnc.getDataEncryptionKey() != null) {
+          IOStreamPair encryptedStreams =
+              DataTransferEncryptor.getEncryptedStreams(
+                  unbufOut, unbufIn, nnc.getDataEncryptionKey());
+          unbufOut = encryptedStreams.out;
+          unbufIn = encryptedStreams.in;
+        }
+        out = new DataOutputStream(new BufferedOutputStream(unbufOut,
+            HdfsConstants.IO_FILE_BUFFER_SIZE));
+        in = new DataInputStream(new BufferedInputStream(unbufIn,
+            HdfsConstants.IO_FILE_BUFFER_SIZE));
+        
-        in = new DataInputStream( new BufferedInputStream(
-            sock.getInputStream(), HdfsConstants.IO_FILE_BUFFER_SIZE));
+        @Override
+      @Override
-      long startTime = Util.now();
+      long startTime = Time.now();
-        if (Util.now()-startTime > MAX_ITERATION_TIME) {
+        if (Time.now()-startTime > MAX_ITERATION_TIME) {
-    private long lastCleanupTime = System.currentTimeMillis();
+    private long lastCleanupTime = Time.now();
-      long curTime = System.currentTimeMillis();
+      long curTime = Time.now();
-      final long startTime = Util.now();
+      final long startTime = Time.now();
-        System.out.println("Balancing took " + time2Str(Util.now()-startTime));
+        System.out.println("Balancing took " + time2Str(Time.now()-startTime));
-          printUsage();
+          printUsage(System.err);
-    private static void printUsage() {
-      System.out.println("Usage: java " + Balancer.class.getSimpleName());
-      System.out.println("    [-policy <policy>]\tthe balancing policy: "
-          + BalancingPolicy.Node.INSTANCE.getName() + " or " 
-          + BalancingPolicy.Pool.INSTANCE.getName());
-      System.out.println(
-          "    [-threshold <threshold>]\tPercentage of disk capacity");
+    private static void printUsage(PrintStream out) {
+      out.println(USAGE + "\n");
+    if (DFSUtil.parseHelpArgument(args, USAGE, System.out, true)) {
+      System.exit(0);
+    }
+

MOV26 MOV26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 UPD40 INS23 INS83 INS83 INS83 INS43 INS59 INS42 INS42 MOV27 INS44 INS8 INS25 INS45 MOV32 INS45 MOV32 INS45 INS78 INS43 INS42 MOV21 INS32 INS8 MOV21 INS42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS40 INS9 INS21 INS60 INS60 INS25 INS42 INS32 INS43 INS59 INS43 INS59 INS27 INS8 UPD42 UPD42 UPD42 UPD42 INS42 UPD45 INS42 INS42 INS34 INS42 INS42 MOV32 INS42 INS42 MOV32 INS32 INS33 INS60 INS21 INS21 INS42 INS42 INS43 INS59 INS7 INS7 INS78 INS42 INS42 INS32 INS42 INS40 INS42 INS40 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 INS42 INS32 INS40 INS42 INS42 UPD42 DEL40 DEL45 DEL40 DEL42 DEL32 DEL21 DEL40 DEL42 DEL45 DEL32 DEL21 DEL8