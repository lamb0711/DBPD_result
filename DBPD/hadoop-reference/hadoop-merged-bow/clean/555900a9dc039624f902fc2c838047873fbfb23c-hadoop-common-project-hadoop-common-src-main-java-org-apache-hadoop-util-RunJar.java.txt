Merge branch 'trunk' into HDFS-6584

-import java.lang.reflect.Array;
-import java.lang.reflect.Method;
-import java.lang.reflect.InvocationTargetException;
-import java.net.URL;
-import java.net.URLClassLoader;
+import java.io.File;
-import java.io.File;
-import java.util.regex.Pattern;
-import java.util.Arrays;
+import java.lang.reflect.Array;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.net.URLClassLoader;
+import java.util.Arrays;
-import java.util.jar.JarFile;
+import java.util.List;
+import java.util.jar.JarFile;
+import java.util.regex.Pattern;
+   * Environment key for using the client classloader.
+   */
+  public static final String HADOOP_USE_CLIENT_CLASSLOADER =
+      "HADOOP_USE_CLIENT_CLASSLOADER";
+  /**
+   * Environment key for the (user-provided) hadoop classpath.
+   */
+  public static final String HADOOP_CLASSPATH = "HADOOP_CLASSPATH";
+  /**
+   * Environment key for the system classes.
+   */
+  public static final String HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES =
+      "HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES";
+
+  /**
+    new RunJar().run(args);
+  }
+
+  public void run(String[] args) throws Throwable {
-    ArrayList<URL> classPath = new ArrayList<URL>();
-    classPath.add(new File(workDir+"/").toURI().toURL());
-    classPath.add(file.toURI().toURL());
-    classPath.add(new File(workDir, "classes/").toURI().toURL());
-    File[] libs = new File(workDir, "lib").listFiles();
-    if (libs != null) {
-      for (int i = 0; i < libs.length; i++) {
-        classPath.add(libs[i].toURI().toURL());
-      }
-    }
-    
-    ClassLoader loader =
-      new URLClassLoader(classPath.toArray(new URL[0]));
+    ClassLoader loader = createClassLoader(file, workDir);
-  
+
+  /**
+   * Creates a classloader based on the environment that was specified by the
+   * user. If HADOOP_USE_CLIENT_CLASSLOADER is specified, it creates an
+   * application classloader that provides the isolation of the user class space
+   * from the hadoop classes and their dependencies. It forms a class space for
+   * the user jar as well as the HADOOP_CLASSPATH. Otherwise, it creates a
+   * classloader that simply adds the user jar to the classpath.
+   */
+  private ClassLoader createClassLoader(File file, final File workDir)
+      throws MalformedURLException {
+    ClassLoader loader;
+    // see if the client classloader is enabled
+    if (useClientClassLoader()) {
+      StringBuilder sb = new StringBuilder();
+      sb.append(workDir+"/").
+          append(File.pathSeparator).append(file).
+          append(File.pathSeparator).append(workDir+"/classes/").
+          append(File.pathSeparator).append(workDir+"/lib/*");
+      // HADOOP_CLASSPATH is added to the client classpath
+      String hadoopClasspath = getHadoopClasspath();
+      if (hadoopClasspath != null && !hadoopClasspath.isEmpty()) {
+        sb.append(File.pathSeparator).append(hadoopClasspath);
+      }
+      String clientClasspath = sb.toString();
+      // get the system classes
+      String systemClasses = getSystemClasses();
+      List<String> systemClassesList = systemClasses == null ?
+          null :
+          Arrays.asList(StringUtils.getTrimmedStrings(systemClasses));
+      // create an application classloader that isolates the user classes
+      loader = new ApplicationClassLoader(clientClasspath,
+          getClass().getClassLoader(), systemClassesList);
+    } else {
+      List<URL> classPath = new ArrayList<URL>();
+      classPath.add(new File(workDir+"/").toURI().toURL());
+      classPath.add(file.toURI().toURL());
+      classPath.add(new File(workDir, "classes/").toURI().toURL());
+      File[] libs = new File(workDir, "lib").listFiles();
+      if (libs != null) {
+        for (int i = 0; i < libs.length; i++) {
+          classPath.add(libs[i].toURI().toURL());
+        }
+      }
+      // create a normal parent-delegating classloader
+      loader = new URLClassLoader(classPath.toArray(new URL[0]));
+    }
+    return loader;
+  }
+
+  boolean useClientClassLoader() {
+    return Boolean.parseBoolean(System.getenv(HADOOP_USE_CLIENT_CLASSLOADER));
+  }
+
+  String getHadoopClasspath() {
+    return System.getenv(HADOOP_CLASSPATH);
+  }
+
+  String getSystemClasses() {
+    return System.getenv(HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES);
+  }

MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 INS26 INS26 INS40 INS40 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS29 INS83 INS83 INS83 INS43 INS59 INS29 INS83 INS83 INS83 INS43 INS59 INS29 INS83 INS83 INS83 INS43 INS59 MOV29 INS83 INS83 INS39 INS42 INS44 INS43 INS8 UPD42 INS29 INS83 MOV43 INS42 INS44 INS44 INS43 INS8 INS39 INS42 INS8 INS43 INS42 INS8 INS43 INS42 INS8 INS65 INS42 INS42 INS45 INS65 INS42 INS42 INS45 INS65 INS42 INS42 INS45 INS5 INS42 INS42 INS21 INS65 INS43 INS42 INS83 INS43 INS42 INS42 INS60 INS25 INS41 INS41 INS42 INS41 INS42 INS41 INS66 INS66 INS66 INS43 INS85 INS32 INS43 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS43 INS59 INS32 INS8 INS8 INS42 INS32 INS32 INS32 INS42 INS14 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS60 INS21 INS60 INS25 INS60 INS60 INS60 INS21 MOV60 MOV21 MOV21 MOV21 MOV60 MOV25 INS21 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS42 INS42 INS43 INS59 INS32 INS43 INS59 INS27 INS8 INS43 INS59 INS43 INS59 INS74 INS59 INS7 UPD74 INS7 INS42 INS42 INS42 INS42 INS42 INS42 INS14 INS32 INS42 INS27 INS42 INS42 INS32 INS27 INS38 INS21 INS42 INS42 INS32 INS42 INS42 INS32 INS43 INS43 INS42 INS16 INS42 INS14 UPD43 INS42 MOV14 INS43 INS32 INS42 INS40 INS42 INS45 INS42 INS42 INS33 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS27 INS33 INS32 INS43 INS42 INS32 INS42 UPD42 INS42 INS32 INS42 INS27 INS42 INS42 INS32 INS42 INS42 INS42 INS33 INS42 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS40 INS42 INS45 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS40 INS42 INS42 INS27 INS42 INS45 DEL83