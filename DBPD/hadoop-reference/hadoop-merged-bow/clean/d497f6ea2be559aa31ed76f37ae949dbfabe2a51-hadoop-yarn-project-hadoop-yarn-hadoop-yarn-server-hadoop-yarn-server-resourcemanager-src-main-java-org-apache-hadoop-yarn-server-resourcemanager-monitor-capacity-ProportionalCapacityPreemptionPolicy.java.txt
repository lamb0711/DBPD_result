YARN-2498. Respect labels in preemption policy of capacity scheduler for inter-queue preemption. Contributed by Wangda Tan

+import java.io.IOException;
-import java.util.NavigableSet;
+import java.util.TreeSet;
-import org.apache.commons.collections.map.HashedMap;
-import org.apache.hadoop.yarn.server.resourcemanager.RMContext;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.QueueCapacities;
+import com.google.common.collect.ImmutableSet;
-  private Map<NodeId, Set<String>> labels;
+  private Map<String, Map<String, TempQueuePerPartition>> queueToPartitions =
+      new HashMap<>();
+  private RMNodeLabelsManager nlm;
-    labels = null;
+    nlm = scheduler.getRMContext().getNodeLabelManager();
-    clusterResources = getNonLabeledResources(clusterResources);
-    setNodeLabels(scheduler.getRMContext().getNodeLabelManager()
-        .getNodeLabels());
-
-  /**
-   * Setting Node Labels
-   * 
-   * @param nodelabels
-   */
-  public void setNodeLabels(Map<NodeId, Set<String>> nodelabels) {
-    labels = nodelabels;
-  }
-
-  /**
-   * This method returns all non labeled resources.
-   * 
-   * @param clusterResources
-   * @return Resources
-   */
-  private Resource getNonLabeledResources(Resource clusterResources) {
-    RMContext rmcontext = scheduler.getRMContext();
-    RMNodeLabelsManager lm = rmcontext.getNodeLabelManager();
-    Resource res = lm.getResourceByLabel(RMNodeLabelsManager.NO_LABEL,
-        clusterResources);
-    return res == null ? clusterResources : res;
-  }
+    // All partitions to look at
+    Set<String> allPartitions = new HashSet<>();
+    allPartitions.addAll(scheduler.getRMContext()
+        .getNodeLabelManager().getClusterNodeLabelNames());
+    allPartitions.add(RMNodeLabelsManager.NO_LABEL);
-    TempQueue tRoot;
-      tRoot = cloneQueues(root, clusterResources);
+      queueToPartitions.clear();
+
+      for (String partitionToLookAt : allPartitions) {
+        cloneQueues(root,
+            nlm.getResourceByLabel(partitionToLookAt, clusterResources),
+            partitionToLookAt);
+      }
-    // compute the ideal distribution of resources among queues
-    // updates cloned queues state accordingly
-    tRoot.idealAssigned = tRoot.guaranteed;
+    // compute total preemption allowed
-    List<TempQueue> queues =
-      recursivelyComputeIdealAssignment(tRoot, totalPreemptionAllowed);
+
+    Set<String> leafQueueNames = null;
+    for (String partition : allPartitions) {
+      TempQueuePerPartition tRoot =
+          getQueueByPartition(CapacitySchedulerConfiguration.ROOT, partition);
+      // compute the ideal distribution of resources among queues
+      // updates cloned queues state accordingly
+      tRoot.idealAssigned = tRoot.guaranteed;
+
+      leafQueueNames =
+          recursivelyComputeIdealAssignment(tRoot, totalPreemptionAllowed);
+    }
-        getContainersToPreempt(queues, clusterResources);
+        getContainersToPreempt(leafQueueNames, clusterResources);
-      logToCSV(queues);
+      logToCSV(new ArrayList<String>(leafQueueNames));
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Send to scheduler: in app=" + e.getKey()
+            + " #containers-to-be-preempted=" + e.getValue().size());
+      }
-  private List<TempQueue> recursivelyComputeIdealAssignment(
-      TempQueue root, Resource totalPreemptionAllowed) {
-    List<TempQueue> leafs = new ArrayList<TempQueue>();
+  private Set<String> recursivelyComputeIdealAssignment(
+      TempQueuePerPartition root, Resource totalPreemptionAllowed) {
+    Set<String> leafQueueNames = new HashSet<>();
-      for(TempQueue t : root.getChildren()) {
-        leafs.addAll(recursivelyComputeIdealAssignment(t, totalPreemptionAllowed));
+      for(TempQueuePerPartition t : root.getChildren()) {
+        leafQueueNames.addAll(recursivelyComputeIdealAssignment(t,
+            totalPreemptionAllowed));
-      return Collections.singletonList(root);
+      return ImmutableSet.of(root.queueName);
-    return leafs;
+    return leafQueueNames;
-      List<TempQueue> queues, Resource totalPreemptionAllowed, Resource tot_guarant) {
+      List<TempQueuePerPartition> queues, Resource totalPreemptionAllowed,
+      Resource tot_guarant) {
-    List<TempQueue> qAlloc = new ArrayList<TempQueue>(queues);
+    List<TempQueuePerPartition> qAlloc = new ArrayList<TempQueuePerPartition>(queues);
-    Set<TempQueue> nonZeroGuarQueues = new HashSet<TempQueue>();
-    Set<TempQueue> zeroGuarQueues = new HashSet<TempQueue>();
+    Set<TempQueuePerPartition> nonZeroGuarQueues = new HashSet<TempQueuePerPartition>();
+    Set<TempQueuePerPartition> zeroGuarQueues = new HashSet<TempQueuePerPartition>();
-    for (TempQueue q : qAlloc) {
+    for (TempQueuePerPartition q : qAlloc) {
-    for (TempQueue t:queues) {
+    for (TempQueuePerPartition t:queues) {
-    for (TempQueue t : queues) {
+    for (TempQueuePerPartition t : queues) {
-      for (TempQueue t : queues) {
+      for (TempQueuePerPartition t : queues) {
-      Resource tot_guarant, Collection<TempQueue> qAlloc, Resource unassigned, 
-      boolean ignoreGuarantee) {
+      Resource tot_guarant, Collection<TempQueuePerPartition> qAlloc,
+      Resource unassigned, boolean ignoreGuarantee) {
-    PriorityQueue<TempQueue> orderedByNeed =
-                                 new PriorityQueue<TempQueue>(10,tqComparator);
-    for (Iterator<TempQueue> i = qAlloc.iterator(); i.hasNext();) {
-      TempQueue q = i.next();
+    PriorityQueue<TempQueuePerPartition> orderedByNeed =
+        new PriorityQueue<TempQueuePerPartition>(10, tqComparator);
+    for (Iterator<TempQueuePerPartition> i = qAlloc.iterator(); i.hasNext();) {
+      TempQueuePerPartition q = i.next();
-      Collection<TempQueue> underserved =
+      Collection<TempQueuePerPartition> underserved =
-      for (Iterator<TempQueue> i = underserved.iterator(); i.hasNext();) {
-        TempQueue sub = i.next();
+      for (Iterator<TempQueuePerPartition> i = underserved.iterator(); i
+          .hasNext();) {
+        TempQueuePerPartition sub = i.next();
-  protected Collection<TempQueue> getMostUnderservedQueues(
-      PriorityQueue<TempQueue> orderedByNeed, TQComparator tqComparator) {
-    ArrayList<TempQueue> underserved = new ArrayList<TempQueue>();
+  protected Collection<TempQueuePerPartition> getMostUnderservedQueues(
+      PriorityQueue<TempQueuePerPartition> orderedByNeed, TQComparator tqComparator) {
+    ArrayList<TempQueuePerPartition> underserved = new ArrayList<TempQueuePerPartition>();
-      TempQueue q1 = orderedByNeed.remove();
+      TempQueuePerPartition q1 = orderedByNeed.remove();
-      TempQueue q2 = orderedByNeed.peek();
+      TempQueuePerPartition q2 = orderedByNeed.peek();
-      Collection<TempQueue> queues, boolean ignoreGuar) {
+      Collection<TempQueuePerPartition> queues, boolean ignoreGuar) {
-      for (TempQueue q : queues) {
+      for (TempQueuePerPartition q : queues) {
-      for (TempQueue q : queues) {
+      for (TempQueuePerPartition q : queues) {
-      for (TempQueue q : queues) {
+      for (TempQueuePerPartition q : queues) {
+  private String getPartitionByNodeId(NodeId nodeId) {
+    return scheduler.getSchedulerNode(nodeId).getPartition();
+  }
+
+  /**
+   * Return should we preempt rmContainer. If we should, deduct from
+   * <code>resourceToObtainByPartition</code>
+   */
+  private boolean tryPreemptContainerAndDeductResToObtain(
+      Map<String, Resource> resourceToObtainByPartitions,
+      RMContainer rmContainer, Resource clusterResource,
+      Map<ApplicationAttemptId, Set<RMContainer>> preemptMap) {
+    ApplicationAttemptId attemptId = rmContainer.getApplicationAttemptId();
+
+    // We will not account resource of a container twice or more
+    if (preemptMapContains(preemptMap, attemptId, rmContainer)) {
+      return false;
+    }
+
+    String nodePartition = getPartitionByNodeId(rmContainer.getAllocatedNode());
+    Resource toObtainByPartition =
+        resourceToObtainByPartitions.get(nodePartition);
+
+    if (null != toObtainByPartition
+        && Resources.greaterThan(rc, clusterResource, toObtainByPartition,
+            Resources.none())) {
+      Resources.subtractFrom(toObtainByPartition,
+          rmContainer.getAllocatedResource());
+      // When we have no more resource need to obtain, remove from map.
+      if (Resources.lessThanOrEqual(rc, clusterResource, toObtainByPartition,
+          Resources.none())) {
+        resourceToObtainByPartitions.remove(nodePartition);
+      }
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Marked container=" + rmContainer.getContainerId()
+            + " in partition=" + nodePartition + " will be preempted");
+      }
+      // Add to preemptMap
+      addToPreemptMap(preemptMap, attemptId, rmContainer);
+      return true;
+    }
+
+    return false;
+  }
+
+  private boolean preemptMapContains(
+      Map<ApplicationAttemptId, Set<RMContainer>> preemptMap,
+      ApplicationAttemptId attemptId, RMContainer rmContainer) {
+    Set<RMContainer> rmContainers;
+    if (null == (rmContainers = preemptMap.get(attemptId))) {
+      return false;
+    }
+    return rmContainers.contains(rmContainer);
+  }
+
+  private void addToPreemptMap(
+      Map<ApplicationAttemptId, Set<RMContainer>> preemptMap,
+      ApplicationAttemptId appAttemptId, RMContainer containerToPreempt) {
+    Set<RMContainer> set;
+    if (null == (set = preemptMap.get(appAttemptId))) {
+      set = new HashSet<RMContainer>();
+      preemptMap.put(appAttemptId, set);
+    }
+    set.add(containerToPreempt);
+  }
+
-      List<TempQueue> queues, Resource clusterResource) {
+      Set<String> leafQueueNames, Resource clusterResource) {
-    Map<ApplicationAttemptId,Set<RMContainer>> preemptMap =
-        new HashMap<ApplicationAttemptId,Set<RMContainer>>();
+    Map<ApplicationAttemptId, Set<RMContainer>> preemptMap =
+        new HashMap<ApplicationAttemptId, Set<RMContainer>>();
-    for (TempQueue qT : queues) {
-      if (qT.preemptionDisabled && qT.leafQueue != null) {
+    // Loop all leaf queues
+    for (String queueName : leafQueueNames) {
+      // check if preemption disabled for the queue
+      if (getQueueByPartition(queueName,
+          RMNodeLabelsManager.NO_LABEL).preemptionDisabled) {
-          if (Resources.greaterThan(rc, clusterResource,
-              qT.toBePreempted, Resource.newInstance(0, 0))) {
-            LOG.debug("Tried to preempt the following "
-                      + "resources from non-preemptable queue: "
-                      + qT.queueName + " - Resources: " + qT.toBePreempted);
-          }
+          LOG.debug("skipping from queue=" + queueName
+              + " because it's a non-preemptable queue");
-      // we act only if we are violating balance by more than
-      // maxIgnoredOverCapacity
-      if (Resources.greaterThan(rc, clusterResource, qT.current,
-          Resources.multiply(qT.guaranteed, 1.0 + maxIgnoredOverCapacity))) {
-        // we introduce a dampening factor naturalTerminationFactor that
-        // accounts for natural termination of containers
-        Resource resToObtain =
-          Resources.multiply(qT.toBePreempted, naturalTerminationFactor);
-        Resource skippedAMSize = Resource.newInstance(0, 0);
-        // lock the leafqueue while we scan applications and unreserve
-        synchronized (qT.leafQueue) {
-          Iterator<FiCaSchedulerApp> desc =   
-            qT.leafQueue.getOrderingPolicy().getPreemptionIterator();
-          qT.actuallyPreempted = Resources.clone(resToObtain);
-          while (desc.hasNext()) {
-            FiCaSchedulerApp fc = desc.next();
-            if (Resources.lessThanOrEqual(rc, clusterResource, resToObtain,
-                Resources.none())) {
-              break;
+      // compute resToObtainByPartition considered inter-queue preemption
+      LeafQueue leafQueue = null;
+
+      Map<String, Resource> resToObtainByPartition =
+          new HashMap<String, Resource>();
+      for (TempQueuePerPartition qT : getQueuePartitions(queueName)) {
+        leafQueue = qT.leafQueue;
+        // we act only if we are violating balance by more than
+        // maxIgnoredOverCapacity
+        if (Resources.greaterThan(rc, clusterResource, qT.current,
+            Resources.multiply(qT.guaranteed, 1.0 + maxIgnoredOverCapacity))) {
+          // we introduce a dampening factor naturalTerminationFactor that
+          // accounts for natural termination of containers
+          Resource resToObtain =
+              Resources.multiply(qT.toBePreempted, naturalTerminationFactor);
+          // Only add resToObtain when it >= 0
+          if (Resources.greaterThan(rc, clusterResource, resToObtain,
+              Resources.none())) {
+            resToObtainByPartition.put(qT.partition, resToObtain);
+            if (LOG.isDebugEnabled()) {
+              LOG.debug("Queue=" + queueName + " partition=" + qT.partition
+                  + " resource-to-obtain=" + resToObtain);
-            preemptMap.put(
-                fc.getApplicationAttemptId(),
-                preemptFrom(fc, clusterResource, resToObtain,
-                    skippedAMContainerlist, skippedAMSize));
-          Resource maxAMCapacityForThisQueue = Resources.multiply(
-              Resources.multiply(clusterResource,
-                  qT.leafQueue.getAbsoluteCapacity()),
-              qT.leafQueue.getMaxAMResourcePerQueuePercent());
-
-          // Can try preempting AMContainers (still saving atmost
-          // maxAMCapacityForThisQueue AMResource's) if more resources are
-          // required to be preempted from this Queue.
-          preemptAMContainers(clusterResource, preemptMap,
-              skippedAMContainerlist, resToObtain, skippedAMSize,
-              maxAMCapacityForThisQueue);
+          qT.actuallyPreempted = Resources.clone(resToObtain);
+        } else {
+          qT.actuallyPreempted = Resources.none();
+
+      synchronized (leafQueue) {
+        // go through all ignore-partition-exclusivity containers first to make
+        // sure such containers will be preempted first
+        Map<String, TreeSet<RMContainer>> ignorePartitionExclusivityContainers =
+            leafQueue.getIgnoreExclusivityRMContainers();
+        for (String partition : resToObtainByPartition.keySet()) {
+          if (ignorePartitionExclusivityContainers.containsKey(partition)) {
+            TreeSet<RMContainer> rmContainers =
+                ignorePartitionExclusivityContainers.get(partition);
+            // We will check container from reverse order, so latter submitted
+            // application's containers will be preempted first.
+            for (RMContainer c : rmContainers.descendingSet()) {
+              boolean preempted =
+                  tryPreemptContainerAndDeductResToObtain(
+                      resToObtainByPartition, c, clusterResource, preemptMap);
+              if (!preempted) {
+                break;
+              }
+            }
+          }
+        }
+
+        // preempt other containers
+        Resource skippedAMSize = Resource.newInstance(0, 0);
+        Iterator<FiCaSchedulerApp> desc =
+            leafQueue.getOrderingPolicy().getPreemptionIterator();
+        while (desc.hasNext()) {
+          FiCaSchedulerApp fc = desc.next();
+          // When we complete preempt from one partition, we will remove from
+          // resToObtainByPartition, so when it becomes empty, we can get no
+          // more preemption is needed
+          if (resToObtainByPartition.isEmpty()) {
+            break;
+          }
+
+          preemptFrom(fc, clusterResource, resToObtainByPartition,
+              skippedAMContainerlist, skippedAMSize, preemptMap);
+        }
+
+        // Can try preempting AMContainers (still saving atmost
+        // maxAMCapacityForThisQueue AMResource's) if more resources are
+        // required to be preempted from this Queue.
+        Resource maxAMCapacityForThisQueue = Resources.multiply(
+            Resources.multiply(clusterResource,
+                leafQueue.getAbsoluteCapacity()),
+            leafQueue.getMaxAMResourcePerQueuePercent());
+
+        preemptAMContainers(clusterResource, preemptMap, skippedAMContainerlist,
+            resToObtainByPartition, skippedAMSize, maxAMCapacityForThisQueue);
+      }
+
-      List<RMContainer> skippedAMContainerlist, Resource resToObtain,
-      Resource skippedAMSize, Resource maxAMCapacityForThisQueue) {
+      List<RMContainer> skippedAMContainerlist,
+      Map<String, Resource> resToObtainByPartition, Resource skippedAMSize,
+      Resource maxAMCapacityForThisQueue) {
-      if (Resources.lessThanOrEqual(rc, clusterResource, resToObtain,
-          Resources.none())) {
+      if (resToObtainByPartition.isEmpty()) {
-      // container selection iteration for preemption will be stopped. 
+      // container selection iteration for preemption will be stopped.
-      Set<RMContainer> contToPrempt = preemptMap.get(c
-          .getApplicationAttemptId());
-      if (null == contToPrempt) {
-        contToPrempt = new HashSet<RMContainer>();
-        preemptMap.put(c.getApplicationAttemptId(), contToPrempt);
+
+      boolean preempted =
+          tryPreemptContainerAndDeductResToObtain(resToObtainByPartition, c,
+              clusterResource, preemptMap);
+      if (preempted) {
+        Resources.subtractFrom(skippedAMSize, c.getAllocatedResource());
-      contToPrempt.add(c);
-      
-      Resources.subtractFrom(resToObtain, c.getContainer().getResource());
-      Resources.subtractFrom(skippedAMSize, c.getContainer()
-          .getResource());
-   *
-   * @param app
-   * @param clusterResource
-   * @param rsrcPreempt
-   * @return Set<RMContainer> Set of RMContainers
-  private Set<RMContainer> preemptFrom(FiCaSchedulerApp app,
-      Resource clusterResource, Resource rsrcPreempt,
-      List<RMContainer> skippedAMContainerlist, Resource skippedAMSize) {
-    Set<RMContainer> ret = new HashSet<RMContainer>();
+  private void preemptFrom(FiCaSchedulerApp app,
+      Resource clusterResource, Map<String, Resource> resToObtainByPartition,
+      List<RMContainer> skippedAMContainerlist, Resource skippedAMSize,
+      Map<ApplicationAttemptId, Set<RMContainer>> preemptMap) {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Looking at application=" + app.getApplicationAttemptId()
+          + " resourceToObtain=" + resToObtainByPartition);
+    }
-    List<RMContainer> reservations =
+    List<RMContainer> reservedContainers =
-    for (RMContainer c : reservations) {
-      if (Resources.lessThanOrEqual(rc, clusterResource,
-          rsrcPreempt, Resources.none())) {
-        return ret;
+    for (RMContainer c : reservedContainers) {
+      if (resToObtainByPartition.isEmpty()) {
+        return;
+
+      // Try to preempt this container
+      tryPreemptContainerAndDeductResToObtain(resToObtainByPartition, c,
+          clusterResource, preemptMap);
+
-      Resources.subtractFrom(rsrcPreempt, c.getContainer().getResource());
-    List<RMContainer> containers =
+    List<RMContainer> liveContainers =
-    sortContainers(containers);
+    sortContainers(liveContainers);
-    for (RMContainer c : containers) {
-      if (Resources.lessThanOrEqual(rc, clusterResource,
-            rsrcPreempt, Resources.none())) {
-        return ret;
+    for (RMContainer c : liveContainers) {
+      if (resToObtainByPartition.isEmpty()) {
+        return;
+
-        Resources.addTo(skippedAMSize, c.getContainer().getResource());
+        Resources.addTo(skippedAMSize, c.getAllocatedResource());
-      // skip Labeled resource
-      if(isLabeledContainer(c)){
-        continue;
-      }
-      ret.add(c);
-      Resources.subtractFrom(rsrcPreempt, c.getContainer().getResource());
-    }
-    return ret;
-  }
-  
-  /**
-   * Checking if given container is a labeled container
-   * 
-   * @param c
-   * @return true/false
-   */
-  private boolean isLabeledContainer(RMContainer c) {
-    return labels.containsKey(c.getAllocatedNode());
+      // Try to preempt this container
+      tryPreemptContainerAndDeductResToObtain(resToObtainByPartition, c,
+          clusterResource, preemptMap);
+    }
-   * @param root the root of the CapacityScheduler queue hierarchy
-   * @param clusterResources the total amount of resources in the cluster
+   * @param curQueue current queue which I'm looking at now
+   * @param partitionResource the total amount of resources in the cluster
-  private TempQueue cloneQueues(CSQueue root, Resource clusterResources) {
-    TempQueue ret;
-    synchronized (root) {
-      String queueName = root.getQueueName();
-      float absUsed = root.getAbsoluteUsedCapacity();
-      float absCap = root.getAbsoluteCapacity();
-      float absMaxCap = root.getAbsoluteMaximumCapacity();
-      boolean preemptionDisabled = root.getPreemptionDisabled();
+  private TempQueuePerPartition cloneQueues(CSQueue curQueue,
+      Resource partitionResource, String partitionToLookAt) {
+    TempQueuePerPartition ret;
+    synchronized (curQueue) {
+      String queueName = curQueue.getQueueName();
+      QueueCapacities qc = curQueue.getQueueCapacities();
+      float absUsed = qc.getAbsoluteUsedCapacity(partitionToLookAt);
+      float absCap = qc.getAbsoluteCapacity(partitionToLookAt);
+      float absMaxCap = qc.getAbsoluteMaximumCapacity(partitionToLookAt);
+      boolean preemptionDisabled = curQueue.getPreemptionDisabled();
-      Resource current = Resources.multiply(clusterResources, absUsed);
-      Resource guaranteed = Resources.multiply(clusterResources, absCap);
-      Resource maxCapacity = Resources.multiply(clusterResources, absMaxCap);
+      Resource current = Resources.multiply(partitionResource, absUsed);
+      Resource guaranteed = Resources.multiply(partitionResource, absCap);
+      Resource maxCapacity = Resources.multiply(partitionResource, absMaxCap);
+
+      // when partition is a non-exclusive partition, the actual maxCapacity
+      // could more than specified maxCapacity
+      try {
+        if (!scheduler.getRMContext().getNodeLabelManager()
+            .isExclusiveNodeLabel(partitionToLookAt)) {
+          maxCapacity =
+              Resources.max(rc, partitionResource, maxCapacity, current);
+        }
+      } catch (IOException e) {
+        // This may cause by partition removed when running capacity monitor,
+        // just ignore the error, this will be corrected when doing next check.
+      }
-      if (Resources.greaterThan(rc, clusterResources, current, guaranteed)) {
+      if (Resources.greaterThan(rc, partitionResource, current, guaranteed)) {
-      if (root instanceof LeafQueue) {
-        LeafQueue l = (LeafQueue) root;
-        Resource pending = l.getTotalResourcePending();
-        ret = new TempQueue(queueName, current, pending, guaranteed,
-            maxCapacity, preemptionDisabled);
+      if (curQueue instanceof LeafQueue) {
+        LeafQueue l = (LeafQueue) curQueue;
+        Resource pending =
+            l.getQueueResourceUsage().getPending(partitionToLookAt);
+        ret = new TempQueuePerPartition(queueName, current, pending, guaranteed,
+            maxCapacity, preemptionDisabled, partitionToLookAt);
-        ret = new TempQueue(root.getQueueName(), current, pending, guaranteed,
-            maxCapacity, false);
+        ret =
+            new TempQueuePerPartition(curQueue.getQueueName(), current, pending,
+                guaranteed, maxCapacity, false, partitionToLookAt);
-        for (CSQueue c : root.getChildQueues()) {
-          TempQueue subq = cloneQueues(c, clusterResources);
+        for (CSQueue c : curQueue.getChildQueues()) {
+          TempQueuePerPartition subq =
+              cloneQueues(c, partitionResource, partitionToLookAt);
-              rc, clusterResources, childrensPreemptable, extra)) {
+              rc, partitionResource, childrensPreemptable, extra)) {
+    addTempQueuePartition(ret);
-  private void logToCSV(List<TempQueue> unorderedqueues){
-    List<TempQueue> queues = new ArrayList<TempQueue>(unorderedqueues);
-    Collections.sort(queues, new Comparator<TempQueue>(){
-      @Override
-      public int compare(TempQueue o1, TempQueue o2) {
-        return o1.queueName.compareTo(o2.queueName);
-      }});
+  private void logToCSV(List<String> leafQueueNames){
+    Collections.sort(leafQueueNames);
-    for (TempQueue tq : queues) {
+
+    for (String queueName : leafQueueNames) {
+      TempQueuePerPartition tq =
+          getQueueByPartition(queueName, RMNodeLabelsManager.NO_LABEL);
+  private void addTempQueuePartition(TempQueuePerPartition queuePartition) {
+    String queueName = queuePartition.queueName;
+
+    Map<String, TempQueuePerPartition> queuePartitions;
+    if (null == (queuePartitions = queueToPartitions.get(queueName))) {
+      queuePartitions = new HashMap<String, TempQueuePerPartition>();
+      queueToPartitions.put(queueName, queuePartitions);
+    }
+    queuePartitions.put(queuePartition.partition, queuePartition);
+  }
+
+  /**
+   * Get queue partition by given queueName and partitionName
+   */
+  private TempQueuePerPartition getQueueByPartition(String queueName,
+      String partition) {
+    Map<String, TempQueuePerPartition> partitionToQueues = null;
+    if (null == (partitionToQueues = queueToPartitions.get(queueName))) {
+      return null;
+    }
+    return partitionToQueues.get(partition);
+  }
+
+  /**
+   * Get all queue partitions by given queueName
+   */
+  private Collection<TempQueuePerPartition> getQueuePartitions(String queueName) {
+    if (!queueToPartitions.containsKey(queueName)) {
+      return null;
+    }
+    return queueToPartitions.get(queueName).values();
+  }
+
-   * need, current utilization. Used to clone {@link CSQueue}.
+   * need, current utilization. This is per-queue-per-partition data structure
-  static class TempQueue {
+  static class TempQueuePerPartition {
+    final String partition;
+    // For logging purpose
-    final ArrayList<TempQueue> children;
+    final ArrayList<TempQueuePerPartition> children;
-    TempQueue(String queueName, Resource current, Resource pending,
-        Resource guaranteed, Resource maxCapacity, boolean preemptionDisabled) {
+    TempQueuePerPartition(String queueName, Resource current, Resource pending,
+        Resource guaranteed, Resource maxCapacity, boolean preemptionDisabled,
+        String partition) {
-      this.children = new ArrayList<TempQueue>();
+      this.children = new ArrayList<TempQueuePerPartition>();
+      this.partition = partition;
-    public void addChild(TempQueue q) {
+    public void addChild(TempQueuePerPartition q) {
-    public void addChildren(ArrayList<TempQueue> queues) {
+    public void addChildren(ArrayList<TempQueuePerPartition> queues) {
-    public ArrayList<TempQueue> getChildren(){
+    public ArrayList<TempQueuePerPartition> getChildren(){
-      for (TempQueue sub : this.getChildren()) {
+      for (TempQueuePerPartition sub : this.getChildren()) {
-  static class TQComparator implements Comparator<TempQueue> {
+  static class TQComparator implements Comparator<TempQueuePerPartition> {
-    public int compare(TempQueue tq1, TempQueue tq2) {
+    public int compare(TempQueuePerPartition tq1, TempQueuePerPartition tq2) {
-    private double getIdealPctOfGuaranteed(TempQueue q) {
+    private double getIdealPctOfGuaranteed(TempQueuePerPartition q) {

MOV26 MOV26 MOV26 INS26 INS26 MOV31 INS40 UPD40 UPD40 UPD40 INS40 INS23 INS31 INS31 INS31 INS31 INS31 INS31 MOV23 INS74 INS83 MOV43 INS59 MOV74 MOV60 UPD74 UPD83 MOV83 INS43 UPD42 MOV42 MOV44 MOV8 INS39 INS42 INS44 INS44 INS44 INS83 INS39 INS42 INS44 INS44 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS44 UPD43 INS44 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS43 INS42 INS44 INS44 INS8 INS29 MOV83 INS74 INS42 INS44 MOV8 UPD42 INS23 UPD74 MOV43 INS43 INS74 UPD42 INS14 INS42 MOV21 INS21 INS70 UPD43 UPD74 MOV74 UPD74 UPD43 UPD74 UPD74 INS42 MOV43 UPD42 INS41 INS65 INS74 INS42 INS43 INS42 UPD42 INS74 INS42 INS25 INS25 INS41 INS74 INS42 INS43 INS42 INS43 INS42 MOV60 INS25 INS41 INS74 INS42 INS43 INS42 INS43 INS42 MOV60 MOV25 INS21 UPD74 UPD42 INS74 UPD42 MOV65 INS74 INS42 INS74 INS42 INS25 UPD42 UPD42 MOV43 INS42 UPD43 UPD42 INS21 UPD74 MOV74 UPD42 INS43 INS42 INS60 INS60 INS25 INS21 MOV65 INS42 INS43 INS42 INS43 INS42 INS60 INS25 INS41 UPD65 MOV65 INS43 INS43 INS43 INS42 INS25 INS41 INS43 INS59 INS83 UPD74 MOV74 MOV59 UPD42 INS44 UPD74 MOV74 UPD43 INS42 MOV43 UPD43 MOV43 INS43 INS74 MOV74 INS59 INS32 UPD74 INS44 INS42 INS8 UPD42 UPD74 UPD42 UPD43 UPD74 MOV74 UPD74 UPD74 UPD43 UPD74 MOV74 UPD42 UPD43 UPD74 MOV74 UPD43 INS32 UPD66 MOV66 UPD66 MOV66 INS43 INS43 MOV43 INS42 INS43 INS43 INS74 UPD43 INS32 INS8 INS43 MOV43 INS27 INS8 INS9 INS43 INS43 INS74 INS42 INS42 INS27 INS8 INS32 INS43 INS43 INS74 INS42 INS42 INS32 UPD43 UPD43 INS44 INS42 INS8 INS43 INS43 INS43 INS43 INS43 INS43 INS43 INS43 INS74 INS32 INS8 UPD42 MOV25 UPD42 UPD42 UPD66 UPD42 UPD42 UPD43 UPD42 INS32 UPD43 UPD42 INS42 INS43 INS59 INS74 INS59 INS27 INS8 INS32 UPD66 INS42 INS42 INS74 INS59 INS27 INS8 INS32 UPD66 INS42 INS42 INS42 INS38 INS8 INS32 UPD66 INS42 INS42 UPD43 INS43 INS42 INS21 UPD43 UPD74 MOV74 UPD43 UPD42 UPD43 UPD43 UPD43 UPD42 INS42 INS43 INS42 INS32 INS42 INS14 UPD42 INS42 INS42 INS42 INS40 INS21 INS70 UPD43 UPD43 UPD42 INS33 INS43 INS42 INS60 MOV21 INS21 INS25 UPD43 UPD43 UPD42 UPD42 UPD43 UPD43 UPD42 UPD43 UPD42 UPD43 UPD43 UPD43 UPD42 UPD43 UPD74 UPD42 UPD43 UPD42 INS32 INS42 INS42 INS42 INS42 INS42 INS43 INS43 UPD42 UPD42 INS42 INS42 INS42 INS42 INS41 INS42 UPD42 INS32 UPD42 INS27 INS32 INS21 INS25 INS25 INS21 INS41 INS42 INS42 INS43 INS43 INS42 INS33 INS36 INS41 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS36 INS42 INS42 INS42 UPD42 UPD42 INS43 INS42 INS25 INS60 INS60 INS70 MOV51 INS42 INS42 INS42 INS60 INS25 INS42 INS42 INS42 INS42 INS42 MOV43 MOV43 INS42 INS42 INS21 UPD42 UPD42 UPD42 UPD42 INS60 INS54 INS42 INS42 UPD42 UPD42 UPD43 UPD42 INS60 INS42 INS42 INS40 INS43 INS43 INS43 INS42 INS33 INS36 INS21 INS21 INS42 INS42 INS40 INS42 INS43 INS43 INS43 INS42 INS33 INS33 INS36 INS41 INS42 INS42 INS42 INS32 INS41 MOV32 INS42 UPD42 INS42 INS7 UPD42 UPD43 UPD42 UPD42 UPD42 UPD42 INS42 INS32 INS42 INS74 UPD42 INS32 INS44 INS42 INS8 UPD42 UPD42 INS42 INS43 INS59 INS7 UPD42 INS32 INS8 UPD42 UPD42 UPD74 UPD42 UPD74 UPD42 UPD74 UPD42 UPD74 UPD42 UPD42 UPD42 UPD42 UPD74 MOV74 UPD43 UPD43 UPD74 UPD42 UPD74 MOV74 UPD43 UPD43 INS42 INS42 INS42 INS42 INS42 UPD42 UPD42 INS9 INS42 INS32 UPD42 UPD42 UPD42 INS33 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 MOV32 INS32 INS32 INS8 MOV32 INS8 INS32 INS9 INS42 INS42 INS7 INS9 INS42 INS42 INS7 INS42 INS22 INS8 INS43 INS59 INS74 INS59 MOV44 INS32 INS8 INS42 INS8 INS39 INS59 INS42 INS8 INS32 INS43 INS43 INS59 MOV43 MOV43 INS8 INS12 UPD42 INS43 INS59 INS42 INS42 INS42 INS7 INS7 INS32 INS42 INS42 INS42 INS7 INS33 UPD42 MOV42 MOV42 INS42 INS33 UPD42 UPD42 INS42 INS22 INS42 UPD42 UPD43 INS42 INS42 INS43 INS42 INS42 INS43 INS42 INS21 INS42 INS42 INS32 INS42 MOV32 INS14 INS42 INS42 INS21 UPD43 UPD43 UPD42 UPD42 INS40 UPD43 UPD43 UPD43 UPD43 UPD43 UPD42 UPD42 UPD43 UPD74 UPD43 UPD42 UPD42 UPD43 UPD43 UPD43 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 MOV32 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS32 UPD42 UPD42 MOV42 UPD42 INS32 INS42 INS25 INS18 INS42 INS42 INS33 INS43 INS43 MOV43 INS42 INS14 UPD43 INS42 INS42 INS21 MOV25 INS60 INS70 MOV60 INS60 INS61 UPD42 UPD42 INS10 INS42 INS32 MOV21 INS42 INS42 INS27 UPD42 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS32 INS25 INS44 INS8 UPD42 UPD42 INS42 INS42 INS32 INS42 INS32 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS32 INS74 INS52 INS42 UPD42 INS42 INS42 INS32 INS42 INS40 INS42 INS74 INS42 INS32 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD43 UPD43 UPD42 UPD42 UPD42 UPD42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS32 INS8 INS42 INS42 INS74 UPD42 INS7 MOV32 INS8 INS74 INS59 INS44 INS32 INS8 MOV74 INS59 MOV32 INS8 MOV43 UPD42 MOV42 UPD42 MOV42 MOV42 UPD42 MOV42 UPD42 MOV42 INS45 INS32 INS45 INS42 UPD42 INS42 INS42 UPD42 INS42 UPD42 INS42 UPD42 INS42 UPD42 UPD42 UPD42 UPD42 INS38 INS8 INS43 INS42 MOV43 MOV43 INS42 INS42 INS40 INS42 INS42 INS42 INS74 INS42 INS42 INS42 MOV43 INS43 MOV42 MOV42 INS32 INS42 INS43 INS43 INS42 INS42 INS27 UPD42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS21 INS43 INS43 INS43 INS42 INS40 MOV60 MOV21 INS21 INS43 INS43 INS74 INS42 INS32 MOV43 INS42 INS42 INS42 INS25 INS42 INS32 MOV60 INS25 INS21 UPD42 INS42 INS42 INS32 INS21 INS42 UPD42 UPD42 INS43 INS43 INS43 INS42 INS42 INS42 INS42 MOV42 INS42 INS42 INS45 INS32 INS45 INS32 INS45 INS32 INS45 INS42 INS45 INS32 INS42 INS42 INS42 INS32 INS8 INS7 INS42 INS42 INS43 INS43 INS42 INS42 INS32 INS8 INS32 UPD42 MOV42 INS32 MOV8 INS32 MOV42 UPD42 MOV42 UPD42 INS32 INS42 INS42 INS7 MOV43 UPD42 INS32 UPD42 INS42 UPD43 INS42 UPD43 INS42 UPD43 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS27 MOV42 MOV42 MOV42 MOV42 INS42 MOV32 INS21 INS25 INS40 MOV32 INS42 INS42 INS42 INS42 INS42 MOV60 INS70 UPD42 MOV42 INS42 INS42 INS42 MOV42 MOV42 MOV42 UPD42 MOV42 MOV42 MOV42 INS42 INS42 INS32 INS42 INS42 INS32 MOV42 INS42 UPD42 UPD42 UPD42 UPD42 INS42 INS42 INS45 INS42 INS45 INS32 INS32 MOV8 INS74 MOV44 INS32 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 UPD40 MOV40 INS42 UPD42 MOV42 UPD42 MOV42 INS43 INS43 UPD42 INS42 INS42 INS60 INS25 INS42 INS42 INS42 UPD42 MOV42 UPD42 INS39 INS59 INS38 MOV8 INS42 INS32 INS42 UPD45 MOV45 INS42 UPD45 MOV45 UPD40 UPD45 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 MOV42 UPD42 MOV42 DEL74 DEL42 DEL33 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL66 DEL65 DEL42 DEL65 DEL29 DEL39 DEL31 DEL42 DEL43 DEL42 DEL59 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL43 DEL42 DEL74 DEL42 DEL42 DEL7 DEL21 DEL65 DEL42 DEL65 DEL65 DEL42 DEL32 DEL40 DEL33 DEL27 DEL42 DEL42 DEL16 DEL41 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL14 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL42 DEL42 DEL32 DEL27 DEL40 DEL34 DEL34 DEL32 DEL32 DEL40 DEL40 DEL32 DEL32 DEL25 DEL42 DEL42 DEL32 DEL32 DEL32 DEL21 DEL8 DEL61 DEL40 DEL40 DEL42 DEL40 DEL40 DEL33 DEL27 DEL27 DEL18 DEL8 DEL25 DEL8 DEL25 DEL8 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL32 DEL32 DEL32 DEL21 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL66 DEL65 DEL29 DEL83 DEL74 DEL42 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL18 DEL8 DEL25 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL32 DEL32 DEL42 DEL41 DEL42 DEL65 DEL29 DEL39 DEL42 DEL31 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL14 DEL59 DEL60 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL78 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL40 DEL42 DEL40 DEL32 DEL41 DEL8 DEL31 DEL1 DEL14 DEL32 DEL41 DEL42 DEL65 DEL66 DEL42 DEL43 DEL74