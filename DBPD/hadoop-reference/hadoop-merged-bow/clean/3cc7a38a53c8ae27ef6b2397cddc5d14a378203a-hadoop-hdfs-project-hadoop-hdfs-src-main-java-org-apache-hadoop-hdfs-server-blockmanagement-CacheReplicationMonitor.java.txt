HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68

-import java.util.ArrayList;
-import java.util.HashMap;
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.LinkedList;
-import java.util.Map.Entry;
+import java.util.Random;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hdfs.DFSConfigKeys;
+import org.apache.hadoop.fs.UnresolvedLinkException;
-import org.apache.hadoop.hdfs.server.namenode.NameNode;
-import org.apache.hadoop.hdfs.server.namenode.Namesystem;
-import org.apache.hadoop.hdfs.util.LightWeightHashSet;
+import org.apache.hadoop.hdfs.protocol.PathBasedCacheEntry;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type;
+import org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState;
+import org.apache.hadoop.hdfs.server.namenode.CacheManager;
+import org.apache.hadoop.hdfs.server.namenode.CachedBlock;
+import org.apache.hadoop.hdfs.server.namenode.FSDirectory;
+import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;
+import org.apache.hadoop.hdfs.server.namenode.INode;
+import org.apache.hadoop.hdfs.server.namenode.INodeDirectory;
+import org.apache.hadoop.hdfs.server.namenode.INodeFile;
+import org.apache.hadoop.hdfs.util.ReadOnlyList;
+import org.apache.hadoop.util.GSet;
+import org.apache.hadoop.util.Time;
- * Periodically computes new replication work. This consists of two tasks:
- * 
- * 1) Assigning blocks in the neededCacheBlocks to datanodes where they will be
- * cached. This moves them to the pendingCacheBlocks list.
- * 
- * 2) Placing caching tasks in pendingCacheBlocks that have timed out
- * back into neededCacheBlocks for reassignment.
+ * Scans the namesystem, scheduling blocks to be cached as appropriate.
+ *
+ * The CacheReplicationMonitor does a full scan when the NameNode first
+ * starts up, and at configurable intervals afterwards.
-class CacheReplicationMonitor implements Runnable {
+public class CacheReplicationMonitor extends Thread implements Closeable {
-  private static final Log blockLog = NameNode.blockStateChangeLog;
+  private final FSNamesystem namesystem;
-  private final Namesystem namesystem;
-  private final DatanodeManager datanodeManager;
-  private final CacheReplicationManager cacheReplManager;
-  private final UncacheBlocks blocksToUncache;
-  private final LightWeightHashSet<Block> neededCacheBlocks;
-  private final PendingReplicationBlocks pendingCacheBlocks;
+  private final CacheManager cacheManager;
+
+  private final GSet<CachedBlock, CachedBlock> cachedBlocks;
-   * Re-check period for computing cache replication work
+   * Pseudorandom number source
-  private final long cacheReplicationRecheckInterval;
+  private final Random random = new Random();
-  public CacheReplicationMonitor(Namesystem namesystem,
-      BlockManager blockManager, DatanodeManager datanodeManager,
-      CacheReplicationManager cacheReplManager,
-      UncacheBlocks blocksToUncache,
-      LightWeightHashSet<Block> neededCacheBlocks,
-      PendingReplicationBlocks pendingCacheBlocks,
-      Configuration conf) {
+  /**
+   * The interval at which we scan the namesystem for caching changes.
+   */
+  private final long intervalMs;
+
+  /**
+   * True if we should rescan immediately, regardless of how much time
+   * elapsed since the previous scan.
+   */
+  private boolean rescanImmediately;
+
+  /**
+   * The monotonic time at which the current scan started.
+   */
+  private long scanTimeMs;
+
+  /**
+   * Mark status of the current scan.
+   */
+  private boolean mark = false;
+
+  /**
+   * True if this monitor should terminate.
+   */
+  private boolean shutdown;
+
+  /**
+   * Cache directives found in the previous scan.
+   */
+  private int scannedDirectives;
+
+  /**
+   * Blocks found in the previous scan.
+   */
+  private long scannedBlocks;
+  
+  public CacheReplicationMonitor(FSNamesystem namesystem,
+      CacheManager cacheManager, long intervalMs) {
-    this.blockManager = blockManager;
-    this.datanodeManager = datanodeManager;
-    this.cacheReplManager = cacheReplManager;
-
-    this.blocksToUncache = blocksToUncache;
-    this.neededCacheBlocks = neededCacheBlocks;
-    this.pendingCacheBlocks = pendingCacheBlocks;
-
-    this.cacheReplicationRecheckInterval = conf.getInt(
-        DFSConfigKeys.DFS_NAMENODE_REPLICATION_INTERVAL_KEY, 
-        DFSConfigKeys.DFS_NAMENODE_REPLICATION_INTERVAL_DEFAULT) * 1000L;
+    this.blockManager = namesystem.getBlockManager();
+    this.cacheManager = cacheManager;
+    this.cachedBlocks = cacheManager.getCachedBlocks();
+    this.intervalMs = intervalMs;
-    LOG.info("CacheReplicationMonitor is starting");
-    while (namesystem.isRunning()) {
-      try {
-        computeCachingWork();
-        processPendingCachingWork();
-        Thread.sleep(cacheReplicationRecheckInterval);
-      } catch (Throwable t) {
-        if (!namesystem.isRunning()) {
-          LOG.info("Stopping CacheReplicationMonitor.");
-          if (!(t instanceof InterruptedException)) {
-            LOG.info("CacheReplicationMonitor received an exception"
-                + " while shutting down.", t);
-          }
-          break;
-        }
-        LOG.fatal("ReplicationMonitor thread received Runtime exception. ", t);
-        terminate(1, t);
-      }
-    }
-  }
-
-  /**
-   * Assigns under-cached blocks to new datanodes.
-   */
-  private void computeCachingWork() {
-    List<Block> blocksToCache = null;
-    namesystem.writeLock();
+    shutdown = false;
+    rescanImmediately = true;
+    scanTimeMs = 0;
+    LOG.info("Starting CacheReplicationMonitor with interval " +
+             intervalMs + " milliseconds");
-      synchronized (neededCacheBlocks) {
-        blocksToCache = neededCacheBlocks.pollAll();
-      }
-    } finally {
-      namesystem.writeUnlock();
-    }
-    computeCachingWorkForBlocks(blocksToCache);
-    computeUncacheWork();
-  }
-
-  private void computeCachingWorkForBlocks(List<Block> blocksToCache) {
-    int requiredRepl, effectiveRepl, additionalRepl;
-    List<DatanodeDescriptor> cachedNodes, storedNodes, targets;
-
-    final HashMap<Block, List<DatanodeDescriptor>> work =
-        new HashMap<Block, List<DatanodeDescriptor>>();
-    namesystem.writeLock();
-    try {
-      synchronized (neededCacheBlocks) {
-        for (Block block: blocksToCache) {
-          // Required number of cached replicas
-          requiredRepl = cacheReplManager.getCacheReplication(block);
-          // Replicas that are safely cached
-          cachedNodes = cacheReplManager.getSafeReplicas(
-              cacheReplManager.cachedBlocksMap, block);
-          // Replicas that are safely stored on disk
-          storedNodes = cacheReplManager.getSafeReplicas(
-              blockManager.blocksMap, block);
-          // "effective" replication factor which includes pending
-          // replication work
-          effectiveRepl = cachedNodes.size()
-              + pendingCacheBlocks.getNumReplicas(block);
-          if (effectiveRepl >= requiredRepl) {
-            neededCacheBlocks.remove(block);
-            blockLog.info("BLOCK* Removing " + block
-                + " from neededCacheBlocks as it has enough cached replicas");
-              continue;
-          }
-          // Choose some replicas to cache if needed
-          additionalRepl = requiredRepl - effectiveRepl;
-          targets = new ArrayList<DatanodeDescriptor>(storedNodes.size());
-          // Only target replicas that aren't already cached.
-          for (DatanodeDescriptor dn: storedNodes) {
-            if (!cachedNodes.contains(dn)) {
-              targets.add(dn);
+      long curTimeMs = Time.monotonicNow();
+      while (true) {
+        synchronized(this) {
+          while (true) {
+            if (shutdown) {
+              LOG.info("Shutting down CacheReplicationMonitor");
+              return;
-          }
-          if (targets.size() < additionalRepl) {
-            if (LOG.isDebugEnabled()) {
-              LOG.debug("Block " + block + " cannot be cached on additional"
-                  + " nodes because there are no more available datanodes"
-                  + " with the block on disk.");
+            if (rescanImmediately) {
+              LOG.info("Rescanning on request");
+              rescanImmediately = false;
+              break;
-          }
-          targets = CacheReplicationPolicy.chooseTargetsToCache(block, targets,
-              additionalRepl);
-          if (targets.size() < additionalRepl) {
-            if (LOG.isDebugEnabled()) {
-              LOG.debug("Block " + block + " cannot be cached on additional"
-                  + " nodes because there is not sufficient cache space on"
-                  + " available target datanodes.");
+            long delta = (scanTimeMs + intervalMs) - curTimeMs;
+            if (delta <= 0) {
+              LOG.info("Rescanning after " + (curTimeMs - scanTimeMs) +
+                  " milliseconds");
+              break;
-          }
-          // Continue if we couldn't get more cache targets
-          if (targets.size() == 0) {
-            continue;
-          }
-
-          // Update datanodes and blocks that were scheduled for caching
-          work.put(block, targets);
-          // Schedule caching on the targets
-          for (DatanodeDescriptor target: targets) {
-            target.addBlockToBeCached(block);
-          }
-          // Add block to the pending queue
-          pendingCacheBlocks.increment(block,
-              targets.toArray(new DatanodeDescriptor[] {}));
-          if (blockLog.isDebugEnabled()) {
-            blockLog.debug("BLOCK* block " + block
-                + " is moved from neededCacheBlocks to pendingCacheBlocks");
-          }
-          // Remove from needed queue if it will be fully replicated
-          if (effectiveRepl + targets.size() >= requiredRepl) {
-            neededCacheBlocks.remove(block);
+            this.wait(delta);
+            curTimeMs = Time.monotonicNow();
+        scanTimeMs = curTimeMs;
+        mark = !mark;
+        rescan();
+        curTimeMs = Time.monotonicNow();
+        LOG.info("Scanned " + scannedDirectives + " directive(s) and " +
+            scannedBlocks + " block(s) in " + (curTimeMs - scanTimeMs) + " " +
+            "millisecond(s).");
-    } finally {
-      namesystem.writeUnlock();
-    }
-
-    if (blockLog.isInfoEnabled()) {
-      // log which blocks have been scheduled for replication
-      for (Entry<Block, List<DatanodeDescriptor>> item : work.entrySet()) {
-        Block block = item.getKey();
-        List<DatanodeDescriptor> nodes = item.getValue();
-        StringBuilder targetList = new StringBuilder("datanode(s)");
-        for (DatanodeDescriptor node: nodes) {
-          targetList.append(' ');
-          targetList.append(node);
-        }
-        blockLog.info("BLOCK* ask " + targetList + " to cache " + block);
-      }
-    }
-
-    if (blockLog.isDebugEnabled()) {
-        blockLog.debug(
-          "BLOCK* neededCacheBlocks = " + neededCacheBlocks.size()
-          + " pendingCacheBlocks = " + pendingCacheBlocks.size());
+    } catch (Throwable t) {
+      LOG.fatal("Thread exiting", t);
+      terminate(1, t);
-   * Reassign pending caching work that has timed out
-   */
-  private void processPendingCachingWork() {
-    Block[] timedOutItems = pendingCacheBlocks.getTimedOutBlocks();
-    if (timedOutItems != null) {
-      namesystem.writeLock();
-      try {
-        for (int i = 0; i < timedOutItems.length; i++) {
-          Block block = timedOutItems[i];
-          final short numCached = cacheReplManager.getNumCached(block);
-          final short cacheReplication =
-              cacheReplManager.getCacheReplication(block);
-          // Needs to be cached if under-replicated
-          if (numCached < cacheReplication) {
-            synchronized (neededCacheBlocks) {
-              neededCacheBlocks.add(block);
-            }
-          }
-        }
-      } finally {
-        namesystem.writeUnlock();
-      }
-    }
-  }
-
-  /**
-   * Schedule blocks for uncaching at datanodes
-   * @return total number of block for deletion
-   */
-  int computeUncacheWork() {
-    final List<String> nodes = blocksToUncache.getStorageIDs();
-    int blockCnt = 0;
-    for (String node: nodes) {
-      blockCnt += uncachingWorkForOneNode(node);
-    }
-    return blockCnt;
-  }
-
-  /**
-   * Gets the list of blocks scheduled for uncaching at a datanode and
-   * schedules them for uncaching.
+   * Kick the monitor thread.
-   * @return number of blocks scheduled for removal
+   * If it is sleeping, it will wake up and start scanning.
+   * If it is currently scanning, it will finish the scan and immediately do 
+   * another one.
-  private int uncachingWorkForOneNode(String nodeId) {
-    final List<Block> toInvalidate;
-    final DatanodeDescriptor dn;
+  public synchronized void kick() {
+    rescanImmediately = true;
+    this.notifyAll();
+  }
+  /**
+   * Shut down and join the monitor thread.
+   */
+  @Override
+  public void close() throws IOException {
+    synchronized(this) {
+      if (shutdown) return;
+      shutdown = true;
+      this.notifyAll();
+    }
+    try {
+      if (this.isAlive()) {
+        this.join(60000);
+      }
+    } catch (InterruptedException e) {
+      Thread.currentThread().interrupt();
+    }
+  }
+
+  private void rescan() {
+    scannedDirectives = 0;
+    scannedBlocks = 0;
-      // get blocks to invalidate for the nodeId
-      assert nodeId != null;
-      dn = datanodeManager.getDatanode(nodeId);
-      if (dn == null) {
-        blocksToUncache.remove(nodeId);
-        return 0;
-      }
-      toInvalidate = blocksToUncache.invalidateWork(nodeId, dn);
-      if (toInvalidate == null) {
-        return 0;
-      }
+      rescanPathBasedCacheEntries();
-    if (blockLog.isInfoEnabled()) {
-      blockLog.info("BLOCK* " + getClass().getSimpleName()
-          + ": ask " + dn + " to uncache " + toInvalidate);
+    namesystem.writeLock();
+    try {
+      rescanCachedBlockMap();
+    } finally {
+      namesystem.writeUnlock();
-    return toInvalidate.size();
+  }
+
+  /**
+   * Scan all PathBasedCacheEntries.  Use the information to figure out
+   * what cache replication factor each block should have.
+   *
+   * @param mark       Whether the current scan is setting or clearing the mark
+   */
+  private void rescanPathBasedCacheEntries() {
+    FSDirectory fsDir = namesystem.getFSDirectory();
+    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {
+      scannedDirectives++;
+      String path = pce.getPath();
+      INode node;
+      try {
+        node = fsDir.getINode(path);
+      } catch (UnresolvedLinkException e) {
+        // We don't cache through symlinks
+        continue;
+      }
+      if (node == null)  {
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("No inode found at " + path);
+        }
+      } else if (node.isDirectory()) {
+        INodeDirectory dir = node.asDirectory();
+        ReadOnlyList<INode> children = dir.getChildrenList(null);
+        for (INode child : children) {
+          if (child.isFile()) {
+            rescanFile(pce, child.asFile());
+          }
+        }
+      } else if (node.isFile()) {
+        rescanFile(pce, node.asFile());
+      } else {
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Ignoring non-directory, non-file inode " + node +
+                    " found at " + path);
+        }
+      }
+    }
+  }
+  
+  /**
+   * Apply a PathBasedCacheEntry to a file.
+   *
+   * @param pce       The PathBasedCacheEntry to apply.
+   * @param file      The file.
+   */
+  private void rescanFile(PathBasedCacheEntry pce, INodeFile file) {
+    BlockInfo[] blockInfos = file.getBlocks();
+    for (BlockInfo blockInfo : blockInfos) {
+      if (!blockInfo.getBlockUCState().equals(BlockUCState.COMPLETE)) {
+        // We don't try to cache blocks that are under construction.
+        continue;
+      }
+      Block block = new Block(blockInfo.getBlockId());
+      CachedBlock ncblock = new CachedBlock(block.getBlockId(),
+          pce.getReplication(), mark);
+      CachedBlock ocblock = cachedBlocks.get(ncblock);
+      if (ocblock == null) {
+        cachedBlocks.put(ncblock);
+      } else {
+        if (mark != ocblock.getMark()) {
+          // Mark hasn't been set in this scan, so update replication and mark.
+          ocblock.setReplicationAndMark(pce.getReplication(), mark);
+        } else {
+          // Mark already set in this scan.  Set replication to highest value in
+          // any PathBasedCacheEntry that covers this file.
+          ocblock.setReplicationAndMark((short)Math.max(
+              pce.getReplication(), ocblock.getReplication()), mark);
+        }
+      }
+    }
+  }
+
+  /**
+   * Scan through the cached block map.
+   * Any blocks which are under-replicated should be assigned new Datanodes.
+   * Blocks that are over-replicated should be removed from Datanodes.
+   */
+  private void rescanCachedBlockMap() {
+    for (Iterator<CachedBlock> cbIter = cachedBlocks.iterator();
+        cbIter.hasNext(); ) {
+      scannedBlocks++;
+      CachedBlock cblock = cbIter.next();
+      List<DatanodeDescriptor> pendingCached =
+          cblock.getDatanodes(Type.PENDING_CACHED);
+      List<DatanodeDescriptor> cached =
+          cblock.getDatanodes(Type.CACHED);
+      List<DatanodeDescriptor> pendingUncached =
+          cblock.getDatanodes(Type.PENDING_UNCACHED);
+      // Remove nodes from PENDING_UNCACHED if they were actually uncached.
+      for (Iterator<DatanodeDescriptor> iter = pendingUncached.iterator();
+          iter.hasNext(); ) {
+        DatanodeDescriptor datanode = iter.next();
+        if (!cblock.isInList(datanode.getCached())) {
+          datanode.getPendingUncached().remove(cblock);
+          iter.remove();
+        }
+      }
+      // If the block's mark doesn't match with the mark of this scan, that
+      // means that this block couldn't be reached during this scan.  That means
+      // it doesn't need to be cached any more.
+      int neededCached = (cblock.getMark() != mark) ?
+          0 : cblock.getReplication();
+      int numCached = cached.size();
+      if (numCached >= neededCached) {
+        // If we have enough replicas, drop all pending cached.
+        for (DatanodeDescriptor datanode : pendingCached) {
+          datanode.getPendingCached().remove(cblock);
+        }
+        pendingCached.clear();
+      }
+      if (numCached < neededCached) {
+        // If we don't have enough replicas, drop all pending uncached.
+        for (DatanodeDescriptor datanode : pendingUncached) {
+          datanode.getPendingUncached().remove(cblock);
+        }
+        pendingUncached.clear();
+      }
+      int neededUncached = numCached -
+          (pendingUncached.size() + neededCached);
+      if (neededUncached > 0) {
+        addNewPendingUncached(neededUncached, cblock, cached,
+            pendingUncached);
+      } else {
+        int additionalCachedNeeded = neededCached -
+            (numCached + pendingCached.size());
+        if (additionalCachedNeeded > 0) {
+          addNewPendingCached(additionalCachedNeeded, cblock, cached,
+              pendingCached);
+        }
+      }
+      if ((neededCached == 0) &&
+          pendingUncached.isEmpty() &&
+          pendingCached.isEmpty()) {
+        // we have nothing more to do with this block.
+        cbIter.remove();
+      }
+    }
+  }
+
+  /**
+   * Add new entries to the PendingUncached list.
+   *
+   * @param neededUncached   The number of replicas that need to be uncached.
+   * @param cachedBlock      The block which needs to be uncached.
+   * @param cached           A list of DataNodes currently caching the block.
+   * @param pendingUncached  A list of DataNodes that will soon uncache the
+   *                         block.
+   */
+  private void addNewPendingUncached(int neededUncached,
+      CachedBlock cachedBlock, List<DatanodeDescriptor> cached,
+      List<DatanodeDescriptor> pendingUncached) {
+    if (!cacheManager.isActive()) {
+      return;
+    }
+    // Figure out which replicas can be uncached.
+    LinkedList<DatanodeDescriptor> possibilities =
+        new LinkedList<DatanodeDescriptor>();
+    for (DatanodeDescriptor datanode : cached) {
+      if (!pendingUncached.contains(datanode)) {
+        possibilities.add(datanode);
+      }
+    }
+    while (neededUncached > 0) {
+      if (possibilities.isEmpty()) {
+        LOG.warn("Logic error: we're trying to uncache more replicas than " +
+            "actually exist for " + cachedBlock);
+        return;
+      }
+      DatanodeDescriptor datanode =
+        possibilities.remove(random.nextInt(possibilities.size()));
+      pendingUncached.add(datanode);
+      boolean added = datanode.getPendingUncached().add(cachedBlock);
+      assert added;
+      neededUncached--;
+    }
+  }
+  
+  /**
+   * Add new entries to the PendingCached list.
+   *
+   * @param neededCached     The number of replicas that need to be cached.
+   * @param cachedBlock      The block which needs to be cached.
+   * @param cached           A list of DataNodes currently caching the block.
+   * @param pendingCached    A list of DataNodes that will soon cache the
+   *                         block.
+   */
+  private void addNewPendingCached(int neededCached,
+      CachedBlock cachedBlock, List<DatanodeDescriptor> cached,
+      List<DatanodeDescriptor> pendingCached) {
+    if (!cacheManager.isActive()) {
+      return;
+    }
+    // To figure out which replicas can be cached, we consult the
+    // blocksMap.  We don't want to try to cache a corrupt replica, though.
+    BlockInfo blockInfo = blockManager.
+          getStoredBlock(new Block(cachedBlock.getBlockId()));
+    if (blockInfo == null) {
+      LOG.debug("Not caching block " + cachedBlock + " because it " +
+          "was deleted from all DataNodes.");
+      return;
+    }
+    if (!blockInfo.isComplete()) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Not caching block " + cachedBlock + " because it " +
+            "is not yet complete.");
+      }
+      return;
+    }
+    List<DatanodeDescriptor> possibilities = new LinkedList<DatanodeDescriptor>();
+    int numReplicas = blockInfo.getCapacity();
+    Collection<DatanodeDescriptor> corrupt =
+        blockManager.getCorruptReplicas(blockInfo);
+    for (int i = 0; i < numReplicas; i++) {
+      DatanodeDescriptor datanode = blockInfo.getDatanode(i);
+      if ((datanode != null) && 
+          ((!pendingCached.contains(datanode)) &&
+          ((corrupt == null) || (!corrupt.contains(datanode))))) {
+        possibilities.add(datanode);
+      }
+    }
+    while (neededCached > 0) {
+      if (possibilities.isEmpty()) {
+        LOG.warn("We need " + neededCached + " more replica(s) than " +
+            "actually exist to provide a cache replication of " +
+            cachedBlock.getReplication() + " for " + cachedBlock);
+        return;
+      }
+      DatanodeDescriptor datanode =
+          possibilities.remove(random.nextInt(possibilities.size()));
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("AddNewPendingCached: datanode " + datanode + 
+            " will now cache block " + cachedBlock);
+      }
+      pendingCached.add(datanode);
+      boolean added = datanode.getPendingCached().add(cachedBlock);
+      assert added;
+      neededCached--;
+    }

MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 UPD40 UPD40 INS40 UPD40 UPD40 INS40 INS40 INS40 INS40 UPD40 UPD40 UPD40 INS40 INS40 INS40 INS40 UPD40 INS40 INS83 UPD43 INS43 INS23 INS23 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 UPD42 UPD42 MOV42 UPD43 UPD43 INS74 INS29 UPD43 INS29 MOV83 MOV83 INS39 INS59 INS29 INS83 INS39 INS59 INS29 INS83 INS39 MOV59 INS29 MOV83 INS39 INS59 INS29 UPD83 MOV83 INS39 INS59 INS29 INS83 INS39 MOV59 MOV83 MOV42 MOV44 MOV44 MOV44 INS8 MOV78 INS83 INS39 INS42 INS8 INS29 INS83 INS83 INS39 INS42 INS8 INS78 UPD83 UPD42 INS43 INS8 MOV83 MOV39 UPD42 MOV42 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS8 INS29 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS39 INS42 INS44 INS44 INS44 INS8 UPD66 UPD66 UPD66 UPD42 UPD42 UPD42 INS43 INS43 INS43 UPD42 INS65 UPD42 UPD42 INS14 INS65 INS42 INS65 INS42 INS65 UPD42 INS65 INS42 INS9 INS65 INS42 INS65 UPD42 UPD42 UPD43 UPD43 UPD42 INS39 INS42 MOV21 MOV21 MOV21 MOV21 MOV21 MOV21 MOV21 MOV21 MOV21 INS54 INS65 INS21 INS21 INS42 UPD42 MOV42 INS51 INS54 INS21 INS21 MOV21 INS54 MOV21 INS54 INS65 INS65 MOV60 INS70 INS65 INS65 INS65 INS43 INS42 INS43 INS42 INS60 INS70 INS65 INS24 INS65 INS65 UPD65 UPD65 INS65 INS39 INS42 INS43 INS42 MOV74 INS42 MOV74 INS42 INS25 INS60 INS70 INS61 INS65 INS65 UPD65 INS65 INS65 INS39 INS42 INS43 INS42 INS74 INS42 INS74 INS42 INS25 MOV60 INS25 MOV25 INS60 INS60 INS60 INS24 INS61 INS42 UPD42 MOV42 INS42 INS66 INS43 INS66 INS66 INS66 INS66 INS66 INS66 INS66 UPD66 UPD42 UPD42 INS8 INS12 INS66 INS66 INS66 INS66 INS7 INS32 UPD66 INS52 INS8 MOV8 INS12 INS7 INS7 INS8 MOV8 INS8 MOV8 INS66 INS66 INS42 INS66 INS43 MOV44 INS32 INS8 INS66 INS42 INS66 INS42 INS66 INS42 INS42 INS5 INS59 INS44 INS42 INS8 INS66 INS66 INS66 INS58 INS32 INS8 INS66 INS42 INS66 INS42 UPD66 INS42 UPD66 INS42 INS66 INS66 INS42 INS38 INS8 UPD74 MOV74 INS59 MOV44 INS42 INS8 INS27 INS8 UPD66 MOV66 INS42 UPD66 MOV66 INS42 UPD66 INS42 INS66 INS42 INS66 INS66 INS42 INS43 INS43 MOV43 UPD43 MOV43 INS38 INS8 INS43 INS27 INS8 INS38 INS74 INS59 INS39 INS59 INS74 INS59 MOV58 INS27 MOV37 INS8 INS27 INS8 INS42 INS32 UPD42 INS32 UPD42 INS42 INS9 INS42 INS9 INS42 INS34 INS27 INS60 INS61 MOV44 INS8 INS42 INS9 INS52 INS42 INS25 INS21 MOV21 INS25 INS44 INS8 INS42 INS34 INS42 INS34 INS21 INS21 UPD42 MOV42 UPD42 INS32 UPD43 UPD42 INS32 UPD42 MOV42 INS21 INS60 INS60 INS54 INS25 INS43 INS85 INS42 INS32 INS43 INS42 MOV25 INS60 INS60 INS60 INS25 INS74 INS59 UPD42 MOV42 UPD42 MOV42 INS21 MOV60 MOV60 INS60 INS60 INS24 INS60 INS60 INS25 INS25 MOV60 INS25 INS25 INS32 INS41 UPD43 INS42 INS14 UPD42 INS25 INS42 INS34 INS25 INS60 INS21 INS60 INS6 INS21 UPD42 MOV42 INS42 UPD42 INS32 INS41 INS42 UPD42 INS32 UPD42 MOV42 MOV33 MOV21 INS41 INS32 INS25 INS43 INS43 INS42 INS14 INS42 INS32 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS25 INS42 INS34 MOV25 INS60 INS25 INS21 INS60 INS6 INS21 INS42 INS42 UPD42 UPD42 INS42 INS42 UPD42 INS45 INS42 INS45 INS39 INS59 INS9 INS8 MOV21 MOV21 INS42 INS41 INS7 INS32 INS8 MOV43 INS42 MOV21 INS32 INS32 INS42 INS42 UPD42 UPD42 MOV42 UPD42 MOV42 INS37 MOV43 INS59 INS43 INS59 INS8 INS12 UPD27 MOV27 INS8 INS25 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS38 INS8 MOV43 INS59 INS43 INS59 INS43 INS59 INS27 MOV8 INS8 UPD43 MOV43 UPD43 MOV43 INS42 INS32 INS37 INS43 MOV74 INS59 MOV74 INS59 INS58 INS32 INS8 INS39 INS59 INS39 MOV59 UPD27 MOV27 INS8 INS27 INS8 UPD39 INS27 INS8 INS8 INS27 INS8 INS42 INS42 UPD42 INS74 INS38 INS8 INS32 INS8 INS43 INS59 INS32 INS39 INS59 INS42 INS37 INS42 INS42 INS42 INS42 INS14 INS32 INS42 INS42 INS32 INS8 INS42 INS42 INS74 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS59 INS27 INS8 INS43 INS59 INS32 INS8 INS32 INS39 INS59 INS42 INS37 INS42 INS32 INS51 INS21 INS21 INS21 INS21 MOV21 INS42 INS9 INS52 UPD42 INS52 INS42 MOV21 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 MOV21 INS44 MOV8 UPD42 INS33 INS25 INS32 INS8 INS25 INS32 INS18 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS32 INS42 INS33 MOV25 UPD42 UPD42 INS42 INS42 INS42 INS42 UPD42 UPD42 INS42 INS32 INS42 INS32 INS74 INS59 INS42 INS42 INS60 INS25 INS42 INS16 UPD42 UPD42 INS42 INS70 INS21 UPD42 MOV42 INS42 INS70 INS21 INS42 INS27 INS42 INS34 INS21 INS60 INS25 INS36 INS32 INS32 MOV21 UPD43 MOV43 UPD43 MOV43 INS32 INS21 INS42 INS42 INS21 INS41 INS42 INS42 INS32 UPD42 MOV42 INS42 UPD42 MOV42 INS42 INS32 INS42 MOV43 INS32 UPD42 MOV42 UPD42 MOV42 INS27 INS42 INS42 MOV21 INS43 INS43 INS42 INS42 INS32 INS36 INS36 MOV21 UPD42 UPD42 INS41 INS42 INS42 INS32 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS32 INS42 UPD42 MOV42 UPD42 MOV42 INS52 INS8 INS7 INS7 INS32 INS7 UPD45 INS32 INS32 INS42 INS42 UPD42 MOV42 INS43 INS42 MOV32 MOV8 INS42 INS42 INS60 INS60 MOV70 INS32 INS8 MOV8 INS32 INS42 INS40 MOV43 INS32 INS43 INS32 INS32 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS27 INS8 UPD42 UPD42 UPD42 UPD42 INS40 INS42 INS42 INS40 INS42 INS42 INS40 INS43 MOV43 UPD42 MOV42 INS32 MOV43 INS59 INS38 INS8 INS36 INS34 INS32 UPD42 UPD42 INS44 INS42 INS8 INS32 MOV44 INS42 INS8 INS32 INS42 INS36 INS32 INS39 INS59 INS27 INS8 INS27 INS42 INS42 INS42 INS42 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 INS42 INS32 INS32 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS45 INS42 INS45 INS45 INS42 INS42 UPD42 MOV42 INS42 UPD42 MOV42 INS27 INS27 INS42 UPD42 MOV42 INS32 INS32 INS32 INS42 INS42 INS61 INS42 INS42 INS42 INS38 INS42 INS42 INS32 INS52 UPD42 MOV42 INS34 INS42 UPD42 MOV42 UPD42 INS42 INS43 INS59 INS74 INS59 INS44 INS42 UPD42 MOV42 UPD42 MOV42 INS21 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 MOV42 UPD42 MOV42 INS42 UPD42 MOV42 UPD42 UPD42 INS42 UPD42 MOV42 MOV32 INS21 UPD42 MOV42 INS42 INS42 INS42 INS32 INS32 MOV21 INS21 INS27 UPD42 MOV42 UPD42 MOV42 MOV43 INS42 MOV21 INS42 INS42 UPD42 INS21 INS42 INS42 INS27 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS27 INS42 INS34 MOV21 INS42 INS34 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS32 INS42 INS42 UPD42 UPD42 INS27 INS42 INS33 INS36 INS36 UPD42 UPD42 INS42 UPD42 UPD42 INS42 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS9 INS8 INS42 INS42 INS42 INS45 INS42 UPD45 INS42 INS45 INS36 UPD45 INS45 UPD42 UPD42 UPD42 INS42 INS42 INS32 INS43 INS43 INS42 INS32 INS43 INS42 INS32 UPD42 UPD42 INS32 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS32 INS32 MOV32 INS42 INS32 INS32 INS42 INS42 INS36 INS45 INS45 INS42 INS42 INS42 INS45 INS42 INS45 INS45 INS38 INS27 UPD45 INS42 UPD45 INS45 INS32 UPD45 UPD42 INS42 MOV42 INS45 INS42 INS45 INS42 INS25 INS25 INS60 INS25 INS21 INS21 INS27 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS33 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS32 INS42 UPD42 INS42 INS11 INS42 UPD42 MOV42 INS42 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 INS32 INS42 UPD42 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS27 UPD42 UPD42 UPD42 INS42 INS42 INS32 INS36 INS36 INS42 INS42 INS42 INS8 INS42 INS8 INS39 INS59 INS27 INS8 INS32 INS7 INS42 INS42 UPD45 UPD42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS39 INS32 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 MOV42 INS32 INS42 INS42 UPD42 MOV42 INS27 INS38 MOV21 INS41 MOV21 INS21 INS10 INS42 INS27 INS42 INS34 MOV21 INS10 INS52 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS32 INS42 INS42 UPD42 MOV42 MOV33 INS32 INS7 INS36 INS42 INS42 INS42 UPD42 INS42 INS32 UPD45 UPD42 UPD45 INS42 UPD42 MOV42 INS42 UPD42 MOV42 INS42 INS42 INS42 INS42 UPD42 INS42 INS45 UPD42 INS42 INS45 INS42 INS9 INS27 INS27 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS45 INS36 INS45 INS27 INS42 INS42 DEL66 DEL66 DEL83 DEL83 DEL83 DEL43 DEL42 DEL40 DEL59 DEL23 DEL43 DEL42 DEL43 DEL42 DEL43 DEL74 DEL23 DEL42 DEL43 DEL23 DEL83 DEL42 DEL43 DEL42 DEL42 DEL42 DEL52 DEL42 DEL22 DEL42 DEL52 DEL42 DEL22 DEL42 DEL52 DEL42 DEL22 DEL42 DEL42 DEL40 DEL40 DEL32 DEL34 DEL27 DEL45 DEL45 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL8 DEL31 DEL83 DEL39 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL42 DEL42 DEL32 DEL38 DEL42 DEL62 DEL36 DEL38 DEL8 DEL25 DEL10 DEL8 DEL25 DEL8 DEL12 DEL54 DEL8 DEL61 DEL8 DEL31 DEL42 DEL42 DEL42 DEL32 DEL7 DEL42 DEL8 DEL51 DEL32 DEL43 DEL42 DEL43 DEL74 DEL42 DEL33 DEL59 DEL60 DEL54 DEL42 DEL42 DEL32 DEL21 DEL8 DEL83 DEL43 DEL42 DEL43 DEL74 DEL42 DEL43 DEL42 DEL43 DEL74 DEL14 DEL40 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL45 DEL18 DEL42 DEL42 DEL32 DEL38 DEL45 DEL45 DEL45 DEL42 DEL45 DEL45 DEL45 DEL27 DEL32 DEL21 DEL8 DEL45 DEL42 DEL45 DEL27 DEL27 DEL42 DEL27 DEL45 DEL42 DEL45 DEL42 DEL27 DEL33 DEL83 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL39 DEL42 DEL59 DEL42 DEL59 DEL42 DEL59 DEL60 DEL42 DEL59 DEL42 DEL59 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL40 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL27 DEL7 DEL21 DEL25 DEL42 DEL42 DEL42 DEL27 DEL7 DEL21 DEL42 DEL32 DEL14 DEL7 DEL21 DEL32 DEL42 DEL27 DEL25 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL32 DEL42 DEL27 DEL8 DEL25 DEL32 DEL34 DEL27 DEL25 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL70 DEL42 DEL42 DEL85 DEL5 DEL4 DEL3 DEL32 DEL32 DEL21 DEL42 DEL42 DEL32 DEL25 DEL8 DEL70 DEL8 DEL51 DEL8 DEL54 DEL42 DEL42 DEL32 DEL74 DEL42 DEL44 DEL32 DEL43 DEL42 DEL43 DEL45 DEL14 DEL59 DEL60 DEL42 DEL44 DEL42 DEL13 DEL32 DEL21 DEL32 DEL21 DEL8 DEL70 DEL8 DEL70 DEL8 DEL25 DEL32 DEL42 DEL42 DEL45 DEL45 DEL32 DEL27 DEL32 DEL21 DEL8 DEL25 DEL8 DEL31 DEL66 DEL65 DEL29 DEL83 DEL39 DEL42 DEL85 DEL5 DEL60 DEL40 DEL27 DEL42 DEL42 DEL42 DEL2 DEL59 DEL60 DEL83 DEL39 DEL42 DEL32 DEL59 DEL60 DEL42 DEL27 DEL42 DEL8 DEL51 DEL8 DEL25 DEL8 DEL24 DEL8 DEL8 DEL54 DEL8 DEL25 DEL8 DEL31 DEL39 DEL42 DEL83 DEL74 DEL42 DEL32 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL60 DEL42 DEL44 DEL42 DEL42 DEL32 DEL7 DEL21 DEL8 DEL70 DEL42 DEL41 DEL65 DEL39 DEL42 DEL43 DEL42 DEL83 DEL42 DEL42 DEL32 DEL7 DEL42 DEL33 DEL27 DEL42 DEL34 DEL42 DEL32 DEL42 DEL32 DEL42 DEL83 DEL74 DEL42 DEL59 DEL60 DEL27 DEL6 DEL42 DEL42 DEL32 DEL7 DEL21 DEL27 DEL34 DEL41 DEL8 DEL25 DEL8 DEL8 DEL54 DEL32 DEL41 DEL8