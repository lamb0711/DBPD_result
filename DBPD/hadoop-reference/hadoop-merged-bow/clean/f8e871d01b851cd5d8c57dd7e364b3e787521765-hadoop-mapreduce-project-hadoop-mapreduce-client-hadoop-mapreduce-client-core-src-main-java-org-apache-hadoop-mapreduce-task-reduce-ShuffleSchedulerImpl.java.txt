MAPREDUCE-6024. Shortened the time when Fetcher is stuck in retrying before concluding the failure by configuration. Contributed by Yunjiong Zhao.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1618677 13f79535-47bb-0310-9956-ffa450edef68

-
+  private int maxHostFailures;
+    this.maxHostFailures = job.getInt(
+        MRJobConfig.MAX_SHUFFLE_FETCH_HOST_FAILURES,
+        MRJobConfig.DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES);
+  
+  public synchronized void hostFailed(String hostname) {
+    if (hostFailures.containsKey(hostname)) {
+      IntWritable x = hostFailures.get(hostname);
+      x.set(x.get() + 1);
+    } else {
+      hostFailures.put(hostname, new IntWritable(1));
+    }
+  }
-                                      boolean readError, boolean connectExcpt) {
+      boolean readError, boolean connectExcpt) {
-    if (hostFailures.containsKey(hostname)) {
-      IntWritable x = hostFailures.get(hostname);
-      x.set(x.get() + 1);
-    } else {
-      hostFailures.put(hostname, new IntWritable(1));
-    }
+    //report failure if already retried maxHostFailures times
+    boolean hostFail = hostFailures.get(hostname).get() > getMaxHostFailures() ? true : false;
+    
-    checkAndInformJobTracker(failures, mapId, readError, connectExcpt);
+    checkAndInformJobTracker(failures, mapId, readError, connectExcpt, hostFail);
-      boolean connectExcpt) {
+      boolean connectExcpt, boolean hostFailed) {
-        || ((failures % maxFetchFailuresBeforeReporting) == 0)) {
+        || ((failures % maxFetchFailuresBeforeReporting) == 0) || hostFailed) {
+  public int getMaxHostFailures() {
+    return maxHostFailures;
+  }

INS23 INS31 INS31 INS83 INS39 INS59 INS83 INS83 INS39 INS42 INS44 INS8 INS44 INS83 INS39 INS42 INS8 INS42 INS21 INS43 INS42 MOV25 INS60 INS39 INS42 INS41 INS7 INS42 INS39 INS59 INS42 INS22 INS32 INS42 INS16 INS42 INS42 INS52 INS42 INS42 INS42 INS40 INS40 INS27 INS9 INS9 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42