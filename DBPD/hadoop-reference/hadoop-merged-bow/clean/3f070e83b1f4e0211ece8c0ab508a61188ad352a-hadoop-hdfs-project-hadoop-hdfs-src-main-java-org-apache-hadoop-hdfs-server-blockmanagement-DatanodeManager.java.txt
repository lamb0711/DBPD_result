HDFS-5009. Include storage information in the LocatedBlock.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1519691 13f79535-47bb-0310-9956-ffa450edef68

-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
-import org.apache.hadoop.hdfs.server.protocol.*;
+import org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand;
+import org.apache.hadoop.hdfs.server.protocol.BlockCommand;
+import org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeCommand;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeStorage;
+import org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException;
+import org.apache.hadoop.hdfs.server.protocol.RegisterCommand;
-import org.apache.hadoop.io.IOUtils;
+  public DatanodeStorageInfo[] getDatanodeStorageInfos(
+      DatanodeID[] datanodeID, String[] storageIDs)
+          throws UnregisteredNodeException {
+    if (datanodeID.length == 0) {
+      return null;
+    }
+    final DatanodeStorageInfo[] storages = new DatanodeStorageInfo[datanodeID.length];
+    for(int i = 0; i < datanodeID.length; i++) {
+      final DatanodeDescriptor dd = getDatanode(datanodeID[i]);
+      storages[i] = dd.getStorageInfo(storageIDs[i]);
+    }
+    return storages; 
+  }
+
-            DatanodeDescriptor[] expectedLocations = b.getExpectedLocations();
+            final DatanodeStorageInfo[] storages = b.getExpectedStorageLocations();
-            List<DatanodeDescriptor> recoveryLocations =
-                new ArrayList<DatanodeDescriptor>(expectedLocations.length);
-            for (int i = 0; i < expectedLocations.length; i++) {
-              if (!expectedLocations[i].isStale(this.staleInterval)) {
-                recoveryLocations.add(expectedLocations[i]);
+            final List<DatanodeStorageInfo> recoveryLocations =
+                new ArrayList<DatanodeStorageInfo>(storages.length);
+            for (int i = 0; i < storages.length; i++) {
+              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {
+                recoveryLocations.add(storages[i]);
-              if (recoveryLocations.size() != expectedLocations.length) {
+              if (recoveryLocations.size() != storages.length) {
-                    (expectedLocations.length - recoveryLocations.size()));
+                    (storages.length - recoveryLocations.size()));
-                  recoveryLocations.toArray(new DatanodeDescriptor[recoveryLocations.size()]),
+                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations),
-                  expectedLocations,
+                  DatanodeStorageInfo.toDatanodeInfos(storages),

MOV26 MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 UPD40 INS40 INS40 INS31 INS83 INS5 INS42 INS44 INS44 INS43 INS8 INS43 INS85 INS5 INS42 INS5 INS42 INS42 INS25 INS60 INS24 INS41 INS42 INS43 INS85 INS43 INS85 INS27 INS8 INS83 INS5 INS59 INS58 INS27 INS37 INS8 INS42 INS42 INS42 INS40 INS34 INS41 INS43 INS85 INS42 INS3 INS39 INS59 INS42 INS40 INS42 INS60 INS21 INS33 INS42 INS5 INS40 INS42 INS34 INS83 MOV43 INS59 INS7 INS43 INS85 INS42 INS32 INS2 INS32 INS42 INS42 INS2 INS42 INS42 INS42 INS42 INS2 INS42 INS42 INS42 INS42 MOV8 INS83 UPD5 INS83 UPD74 UPD43 UPD42 INS43 UPD40 INS25 UPD42 UPD42 INS42 UPD74 UPD40 MOV27 INS8 UPD43 UPD40 INS21 UPD42 INS32 INS42 INS32 INS32 MOV2 INS42 INS42 INS42 INS27 INS42 INS42 INS42 UPD42 UPD42 INS42 UPD42 UPD42 INS45 INS36 INS27 INS40 MOV32 DEL52 DEL42 DEL22 DEL42 DEL42 DEL42 DEL45 DEL40 DEL42 DEL42 DEL32 DEL27 DEL36 DEL27 DEL32 DEL21 DEL8 DEL25 DEL42 DEL43 DEL85 DEL5 DEL3