HDDS-726. Ozone Client should update SCM to move the container out of allocation path in case a write transaction fails. Contributed by Shashikant Banerjee.

-import com.google.common.base.Preconditions;
+import org.apache.hadoop.hdds.protocol.DatanodeDetails;
+import java.util.stream.Collectors;
-  private final ConcurrentHashMap<String, Long> commitInfoMap;
+  private final ConcurrentHashMap<UUID, Long> commitInfoMap;
-          .put(proto.getServer().getAddress(), proto.getCommitIndex()));
+          .put(RatisHelper.toDatanodeId(proto.getServer()),
+              proto.getCommitIndex()));
-          .computeIfPresent(proto.getServer().getAddress(),
+          .computeIfPresent(RatisHelper.toDatanodeId(proto.getServer()),
+  private void addDatanodetoReply(UUID address, XceiverClientReply reply) {
+    DatanodeDetails.Builder builder = DatanodeDetails.newBuilder();
+    builder.setUuid(address.toString());
+    reply.addDatanode(builder.build());
+  }
+
-  public long watchForCommit(long index, long timeout)
+  public XceiverClientReply watchForCommit(long index, long timeout)
+    XceiverClientReply clientReply = new XceiverClientReply(null);
-      return commitIndex;
+      clientReply.setLogIndex(commitIndex);
+      return clientReply;
-      watchClient =
-          RatisHelper.newRaftClient(rpcType, getPipeline(), retryPolicy,
+      watchClient = RatisHelper
+          .newRaftClient(rpcType, getPipeline(), retryPolicy,
-      Optional<RaftProtos.CommitInfoProto>
-          proto = reply.getCommitInfos().stream().min(Comparator.comparing(
-          RaftProtos.CommitInfoProto :: getCommitIndex));
-      Preconditions.checkState(proto.isPresent());
-      String address = proto.get().getServer().getAddress();
-      // since 3 way commit has failed, the updated map from now on  will
-      // only store entries for those datanodes which have had successful
-      // replication.
-      commitInfoMap.remove(address);
-      LOG.info(
-          "Could not commit " + index + " to all the nodes. Server " + address
-              + " has failed." + " Committed by majority.");
+      List<RaftProtos.CommitInfoProto> commitInfoProtoList =
+          reply.getCommitInfos().stream()
+              .filter(i -> i.getCommitIndex() < index)
+              .collect(Collectors.toList());
+      commitInfoProtoList.parallelStream().forEach(proto -> {
+        UUID address = RatisHelper.toDatanodeId(proto.getServer());
+        addDatanodetoReply(address, clientReply);
+        // since 3 way commit has failed, the updated map from now on  will
+        // only store entries for those datanodes which have had successful
+        // replication.
+        commitInfoMap.remove(address);
+        LOG.info(
+            "Could not commit " + index + " to all the nodes. Server " + address
+                + " has failed." + " Committed by majority.");
+      });
-    return index;
+    clientReply.setLogIndex(index);
+    return clientReply;
+                  // in case of raft retry failure, the raft client is
+                  // not able to connect to the leader hence the pipeline
+                  // can not be used but this instance of RaftClient will close
+                  // and refreshed again. In case the client cannot connect to
+                   // leader, getClient call will fail.
+
+                  // No need to set the failed Server ID here. Ozone client
+                  // will directly exclude this pipeline in next allocate block
+                  // to SCM as in this case, it is the raft client which is not
+                  // able to connect to leader in the pipeline, though the
+                  // pipeline can still be functional.
+                UUID serverId = RatisHelper.toDatanodeId(reply.getReplierId());
-                  asyncReply.setLogIndex(reply.getLogIndex());
-                  asyncReply.setDatanode(
-                      RatisHelper.toDatanodeId(reply.getReplierId()));
+                asyncReply.setLogIndex(reply.getLogIndex());
+                addDatanodetoReply(serverId, asyncReply);

MOV26 INS26 INS40 UPD40 INS31 UPD74 INS83 INS39 INS42 INS44 INS44 INS8 INS43 UPD43 INS43 INS42 INS43 INS42 INS60 INS21 INS21 INS42 INS60 INS21 INS41 UPD42 INS42 INS42 INS43 INS59 INS32 INS32 INS43 INS59 INS32 INS42 INS40 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS14 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS33 INS32 UPD42 INS21 INS42 INS42 INS42 INS42 UPD74 INS32 UPD43 UPD42 INS32 INS42 INS86 MOV32 MOV32 UPD42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 INS59 INS8 UPD42 INS42 UPD42 INS42 MOV32 UPD42 INS86 INS42 INS42 INS42 MOV60 INS21 MOV21 MOV21 INS60 MOV21 INS21 INS59 INS27 UPD43 INS32 INS43 INS59 INS32 INS42 INS32 INS42 UPD42 INS42 INS42 INS42 INS42 INS42 MOV32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV42 DEL39 DEL42 DEL42 DEL40 DEL42 DEL90 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL32 DEL21 DEL42 DEL41 DEL42 DEL42 DEL32 DEL21