svn merge --reintegrate https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535 back to trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1574259 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos.DiscardSegmentsRequestProto;
+import org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos.DiscardSegmentsResponseProto;
+import org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType;
+import org.apache.hadoop.hdfs.server.common.StorageInfo;
+    StorageInfo si = PBHelper.convert(request.getSInfo(), NodeType.JOURNAL_NODE);
-      impl.doUpgrade(convert(request.getJid()),
-          PBHelper.convert(request.getSInfo()));
+      impl.doUpgrade(convert(request.getJid()), si);
-      Boolean result = impl.canRollBack(convert(request.getJid()),
-          PBHelper.convert(request.getStorage()),
-          PBHelper.convert(request.getPrevStorage()),
+      StorageInfo si = PBHelper.convert(request.getStorage(), NodeType.JOURNAL_NODE);
+      Boolean result = impl.canRollBack(convert(request.getJid()), si,
+          PBHelper.convert(request.getPrevStorage(), NodeType.JOURNAL_NODE),
+  public DiscardSegmentsResponseProto discardSegments(
+      RpcController controller, DiscardSegmentsRequestProto request)
+      throws ServiceException {
+    try {
+      impl.discardSegments(convert(request.getJid()), request.getStartTxId());
+      return DiscardSegmentsResponseProto.getDefaultInstance();
+    } catch (IOException e) {
+      throw new ServiceException(e);
+    }
+  }
+
+  @Override

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS31 INS78 INS83 INS43 INS42 INS44 INS44 INS43 INS8 INS60 INS42 INS42 INS43 INS42 INS43 INS42 INS42 INS54 INS43 INS59 INS42 INS42 INS8 INS12 INS42 INS42 MOV32 INS60 INS21 INS41 INS44 INS8 INS40 INS43 INS59 INS32 INS32 INS43 INS42 INS53 INS42 INS42 INS42 MOV32 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS14 INS40 INS42 INS42 INS32 INS42 INS42 INS43 INS42 INS40 INS42 INS42 INS42