HDFS-12443. Ozone: Improve SCM block deletion throttling algorithm. Contributed by Yiqun Lin.

-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Preconditions;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.ozone.protocol.proto.OzoneProtos.NodeState;
-import org.apache.hadoop.scm.container.common.helpers.ContainerInfo;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_BLOCK_DELETING_CONTAINER_LIMIT_PER_INTERVAL;
+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_BLOCK_DELETING_CONTAINER_LIMIT_PER_INTERVAL_DEFAULT;
+
-import java.util.Collections;
-import java.util.Map;
-import java.util.Set;
-import java.util.stream.Collectors;
-  private static final Logger LOG =
+  static final Logger LOG =
-  // Default container size is 5G and block size is 256MB, a full container
-  // at most contains 20 blocks. At most each TX contains 20 blocks.
-  // When SCM sends block deletion TXs to datanode, each command we allow
-  // at most 50 containers so that will limit number of to be deleted blocks
-  // less than 1000.
-  // TODO - a better throttle algorithm
-  // Note, this is not an accurate limit of blocks. When we scan
-  // the log, worst case we may get 50 TX for 50 different datanodes,
-  // that will cause the deletion message sent by SCM extremely small.
-  // As a result, the deletion will be slow. An improvement is to scan
-  // log multiple times until we get enough TXs for each datanode, or
-  // the entire log is scanned.
-  private static final int BLOCK_DELETE_TX_PER_REQUEST_LIMIT = 50;
+  // Block delete limit size is dynamically calculated based on container
+  // delete limit size (ozone.block.deleting.container.limit.per.interval)
+  // that configured for datanode. To ensure DN not wait for
+  // delete commands, we use this value multiply by a factor 2 as the final
+  // limit TX size for each node.
+  // Currently we implement a throttle algorithm that throttling delete blocks
+  // for each datanode. Each node is limited by the calculation size. Firstly
+  // current node info is fetched from nodemanager, then scan entire delLog
+  // from the beginning to end. If one node reaches maximum value, its records
+  // will be skipped. If not, keep scanning until it reaches maximum value.
+  // Once all node are full, the scan behavior will stop.
+  private int blockDeleteLimitSize;
-      int interval, long serviceTimeout) {
+      int interval, long serviceTimeout, Configuration conf) {
+
+    int containerLimit = conf.getInt(
+        OZONE_BLOCK_DELETING_CONTAINER_LIMIT_PER_INTERVAL,
+        OZONE_BLOCK_DELETING_CONTAINER_LIMIT_PER_INTERVAL_DEFAULT);
+    Preconditions.checkArgument(containerLimit > 0,
+        "Container limit size should be " + "positive.");
+    // Use container limit value multiply by a factor 2 to ensure DN
+    // not wait for orders.
+    this.blockDeleteLimitSize = containerLimit * 2;
-      DatanodeDeletedBlockTransactions transactions =
-          getToDeleteContainerBlocks();
+      DatanodeDeletedBlockTransactions transactions = null;
+      List<DatanodeID> datanodes = nodeManager.getNodes(NodeState.HEALTHY);
+      if (datanodes != null) {
+        transactions = new DatanodeDeletedBlockTransactions(mappingService,
+            blockDeleteLimitSize, datanodes.size());
+        try {
+          deletedBlockLog.getTransactions(transactions);
+        } catch (IOException e) {
+          // We may tolerant a number of failures for sometime
+          // but if it continues to fail, at some point we need to raise
+          // an exception and probably fail the SCM ? At present, it simply
+          // continues to retry the scanning.
+          LOG.error("Failed to get block deletion transactions from delTX log",
+              e);
+        }
+        LOG.debug("Scanned deleted blocks log and got {} delTX to process.",
+            transactions.getTXNum());
+      }
+
-          dnTxCount += dnTXs.size();
-          // TODO commandQueue needs a cap.
-          // We should stop caching new commands if num of un-processed
-          // command is bigger than a limit, e.g 50. In case datanode goes
-          // offline for sometime, the cached commands be flooded.
-          nodeManager.addDatanodeCommand(datanodeID,
-              new DeleteBlocksCommand(dnTXs));
-          LOG.debug(
-              "Added delete block command for datanode {} in the queue,"
-                  + " number of delete block transactions: {}, TxID list: {}",
-              datanodeID, dnTXs.size(),
-              String.join(",", transactions.getTransactionIDList(datanodeID)));
+          if (dnTXs != null && !dnTXs.isEmpty()) {
+            dnTxCount += dnTXs.size();
+            // TODO commandQueue needs a cap.
+            // We should stop caching new commands if num of un-processed
+            // command is bigger than a limit, e.g 50. In case datanode goes
+            // offline for sometime, the cached commands be flooded.
+            nodeManager.addDatanodeCommand(datanodeID,
+                new DeleteBlocksCommand(dnTXs));
+            LOG.debug(
+                "Added delete block command for datanode {} in the queue,"
+                    + " number of delete block transactions: {}, TxID list: {}",
+                datanodeID, dnTXs.size(), String.join(",",
+                    transactions.getTransactionIDList(datanodeID)));
+          }
-        LOG.info("Totally added {} delete blocks command for"
-            + " {} datanodes, task elapsed time: {}ms",
+        LOG.info(
+            "Totally added {} delete blocks command for"
+                + " {} datanodes, task elapsed time: {}ms",
-
-    // Scan deleteBlocks.db to get a number of to-delete blocks.
-    // this is going to be properly throttled.
-    private DatanodeDeletedBlockTransactions getToDeleteContainerBlocks() {
-      DatanodeDeletedBlockTransactions dnTXs =
-          new DatanodeDeletedBlockTransactions();
-      List<DeletedBlocksTransaction> txs = null;
-      try {
-        // Get a limited number of TXs to send via HB at a time.
-        txs = deletedBlockLog
-            .getTransactions(BLOCK_DELETE_TX_PER_REQUEST_LIMIT);
-        LOG.debug("Scanned deleted blocks log and got {} delTX to process",
-            txs.size());
-      } catch (IOException e) {
-        // We may tolerant a number of failures for sometime
-        // but if it continues to fail, at some point we need to raise
-        // an exception and probably fail the SCM ? At present, it simply
-        // continues to retry the scanning.
-        LOG.error("Failed to get block deletion transactions from delTX log",
-            e);
-      }
-
-      if (txs != null) {
-        for (DeletedBlocksTransaction tx : txs) {
-          try {
-            ContainerInfo info = mappingService
-                .getContainer(tx.getContainerName());
-            // Find out the datanode where this TX is supposed to send to.
-            info.getPipeline().getMachines()
-                .forEach(entry -> dnTXs.addTransaction(entry, tx));
-          } catch (IOException e) {
-            LOG.warn("Container {} not found, continue to process next",
-                tx.getContainerName(), e);
-          }
-        }
-      }
-      return dnTXs;
-    }
-  /**
-   * A wrapper class to hold info about datanode and all deleted block
-   * transactions that will be sent to this datanode.
-   */
-  private static class DatanodeDeletedBlockTransactions {
-
-    // A list of TXs mapped to a certain datanode ID.
-    private final Map<DatanodeID, List<DeletedBlocksTransaction>> transactions;
-
-    DatanodeDeletedBlockTransactions() {
-      this.transactions = Maps.newHashMap();
-    }
-
-    void addTransaction(DatanodeID dnID, DeletedBlocksTransaction tx) {
-      if (transactions.containsKey(dnID)) {
-        transactions.get(dnID).add(tx);
-      } else {
-        List<DeletedBlocksTransaction> first = Lists.newArrayList();
-        first.add(tx);
-        transactions.put(dnID, first);
-      }
-      LOG.debug("Transaction added: {} <- TX({})", dnID, tx.getTxID());
-    }
-
-    Set<DatanodeID> getDatanodes() {
-      return transactions.keySet();
-    }
-
-    boolean isEmpty() {
-      return transactions.isEmpty();
-    }
-
-    boolean hasTransactions(DatanodeID dnID) {
-      return transactions.containsKey(dnID) &&
-          !transactions.get(dnID).isEmpty();
-    }
-
-    List<DeletedBlocksTransaction> getDatanodeTransactions(DatanodeID dnID) {
-      return transactions.get(dnID);
-    }
-
-    List<String> getTransactionIDList(DatanodeID dnID) {
-      if (hasTransactions(dnID)) {
-        return transactions.get(dnID).stream()
-            .map(DeletedBlocksTransaction::getTxID)
-            .map(String::valueOf)
-            .collect(Collectors.toList());
-      } else {
-        return Collections.emptyList();
-      }
-    }
+  @VisibleForTesting
+  public void setBlockDeleteTXNum(int numTXs) {
+    blockDeleteLimitSize = numTXs;

MOV26 MOV26 MOV26 MOV26 UPD40 UPD40 UPD40 UPD40 UPD40 UPD40 INS31 INS44 INS78 INS83 MOV39 UPD42 MOV42 MOV44 INS8 UPD42 INS43 INS42 INS60 INS21 INS21 INS42 INS39 INS42 MOV21 INS42 INS39 INS59 INS32 INS7 INS60 INS25 INS7 INS42 INS32 INS42 INS42 INS27 INS27 INS22 INS27 MOV43 INS59 INS74 INS27 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 INS45 INS45 INS52 INS42 INS42 INS34 INS42 INS33 MOV43 MOV43 UPD42 INS42 INS33 INS21 INS54 INS21 INS42 UPD42 INS40 INS7 INS8 MOV12 INS32 INS42 INS14 INS21 INS42 INS42 INS45 INS32 INS25 MOV43 INS42 INS42 INS32 INS32 INS42 INS42 INS27 INS8 INS42 INS42 INS42 INS42 INS42 INS27 INS38 MOV21 MOV21 MOV21 INS42 INS33 INS32 INS42 INS42 DEL40 DEL26 DEL83 DEL83 DEL83 DEL34 DEL83 DEL42 DEL43 DEL42 DEL42 DEL42 DEL43 DEL14 DEL59 DEL60 DEL42 DEL43 DEL74 DEL42 DEL33 DEL59 DEL60 DEL42 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL45 DEL42 DEL42 DEL32 DEL32 DEL21 DEL8 DEL54 DEL42 DEL33 DEL27 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL59 DEL42 DEL42 DEL42 DEL42 DEL32 DEL86 DEL32 DEL21 DEL8 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL45 DEL42 DEL42 DEL32 DEL42 DEL32 DEL21 DEL8 DEL12 DEL54 DEL8 DEL70 DEL8 DEL25 DEL42 DEL41 DEL8 DEL31 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL66 DEL66 DEL65 DEL29 DEL83 DEL83 DEL42 DEL83 DEL83 DEL42 DEL43 DEL42 DEL43 DEL42 DEL43 DEL74 DEL74 DEL42 DEL59 DEL23 DEL42 DEL52 DEL42 DEL22 DEL42 DEL42 DEL32 DEL7 DEL21 DEL8 DEL31 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL32 DEL8 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL42 DEL42 DEL45 DEL42 DEL42 DEL42 DEL32 DEL32 DEL21 DEL8 DEL31 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL42 DEL32 DEL41 DEL8 DEL31 DEL39 DEL42 DEL42 DEL42 DEL32 DEL41 DEL8 DEL31 DEL39 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL38 DEL27 DEL41 DEL8 DEL31 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL32 DEL41 DEL8 DEL31 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL42 DEL90 DEL32 DEL42 DEL42 DEL42 DEL90 DEL32 DEL42 DEL42 DEL42 DEL32 DEL32 DEL41 DEL8 DEL42 DEL42 DEL32 DEL41 DEL8 DEL25 DEL8 DEL31 DEL55