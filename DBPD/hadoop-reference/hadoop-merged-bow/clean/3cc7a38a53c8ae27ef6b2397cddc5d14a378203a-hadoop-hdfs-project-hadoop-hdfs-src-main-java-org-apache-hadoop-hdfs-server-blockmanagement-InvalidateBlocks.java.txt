HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68

+import java.io.PrintWriter;
-abstract class InvalidateBlocks {
+class InvalidateBlocks {
+  private final DatanodeManager datanodeManager;
+
+  InvalidateBlocks(final DatanodeManager datanodeManager) {
+    this.datanodeManager = datanodeManager;
+  }
+
-  synchronized int numStorages() {
-    return node2blocks.size();
-  }
-
-  /**
-   * Polls up to <i>limit</i> blocks from the list of to-be-invalidated Blocks
-   * for a storage.
-   */
-  synchronized List<Block> pollNumBlocks(final String storageId, final int limit) {
-    final LightWeightHashSet<Block> set = node2blocks.get(storageId);
-    if (set == null) {
-      return null;
+  /** Print the contents to out. */
+  synchronized void dump(final PrintWriter out) {
+    final int size = node2blocks.values().size();
+    out.println("Metasave: Blocks " + numBlocks 
+        + " waiting deletion from " + size + " datanodes.");
+    if (size == 0) {
+      return;
-    List<Block> polledBlocks = set.pollN(limit);
-    // Remove the storage if the set is now empty
-    if (set.isEmpty()) {
-      remove(storageId);
+
+    for(Map.Entry<String,LightWeightHashSet<Block>> entry : node2blocks.entrySet()) {
+      final LightWeightHashSet<Block> blocks = entry.getValue();
+      if (blocks.size() > 0) {
+        out.println(datanodeManager.getDatanode(entry.getKey()));
+        out.println(blocks);
+      }
-    numBlocks -= polledBlocks.size();
-    return polledBlocks;
-  /**
-   * Return the set of to-be-invalidated blocks for a storage.
-   */
-  synchronized LightWeightHashSet<Block> getBlocks(String storageId) {
-    return node2blocks.get(storageId);
-  }
+  synchronized List<Block> invalidateWork(
+      final String storageId, final DatanodeDescriptor dn) {
+    final LightWeightHashSet<Block> set = node2blocks.get(storageId);
+    if (set == null) {
+      return null;
+    }
-  /**
-   * Schedules invalidation work associated with a storage at the corresponding
-   * datanode.
-   * @param storageId Storage of blocks to be invalidated
-   * @param dn Datanode where invalidation work will be scheduled
-   * @return List of blocks scheduled for invalidation at the datanode
-   */
-  abstract List<Block> invalidateWork(final String storageId,
-      final DatanodeDescriptor dn);
+    // # blocks that can be sent in one message is limited
+    final int limit = datanodeManager.blockInvalidateLimit;
+    final List<Block> toInvalidate = set.pollN(limit);
+
+    // If we send everything in this message, remove this node entry
+    if (set.isEmpty()) {
+      remove(storageId);
+    }
+
+    dn.addBlocksToBeInvalidated(toInvalidate);
+    numBlocks -= toInvalidate.size();
+    return toInvalidate;
+  }

INS26 MOV31 MOV31 INS40 INS42 INS23 INS31 INS83 INS83 INS43 INS59 INS42 INS44 MOV29 MOV83 INS39 UPD42 MOV42 MOV44 INS8 UPD42 MOV44 INS42 INS42 INS83 INS43 INS42 INS21 INS83 INS43 INS42 INS60 INS21 INS25 INS70 INS60 INS21 INS42 INS7 UPD66 INS42 INS83 INS39 INS59 INS32 INS27 INS8 INS44 INS32 INS8 INS83 INS39 INS59 INS83 INS32 UPD42 INS22 INS42 INS42 INS32 INS42 INS42 INS27 INS42 INS34 INS41 INS74 INS42 INS42 INS42 INS60 INS25 INS42 INS40 UPD42 INS42 INS42 INS42 INS52 INS42 INS32 UPD42 MOV42 INS45 INS42 INS45 INS42 INS45 INS43 MOV43 MOV74 INS83 INS74 INS59 INS27 INS8 UPD42 MOV42 UPD42 MOV42 INS40 UPD43 MOV43 MOV43 INS42 INS32 INS32 INS34 INS21 INS21 UPD42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 DEL83 DEL42 DEL83 DEL39 DEL42 DEL42 DEL42 DEL32 DEL41 DEL42 DEL66 DEL66 DEL65 DEL29 DEL39 DEL42 DEL32 DEL41 DEL8 DEL31 DEL66 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL66 DEL65 DEL66 DEL65 DEL29 DEL83 DEL74 DEL42 DEL83 DEL42 DEL43 DEL42 DEL44 DEL31