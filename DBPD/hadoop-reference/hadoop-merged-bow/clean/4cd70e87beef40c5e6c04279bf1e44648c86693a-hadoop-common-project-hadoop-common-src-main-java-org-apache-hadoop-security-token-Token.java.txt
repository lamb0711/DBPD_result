Merge trunk into auto-HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3042@1337645 13f79535-47bb-0310-9956-ffa450edef68

+import com.google.common.collect.Maps;
+
+import java.io.ByteArrayInputStream;
+import java.io.DataInputStream;
+import java.util.Map;
+import org.apache.hadoop.util.ReflectionUtils;
+  
+  private static Map<Text, Class<? extends TokenIdentifier>> tokenKindMap;
+  
-   * Get the token identifier
-   * @return the token identifier
+   * Get the token identifier's byte representation
+   * @return the token identifier's byte representation
+  private static synchronized Class<? extends TokenIdentifier>
+      getClassForIdentifier(Text kind) {
+    if (tokenKindMap == null) {
+      tokenKindMap = Maps.newHashMap();
+      for (TokenIdentifier id : ServiceLoader.load(TokenIdentifier.class)) {
+        tokenKindMap.put(id.getKind(), id.getClass());
+      }
+    }
+    Class<? extends TokenIdentifier> cls = tokenKindMap.get(kind);
+    if (cls == null) {
+      LOG.warn("Cannot find class for token kind " + kind);
+       return null;
+    }
+    return cls;
+  }
+  
+  /**
+   * Get the token identifier object, or null if it could not be constructed
+   * (because the class could not be loaded, for example).
+   * @return the token identifier, or null
+   * @throws IOException 
+   */
+  @SuppressWarnings("unchecked")
+  public T decodeIdentifier() throws IOException {
+    Class<? extends TokenIdentifier> cls = getClassForIdentifier(getKind());
+    if (cls == null) {
+      return null;
+    }
+    TokenIdentifier tokenIdentifier = ReflectionUtils.newInstance(cls, null);
+    ByteArrayInputStream buf = new ByteArrayInputStream(identifier);
+    DataInputStream in = new DataInputStream(buf);  
+    tokenIdentifier.readFields(in);
+    in.close();
+    return (T) tokenIdentifier;
+  }
+  
+  
+  private void identifierToString(StringBuilder buffer) {
+    T id = null;
+    try {
+      id = decodeIdentifier();
+    } catch (IOException e) {
+      // handle in the finally block
+    } finally {
+      if (id != null) {
+        buffer.append("(").append(id).append(")");
+      } else {
+        addBinaryBuffer(buffer, identifier);
+      }
+    }
+  }
-    buffer.append("Ident: ");
-    addBinaryBuffer(buffer, identifier);
-    buffer.append(", Kind: ");
+    buffer.append("Kind: ");
+    buffer.append(", Ident: ");
+    identifierToString(buffer);

INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS23 INS31 INS31 INS31 INS83 INS83 INS74 INS59 INS83 INS83 INS83 INS74 INS42 INS44 INS8 INS29 INS79 INS83 INS43 INS42 INS43 INS8 INS83 INS39 INS42 INS44 INS8 MOV21 INS43 INS43 INS74 INS42 INS43 INS76 INS43 INS42 INS25 INS60 INS25 INS41 INS65 INS65 INS65 INS42 INS45 INS42 INS42 INS60 INS25 INS60 INS60 INS60 INS21 INS21 INS41 INS43 INS42 INS60 INS54 INS21 INS42 INS42 INS43 INS76 UPD66 UPD66 INS42 INS43 INS42 INS27 INS8 INS74 INS59 INS27 INS8 INS42 INS66 INS66 INS66 INS42 INS66 INS74 INS59 INS27 INS8 INS43 INS59 INS43 INS59 INS43 INS59 INS32 INS32 INS11 INS42 INS43 INS59 INS8 INS12 INS8 INS32 INS42 INS43 INS42 INS42 INS33 INS21 INS70 INS43 INS76 INS42 INS32 INS42 INS33 INS21 INS41 INS43 INS76 INS42 INS32 INS42 INS33 INS41 INS42 INS42 INS32 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS42 INS42 INS33 INS21 INS44 INS8 INS25 UPD45 UPD45 INS42 INS42 INS42 INS7 INS44 INS32 INS8 INS42 INS43 INS42 INS42 INS42 INS32 INS33 INS42 INS43 INS42 INS32 INS33 INS42 INS42 INS42 INS33 INS43 INS42 INS43 INS42 INS42 INS7 INS43 INS42 INS27 INS8 INS8 INS42 INS32 INS43 INS42 INS42 INS42 INS57 INS21 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS33 INS21 MOV21 INS42 INS42 INS42 INS43 INS32 INS45 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS32 INS32 INS42 INS45 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS45