MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1292736 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.mapreduce.JobID;
+import org.apache.hadoop.mapreduce.JobStatus;
+import java.util.HashSet;
+import java.util.Set;
+   * Represents a list of blacklisted jobs. Jobs are blacklisted when either 
+   * they are complete or their status cannot be obtained. Stress mode will 
+   * ignore blacklisted jobs from its overload computation.
+   */
+  private Set<JobID> blacklistedJobs = new HashSet<JobID>();
+  
+  /**
+          LOG.warn("[STRESS] Interrupted before start!. Exiting..");
+              // update the overload status
-                LOG.debug("Cluster overloaded in run! Sleeping...");
+                LOG.debug("Updating the overload status.");
-              // sleep 
-                Thread.sleep(1000);
-              } catch (InterruptedException ie) {
+                checkLoadAndGetSlotsToBackfill();
+              } catch (IOException ioe) {
+                LOG.warn("[STRESS] Check failed!", ioe);
+              
+              // if the cluster is still overloaded, then sleep
+              if (loadStatus.overloaded()) {
+                if (LOG.isDebugEnabled()) {
+                  LOG.debug("[STRESS] Cluster overloaded in run! Sleeping...");
+                }
+
+                // sleep 
+                try {
+                  Thread.sleep(1000);
+                } catch (InterruptedException ie) {
+                  LOG.warn("[STRESS] Interrupted while sleeping! Exiting.", ie);
+                  return;
+                }
+              }
-                LOG.debug("Cluster underloaded in run! Stressing...");
+                LOG.debug("[STRESS] Cluster underloaded in run! Stressing...");
+                  LOG.warn("[STRESS] Finished consuming the input trace. " 
+                           + "Exiting..");
-                submitter.add(
-                  jobCreator.createGridmixJob(
-                    conf, 0L, job, scratch, 
-                    userResolver.getTargetUgi(
-                      UserGroupInformation.createRemoteUser(job.getUser())), 
-                    sequence.getAndIncrement()));
+                
+                UserGroupInformation ugi = 
+                  UserGroupInformation.createRemoteUser(job.getUser());
+                UserGroupInformation tgtUgi = userResolver.getTargetUgi(ugi);
+                GridmixJob tJob = 
+                  jobCreator.createGridmixJob(conf, 0L, job, scratch, 
+                               tgtUgi, sequence.getAndIncrement());
+                
+                // submit the job
+                submitter.add(tJob);
+                
-                LOG.error("Error while submitting the job ", e);
+                LOG.error("[STRESS] Error while submitting the job ", e);
+        LOG.error("[STRESS] Interrupted in the main block!", e);
-    ClusterStatus clusterMetrics = item.getStatus();
+    ClusterStatus clusterStatus = item.getStatus();
-      checkLoadAndGetSlotsToBackfill(item, clusterMetrics);
+      // update the max cluster map/reduce task capacity
+      loadStatus.updateMapCapacity(clusterStatus.getMaxMapTasks());
+      
+      loadStatus.updateReduceCapacity(clusterStatus.getMaxReduceTasks());
+      
+      int numTrackers = clusterStatus.getTaskTrackers();
+      int jobLoad = 
+        (int) (maxJobTrackerRatio * numTrackers) - item.getNumRunningJob();
+      loadStatus.updateJobLoad(jobLoad);
-  private void checkLoadAndGetSlotsToBackfill(
-    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {
-    
-    // update the max cluster capacity incase its updated
-    int mapCapacity = clusterStatus.getMaxMapTasks();
-    loadStatus.updateMapCapacity(mapCapacity);
-    
-    int reduceCapacity = clusterStatus.getMaxReduceTasks();
-    
-    loadStatus.updateReduceCapacity(reduceCapacity);
-    
-    int numTrackers = clusterStatus.getTaskTrackers();
-    
-    int jobLoad = 
-      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();
-    loadStatus.updateJobLoad(jobLoad);
+  protected void checkLoadAndGetSlotsToBackfill() 
+  throws IOException, InterruptedException {
-    float incompleteMapTasks = 0; // include pending & running map tasks.
-    for (JobStats job : ClusterStats.getRunningJobStats()) {
-      float mapProgress = job.getJob().mapProgress();
-      int noOfMaps = job.getNoOfMaps();
-      incompleteMapTasks += 
-        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);
+    int mapCapacity = loadStatus.getMapCapacity();
+    int reduceCapacity = loadStatus.getReduceCapacity();
+    
+    // return if the cluster status is not set
+    if (mapCapacity < 0 || reduceCapacity < 0) {
+      // note that, by default, the overload status is true
+      // missing cluster status will result into blocking of job submission
+      return;
-    int mapSlotsBackFill = 
-      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);
-    loadStatus.updateMapLoad(mapSlotsBackFill);
+    // Determine the max permissible map & reduce task load
+    int maxMapLoad = (int) (overloadMapTaskMapSlotRatio * mapCapacity);
+    int maxReduceLoad = 
+      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);
+    
+    // compute the total number of map & reduce tasks submitted
+    int totalMapTasks = ClusterStats.getSubmittedMapTasks();
+    int totalReduceTasks = ClusterStats.getSubmittedReduceTasks();
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Total submitted map tasks: " + totalMapTasks);
+      LOG.debug("Total submitted reduce tasks: " + totalReduceTasks);
+      LOG.debug("Max map load: " + maxMapLoad);
+      LOG.debug("Max reduce load: " + maxReduceLoad);
+    }
+    
+    // generate a pessimistic bound on the max running+pending map tasks
+    // this check is to avoid the heavy-duty actual map load calculation
+    int mapSlotsBackFill = (int) (maxMapLoad - totalMapTasks);
+    
+    // generate a pessimistic bound on the max running+pending reduce tasks
+    // this check is to avoid the heavy-duty actual reduce load calculation
+    int reduceSlotsBackFill = (int) (maxReduceLoad - totalReduceTasks);
+    
+    // maintain a list of seen job ids
+    Set<JobID> seenJobIDs = new HashSet<JobID>();
+    
+    // check if the total number of submitted map/reduce tasks exceeds the 
+    // permissible limit
+    if (totalMapTasks > maxMapLoad || totalReduceTasks > maxReduceLoad) {
+      // if yes, calculate the real load
+      float incompleteMapTasks = 0; // include pending & running map tasks.
+      float incompleteReduceTasks = 0; // include pending & running reduce tasks
+      
+      for (JobStats job : ClusterStats.getRunningJobStats()) {
+        JobID id = job.getJob().getJobID();
+        seenJobIDs.add(id);
+        
+        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()
+        // should be smart enough to take care of completed jobs.
+        if (blacklistedJobs.contains(id)) {
+          LOG.warn("Ignoring blacklisted job: " + id);
+          continue;
+        }
+        
+        int noOfMaps = job.getNoOfMaps();
+        int noOfReduces = job.getNoOfReds();
+        
+        // consider polling for jobs where maps>0 and reds>0
+        // TODO: What about setup/cleanup tasks for cases where m=0 and r=0
+        //       What otherwise?
+        if (noOfMaps > 0 || noOfReduces > 0) {
+          // get the job's status
+          JobStatus status = job.getJobStatus();
+          
+          // blacklist completed jobs and continue
+          if (status != null && status.isJobComplete()) {
+            LOG.warn("Blacklisting completed job: " + id);
+            blacklistedJobs.add(id);
+            continue;
+          }
+          
+          // get the map and reduce tasks' progress
+          float mapProgress = 0f;
+          float reduceProgress = 0f;
+          
+          // check if the status is missing (this can happen for unpolled jobs)
+          if (status != null) {
+            mapProgress = status.getMapProgress();
+            reduceProgress = status.getReduceProgress();
+          }
+          
+          incompleteMapTasks += 
+            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);
+
+          // bail out early
+          int currentMapSlotsBackFill = (int) (maxMapLoad - incompleteMapTasks);
+          if (currentMapSlotsBackFill <= 0) {
+            // reset the reduce task load since we are bailing out
+            incompleteReduceTasks = totalReduceTasks;
+            if (LOG.isDebugEnabled()) {
+              LOG.debug("Terminating overload check due to high map load.");
+            }
+            break;
+          }
+
+          // compute the real reduce load
+          if (noOfReduces > 0) {
+            incompleteReduceTasks += 
+              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, 
+                  reduceProgress);
+          }
+
+          // bail out early
+          int currentReduceSlotsBackFill = 
+            (int) (maxReduceLoad - incompleteReduceTasks);
+          if (currentReduceSlotsBackFill <= 0) {
+            // reset the map task load since we are bailing out
+            incompleteMapTasks = totalMapTasks;
+            if (LOG.isDebugEnabled()) {
+              LOG.debug("Terminating overload check due to high reduce load.");
+            }
+            break;
+          }
+        } else {
+          LOG.warn("Blacklisting empty job: " + id);
+          blacklistedJobs.add(id);
+        }
+      }
+
+      // calculate the real map load on the cluster
+      mapSlotsBackFill = (int) (maxMapLoad - incompleteMapTasks);
+      
+      // calculate the real reduce load on the cluster
+      reduceSlotsBackFill = (int)(maxReduceLoad - incompleteReduceTasks);
+      
+      // clean up the backlisted set to keep the memory footprint minimal
+      // retain only the jobs that are seen in this cycle
+      blacklistedJobs.retainAll(seenJobIDs);
+      if (LOG.isDebugEnabled() && blacklistedJobs.size() > 0) {
+        LOG.debug("Blacklisted jobs count: " + blacklistedJobs.size());
+      }
+    }
+    
+    // update
+    loadStatus.updateMapLoad(mapSlotsBackFill); 
+    loadStatus.updateReduceLoad(reduceSlotsBackFill);
-
-    float incompleteReduceTasks = 0; // include pending & running reduce tasks.
-    for (JobStats job : ClusterStats.getRunningJobStats()) {
-      // Cached the num-reds value in JobStats
-      int noOfReduces = job.getNoOfReds();
-      if (noOfReduces > 0) {
-        float reduceProgress = job.getJob().reduceProgress();
-        incompleteReduceTasks += 
-          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, 
-                                             reduceProgress);
-      }
-    }
-    int reduceSlotsBackFill = 
-      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) 
-             - incompleteReduceTasks);
-    loadStatus.updateReduceLoad(reduceSlotsBackFill);
-    public synchronized boolean overloaded() {
+    public boolean overloaded() {

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS23 INS29 INS83 INS74 INS59 UPD83 MOV25 MOV60 MOV25 MOV60 INS65 INS43 INS43 INS42 INS14 INS60 INS25 INS60 INS25 INS60 INS60 INS25 INS66 INS66 INS66 INS42 INS42 INS74 INS39 INS59 INS27 MOV8 INS39 INS59 INS32 INS8 MOV39 INS59 INS74 INS59 INS27 INS8 INS43 INS43 UPD42 INS21 INS60 INS60 INS21 INS42 INS32 INS27 INS27 UPD42 UPD42 INS42 INS32 UPD42 INS42 INS42 INS21 INS21 INS21 MOV21 UPD42 INS11 UPD42 MOV42 INS11 INS43 INS43 INS42 INS14 INS27 INS27 MOV60 MOV60 INS70 INS21 INS21 INS21 INS25 INS42 INS42 INS8 INS32 INS39 INS59 INS39 INS59 INS32 UPD42 UPD42 MOV42 UPD42 MOV42 INS42 INS34 INS42 INS34 MOV36 MOV36 INS42 INS42 UPD42 UPD42 INS32 INS32 INS32 INS39 INS36 MOV39 MOV36 INS42 INS42 INS74 INS42 INS42 INS42 INS42 MOV44 MOV32 INS8 INS7 INS7 INS32 INS27 INS8 INS21 INS41 UPD42 UPD42 INS32 INS42 INS42 INS32 INS42 MOV32 INS42 INS27 INS42 INS42 MOV42 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 UPD42 UPD42 INS27 INS27 UPD27 INS43 INS43 MOV60 INS21 INS25 MOV60 MOV60 INS25 INS42 INS11 INS42 INS11 UPD42 MOV42 INS42 UPD42 MOV42 INS32 INS27 INS21 INS21 INS32 UPD42 MOV42 INS42 INS42 INS42 MOV11 INS32 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS42 INS42 UPD42 UPD42 INS42 INS42 INS43 INS32 INS32 INS8 INS27 INS8 INS8 INS39 INS36 INS39 INS36 INS42 INS42 INS32 INS34 INS32 INS32 INS42 INS42 INS45 INS42 INS39 INS36 INS42 INS42 INS42 UPD42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 MOV21 INS18 INS27 INS27 INS60 INS25 INS60 INS60 INS25 MOV21 INS60 INS25 MOV25 INS60 INS25 INS21 INS21 INS27 INS27 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS45 INS27 UPD42 INS42 INS34 INS42 INS34 INS43 INS59 INS27 INS8 MOV39 INS59 INS39 INS59 INS27 INS8 INS39 INS59 INS27 INS8 INS39 INS59 INS27 INS8 INS32 INS32 INS42 INS42 INS42 INS42 INS45 INS32 INS32 INS8 INS42 INS42 UPD42 UPD42 INS27 INS42 INS42 INS32 INS27 INS32 INS21 INS21 INS18 MOV42 INS34 INS42 INS34 INS42 INS33 INS21 INS21 INS42 INS11 INS42 INS34 INS21 INS25 INS10 INS42 INS11 INS42 INS34 INS21 INS25 INS10 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS25 INS54 INS25 INS45 INS42 INS42 INS42 INS42 INS33 INS42 INS42 INS32 INS32 INS7 INS7 INS39 INS36 INS7 INS32 INS8 INS39 INS36 INS7 INS32 INS8 INS45 INS42 INS32 INS8 INS8 INS12 MOV32 MOV8 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS27 INS42 INS42 INS42 INS42 INS21 INS27 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS21 INS21 INS44 INS8 INS60 INS60 INS60 INS21 INS45 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS32 INS32 INS43 INS42 INS21 INS41 INS43 INS59 INS43 INS59 INS43 INS59 INS32 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS32 UPD45 INS21 INS42 INS42 MOV32 INS42 INS42 INS32 INS42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS45 INS42 INS21 INS32 UPD42 MOV42 UPD42 MOV42 INS42 MOV42 MOV42 MOV42 MOV34 MOV42 MOV42 INS42 MOV32 UPD45 UPD45 INS32 INS42 INS42 INS27 INS42 INS42 INS45 INS42 INS45 INS45 DEL32 DEL32 DEL32 DEL21 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL42 DEL27 DEL36 DEL42 DEL27 DEL36 DEL42 DEL32 DEL21 DEL42 DEL39 DEL32 DEL27 DEL59 DEL60 DEL32 DEL42 DEL32 DEL59 DEL60 DEL8 DEL70 DEL42 DEL43 DEL42 DEL44 DEL32 DEL8 DEL70 DEL83