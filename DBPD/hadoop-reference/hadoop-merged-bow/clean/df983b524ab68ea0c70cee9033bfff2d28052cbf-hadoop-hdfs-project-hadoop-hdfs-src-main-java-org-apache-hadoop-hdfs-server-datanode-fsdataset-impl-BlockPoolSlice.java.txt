HDFS-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.

+import org.apache.hadoop.hdfs.server.datanode.LocalReplica;
+import org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaInputStreams;
+
-import org.apache.hadoop.io.nativeio.NativeIO;
-      FileUtil.fullyDelete(tmpDir);
+      DataStorage.fullyDelete(tmpDir);
-            NativeIO.renameTo(metaFile, targetMetaFile);
+            LocalReplica.rename(metaFile, targetMetaFile);
-            NativeIO.renameTo(blockFile, targetBlockFile);
+            LocalReplica.rename(blockFile, targetBlockFile);
-    DataInputStream checksumIn = null;
-    InputStream blockIn = null;
-      checksumIn = new DataInputStream(
+      try (DataInputStream checksumIn = new DataInputStream(
-              ioFileBufferSize));
-
-      // read and handle the common header here. For now just a version
-      final DataChecksum checksum = BlockMetadataHeader.readDataChecksum(
-          checksumIn, metaFile);
-      int bytesPerChecksum = checksum.getBytesPerChecksum();
-      int checksumSize = checksum.getChecksumSize();
-      long numChunks = Math.min(
-          (blockFileLen + bytesPerChecksum - 1)/bytesPerChecksum,
-          (metaFileLen - crcHeaderLen)/checksumSize);
-      if (numChunks == 0) {
-        return 0;
-      }
-      IOUtils.skipFully(checksumIn, (numChunks-1)*checksumSize);
-      blockIn = new FileInputStream(blockFile);
-      long lastChunkStartPos = (numChunks-1)*bytesPerChecksum;
-      IOUtils.skipFully(blockIn, lastChunkStartPos);
-      int lastChunkSize = (int)Math.min(
-          bytesPerChecksum, blockFileLen-lastChunkStartPos);
-      byte[] buf = new byte[lastChunkSize+checksumSize];
-      checksumIn.readFully(buf, lastChunkSize, checksumSize);
-      IOUtils.readFully(blockIn, buf, 0, lastChunkSize);
-
-      checksum.update(buf, 0, lastChunkSize);
-      long validFileLength;
-      if (checksum.compare(buf, lastChunkSize)) { // last chunk matches crc
-        validFileLength = lastChunkStartPos + lastChunkSize;
-      } else { // last chunck is corrupt
-        validFileLength = lastChunkStartPos;
-      }
-
-      // truncate if extra bytes are present without CRC
-      if (blockFile.length() > validFileLength) {
-        RandomAccessFile blockRAF = new RandomAccessFile(blockFile, "rw");
-        try {
-          // truncate blockFile
-          blockRAF.setLength(validFileLength);
-        } finally {
-          blockRAF.close();
+              ioFileBufferSize))) {
+        // read and handle the common header here. For now just a version
+        final DataChecksum checksum = BlockMetadataHeader.readDataChecksum(
+            checksumIn, metaFile);
+        int bytesPerChecksum = checksum.getBytesPerChecksum();
+        int checksumSize = checksum.getChecksumSize();
+        long numChunks = Math.min(
+            (blockFileLen + bytesPerChecksum - 1) / bytesPerChecksum,
+            (metaFileLen - crcHeaderLen) / checksumSize);
+        if (numChunks == 0) {
+          return 0;
+        }
+        try (InputStream blockIn = new FileInputStream(blockFile);
+             ReplicaInputStreams ris = new ReplicaInputStreams(blockIn,
+                 checksumIn, volume.obtainReference())) {
+          ris.skipChecksumFully((numChunks - 1) * checksumSize);
+          long lastChunkStartPos = (numChunks - 1) * bytesPerChecksum;
+          ris.skipDataFully(lastChunkStartPos);
+          int lastChunkSize = (int) Math.min(
+              bytesPerChecksum, blockFileLen - lastChunkStartPos);
+          byte[] buf = new byte[lastChunkSize + checksumSize];
+          ris.readChecksumFully(buf, lastChunkSize, checksumSize);
+          ris.readDataFully(buf, 0, lastChunkSize);
+          checksum.update(buf, 0, lastChunkSize);
+          long validFileLength;
+          if (checksum.compare(buf, lastChunkSize)) { // last chunk matches crc
+            validFileLength = lastChunkStartPos + lastChunkSize;
+          } else { // last chunk is corrupt
+            validFileLength = lastChunkStartPos;
+          }
+          // truncate if extra bytes are present without CRC
+          if (blockFile.length() > validFileLength) {
+            try (RandomAccessFile blockRAF =
+                     new RandomAccessFile(blockFile, "rw")) {
+              // truncate blockFile
+              blockRAF.setLength(validFileLength);
+            }
+          }
+          return validFileLength;
-
-      return validFileLength;
-    } finally {
-      IOUtils.closeStream(checksumIn);
-      IOUtils.closeStream(blockIn);

MOV26 INS26 UPD40 INS40 INS54 INS58 INS8 UPD42 MOV43 INS59 MOV60 MOV60 MOV60 MOV60 MOV25 INS54 INS42 MOV14 INS58 INS58 INS8 MOV43 INS59 INS43 INS59 MOV21 MOV60 MOV21 MOV60 MOV60 MOV21 MOV21 MOV21 MOV60 MOV25 MOV25 MOV41 INS42 MOV14 INS42 INS42 INS14 INS43 INS42 INS42 INS32 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS42 INS42 INS42 INS58 UPD42 UPD42 UPD42 UPD42 MOV43 MOV59 DEL42 DEL33 DEL59 DEL60 DEL42 DEL33 DEL59 DEL60 DEL42 DEL42 DEL42 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL42 DEL7 DEL21 DEL42 DEL7 DEL21 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8