merge the rest of trunk to branch HDFS-4949

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532967 13f79535-47bb-0310-9956-ffa450edef68

+import java.nio.ByteBuffer;
+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Preconditions;
+
+  
+  //Only needed for overlapped write, referring OpenFileCtx.addWritesToCache()  
+  private final int originalCount; 
+  public static final int INVALID_ORIGINAL_COUNT = -1;
+  
+  public int getOriginalCount() {
+    return originalCount;
+  }
+
-  private byte[] data;
+  private volatile ByteBuffer data;
-  private DataState dataState;
+  /** 
+   * Data belonging to the same {@link OpenFileCtx} may be dumped to a file. 
+   * After being dumped to the file, the corresponding {@link WriteCtx} records 
+   * the dump file and the offset.  
+   */
+  private RandomAccessFile raf;
+  private long dumpFileOffset;
+  
+  private volatile DataState dataState;
-
-  private RandomAccessFile raf;
-  private long dumpFileOffset;
-  // Return the dumped data size
-  public long dumpData(FileOutputStream dumpOut, RandomAccessFile raf)
+  /** 
+   * Writing the data into a local file. After the writing, if 
+   * {@link #dataState} is still ALLOW_DUMP, set {@link #data} to null and set 
+   * {@link #dataState} to DUMPED.
+   */
+  long dumpData(FileOutputStream dumpOut, RandomAccessFile raf)
+
+    // Resized write should not allow dump
+    Preconditions.checkState(originalCount == INVALID_ORIGINAL_COUNT);
+
-    dumpOut.write(data, 0, count);
+    dumpOut.write(data.array(), 0, count);
-    data = null;
-    dataState = DataState.DUMPED;
-    return count;
+    // it is possible that while we dump the data, the data is also being
+    // written back to HDFS. After dump, if the writing back has not finished
+    // yet, we change its flag to DUMPED and set the data to null. Otherwise
+    // this WriteCtx instance should have been removed from the buffer.
+    if (dataState == DataState.ALLOW_DUMP) {
+      synchronized (this) {
+        if (dataState == DataState.ALLOW_DUMP) {
+          data = null;
+          dataState = DataState.DUMPED;
+          return count;
+        }
+      }
+    }
+    return 0;
-  public FileHandle getHandle() {
+  FileHandle getHandle() {
-  public long getOffset() {
+  long getOffset() {
-  public int getCount() {
+  int getCount() {
-  public WriteStableHow getStableHow() {
+  WriteStableHow getStableHow() {
-  public byte[] getData() throws IOException {
+  @VisibleForTesting
+  ByteBuffer getData() throws IOException {
-      if (data == null) {
-        throw new IOException("Data is not dumpted but has null:" + this);
-      }
-    } else {
-      // read back
-      if (data != null) {
-        throw new IOException("Data is dumpted but not null");
-      }
-      data = new byte[count];
-      raf.seek(dumpFileOffset);
-      int size = raf.read(data, 0, count);
-      if (size != count) {
-        throw new IOException("Data count is " + count + ", but read back "
-            + size + "bytes");
+      synchronized (this) {
+        if (dataState != DataState.DUMPED) {
+          Preconditions.checkState(data != null);
+          return data;
+        }
+    // read back from dumped file
+    this.loadData();
+  private void loadData() throws IOException {
+    Preconditions.checkState(data == null);
+    byte[] rawData = new byte[count];
+    raf.seek(dumpFileOffset);
+    int size = raf.read(rawData, 0, count);
+    if (size != count) {
+      throw new IOException("Data count is " + count + ", but read back "
+          + size + "bytes");
+    }
+    data = ByteBuffer.wrap(rawData);
+  }
+
+  public void writeData(HdfsDataOutputStream fos) throws IOException {
+    Preconditions.checkState(fos != null);
+
+    ByteBuffer dataBuffer = null;
+    try {
+      dataBuffer = getData();
+    } catch (Exception e1) {
+      LOG.error("Failed to get request data offset:" + offset + " count:"
+          + count + " error:" + e1);
+      throw new IOException("Can't get WriteCtx.data");
+    }
+
+    byte[] data = dataBuffer.array();
+    int position = dataBuffer.position();
+    int limit = dataBuffer.limit();
+    Preconditions.checkState(limit - position == count);
+    // Modified write has a valid original count
+    if (position != 0) {
+      if (limit != getOriginalCount()) {
+        throw new IOException("Modified write has differnt original size."
+            + "buff position:" + position + " buff limit:" + limit + ". "
+            + toString());
+      }
+    }
+    
+    // Now write data
+    fos.write(data, position, count);
+  }
+  
-  WriteCtx(FileHandle handle, long offset, int count, WriteStableHow stableHow,
-      byte[] data, Channel channel, int xid, boolean replied, DataState dataState) {
+  WriteCtx(FileHandle handle, long offset, int count, int originalCount,
+      WriteStableHow stableHow, ByteBuffer data, Channel channel, int xid,
+      boolean replied, DataState dataState) {
+    this.originalCount = originalCount;
-        + " stableHow:" + stableHow + " replied:" + replied + " dataState:"
-        + dataState + " xid:" + xid;
+        + " originalCount:" + originalCount + " stableHow:" + stableHow
+        + " replied:" + replied + " dataState:" + dataState + " xid:" + xid;

INS26 INS26 INS26 INS26 MOV23 MOV23 MOV23 INS40 INS40 INS40 INS40 INS23 INS31 INS23 INS31 INS31 INS83 INS39 INS59 INS83 INS83 INS83 INS39 INS59 INS83 INS39 INS42 INS8 INS83 INS43 MOV59 INS29 INS83 MOV43 MOV59 INS83 INS29 INS78 INS43 INS42 INS43 INS8 UPD83 INS39 UPD42 MOV8 INS83 INS39 INS42 INS44 INS43 INS8 INS44 INS42 INS42 INS38 INS41 INS42 INS65 INS65 INS21 INS25 INS41 INS42 INS42 INS42 INS25 INS21 INS41 INS60 INS21 INS43 INS42 INS42 INS21 INS60 INS54 INS60 INS60 INS60 INS21 INS25 INS21 INS39 INS42 INS43 INS21 INS34 INS42 INS66 INS65 INS66 INS66 INS65 INS66 INS66 INS66 INS65 INS66 INS65 INS66 INS65 INS66 INS32 INS27 INS8 INS34 INS27 INS8 INS32 INS42 INS32 MOV5 INS59 INS7 INS42 INS32 INS43 INS59 INS8 INS12 MOV5 INS59 INS39 INS59 INS39 INS59 INS32 INS27 INS8 INS32 INS42 INS7 INS42 INS42 INS67 INS67 INS67 INS42 INS42 INS27 INS32 INS42 INS40 INS51 INS42 INS40 INS51 INS52 INS42 INS42 INS42 MOV27 INS42 MOV3 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS33 INS21 INS44 MOV8 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS42 INS27 INS42 INS34 INS25 INS42 INS42 INS42 INS42 INS42 INS22 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS42 MOV42 INS42 INS52 INS8 INS52 INS8 UPD42 INS42 INS42 INS42 INS42 INS33 INS7 INS43 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS27 INS8 INS52 INS42 INS25 INS25 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS32 INS53 INS27 INS8 MOV27 INS8 INS42 INS42 INS42 INS27 UPD45 INS42 INS14 INS42 INS40 MOV21 MOV21 MOV41 INS21 MOV41 INS45 INS42 INS45 INS42 INS45 INS42 MOV43 INS27 INS32 INS27 INS42 INS45 INS42 INS45 INS32 INS42 INS42 MOV27 INS45 INS45 INS42 DEL39 DEL85 DEL5 DEL83 DEL83 DEL83 DEL83 DEL83 DEL25 DEL42 DEL7 DEL45 DEL52 DEL27 DEL14 DEL53 DEL8 DEL25 DEL8 DEL25 DEL8