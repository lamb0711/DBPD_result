YARN-3367. Replace starting a separate thread for post entity with event loop in TimelineClient (Naganarasimha G R via sjlee)

+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+  private TimelineEntityDispatcher entityDispatcher;
+
+      entityDispatcher = new TimelineEntityDispatcher(conf);
-    if (!timelineServiceV2) {
+    if (timelineServiceV2) {
+      entityDispatcher.start();
+    } else {
+    if (timelineServiceV2) {
+      entityDispatcher.stop();
+    }
-      throws IOException, YarnException {
-    putEntities(false, entities);
+          throws IOException, YarnException {
+    if (!timelineServiceV2) {
+      throw new YarnException("v.2 method is invoked on a v.1.x client");
+    }
+    entityDispatcher.dispatchEntities(true, entities);
-    putEntities(true, entities);
-  }
-
-  private void putEntities(boolean async,
-      org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity... entities)
-      throws IOException, YarnException {
-    org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities
-        entitiesContainer =
-        new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities();
-    for (org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity : entities) {
-      entitiesContainer.addEntity(entity);
-    }
-    MultivaluedMap<String, String> params = new MultivaluedMapImpl();
-    if (getContextAppId() != null) {
-      params.add("appid", getContextAppId().toString());
-    }
-    if (async) {
-      params.add("async", Boolean.TRUE.toString());
-    }
-    putObjects("entities", params, entitiesContainer);
+    entityDispatcher.dispatchEntities(false, entities);
-  public void putObjects(String path, MultivaluedMap<String, String> params,
+  protected void putObjects(String path, MultivaluedMap<String, String> params,
-    // timelineServiceAddress could haven't be initialized yet
-    // or stale (only for new timeline service)
-    int retries = pollTimelineServiceAddress(this.maxServiceRetries);
-    if (timelineServiceAddress == null) {
-      String errMessage = "TimelineClient has reached to max retry times : "
-          + this.maxServiceRetries
-          + ", but failed to fetch timeline service address. Please verify"
-          + " Timeline Auxillary Service is configured in all the NMs";
-      LOG.error(errMessage);
-      throw new YarnException(errMessage);
-    }
+    int retries = verifyRestEndPointAvailable();
+  private int verifyRestEndPointAvailable() throws YarnException {
+    // timelineServiceAddress could haven't be initialized yet
+    // or stale (only for new timeline service)
+    int retries = pollTimelineServiceAddress(this.maxServiceRetries);
+    if (timelineServiceAddress == null) {
+      String errMessage = "TimelineClient has reached to max retry times : "
+          + this.maxServiceRetries
+          + ", but failed to fetch timeline service address. Please verify"
+          + " Timeline Auxillary Service is configured in all the NMs";
+      LOG.error(errMessage);
+      throw new YarnException(errMessage);
+    }
+    return retries;
+  }
+
-      timelineServiceAddress = getTimelineServiceAddress();
+      // timelineServiceAddress = getTimelineServiceAddress();
+  private final class EntitiesHolder extends FutureTask<Void> {
+    private final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities entities;
+    private final boolean isSync;
+
+    EntitiesHolder(
+        final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities entities,
+        final boolean isSync) {
+      super(new Callable<Void>() {
+        // publishEntities()
+        public Void call() throws Exception {
+          MultivaluedMap<String, String> params = new MultivaluedMapImpl();
+          params.add("appid", contextAppId.toString());
+          params.add("async", Boolean.toString(!isSync));
+          putObjects("entities", params, entities);
+          return null;
+        }
+      });
+      this.entities = entities;
+      this.isSync = isSync;
+    }
+
+    public boolean isSync() {
+      return isSync;
+    }
+
+    public org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities getEntities() {
+      return entities;
+    }
+  }
+
+  /**
+   * This class is responsible for collecting the timeline entities and
+   * publishing them in async.
+   */
+  private class TimelineEntityDispatcher {
+    /**
+     * Time period for which the timelineclient will wait for draining after
+     * stop
+     */
+    private static final long DRAIN_TIME_PERIOD = 2000L;
+
+    private int numberOfAsyncsToMerge;
+    private final BlockingQueue<EntitiesHolder> timelineEntityQueue;
+    private ExecutorService executor;
+
+    TimelineEntityDispatcher(Configuration conf) {
+      timelineEntityQueue = new LinkedBlockingQueue<EntitiesHolder>();
+      numberOfAsyncsToMerge =
+          conf.getInt(YarnConfiguration.NUMBER_OF_ASYNC_ENTITIES_TO_MERGE,
+              YarnConfiguration.DEFAULT_NUMBER_OF_ASYNC_ENTITIES_TO_MERGE);
+    }
+
+    Runnable createRunnable() {
+      return new Runnable() {
+        @Override
+        public void run() {
+          try {
+            EntitiesHolder entitiesHolder;
+            while (!Thread.currentThread().isInterrupted()) {
+              // Merge all the async calls and make one push, but if its sync
+              // call push immediately
+              try {
+                entitiesHolder = timelineEntityQueue.take();
+              } catch (InterruptedException ie) {
+                LOG.info("Timeline dispatcher thread was interrupted ");
+                Thread.currentThread().interrupt();
+                return;
+              }
+              if (entitiesHolder != null) {
+                publishWithoutBlockingOnQueue(entitiesHolder);
+              }
+            }
+          } finally {
+            if (!timelineEntityQueue.isEmpty()) {
+              LOG.info("Yet to publish " + timelineEntityQueue.size()
+                  + " timelineEntities, draining them now. ");
+            }
+            // Try to drain the remaining entities to be published @ the max for
+            // 2 seconds
+            long timeTillweDrain =
+                System.currentTimeMillis() + DRAIN_TIME_PERIOD;
+            while (!timelineEntityQueue.isEmpty()) {
+              publishWithoutBlockingOnQueue(timelineEntityQueue.poll());
+              if (System.currentTimeMillis() > timeTillweDrain) {
+                // time elapsed stop publishing further....
+                if (!timelineEntityQueue.isEmpty()) {
+                  LOG.warn("Time to drain elapsed! Remaining "
+                      + timelineEntityQueue.size() + "timelineEntities will not"
+                      + " be published");
+                  // if some entities were not drained then we need interrupt
+                  // the threads which had put sync EntityHolders to the queue.
+                  EntitiesHolder nextEntityInTheQueue = null;
+                  while ((nextEntityInTheQueue =
+                      timelineEntityQueue.poll()) != null) {
+                    nextEntityInTheQueue.cancel(true);
+                  }
+                }
+                break;
+              }
+            }
+          }
+        }
+
+        /**
+         * Publishes the given EntitiesHolder and return immediately if sync
+         * call, else tries to fetch the EntitiesHolder from the queue in non
+         * blocking fashion and collate the Entities if possible before
+         * publishing through REST.
+         *
+         * @param entitiesHolder
+         */
+        private void publishWithoutBlockingOnQueue(
+            EntitiesHolder entitiesHolder) {
+          if (entitiesHolder.isSync()) {
+            entitiesHolder.run();
+            return;
+          }
+          int count = 1;
+          while (true) {
+            // loop till we find a sync put Entities or there is nothing
+            // to take
+            EntitiesHolder nextEntityInTheQueue = timelineEntityQueue.poll();
+            if (nextEntityInTheQueue == null) {
+              // Nothing in the queue just publish and get back to the
+              // blocked wait state
+              entitiesHolder.run();
+              break;
+            } else if (nextEntityInTheQueue.isSync()) {
+              // flush all the prev async entities first
+              entitiesHolder.run();
+              // and then flush the sync entity
+              nextEntityInTheQueue.run();
+              break;
+            } else {
+              // append all async entities together and then flush
+              entitiesHolder.getEntities().addEntities(
+                  nextEntityInTheQueue.getEntities().getEntities());
+              count++;
+              if (count == numberOfAsyncsToMerge) {
+                // Flush the entities if the number of the async
+                // putEntites merged reaches the desired limit. To avoid
+                // collecting multiple entities and delaying for a long
+                // time.
+                entitiesHolder.run();
+                break;
+              }
+            }
+          }
+        }
+      };
+    }
+
+    public void dispatchEntities(boolean sync,
+        org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity[] entitiesTobePublished)
+            throws YarnException {
+      if (executor.isShutdown()) {
+        throw new YarnException("Timeline client is in the process of stopping,"
+            + " not accepting any more TimelineEntities");
+      }
+
+      // wrap all TimelineEntity into TimelineEntities object
+      org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities entities =
+          new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities();
+      for (org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity : entitiesTobePublished) {
+        entities.addEntity(entity);
+      }
+
+      // created a holder and place it in queue
+      EntitiesHolder entitiesHolder = new EntitiesHolder(entities, sync);
+      try {
+        timelineEntityQueue.put(entitiesHolder);
+      } catch (InterruptedException e) {
+        Thread.currentThread().interrupt();
+        throw new YarnException(
+            "Failed while adding entity to the queue for publishing", e);
+      }
+
+      if (sync) {
+        // In sync call we need to wait till its published and if any error then
+        // throw it back
+        try {
+          entitiesHolder.get();
+        } catch (ExecutionException e) {
+          throw new YarnException("Failed while publishing entity",
+              e.getCause());
+        } catch (InterruptedException e) {
+          Thread.currentThread().interrupt();
+          throw new YarnException("Interrupted while publishing entity", e);
+        }
+      }
+    }
+
+    public void start() {
+      executor = Executors.newSingleThreadExecutor();
+      executor.execute(createRunnable());
+    }
+
+    public void stop() {
+      LOG.info("Stopping TimelineClient.");
+      executor.shutdownNow();
+      try {
+        executor.awaitTermination(DRAIN_TIME_PERIOD, TimeUnit.MILLISECONDS);
+      } catch (InterruptedException e) {
+        Thread.currentThread().interrupt();
+        e.printStackTrace();
+      }
+    }
+  }

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS23 INS31 INS31 INS31 INS55 INS55 INS83 INS43 INS59 MOV78 MOV83 MOV39 MOV42 MOV44 MOV43 MOV43 INS8 MOV78 INS83 INS39 INS42 MOV44 MOV43 MOV43 INS8 UPD83 INS83 INS39 INS42 INS43 INS8 INS83 INS83 INS42 INS74 INS23 INS23 INS31 INS31 INS31 INS29 INS83 INS42 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS42 INS42 INS25 MOV25 INS21 INS25 INS21 INS60 INS42 MOV60 MOV25 INS41 INS43 INS43 INS83 INS83 INS43 INS59 INS83 INS83 INS39 INS59 INS42 MOV44 INS44 INS8 INS83 INS39 INS42 INS8 INS83 INS43 INS42 INS8 INS65 INS29 INS83 INS83 INS83 INS39 INS59 INS83 INS39 INS59 INS83 INS83 INS74 INS59 INS83 INS43 INS59 INS42 INS44 INS8 INS43 INS42 INS8 INS83 INS39 INS42 MOV44 INS44 MOV43 INS8 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS42 INS8 INS42 INS8 INS32 INS38 INS8 INS32 INS39 INS59 INS42 INS42 INS42 INS40 INS42 INS42 INS83 UPD43 INS83 INS39 INS42 INS46 INS21 INS21 INS41 INS40 INS41 INS66 INS66 INS65 INS42 INS34 INS42 INS43 INS43 INS42 INS42 INS42 INS43 INS42 INS21 INS21 INS42 INS41 UPD42 INS5 INS42 INS25 MOV60 MOV70 INS60 INS54 MOV25 INS21 MOV21 INS21 INS21 INS54 INS21 INS21 INS21 INS42 INS42 INS9 INS42 INS42 INS53 INS42 INS42 INS9 INS42 INS42 INS32 UPD40 INS14 INS7 INS7 INS42 INS42 INS66 INS66 INS42 INS42 INS42 INS7 INS7 INS14 INS43 INS85 INS32 INS8 UPD42 INS43 INS59 INS8 INS12 INS42 INS8 INS7 INS32 INS32 INS8 INS12 INS7 INS32 INS32 INS14 INS42 INS74 INS1 INS22 INS42 INS22 INS42 INS42 INS14 INS42 INS32 INS43 INS1 INS40 INS42 INS42 INS53 UPD42 INS42 INS42 INS14 INS21 INS44 INS8 INS54 INS42 INS32 UPD42 UPD42 INS42 INS42 INS45 INS42 INS42 MOV21 INS44 INS8 INS42 INS14 INS42 INS42 INS42 INS42 INS43 INS45 INS43 INS43 INS31 INS52 INS42 INS52 INS42 INS74 INS42 INS42 INS40 INS40 INS42 INS31 INS31 INS14 INS43 INS42 INS42 INS32 INS43 INS42 INS21 INS53 INS8 INS12 INS12 INS42 INS42 UPD42 INS43 INS42 INS21 INS21 INS43 INS42 INS42 INS42 INS42 INS83 INS43 INS42 UPD43 MOV43 MOV8 INS43 INS43 INS78 MOV83 MOV39 INS42 INS8 INS29 MOV83 MOV39 INS42 INS44 INS8 INS43 INS27 UPD42 INS42 INS42 INS42 INS42 INS42 INS32 INS14 INS21 INS44 INS8 INS44 INS8 UPD42 UPD42 UPD42 INS40 INS42 INS32 INS32 INS42 INS42 UPD42 MOV60 INS21 INS21 INS41 INS42 INS42 INS42 INS54 INS65 INS65 INS43 INS42 INS25 INS60 INS61 INS42 INS45 INS45 INS32 INS42 INS43 INS45 INS42 INS32 INS43 INS42 INS53 INS43 INS42 INS21 INS53 INS32 INS42 INS42 INS42 INS32 INS32 INS33 INS8 INS8 INS66 INS66 INS66 INS66 INS42 INS42 INS32 INS8 INS39 INS59 INS9 INS8 INS42 INS42 INS42 INS42 UPD42 MOV42 INS42 INS14 INS42 INS32 INS14 INS42 INS42 INS42 INS42 INS45 INS32 INS42 INS42 INS45 INS32 UPD42 INS45 INS42 INS60 INS61 INS25 INS60 INS61 INS42 INS42 INS21 INS41 INS42 INS34 INS60 INS25 INS43 INS45 INS32 MOV32 UPD42 MOV42 INS43 INS45 INS42 INS42 INS42 INS42 INS42 INS38 INS43 INS59 INS38 INS8 INS38 INS8 INS39 INS59 INS38 INS8 INS32 INS43 INS59 INS27 INS8 INS25 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 INS42 INS42 INS32 INS54 INS25 INS32 INS21 INS42 INS27 INS32 INS21 INS25 INS42 INS42 INS42 INS42 INS32 INS42 INS33 INS21 INS10 INS32 INS8 INS8 INS32 INS42 INS8 INS12 INS27 INS8 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS32 INS27 INS8 INS42 INS42 INS32 INS42 INS42 INS21 INS21 INS10 INS21 INS21 INS25 INS42 INS42 INS21 INS44 INS8 INS42 INS33 INS21 INS42 INS42 INS27 INS42 INS42 INS42 INS32 INS32 INS42 INS25 INS10 INS42 INS42 INS32 INS32 INS32 INS37 INS27 INS8 INS7 INS43 INS42 INS21 INS21 INS41 INS32 INS45 INS32 INS45 INS42 INS42 INS42 INS42 INS38 INS8 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS21 INS10 INS42 INS32 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS32 INS21 INS60 INS61 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS45 INS32 INS42 INS42 INS42 INS32 INS43 INS59 INS27 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS33 INS36 INS33 MOV21 INS45 INS32 INS45 INS45 INS7 INS42 INS42 INS42 INS32 UPD42 INS42 INS42 INS42 DEL42 DEL38 DEL31 DEL42 DEL8 DEL31 DEL42 DEL42 DEL8 DEL25 DEL8 DEL31 DEL42 DEL42 DEL32 DEL7 DEL21 DEL9 DEL42 DEL32 DEL33 DEL27 DEL42 DEL42 DEL45 DEL32 DEL32 DEL21 DEL8 DEL45 DEL40 DEL45