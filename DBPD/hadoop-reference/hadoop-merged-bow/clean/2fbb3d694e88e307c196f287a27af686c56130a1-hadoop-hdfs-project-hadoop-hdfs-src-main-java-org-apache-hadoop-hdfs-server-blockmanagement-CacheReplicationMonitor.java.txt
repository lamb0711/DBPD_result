Merge trunk to HDFS-4685.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1556097 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.ArrayList;
+import java.util.TreeMap;
-  private final Random random = new Random();
+  private static final Random random = new Random();
-  private final ReentrantLock lock = new ReentrantLock();
+  private final ReentrantLock lock;
-  private final Condition doRescan = lock.newCondition();
+  private final Condition doRescan;
-  private final Condition scanFinished = lock.newCondition();
+  private final Condition scanFinished;
-   * The monotonic time at which the current scan started.
-   */
-  private long startTimeMs;
-
-  /**
-      CacheManager cacheManager, long intervalMs) {
+      CacheManager cacheManager, long intervalMs, ReentrantLock lock) {
+    this.lock = lock;
+    this.doRescan = this.lock.newCondition();
+    this.scanFinished = this.lock.newCondition();
-    startTimeMs = 0;
+    long startTimeMs = 0;
+    Thread.currentThread().setName("CacheReplicationMonitor(" +
+        System.identityHashCode(this) + ")");
-        // Not all of the variables accessed here need the CRM lock, but take
-        // it anyway for simplicity
-        } finally {
-          lock.unlock();
-        }
-        // Mark scan as started, clear needsRescan
-        lock.lock();
-        try {
-        // Retake the CRM lock to update synchronization-related variables
+        // Update synchronization-related variables.
+    } catch (InterruptedException e) {
+      LOG.info("Shutting down CacheReplicationMonitor.");
+      return;
-   * Similar to {@link CacheReplicationMonitor#waitForRescan()}, except it only
-   * waits if there are pending operations that necessitate a rescan as
-   * indicated by {@link #setNeedsRescan()}.
-   * <p>
-   * Note that this call may release the FSN lock, so operations before and
-   * after are not necessarily atomic.
-   */
-  public void waitForRescanIfNeeded() {
-    lock.lock();
-    try {
-      if (!needsRescan) {
-        return;
-      }
-    } finally {
-      lock.unlock();
-    }
-    waitForRescan();
-  }
-
-  /**
-  public void waitForRescan() {
-    // Drop the FSN lock temporarily and retake it after we finish waiting
-    // Need to handle both the read lock and the write lock
-    boolean retakeWriteLock = false;
-    if (namesystem.hasWriteLock()) {
-      namesystem.writeUnlock();
-      retakeWriteLock = true;
-    } else if (namesystem.hasReadLock()) {
-      namesystem.readUnlock();
-    } else {
-      // Expected to have at least one of the locks
-      Preconditions.checkState(false,
-          "Need to be holding either the read or write lock");
+  public void waitForRescanIfNeeded() {
+    Preconditions.checkArgument(!namesystem.hasWriteLock(),
+        "Must not hold the FSN write lock when waiting for a rescan.");
+    Preconditions.checkArgument(lock.isHeldByCurrentThread(),
+        "Must hold the CRM lock when waiting for a rescan.");
+    if (!needsRescan) {
+      return;
-    // try/finally for retaking FSN lock
-    try {
-      lock.lock();
-      // try/finally for releasing CRM lock
+    // If no scan is already ongoing, mark the CRM as dirty and kick
+    if (!isScanning) {
+      doRescan.signal();
+    }
+    // Wait until the scan finishes and the count advances
+    final long startCount = scanCount;
+    while ((!shutdown) && (startCount >= scanCount)) {
-        // If no scan is already ongoing, mark the CRM as dirty and kick
-        if (!isScanning) {
-          needsRescan = true;
-          doRescan.signal();
-        }
-        // Wait until the scan finishes and the count advances
-        final long startCount = scanCount;
-        while (startCount >= scanCount) {
-          try {
-            scanFinished.await();
-          } catch (InterruptedException e) {
-            LOG.warn("Interrupted while waiting for CacheReplicationMonitor"
-                + " rescan", e);
-            break;
-          }
-        }
-      } finally {
-        lock.unlock();
-      }
-    } finally {
-      if (retakeWriteLock) {
-        namesystem.writeLock();
-      } else {
-        namesystem.readLock();
+        scanFinished.await();
+      } catch (InterruptedException e) {
+        LOG.warn("Interrupted while waiting for CacheReplicationMonitor"
+            + " rescan", e);
+        break;
-    lock.lock();
-    try {
-      this.needsRescan = true;
-    } finally {
-      lock.unlock();
-    }
+    Preconditions.checkArgument(lock.isHeldByCurrentThread(),
+        "Must hold the CRM lock when setting the needsRescan bit.");
+    this.needsRescan = true;
-   * Shut down and join the monitor thread.
+   * Shut down the monitor thread.
+    Preconditions.checkArgument(namesystem.hasWriteLock());
+      // Since we hold both the FSN write lock and the CRM lock here,
+      // we know that the CRM thread cannot be currently modifying
+      // the cache manager state while we're closing it.
+      // Since the CRM thread checks the value of 'shutdown' after waiting
+      // for a lock, we know that the thread will not modify the cache
+      // manager state after this point.
-    try {
-      if (this.isAlive()) {
-        this.join(60000);
-      }
-    } catch (InterruptedException e) {
-      Thread.currentThread().interrupt();
-    }
-  private void rescan() {
+  private void rescan() throws InterruptedException {
+      if (shutdown) {
+        throw new InterruptedException("CacheReplicationMonitor was " +
+            "shut down.");
+      }
-      // Reset the directive's statistics
-      directive.resetStatistics();
-        if (mark != ocblock.getMark()) {
-          // Mark hasn't been set in this scan, so update replication and mark.
+        if ((mark != ocblock.getMark()) ||
+            (ocblock.getReplication() < directive.getReplication())) {
+          //
+          // Overwrite the block's replication and mark in two cases:
+          //
+          // 1. If the mark on the CachedBlock is different from the mark for
+          // this scan, that means the block hasn't been updated during this
+          // scan, and we should overwrite whatever is there, since it is no
+          // longer valid.
+          //
+          // 2. If the replication in the CachedBlock is less than what the
+          // directive asks for, we want to increase the block's replication
+          // field to what the directive asks for.
+          //
-        } else {
-          // Mark already set in this scan.  Set replication to highest value in
-          // any CacheDirective that covers this file.
-          ocblock.setReplicationAndMark((short)Math.max(
-              directive.getReplication(), ocblock.getReplication()), mark);
+  private String findReasonForNotCaching(CachedBlock cblock, 
+          BlockInfo blockInfo) {
+    if (blockInfo == null) {
+      // Somehow, a cache report with the block arrived, but the block
+      // reports from the DataNode haven't (yet?) described such a block.
+      // Alternately, the NameNode might have invalidated the block, but the
+      // DataNode hasn't caught up.  In any case, we want to tell the DN
+      // to uncache this.
+      return "not tracked by the BlockManager";
+    } else if (!blockInfo.isComplete()) {
+      // When a cached block changes state from complete to some other state
+      // on the DataNode (perhaps because of append), it will begin the
+      // uncaching process.  However, the uncaching process is not
+      // instantaneous, especially if clients have pinned the block.  So
+      // there may be a period of time when incomplete blocks remain cached
+      // on the DataNodes.
+      return "not complete";
+    } else if (cblock.getReplication() == 0) {
+      // Since 0 is not a valid value for a cache directive's replication
+      // field, seeing a replication of 0 on a CacheBlock means that it
+      // has never been reached by any sweep.
+      return "not needed by any directives";
+    } else if (cblock.getMark() != mark) { 
+      // Although the block was needed in the past, we didn't reach it during
+      // the current sweep.  Therefore, it doesn't need to be cached any more.
+      // Need to set the replication to 0 so it doesn't flip back to cached
+      // when the mark flips on the next scan
+      cblock.setReplicationAndMark((short)0, mark);
+      return "no longer needed by any directives";
+    }
+    return null;
+  }
+
-      // If the block's mark doesn't match with the mark of this scan, that
-      // means that this block couldn't be reached during this scan.  That means
-      // it doesn't need to be cached any more.
-      int neededCached = (cblock.getMark() != mark) ?
-          0 : cblock.getReplication();
+      BlockInfo blockInfo = blockManager.
+            getStoredBlock(new Block(cblock.getBlockId()));
+      String reason = findReasonForNotCaching(cblock, blockInfo);
+      int neededCached = 0;
+      if (reason != null) {
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("not caching " + cblock + " because it is " + reason);
+        }
+      } else {
+        neededCached = cblock.getReplication();
+      }
-    if (!cacheManager.isActive()) {
-      return;
-    }
-  private void addNewPendingCached(int neededCached,
+  private void addNewPendingCached(final int neededCached,
-    if (!cacheManager.isActive()) {
-      return;
-    }
-      LOG.debug("Not caching block " + cachedBlock + " because it " +
-          "was deleted from all DataNodes.");
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Not caching block " + cachedBlock + " because there " +
+            "is no record of it on the NameNode.");
+      }
-    List<DatanodeDescriptor> possibilities = new LinkedList<DatanodeDescriptor>();
+    // Filter the list of replicas to only the valid targets
+    List<DatanodeDescriptor> possibilities =
+        new LinkedList<DatanodeDescriptor>();
+    int outOfCapacity = 0;
-      if ((datanode != null) && 
-          ((!pendingCached.contains(datanode)) &&
-          ((corrupt == null) || (!corrupt.contains(datanode))))) {
-        possibilities.add(datanode);
+      if (datanode == null) {
+        continue;
+      if (datanode.isDecommissioned() || datanode.isDecommissionInProgress()) {
+        continue;
+      }
+      if (corrupt != null && corrupt.contains(datanode)) {
+        continue;
+      }
+      if (pendingCached.contains(datanode) || cached.contains(datanode)) {
+        continue;
+      }
+      long pendingCapacity = datanode.getCacheRemaining();
+      // Subtract pending cached blocks from effective capacity
+      Iterator<CachedBlock> it = datanode.getPendingCached().iterator();
+      while (it.hasNext()) {
+        CachedBlock cBlock = it.next();
+        BlockInfo info =
+            blockManager.getStoredBlock(new Block(cBlock.getBlockId()));
+        if (info != null) {
+          pendingCapacity -= info.getNumBytes();
+        }
+      }
+      it = datanode.getPendingUncached().iterator();
+      // Add pending uncached blocks from effective capacity
+      while (it.hasNext()) {
+        CachedBlock cBlock = it.next();
+        BlockInfo info =
+            blockManager.getStoredBlock(new Block(cBlock.getBlockId()));
+        if (info != null) {
+          pendingCapacity += info.getNumBytes();
+        }
+      }
+      if (pendingCapacity < blockInfo.getNumBytes()) {
+        if (LOG.isTraceEnabled()) {
+          LOG.trace("Datanode " + datanode + " is not a valid possibility for"
+              + " block " + blockInfo.getBlockId() + " of size "
+              + blockInfo.getNumBytes() + " bytes, only has "
+              + datanode.getCacheRemaining() + " bytes of cache remaining.");
+        }
+        outOfCapacity++;
+        continue;
+      }
+      possibilities.add(datanode);
-    while (neededCached > 0) {
-      if (possibilities.isEmpty()) {
-        LOG.warn("We need " + neededCached + " more replica(s) than " +
-            "actually exist to provide a cache replication of " +
-            cachedBlock.getReplication() + " for " + cachedBlock);
-        return;
-      }
-      DatanodeDescriptor datanode =
-          possibilities.remove(random.nextInt(possibilities.size()));
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("AddNewPendingCached: datanode " + datanode + 
-            " will now cache block " + cachedBlock);
-      }
+    List<DatanodeDescriptor> chosen = chooseDatanodesForCaching(possibilities,
+        neededCached, blockManager.getDatanodeManager().getStaleInterval());
+    for (DatanodeDescriptor datanode : chosen) {
-      neededCached--;
+    // We were unable to satisfy the requested replication factor
+    if (neededCached > chosen.size()) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(
+            "Only have " +
+            (cachedBlock.getReplication() - neededCached + chosen.size()) +
+            " of " + cachedBlock.getReplication() + " cached replicas for " +
+            cachedBlock + " (" + outOfCapacity + " nodes have insufficient " +
+            "capacity).");
+      }
+    }
+  }
+
+  /**
+   * Chooses datanode locations for caching from a list of valid possibilities.
+   * Non-stale nodes are chosen before stale nodes.
+   * 
+   * @param possibilities List of candidate datanodes
+   * @param neededCached Number of replicas needed
+   * @param staleInterval Age of a stale datanode
+   * @return A list of chosen datanodes
+   */
+  private static List<DatanodeDescriptor> chooseDatanodesForCaching(
+      final List<DatanodeDescriptor> possibilities, final int neededCached,
+      final long staleInterval) {
+    // Make a copy that we can modify
+    List<DatanodeDescriptor> targets =
+        new ArrayList<DatanodeDescriptor>(possibilities);
+    // Selected targets
+    List<DatanodeDescriptor> chosen = new LinkedList<DatanodeDescriptor>();
+
+    // Filter out stale datanodes
+    List<DatanodeDescriptor> stale = new LinkedList<DatanodeDescriptor>();
+    Iterator<DatanodeDescriptor> it = targets.iterator();
+    while (it.hasNext()) {
+      DatanodeDescriptor d = it.next();
+      if (d.isStale(staleInterval)) {
+        it.remove();
+        stale.add(d);
+      }
+    }
+    // Select targets
+    while (chosen.size() < neededCached) {
+      // Try to use stale nodes if we're out of non-stale nodes, else we're done
+      if (targets.isEmpty()) {
+        if (!stale.isEmpty()) {
+          targets = stale;
+        } else {
+          break;
+        }
+      }
+      // Select a random target
+      DatanodeDescriptor target =
+          chooseRandomDatanodeByRemainingCapacity(targets);
+      chosen.add(target);
+      targets.remove(target);
+    }
+    return chosen;
+  }
+
+  /**
+   * Choose a single datanode from the provided list of possible
+   * targets, weighted by the percentage of free space remaining on the node.
+   * 
+   * @return The chosen datanode
+   */
+  private static DatanodeDescriptor chooseRandomDatanodeByRemainingCapacity(
+      final List<DatanodeDescriptor> targets) {
+    // Use a weighted probability to choose the target datanode
+    float total = 0;
+    for (DatanodeDescriptor d : targets) {
+      total += d.getCacheRemainingPercent();
+    }
+    // Give each datanode a portion of keyspace equal to its relative weight
+    // [0, w1) selects d1, [w1, w2) selects d2, etc.
+    TreeMap<Integer, DatanodeDescriptor> lottery =
+        new TreeMap<Integer, DatanodeDescriptor>();
+    int offset = 0;
+    for (DatanodeDescriptor d : targets) {
+      // Since we're using floats, be paranoid about negative values
+      int weight =
+          Math.max(1, (int)((d.getCacheRemainingPercent() / total) * 1000000));
+      offset += weight;
+      lottery.put(offset, d);
+    }
+    // Choose a number from [0, offset), which is the total amount of weight,
+    // to select the winner
+    DatanodeDescriptor winner =
+        lottery.higherEntry(random.nextInt(offset)).getValue();
+    return winner;

INS26 INS26 INS40 INS40 INS31 INS31 INS31 INS83 INS44 UPD42 MOV8 MOV8 INS43 INS83 INS43 INS42 INS44 INS44 INS8 INS29 INS83 INS83 INS74 INS42 INS44 INS44 INS44 INS8 INS29 INS83 UPD83 MOV83 INS43 INS42 INS44 INS8 MOV43 INS42 INS21 INS21 INS21 INS60 INS21 INS21 INS21 MOV25 INS21 MOV21 INS42 INS42 INS43 INS42 INS43 INS42 INS25 INS41 INS83 INS60 INS24 MOV60 INS70 INS25 MOV65 INS65 INS65 INS65 INS65 INS43 INS43 INS83 INS74 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS60 INS60 INS60 INS60 INS61 INS61 INS41 INS65 INS65 INS42 INS83 INS74 INS42 INS60 INS70 INS60 INS60 INS70 INS60 INS41 INS7 INS7 INS7 INS39 INS59 INS32 INS12 INS32 INS32 INS27 INS32 UPD66 INS42 INS42 INS27 INS8 INS25 INS33 INS39 INS59 MOV58 MOV27 MOV37 INS8 INS74 INS44 INS42 INS8 INS27 INS8 INS66 UPD66 INS42 INS66 INS42 INS66 INS42 INS66 INS66 INS42 INS42 INS43 INS43 INS74 INS59 INS74 INS59 INS74 INS59 INS74 INS59 INS32 INS8 INS27 INS8 INS42 UPD66 MOV66 UPD66 MOV66 UPD66 MOV66 INS43 INS43 INS39 INS59 INS44 INS42 INS8 INS74 INS59 INS39 INS59 INS44 INS42 INS8 INS43 INS59 INS42 INS22 INS42 INS22 INS32 INS22 INS32 INS42 INS34 MOV32 INS42 INS27 MOV44 INS8 INS42 INS42 INS38 INS45 INS42 INS42 INS32 INS45 INS36 INS36 INS42 INS42 INS32 INS45 UPD42 MOV42 UPD42 MOV42 INS32 INS25 INS42 INS33 INS41 INS38 INS8 INS25 INS60 INS60 INS25 INS25 INS42 INS34 MOV60 INS25 INS25 INS25 INS25 INS60 INS60 INS61 INS21 INS61 INS25 MOV21 INS43 INS43 UPD42 MOV43 INS42 MOV21 MOV60 MOV6 INS42 INS32 MOV25 INS42 INS42 INS43 INS43 INS42 INS14 INS43 INS43 INS42 INS14 INS43 INS43 UPD42 MOV42 INS14 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS25 INS32 INS42 INS25 INS60 INS21 INS21 INS42 INS42 INS42 INS34 INS43 INS42 MOV21 INS43 INS43 INS43 INS42 INS14 INS42 INS34 INS43 INS42 INS60 INS21 MOV21 INS42 INS42 INS32 INS52 INS42 INS52 INS42 INS22 INS42 INS52 INS42 INS22 INS42 INS42 INS42 INS45 INS32 INS45 INS21 INS41 MOV32 INS42 INS42 INS38 MOV27 INS42 INS42 UPD42 MOV42 INS42 INS42 INS8 INS45 INS32 INS41 INS27 INS8 INS25 INS43 INS59 INS43 INS59 INS27 INS8 INS8 MOV32 INS8 INS27 INS8 INS27 INS8 UPD27 MOV27 INS8 INS27 INS8 INS39 INS59 INS74 INS59 INS32 INS8 INS7 INS32 INS8 INS27 INS8 INS42 INS42 INS42 UPD42 INS42 INS42 INS32 INS42 INS42 INS74 INS42 INS42 INS42 INS74 INS42 INS42 INS74 INS42 INS42 INS42 INS42 INS43 INS59 INS32 INS8 INS42 INS42 INS32 INS8 INS43 INS59 INS32 INS32 INS42 INS7 INS42 INS42 INS42 INS74 INS42 INS39 INS59 INS7 INS32 INS42 INS52 INS42 INS52 INS42 INS42 INS42 INS52 INS32 INS42 INS53 INS42 INS42 INS45 INS32 INS34 INS41 MOV27 INS8 INS42 INS42 INS32 INS42 INS42 INS32 INS34 INS42 INS33 INS25 INS21 MOV21 INS42 INS33 INS18 INS32 INS32 INS18 INS27 MOV32 INS18 MOV32 INS32 INS18 INS42 INS32 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS60 MOV25 INS42 INS32 INS42 INS42 INS60 INS60 INS25 INS42 INS32 MOV25 INS21 INS18 INS32 UPD42 MOV42 INS42 INS42 INS43 INS43 INS43 INS43 INS43 INS43 INS42 INS42 INS32 INS42 INS42 INS42 INS21 INS21 INS42 INS42 INS25 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS43 INS43 INS43 INS42 INS32 INS42 INS42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS45 INS14 INS27 INS42 INS42 INS45 INS21 INS41 INS42 INS42 INS14 INS42 INS42 INS42 INS32 INS8 INS7 INS42 INS42 INS42 INS42 MOV42 MOV33 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS43 INS59 INS43 INS59 INS27 INS32 INS42 INS43 INS59 INS43 INS59 INS27 INS8 INS42 INS42 INS37 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS38 INS8 INS8 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 INS34 INS11 UPD42 MOV42 INS42 INS42 MOV21 MOV21 INS43 INS27 INS36 INS36 INS32 INS45 INS43 INS32 INS42 INS42 INS21 INS42 MOV32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 UPD42 MOV42 MOV33 INS21 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 UPD42 MOV42 INS33 INS21 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS21 INS10 INS39 INS36 INS42 INS45 INS45 MOV27 INS27 INS42 INS42 INS11 INS42 INS42 INS42 INS42 INS32 UPD45 UPD45 INS42 INS42 INS42 INS42 INS14 INS7 INS42 INS42 INS42 INS42 INS14 INS7 UPD45 INS36 INS45 MOV32 UPD45 INS45 INS42 INS45 INS45 INS42 INS42 INS7 INS27 MOV32 MOV32 INS39 INS34 INS42 INS42 INS27 INS43 INS32 INS42 INS32 INS43 INS32 INS42 INS32 UPD42 INS27 INS42 INS42 INS36 INS34 INS45 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD45 UPD42 INS45 UPD45 INS32 UPD45 INS32 UPD45 INS32 INS45 INS27 INS32 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 DEL14 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL29 DEL83 DEL39 DEL59 DEL23 DEL42 DEL34 DEL7 DEL21 DEL42 DEL42 DEL32 DEL21 DEL8 DEL42 DEL42 DEL32 DEL21 DEL8 DEL54 DEL66 DEL42 DEL42 DEL68 DEL65 DEL66 DEL66 DEL66 DEL42 DEL68 DEL65 DEL66 DEL65 DEL29 DEL39 DEL42 DEL8 DEL8 DEL54 DEL32 DEL21 DEL8 DEL31 DEL42 DEL9 DEL7 DEL21 DEL39 DEL42 DEL9 DEL59 DEL60 DEL42 DEL42 DEL32 DEL21 DEL42 DEL9 DEL7 DEL21 DEL8 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL21 DEL8 DEL42 DEL42 DEL9 DEL45 DEL32 DEL21 DEL8 DEL25 DEL25 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL32 DEL21 DEL8 DEL54 DEL8 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL54 DEL8 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL32 DEL21 DEL8 DEL54 DEL8 DEL52 DEL42 DEL32 DEL52 DEL42 DEL34 DEL32 DEL21 DEL8 DEL25 DEL8 DEL8 DEL12 DEL54 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL39 DEL42 DEL42 DEL32 DEL11 DEL42 DEL32 DEL21 DEL8 DEL36 DEL34 DEL16 DEL42 DEL42 DEL32 DEL38 DEL41 DEL8 DEL25 DEL42 DEL42 DEL32 DEL38 DEL41 DEL8 DEL25 DEL27 DEL36 DEL38 DEL36 DEL27 DEL36 DEL38 DEL36 DEL36 DEL27 DEL36 DEL27 DEL42 DEL41 DEL42 DEL32 DEL42 DEL8 DEL24 DEL34 DEL27 DEL42 DEL37 DEL21 DEL8 DEL61 DEL32