HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.

-import org.apache.hadoop.fs.FileSystem;
-   * Number of times to retry creating a file when there are transient 
+   * Number of times to retry creating a file when there are transient
-  protected DFSPacket createPacket(int packetSize, int chunksPerPkt, long offsetInBlock,
-      long seqno, boolean lastPacketInBlock) throws InterruptedIOException {
+  protected DFSPacket createPacket(int packetSize, int chunksPerPkt,
+      long offsetInBlock, long seqno, boolean lastPacketInBlock)
+      throws InterruptedIOException {
-    for (int i = 0; i < currentNodes.length; i++) {
-      value[i] = currentNodes[i];
-    }
+    System.arraycopy(currentNodes, 0, value, 0, currentNodes.length);
-  private DFSOutputStream(DFSClient dfsClient, String src, Progressable progress,
-      HdfsFileStatus stat, DataChecksum checksum) throws IOException {
+  private DFSOutputStream(DFSClient dfsClient, String src,
+      Progressable progress, HdfsFileStatus stat, DataChecksum checksum) {
-    this.cachingStrategy = new AtomicReference<CachingStrategy>(
+    this.cachingStrategy = new AtomicReference<>(
-          + HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY + " (=" + bytesPerChecksum
-          + ") must divide block size (=" + blockSize + ").");
+          + HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY
+          + " (=" + bytesPerChecksum + ") must divide block size (=" +
+          blockSize + ").");
-  protected DFSOutputStream(DFSClient dfsClient, String src, HdfsFileStatus stat,
-      EnumSet<CreateFlag> flag, Progressable progress,
-      DataChecksum checksum, String[] favoredNodes, boolean createStreamer)
-      throws IOException {
+  protected DFSOutputStream(DFSClient dfsClient, String src,
+      HdfsFileStatus stat, EnumSet<CreateFlag> flag, Progressable progress,
+      DataChecksum checksum, String[] favoredNodes, boolean createStreamer) {
-    computePacketChunkSize(dfsClient.getConf().getWritePacketSize(), bytesPerChecksum);
+    computePacketChunkSize(dfsClient.getConf().getWritePacketSize(),
+        bytesPerChecksum);
-      short replication, long blockSize, Progressable progress, int buffersize,
+      short replication, long blockSize, Progressable progress,
-    TraceScope scope =
-        dfsClient.newPathTraceScope("newStreamForCreate", src);
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("newStreamForCreate", src)) {
-              new EnumSetWritable<CreateFlag>(flag), createParent, replication,
+              new EnumSetWritable<>(flag), createParent, replication,
-    } finally {
-      scope.close();
-      streamer = new DataStreamer(lastBlock, stat, dfsClient, src, progress, checksum,
-          cachingStrategy, byteArrayManager);
+      streamer = new DataStreamer(lastBlock, stat, dfsClient, src, progress,
+          checksum, cachingStrategy, byteArrayManager);
-      streamer = new DataStreamer(stat, lastBlock != null ? lastBlock.getBlock() : null,
-          dfsClient, src, progress, checksum, cachingStrategy, byteArrayManager,
-          favoredNodes);
+      streamer = new DataStreamer(stat,
+          lastBlock != null ? lastBlock.getBlock() : null, dfsClient, src,
+          progress, checksum, cachingStrategy, byteArrayManager, favoredNodes);
-      EnumSet<CreateFlag> flags, int bufferSize, Progressable progress,
-      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,
-      String[] favoredNodes) throws IOException {
-    TraceScope scope =
-        dfsClient.newPathTraceScope("newStreamForAppend", src);
+      EnumSet<CreateFlag> flags, Progressable progress, LocatedBlock lastBlock,
+      HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)
+      throws IOException {
-      throw new IOException("Not support appending to a striping layout file yet.");
+      throw new IOException(
+          "Not support appending to a striping layout file yet.");
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("newStreamForAppend", src)) {
-    } finally {
-      scope.close();
-   * it guarantees that flushed data become visible to new readers. 
-   * It is not guaranteed that data has been flushed to 
-   * persistent store on the datanode. 
+   * it guarantees that flushed data become visible to new readers.
+   * It is not guaranteed that data has been flushed to
+   * persistent store on the datanode.
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hflush", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hflush", src)) {
-    } finally {
-      scope.close();
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hsync", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
-    } finally {
-      scope.close();
-   * The expected semantics is all data have flushed out to all replicas 
-   * and all replicas have done posix fsync equivalent - ie the OS has 
+   * The expected semantics is all data have flushed out to all replicas
+   * and all replicas have done posix fsync equivalent - ie the OS has
-    TraceScope scope =
-        dfsClient.newPathTraceScope("hsync", src);
-    try {
+    try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
-    } finally {
-      scope.close();
-          DFSClient.LOG.warn("Unable to persist blocks in hflush for " + src, ioe);
-          // If we got an error here, it might be because some other thread called
-          // close before our hflush completed. In that case, we should throw an
-          // exception that the stream is closed.
+          DFSClient.LOG.warn("Unable to persist blocks in hflush for " + src,
+              ioe);
+          // If we got an error here, it might be because some other thread
+          // called close before our hflush completed. In that case, we should
+          // throw an exception that the stream is closed.
-          // If we aren't closed but failed to sync, we should expose that to the
-          // caller.
+          // If we aren't closed but failed to sync, we should expose that to
+          // the caller.
-      // This kind of error doesn't mean that the stream itself is broken - just the
-      // flushing thread got interrupted. So, we shouldn't close down the writer,
-      // but instead just propagate the error
+      // This kind of error doesn't mean that the stream itself is broken - just
+      // the flushing thread got interrupted. So, we shouldn't close down the
+      // writer, but instead just propagate the error
-   * Waits till all existing data is flushed and confirmations 
-   * received from datanodes. 
+   * Waits till all existing data is flushed and confirmations
+   * received from datanodes.
-   * Aborts this output stream and releases any system 
+   * Aborts this output stream and releases any system
-        + (dfsClient.getConf().getHdfsTimeout()/1000) + " seconds expired."));
+        + (dfsClient.getConf().getHdfsTimeout() / 1000) + " seconds expired."));
-   * Closes this output stream and releases any system 
+   * Closes this output stream and releases any system
-    TraceScope scope =
-        dfsClient.newPathTraceScope("DFSOutputStream#close", src);
-    try {
+    try (TraceScope ignored =
+             dfsClient.newPathTraceScope("DFSOutputStream#close", src)) {
-    } finally {
-      scope.close();
-      TraceScope scope = dfsClient.getTracer().newScope("completeFile");
-      try {
+      try (TraceScope ignored =
+               dfsClient.getTracer().newScope("completeFile")) {
-      } finally {
-        scope.close();
-    } catch (ClosedChannelException e) {
+    } catch (ClosedChannelException ignored) {
-  // should be called holding (this) lock since setTestFilename() may 
+  // should be called holding (this) lock since setTestFilename() may
-            String msg = "Unable to close file because dfsclient " +
-                          " was unable to contact the HDFS servers." +
-                          " clientRunning " + dfsClient.clientRunning +
-                          " hdfsTimeout " + hdfsTimeout;
-            DFSClient.LOG.info(msg);
-            throw new IOException(msg);
+          String msg = "Unable to close file because dfsclient " +
+              " was unable to contact the HDFS servers. clientRunning " +
+              dfsClient.clientRunning + " hdfsTimeout " + hdfsTimeout;
+          DFSClient.LOG.info(msg);
+          throw new IOException(msg);
-  static LocatedBlock addBlock(DatanodeInfo[] excludedNodes, DFSClient dfsClient,
-      String src, ExtendedBlock prevBlock, long fileId, String[] favoredNodes)
-      throws IOException {
+  static LocatedBlock addBlock(DatanodeInfo[] excludedNodes,
+      DFSClient dfsClient, String src, ExtendedBlock prevBlock, long fileId,
+      String[] favoredNodes) throws IOException {
-        if (NotReplicatedYetException.class.getName().equals(e.getClassName())) {
+        if (NotReplicatedYetException.class.getName()
+            .equals(e.getClassName())) {

MOV21 UPD66 INS32 INS58 INS58 UPD66 UPD66 UPD66 INS58 INS58 UPD66 UPD66 INS58 UPD66 UPD66 UPD66 UPD66 INS58 INS42 INS42 INS42 INS34 INS42 INS34 INS40 MOV43 MOV59 MOV43 MOV59 MOV43 MOV59 MOV43 INS59 MOV43 MOV59 MOV43 MOV59 UPD74 UPD42 UPD42 UPD42 INS42 MOV32 UPD42 UPD42 INS58 UPD42 UPD42 MOV42 MOV43 MOV59 UPD42 UPD74 UPD45 DEL40 DEL26 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL7 DEL39 DEL42 DEL34 DEL59 DEL58 DEL42 DEL40 DEL27 DEL42 DEL37 DEL8 DEL24 DEL42 DEL43 DEL42 DEL43 DEL42 DEL43 DEL39 DEL42 DEL44 DEL60 DEL42 DEL43 DEL42 DEL42 DEL32 DEL21 DEL8 DEL39 DEL42 DEL44 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL60 DEL32 DEL21 DEL8 DEL42 DEL59 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL60 DEL42 DEL42 DEL32 DEL21 DEL8 DEL45