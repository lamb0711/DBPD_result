Merge HDFS-3042 (automatic failover) to trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1342112 13f79535-47bb-0310-9956-ffa450edef68

+import java.net.InetSocketAddress;
+import java.security.PrivilegedExceptionAction;
+import java.util.Collections;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import org.apache.hadoop.ha.ActiveStandbyElector.ActiveNotFoundException;
+import org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo;
+import org.apache.hadoop.ha.HAServiceProtocol.RequestSource;
+import org.apache.hadoop.ha.HAZKUtil.ZKAuthInfo;
+import org.apache.hadoop.ipc.Server;
+import org.apache.hadoop.security.AccessControlException;
-import org.apache.hadoop.util.Tool;
-import org.apache.hadoop.util.ToolRunner;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.security.authorize.PolicyProvider;
+import org.apache.hadoop.util.StringUtils;
+import org.apache.zookeeper.KeeperException;
+import org.apache.hadoop.util.ToolRunner;
+import com.google.common.base.Throwables;
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
-public abstract class ZKFailoverController implements Tool {
+public abstract class ZKFailoverController {
-  // TODO: this should be namespace-scoped
+  public static final String ZK_ACL_KEY = "ha.zookeeper.acl";
+  private static final String ZK_ACL_DEFAULT = "world:anyone:rwcda";
+  public static final String ZK_AUTH_KEY = "ha.zookeeper.auth";
+  /**
+   * All of the conf keys used by the ZKFC. This is used in order to allow
+   * them to be overridden on a per-nameservice or per-namenode basis.
+   */
+  protected static final String[] ZKFC_CONF_KEYS = new String[] {
+    ZK_QUORUM_KEY,
+    ZK_SESSION_TIMEOUT_KEY,
+    ZK_PARENT_ZNODE_KEY,
+    ZK_ACL_KEY,
+    ZK_AUTH_KEY
+  };
+  
+
+  /** Automatic failover is not enabled */
+  static final int ERR_CODE_AUTO_FAILOVER_NOT_ENABLED = 5;
+  /** Cannot connect to ZooKeeper */
+  static final int ERR_CODE_NO_ZK = 6;
-  private Configuration conf;
+  protected Configuration conf;
+  private String zkQuorum;
+  protected final HAServiceTarget localTarget;
-
-  private HAServiceTarget localTarget;
-
-  private String parentZnode;
+  protected ZKFCRpcServer rpcServer;
-  @Override
-  public void setConf(Configuration conf) {
+  /**
+   * A future nanotime before which the ZKFC will not join the election.
+   * This is used during graceful failover.
+   */
+  private long delayJoiningUntilNanotime = 0;
+
+  /** Executor on which {@link #scheduleRecheck(long)} schedules events */
+  private ScheduledExecutorService delayExecutor =
+    Executors.newScheduledThreadPool(1,
+        new ThreadFactoryBuilder().setDaemon(true)
+            .setNameFormat("ZKFC Delay timer #%d")
+            .build());
+
+  private ActiveAttemptRecord lastActiveAttemptRecord;
+  private Object activeAttemptRecordLock = new Object();
+
+  protected ZKFailoverController(Configuration conf, HAServiceTarget localTarget) {
+    this.localTarget = localTarget;
-    localTarget = getLocalTarget();
-  protected abstract HAServiceTarget getLocalTarget();  
+  protected abstract void loginAsFCUser() throws IOException;
+  protected abstract void checkRpcAdminAccess()
+      throws AccessControlException, IOException;
+  protected abstract InetSocketAddress getRpcAddressToBindTo();
+  protected abstract PolicyProvider getPolicyProvider();
+  /**
+   * Return the name of a znode inside the configured parent znode in which
+   * the ZKFC will do all of its work. This is so that multiple federated
+   * nameservices can run on the same ZK quorum without having to manually
+   * configure them to separate subdirectories.
+   */
+  protected abstract String getScopeInsideParentNode();
-  @Override
-  public Configuration getConf() {
-    return conf;
+  public HAServiceTarget getLocalTarget() {
+    return localTarget;
-
-  @Override
+  
-    // TODO: need to hook DFS here to find the NN keytab info, etc,
-    // similar to what DFSHAAdmin does. Annoying that this is in common.
+    if (!localTarget.isAutoFailoverEnabled()) {
+      LOG.fatal("Automatic failover is not enabled for " + localTarget + "." +
+          " Please ensure that automatic failover is enabled in the " +
+          "configuration before running the ZK failover controller.");
+      return ERR_CODE_AUTO_FAILOVER_NOT_ENABLED;
+    }
+    loginAsFCUser();
+          } finally {
+            if (elector != null) {
+              elector.terminateConnection();
+            }
+
-    if (!elector.parentZNodeExists()) {
-      LOG.fatal("Unable to start failover controller. " +
-          "Parent znode does not exist.\n" +
-          "Run with -formatZK flag to initialize ZooKeeper.");
-      return ERR_CODE_NO_PARENT_ZNODE;
+    try {
+      if (!elector.parentZNodeExists()) {
+        LOG.fatal("Unable to start failover controller. " +
+            "Parent znode does not exist.\n" +
+            "Run with -formatZK flag to initialize ZooKeeper.");
+        return ERR_CODE_NO_PARENT_ZNODE;
+      }
+    } catch (IOException ioe) {
+      if (ioe.getCause() instanceof KeeperException.ConnectionLossException) {
+        LOG.fatal("Unable to start failover controller. Unable to connect " +
+            "to ZooKeeper quorum at " + zkQuorum + ". Please check the " +
+            "configured value for " + ZK_QUORUM_KEY + " and ensure that " +
+            "ZooKeeper is running.");
+        return ERR_CODE_NO_ZK;
+      } else {
+        throw ioe;
+      }
+    initRPC();
-    mainLoop();
+    startRPC();
+    try {
+      mainLoop();
+    } finally {
+      rpcServer.stopAndJoin();
+      
+      elector.quitElection(true);
+      healthMonitor.shutdown();
+      healthMonitor.join();
+    }
+    String parentZnode = getParentZnode();
+  
+  protected void initRPC() throws IOException {
+    InetSocketAddress bindAddr = getRpcAddressToBindTo();
+    rpcServer = new ZKFCRpcServer(conf, bindAddr, this, getPolicyProvider());
+  }
+
+  protected void startRPC() throws IOException {
+    rpcServer.start();
+  }
+
-    String zkQuorum = conf.get(ZK_QUORUM_KEY);
+    zkQuorum = conf.get(ZK_QUORUM_KEY);
-    parentZnode = conf.get(ZK_PARENT_ZNODE_KEY,
-        ZK_PARENT_ZNODE_DEFAULT);
-    // TODO: need ZK ACL support in config, also maybe auth!
-    List<ACL> zkAcls = Ids.OPEN_ACL_UNSAFE;
+    // Parse ACLs from configuration.
+    String zkAclConf = conf.get(ZK_ACL_KEY, ZK_ACL_DEFAULT);
+    zkAclConf = HAZKUtil.resolveConfIndirection(zkAclConf);
+    List<ACL> zkAcls = HAZKUtil.parseACLs(zkAclConf);
+    if (zkAcls.isEmpty()) {
+      zkAcls = Ids.CREATOR_ALL_ACL;
+    }
+    
+    // Parse authentication from configuration.
+    String zkAuthConf = conf.get(ZK_AUTH_KEY);
+    zkAuthConf = HAZKUtil.resolveConfIndirection(zkAuthConf);
+    List<ZKAuthInfo> zkAuths;
+    if (zkAuthConf != null) {
+      zkAuths = HAZKUtil.parseAuth(zkAuthConf);
+    } else {
+      zkAuths = Collections.emptyList();
+    }
+    // Sanity check configuration.
-        zkTimeout, parentZnode, zkAcls, new ElectorCallbacks());
+        zkTimeout, getParentZnode(), zkAcls, zkAuths,
+        new ElectorCallbacks());
+  private String getParentZnode() {
+    String znode = conf.get(ZK_PARENT_ZNODE_KEY,
+        ZK_PARENT_ZNODE_DEFAULT);
+    if (!znode.endsWith("/")) {
+      znode += "/";
+    }
+    return znode + getScopeInsideParentNode();
+  }
+
-  private synchronized void becomeActive() {
+  private synchronized void becomeActive() throws ServiceFailedException {
-          conf, FailoverController.getRpcTimeoutToNewActive(conf)));
-      LOG.info("Successfully transitioned " + localTarget +
-          " to active state");
+          conf, FailoverController.getRpcTimeoutToNewActive(conf)),
+          createReqInfo());
+      String msg = "Successfully transitioned " + localTarget +
+          " to active state";
+      LOG.info(msg);
+      recordActiveAttempt(new ActiveAttemptRecord(true, msg));
+
-      LOG.fatal("Couldn't make " + localTarget + " active", t);
-      elector.quitElection(true);
+      String msg = "Couldn't make " + localTarget + " active";
+      LOG.fatal(msg, t);
+      
+      recordActiveAttempt(new ActiveAttemptRecord(false, msg + "\n" +
+          StringUtils.stringifyException(t)));
+
+      if (t instanceof ServiceFailedException) {
+        throw (ServiceFailedException)t;
+      } else {
+        throw new ServiceFailedException("Couldn't transition to active",
+            t);
+      }
+  /**
+   * Store the results of the last attempt to become active.
+   * This is used so that, during manually initiated failover,
+   * we can report back the results of the attempt to become active
+   * to the initiator of the failover.
+   */
+  private void recordActiveAttempt(
+      ActiveAttemptRecord record) {
+    synchronized (activeAttemptRecordLock) {
+      lastActiveAttemptRecord = record;
+      activeAttemptRecordLock.notifyAll();
+    }
+  }
+
+  /**
+   * Wait until one of the following events:
+   * <ul>
+   * <li>Another thread publishes the results of an attempt to become active
+   * using {@link #recordActiveAttempt(ActiveAttemptRecord)}</li>
+   * <li>The node enters bad health status</li>
+   * <li>The specified timeout elapses</li>
+   * </ul>
+   * 
+   * @param timeoutMillis number of millis to wait
+   * @return the published record, or null if the timeout elapses or the
+   * service becomes unhealthy 
+   * @throws InterruptedException if the thread is interrupted.
+   */
+  private ActiveAttemptRecord waitForActiveAttempt(int timeoutMillis)
+      throws InterruptedException {
+    long st = System.nanoTime();
+    long waitUntil = st + TimeUnit.NANOSECONDS.convert(
+        timeoutMillis, TimeUnit.MILLISECONDS);
+    
+    do {
+      // periodically check health state, because entering an
+      // unhealthy state could prevent us from ever attempting to
+      // become active. We can detect this and respond to the user
+      // immediately.
+      synchronized (this) {
+        if (lastHealthState != State.SERVICE_HEALTHY) {
+          // early out if service became unhealthy
+          return null;
+        }
+      }
+
+      synchronized (activeAttemptRecordLock) {
+        if ((lastActiveAttemptRecord != null &&
+            lastActiveAttemptRecord.nanoTime >= st)) {
+          return lastActiveAttemptRecord;
+        }
+        // Only wait 1sec so that we periodically recheck the health state
+        // above.
+        activeAttemptRecordLock.wait(1000);
+      }
+    } while (System.nanoTime() < waitUntil);
+    
+    // Timeout elapsed.
+    LOG.warn(timeoutMillis + "ms timeout elapsed waiting for an attempt " +
+        "to become active");
+    return null;
+  }
+
+  private StateChangeRequestInfo createReqInfo() {
+    return new StateChangeRequestInfo(RequestSource.REQUEST_BY_ZKFC);
+  }
+
-      localTarget.getProxy(conf, timeout).transitionToStandby();
+      localTarget.getProxy(conf, timeout).transitionToStandby(createReqInfo());
+  
+
+  private synchronized void fenceOldActive(byte[] data) {
+    HAServiceTarget target = dataToTarget(data);
+    
+    try {
+      doFence(target);
+    } catch (Throwable t) {
+      recordActiveAttempt(new ActiveAttemptRecord(false, "Unable to fence old active: " + StringUtils.stringifyException(t)));
+      Throwables.propagate(t);
+    }
+  }
+  
+  private void doFence(HAServiceTarget target) {
+    LOG.info("Should fence: " + target);
+    boolean gracefulWorked = new FailoverController(conf,
+        RequestSource.REQUEST_BY_ZKFC).tryGracefulFence(target);
+    if (gracefulWorked) {
+      // It's possible that it's in standby but just about to go into active,
+      // no? Is there some race here?
+      LOG.info("Successfully transitioned " + target + " to standby " +
+          "state without fencing");
+      return;
+    }
+    
+    try {
+      target.checkFencingConfigured();
+    } catch (BadFencingConfigurationException e) {
+      LOG.error("Couldn't fence old active " + target, e);
+      recordActiveAttempt(new ActiveAttemptRecord(false, "Unable to fence old active"));
+      throw new RuntimeException(e);
+    }
+    
+    if (!target.getFencer().fence(target)) {
+      throw new RuntimeException("Unable to fence " + target);
+    }
+  }
+
+
+  /**
+   * Request from graceful failover to cede active role. Causes
+   * this ZKFC to transition its local node to standby, then quit
+   * the election for the specified period of time, after which it
+   * will rejoin iff it is healthy.
+   */
+  void cedeActive(final int millisToCede)
+      throws AccessControlException, ServiceFailedException, IOException {
+    try {
+      UserGroupInformation.getLoginUser().doAs(new PrivilegedExceptionAction<Void>() {
+        @Override
+        public Void run() throws Exception {
+          doCedeActive(millisToCede);
+          return null;
+        }
+      });
+    } catch (InterruptedException e) {
+      throw new IOException(e);
+    }
+  }
+  
+  private void doCedeActive(int millisToCede) 
+      throws AccessControlException, ServiceFailedException, IOException {
+    int timeout = FailoverController.getGracefulFenceTimeout(conf);
+
+    // Lock elector to maintain lock ordering of elector -> ZKFC
+    synchronized (elector) {
+      synchronized (this) {
+        if (millisToCede <= 0) {
+          delayJoiningUntilNanotime = 0;
+          recheckElectability();
+          return;
+        }
+  
+        LOG.info("Requested by " + UserGroupInformation.getCurrentUser() +
+            " at " + Server.getRemoteAddress() + " to cede active role.");
+        boolean needFence = false;
+        try {
+          localTarget.getProxy(conf, timeout).transitionToStandby(createReqInfo());
+          LOG.info("Successfully ensured local node is in standby mode");
+        } catch (IOException ioe) {
+          LOG.warn("Unable to transition local node to standby: " +
+              ioe.getLocalizedMessage());
+          LOG.warn("Quitting election but indicating that fencing is " +
+              "necessary");
+          needFence = true;
+        }
+        delayJoiningUntilNanotime = System.nanoTime() +
+            TimeUnit.MILLISECONDS.toNanos(millisToCede);
+        elector.quitElection(needFence);
+      }
+    }
+    recheckElectability();
+  }
+  
+  /**
+   * Coordinate a graceful failover to this node.
+   * @throws ServiceFailedException if the node fails to become active
+   * @throws IOException some other error occurs
+   */
+  void gracefulFailoverToYou() throws ServiceFailedException, IOException {
+    try {
+      UserGroupInformation.getLoginUser().doAs(new PrivilegedExceptionAction<Void>() {
+        @Override
+        public Void run() throws Exception {
+          doGracefulFailover();
+          return null;
+        }
+        
+      });
+    } catch (InterruptedException e) {
+      throw new IOException(e);
+    }
+  }
+
+  /**
+   * Coordinate a graceful failover. This proceeds in several phases:
+   * 1) Pre-flight checks: ensure that the local node is healthy, and
+   * thus a candidate for failover.
+   * 2) Determine the current active node. If it is the local node, no
+   * need to failover - return success.
+   * 3) Ask that node to yield from the election for a number of seconds.
+   * 4) Allow the normal election path to run in other threads. Wait until
+   * we either become unhealthy or we see an election attempt recorded by
+   * the normal code path.
+   * 5) Allow the old active to rejoin the election, so a future
+   * failback is possible.
+   */
+  private void doGracefulFailover()
+      throws ServiceFailedException, IOException, InterruptedException {
+    int timeout = FailoverController.getGracefulFenceTimeout(conf) * 2;
+    
+    // Phase 1: pre-flight checks
+    checkEligibleForFailover();
+    
+    // Phase 2: determine old/current active node. Check that we're not
+    // ourselves active, etc.
+    HAServiceTarget oldActive = getCurrentActive();
+    if (oldActive == null) {
+      // No node is currently active. So, if we aren't already
+      // active ourselves by means of a normal election, then there's
+      // probably something preventing us from becoming active.
+      throw new ServiceFailedException(
+          "No other node is currently active.");
+    }
+    
+    if (oldActive.getAddress().equals(localTarget.getAddress())) {
+      LOG.info("Local node " + localTarget + " is already active. " +
+          "No need to failover. Returning success.");
+      return;
+    }
+    
+    // Phase 3: ask the old active to yield from the election.
+    LOG.info("Asking " + oldActive + " to cede its active state for " +
+        timeout + "ms");
+    ZKFCProtocol oldZkfc = oldActive.getZKFCProxy(conf, timeout);
+    oldZkfc.cedeActive(timeout);
+
+    // Phase 4: wait for the normal election to make the local node
+    // active.
+    ActiveAttemptRecord attempt = waitForActiveAttempt(timeout + 60000);
+    
+    if (attempt == null) {
+      // We didn't even make an attempt to become active.
+      synchronized(this) {
+        if (lastHealthState != State.SERVICE_HEALTHY) {
+          throw new ServiceFailedException("Unable to become active. " +
+            "Service became unhealthy while trying to failover.");          
+        }
+      }
+      
+      throw new ServiceFailedException("Unable to become active. " +
+          "Local node did not get an opportunity to do so from ZooKeeper, " +
+          "or the local node took too long to transition to active.");
+    }
+
+    // Phase 5. At this point, we made some attempt to become active. So we
+    // can tell the old active to rejoin if it wants. This allows a quick
+    // fail-back if we immediately crash.
+    oldZkfc.cedeActive(-1);
+    
+    if (attempt.succeeded) {
+      LOG.info("Successfully became active. " + attempt.status);
+    } else {
+      // Propagate failure
+      String msg = "Failed to become active. " + attempt.status;
+      throw new ServiceFailedException(msg);
+    }
+  }
+
+  /**
+   * Ensure that the local node is in a healthy state, and thus
+   * eligible for graceful failover.
+   * @throws ServiceFailedException if the node is unhealthy
+   */
+  private synchronized void checkEligibleForFailover()
+      throws ServiceFailedException {
+    // Check health
+    if (this.getLastHealthState() != State.SERVICE_HEALTHY) {
+      throw new ServiceFailedException(
+          localTarget + " is not currently healthy. " +
+          "Cannot be failover target");
+    }
+  }
+
+  /**
+   * @return an {@link HAServiceTarget} for the current active node
+   * in the cluster, or null if no node is active.
+   * @throws IOException if a ZK-related issue occurs
+   * @throws InterruptedException if thread is interrupted 
+   */
+  private HAServiceTarget getCurrentActive()
+      throws IOException, InterruptedException {
+    synchronized (elector) {
+      synchronized (this) {
+        byte[] activeData;
+        try {
+          activeData = elector.getActiveData();
+        } catch (ActiveNotFoundException e) {
+          return null;
+        } catch (KeeperException ke) {
+          throw new IOException(
+              "Unexpected ZooKeeper issue fetching active node info", ke);
+        }
+        
+        HAServiceTarget oldActive = dataToTarget(activeData);
+        return oldActive;
+      }
+    }
+  }
+
+  /**
+   * Check the current state of the service, and join the election
+   * if it should be in the election.
+   */
+  private void recheckElectability() {
+    // Maintain lock ordering of elector -> ZKFC
+    synchronized (elector) {
+      synchronized (this) {
+        boolean healthy = lastHealthState == State.SERVICE_HEALTHY;
+    
+        long remainingDelay = delayJoiningUntilNanotime - System.nanoTime(); 
+        if (remainingDelay > 0) {
+          if (healthy) {
+            LOG.info("Would have joined master election, but this node is " +
+                "prohibited from doing so for " +
+                TimeUnit.NANOSECONDS.toMillis(remainingDelay) + " more ms");
+          }
+          scheduleRecheck(remainingDelay);
+          return;
+        }
+    
+        switch (lastHealthState) {
+        case SERVICE_HEALTHY:
+          elector.joinElection(targetToData(localTarget));
+          break;
+          
+        case INITIALIZING:
+          LOG.info("Ensuring that " + localTarget + " does not " +
+              "participate in active master election");
+          elector.quitElection(false);
+          break;
+    
+        case SERVICE_UNHEALTHY:
+        case SERVICE_NOT_RESPONDING:
+          LOG.info("Quitting master election for " + localTarget +
+              " and marking that fencing is necessary");
+          elector.quitElection(true);
+          break;
+          
+        case HEALTH_MONITOR_FAILED:
+          fatalError("Health monitor failed!");
+          break;
+          
+        default:
+          throw new IllegalArgumentException("Unhandled state:" + lastHealthState);
+        }
+      }
+    }
+  }
+  
+  /**
+   * Schedule a call to {@link #recheckElectability()} in the future.
+   */
+  private void scheduleRecheck(long whenNanos) {
+    delayExecutor.schedule(
+        new Runnable() {
+          @Override
+          public void run() {
+            try {
+              recheckElectability();
+            } catch (Throwable t) {
+              fatalError("Failed to recheck electability: " +
+                  StringUtils.stringifyException(t));
+            }
+          }
+        },
+        whenNanos, TimeUnit.NANOSECONDS);
+  }
-  State getLastHealthState() {
+  synchronized State getLastHealthState() {
+
+  private synchronized void setLastHealthState(HealthMonitor.State newState) {
+    LOG.info("Local service " + localTarget +
+        " entered state: " + newState);
+    lastHealthState = newState;
+  }
+  
+  @VisibleForTesting
+  ZKFCRpcServer getRpcServerForTests() {
+    return rpcServer;
+  }
-    public void becomeActive() {
+    public void becomeActive() throws ServiceFailedException {
-      HAServiceTarget target = dataToTarget(data);
-      
-      LOG.info("Should fence: " + target);
-      boolean gracefulWorked = new FailoverController(conf)
-          .tryGracefulFence(target);
-      if (gracefulWorked) {
-        // It's possible that it's in standby but just about to go into active,
-        // no? Is there some race here?
-        LOG.info("Successfully transitioned " + target + " to standby " +
-            "state without fencing");
-        return;
-      }
-      
-      try {
-        target.checkFencingConfigured();
-      } catch (BadFencingConfigurationException e) {
-        LOG.error("Couldn't fence old active " + target, e);
-        // TODO: see below todo
-        throw new RuntimeException(e);
-      }
-      
-      if (!target.getFencer().fence(target)) {
-        // TODO: this will end up in some kind of tight loop,
-        // won't it? We need some kind of backoff
-        throw new RuntimeException("Unable to fence " + target);
+      ZKFailoverController.this.fenceOldActive(data);
+    }
+    
+    @Override
+    public String toString() {
+      synchronized (ZKFailoverController.this) {
+        return "Elector callbacks for " + localTarget;
-      LOG.info("Local service " + localTarget +
-          " entered state: " + newState);
-      switch (newState) {
-      case SERVICE_HEALTHY:
-        LOG.info("Joining master election for " + localTarget);
-        elector.joinElection(targetToData(localTarget));
-        break;
-        
-      case INITIALIZING:
-        LOG.info("Ensuring that " + localTarget + " does not " +
-            "participate in active master election");
-        elector.quitElection(false);
-        break;
-
-      case SERVICE_UNHEALTHY:
-      case SERVICE_NOT_RESPONDING:
-        LOG.info("Quitting master election for " + localTarget +
-            " and marking that fencing is necessary");
-        elector.quitElection(true);
-        break;
-        
-      case HEALTH_MONITOR_FAILED:
-        fatalError("Health monitor failed!");
-        break;
-        
-      default:
-        throw new IllegalArgumentException("Unhandled state:" + newState);
-      }
-      
-      lastHealthState = newState;
+      setLastHealthState(newState);
+      recheckElectability();
+  
+  private static class ActiveAttemptRecord {
+    private final boolean succeeded;
+    private final String status;
+    private final long nanoTime;
+    
+    public ActiveAttemptRecord(boolean succeeded, String status) {
+      this.succeeded = succeeded;
+      this.status = status;
+      this.nanoTime = System.nanoTime();
+    }
+  }
+

MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 MOV23 MOV23 MOV31 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS23 INS23 INS23 INS23 INS23 INS23 INS23 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 MOV31 INS31 INS31 INS31 INS31 INS31 INS31 MOV31 INS31 INS31 INS31 INS55 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS83 INS43 INS59 INS29 INS83 INS83 INS83 INS5 INS59 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS83 INS39 INS59 UPD83 INS83 MOV43 INS59 UPD83 INS83 INS83 INS43 INS59 INS29 INS83 INS39 INS59 INS29 INS83 INS43 INS59 INS43 INS83 INS43 INS59 UPD83 UPD42 INS44 MOV21 INS83 INS83 INS39 INS42 INS43 INS83 INS83 INS39 INS42 INS43 INS43 INS83 INS83 INS43 INS42 INS43 UPD42 INS29 INS83 INS83 INS43 INS42 UPD43 UPD42 INS83 INS39 INS42 INS43 INS8 INS83 INS39 INS42 INS43 INS8 MOV60 INS83 INS43 INS42 INS8 INS43 INS29 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS43 INS42 INS44 INS43 INS8 INS83 INS43 INS42 INS8 INS83 INS83 INS39 INS42 MOV44 INS8 UPD83 UPD42 INS44 INS29 INS39 INS42 INS44 INS43 INS43 INS43 INS8 INS83 INS39 INS42 INS44 INS43 INS43 INS43 INS8 INS29 INS39 INS42 INS43 INS43 INS8 INS29 INS83 INS39 INS42 INS43 INS43 INS43 INS8 INS29 INS83 INS83 INS39 INS42 INS43 INS8 INS29 INS83 MOV43 INS42 INS43 INS43 INS8 INS29 UPD83 INS42 INS8 INS29 INS83 INS39 INS42 INS44 INS8 INS83 INS83 INS83 INS39 INS42 MOV44 INS8 INS78 INS43 INS42 INS8 INS31 INS31 INS31 INS83 INS83 INS42 INS23 INS23 INS23 INS31 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS45 INS65 INS43 INS85 INS42 INS3 INS65 INS42 INS34 INS65 INS42 INS34 INS42 INS42 INS42 INS65 INS42 INS34 INS65 INS42 INS42 INS32 INS42 UPD42 INS42 INS42 INS14 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS65 INS42 UPD42 INS25 INS21 INS54 INS21 INS21 INS54 INS60 INS42 INS60 INS21 INS42 INS21 INS21 INS21 INS25 INS60 INS21 INS60 INS25 INS42 INS60 INS25 INS41 INS42 INS65 INS43 INS42 INS51 INS65 INS65 INS65 INS65 INS42 INS39 INS42 INS42 INS60 INS60 INS19 INS21 INS41 INS42 INS41 MOV60 INS54 INS43 INS42 INS65 INS83 INS39 INS42 INS42 INS42 INS42 INS54 INS39 INS42 INS42 INS42 INS42 INS60 INS51 INS21 INS65 INS65 INS65 INS42 INS42 INS54 INS65 INS42 INS42 INS42 INS60 INS21 INS60 INS25 INS25 INS21 INS60 INS21 INS60 INS25 INS21 INS25 INS65 INS65 INS42 INS25 INS65 INS65 INS65 INS42 INS42 INS51 INS65 INS51 INS65 INS39 INS42 INS21 MOV21 MOV21 INS42 INS42 INS41 INS43 MOV78 INS83 INS39 INS42 INS44 INS8 MOV78 INS83 INS43 INS42 INS8 INS78 INS83 INS39 INS42 INS44 INS8 INS83 INS83 INS39 INS59 INS83 INS83 INS43 INS59 INS83 INS83 INS39 INS59 INS83 INS42 INS44 INS44 INS8 INS66 INS66 INS42 INS5 INS4 INS66 INS66 INS66 INS66 INS66 INS65 INS66 INS42 INS42 INS34 INS32 INS43 INS42 INS66 INS66 INS66 INS66 UPD42 INS38 INS8 INS32 INS8 INS12 INS32 INS32 INS8 INS8 INS43 INS59 INS43 INS59 INS7 INS32 INS7 INS7 INS32 INS8 INS43 INS59 INS7 INS74 INS59 INS27 INS8 INS8 INS43 INS59 INS38 INS8 INS27 INS66 INS66 INS66 INS66 INS42 INS42 INS8 INS66 INS66 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS42 INS66 INS66 INS66 INS42 INS66 INS39 INS59 INS39 INS59 INS8 INS27 INS32 INS33 INS14 INS8 INS12 INS42 INS66 INS66 INS66 INS66 INS8 INS12 INS39 INS59 INS42 INS8 INS32 INS66 INS42 INS66 INS42 INS66 INS8 INS12 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS39 INS59 INS32 INS43 INS59 INS27 INS8 INS32 INS8 INS32 INS43 INS59 INS32 INS43 INS59 INS27 INS8 INS32 INS40 INS8 INS8 INS66 INS66 INS42 INS66 INS27 INS8 INS66 INS65 INS66 INS66 INS42 INS66 INS42 INS66 INS42 INS8 INS66 INS66 INS42 INS8 INS66 INS65 INS66 INS32 INS42 INS42 INS5 INS42 INS21 INS42 INS51 INS42 INS43 INS42 INS21 INS21 INS42 INS42 INS42 INS42 INS39 INS42 INS43 INS42 INS21 INS21 INS21 INS43 INS85 INS42 INS42 INS42 INS42 INS42 INS68 INS32 INS42 INS42 INS22 INS42 INS32 INS21 INS41 INS42 MOV25 INS44 INS8 INS42 INS42 MOV21 INS21 INS21 INS21 INS21 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS14 INS42 INS42 INS42 MOV32 UPD42 INS32 INS42 INS32 INS32 INS42 INS42 INS21 INS42 INS42 INS32 INS42 INS32 INS43 INS43 INS42 INS42 INS33 MOV21 INS21 INS42 INS42 MOV32 INS32 INS21 INS42 INS32 INS60 INS21 INS21 INS21 INS68 INS42 INS32 INS42 INS27 INS51 INS51 INS32 INS42 INS42 INS42 INS27 INS43 INS40 INS21 INS44 INS8 INS21 INS44 INS8 INS42 INS32 INS51 INS42 INS21 INS44 INS8 INS42 INS27 INS42 INS42 INS42 INS32 INS42 INS33 INS53 INS32 INS42 INS32 INS21 INS41 INS42 INS42 INS27 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS33 INS51 INS53 INS42 INS42 INS38 INS21 INS60 INS53 INS32 INS40 INS53 INS42 INS51 INS51 INS68 INS42 INS42 INS14 INS42 INS40 INS39 INS85 INS32 INS52 INS8 INS40 INS32 INS32 INS42 INS7 INS7 INS7 INS42 INS42 INS69 INS32 INS42 INS45 INS52 INS42 INS42 INS42 INS32 INS42 INS43 INS42 INS25 INS32 INS32 INS32 INS32 INS42 INS42 INS43 INS42 INS42 INS52 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS32 INS42 INS42 INS42 INS45 INS7 INS42 INS43 INS59 INS32 INS60 INS25 INS7 INS32 INS42 INS69 INS42 INS42 INS42 INS32 INS52 INS8 INS42 INS8 INS42 INS42 INS42 INS45 INS45 INS42 INS32 INS43 INS42 INS21 INS21 INS21 INS32 INS43 INS42 INS53 INS42 INS42 INS42 INS52 INS8 INS32 INS43 INS42 INS53 INS32 INS34 INS42 INS14 INS42 INS42 INS42 INS42 INS32 INS45 INS42 INS45 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS27 INS52 INS8 INS14 INS34 INS32 INS43 INS59 INS14 INS52 INS42 INS14 INS52 INS8 INS52 MOV8 INS42 INS43 INS1 INS52 INS42 INS42 INS42 INS41 INS42 INS42 INS42 INS22 INS42 INS22 INS42 INS22 INS32 INS39 INS14 INS42 INS9 INS42 INS42 INS27 INS42 INS62 INS8 INS8 INS42 INS42 INS42 MOV42 MOV9 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS32 INS42 INS32 INS42 INS42 INS45 INS32 INS42 INS42 MOV27 INS42 INS42 INS14 INS43 INS59 INS62 INS8 INS8 INS42 INS42 INS42 INS42 INS43 INS40 INS42 INS42 INS40 INS25 INS25 INS21 INS32 INS42 INS42 INS42 INS32 INS32 INS40 INS32 INS32 INS42 INS14 INS42 INS14 INS25 INS21 INS60 INS54 INS21 INS21 INS32 INS42 INS14 INS42 INS14 INS42 INS42 INS42 INS43 INS45 INS42 INS42 INS27 INS42 INS34 INS25 INS43 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS43 INS42 INS43 INS27 INS60 INS54 INS60 INS41 INS60 INS60 INS25 INS42 INS31 INS42 INS27 INS52 INS42 INS52 INS42 INS52 INS42 INS42 INS42 INS43 INS45 INS42 INS45 INS45 INS45 INS32 INS43 INS21 INS41 INS53 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS9 INS42 INS42 INS42 MOV27 INS42 UPD42 INS14 INS42 INS43 INS53 INS53 INS42 INS27 INS8 INS36 INS8 INS32 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS74 INS1 INS43 INS42 INS27 INS8 INS32 INS39 INS59 INS8 INS12 INS7 INS32 INS42 INS42 INS74 INS1 INS43 INS42 INS42 INS45 INS42 INS45 INS45 INS27 INS8 INS42 INS45 INS45 INS45 INS45 INS40 INS45 INS40 INS42 INS42 INS42 INS45 INS45 INS5 INS59 INS8 INS12 INS12 INS43 INS59 INS42 INS39 INS59 INS39 INS59 INS27 INS8 UPD42 MOV78 INS83 INS39 INS42 INS8 INS45 INS42 UPD42 MOV42 INS42 INS42 INS40 INS32 INS42 INS42 INS42 INS43 INS9 INS27 INS42 INS11 INS14 INS42 INS40 INS41 INS27 INS41 INS42 INS42 INS34 INS43 INS9 INS27 INS43 INS9 INS45 INS43 INS43 INS31 INS42 INS42 INS34 INS21 INS21 INS41 INS42 INS42 INS27 INS42 INS9 INS21 INS21 INS44 INS8 INS42 INS27 INS42 INS42 INS42 INS43 INS43 INS31 INS42 INS42 INS40 INS53 INS39 INS85 INS42 INS21 INS44 INS8 INS44 INS8 INS42 INS42 INS32 INS42 INS27 INS42 INS27 INS42 INS34 INS25 INS21 INS41 INS54 INS42 INS42 INS27 INS42 INS42 INS45 INS32 INS43 INS42 INS43 INS45 INS42 INS33 INS27 INS27 INS42 INS42 INS45 INS32 INS42 INS42 INS42 MOV78 INS83 INS43 INS42 INS43 INS8 INS7 INS32 INS45 INS32 INS45 INS32 INS45 INS32 INS32 INS43 INS42 INS21 INS21 INS21 INS32 INS32 INS42 INS42 MOV78 INS83 INS43 INS42 INS43 INS8 INS14 INS7 INS43 INS42 INS41 INS43 INS42 INS53 INS42 INS42 INS42 INS40 INS42 INS32 INS42 INS8 INS32 INS8 INS12 INS27 INS42 INS45 INS45 INS42 INS45 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS33 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS41 INS42 INS34 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS42 INS45 INS42 INS32 INS32 INS7 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS21 INS41 INS43 INS27 INS42 INS32 INS42 INS33 INS42 INS14 INS42 INS42 INS21 INS42 INS42 UPD42 INS21 INS44 INS8 INS8 INS45 INS45 INS32 INS33 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS9 INS32 INS33 INS42 INS45 INS45 INS42 INS42 INS43 INS45 INS42 INS32 INS32 INS43 INS42 INS21 INS25 INS42 INS42 INS45 INS32 INS45 INS45 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS32 INS27 INS8 INS42 INS42 INS27 INS32 INS45 INS42 INS27 INS42 INS33 INS21 INS45 INS45 INS40 INS42 INS42 INS45 INS32 INS32 INS42 INS42 INS42 INS42 INS42 DEL43 DEL39 DEL42 DEL42 DEL32 DEL40 DEL42 DEL42 DEL42 DEL42 DEL45 DEL42 DEL27 DEL32 DEL21 DEL42