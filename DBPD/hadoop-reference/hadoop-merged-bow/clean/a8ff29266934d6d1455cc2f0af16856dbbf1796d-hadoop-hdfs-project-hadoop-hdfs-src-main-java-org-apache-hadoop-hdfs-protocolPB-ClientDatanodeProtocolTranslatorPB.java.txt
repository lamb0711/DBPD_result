Merge trunk into HDFS-3077 branch.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1377092 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.ArrayList;
+import java.util.List;
+import org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata;
+import org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos.GetHdfsBlockLocationsRequestProto;
+import org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos.GetHdfsBlockLocationsResponseProto;
+import org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockTokenIdentifierProto;
+import org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ExtendedBlockProto;
+import com.google.protobuf.ByteString;
-}
+
+  @Override
+  public HdfsBlocksMetadata getHdfsBlocksMetadata(List<ExtendedBlock> blocks,
+      List<Token<BlockTokenIdentifier>> tokens) throws IOException {
+    // Convert to proto objects
+    List<ExtendedBlockProto> blocksProtos = 
+        new ArrayList<ExtendedBlockProto>(blocks.size());
+    List<BlockTokenIdentifierProto> tokensProtos = 
+        new ArrayList<BlockTokenIdentifierProto>(tokens.size());
+    for (ExtendedBlock b : blocks) {
+      blocksProtos.add(PBHelper.convert(b));
+    }
+    for (Token<BlockTokenIdentifier> t : tokens) {
+      tokensProtos.add(PBHelper.convert(t));
+    }
+    // Build the request
+    GetHdfsBlockLocationsRequestProto request = 
+        GetHdfsBlockLocationsRequestProto.newBuilder()
+        .addAllBlocks(blocksProtos)
+        .addAllTokens(tokensProtos)
+        .build();
+    // Send the RPC
+    GetHdfsBlockLocationsResponseProto response;
+    try {
+      response = rpcProxy.getHdfsBlockLocations(NULL_CONTROLLER, request);
+    } catch (ServiceException e) {
+      throw ProtobufHelper.getRemoteException(e);
+    }
+    // List of volumes in the response
+    List<ByteString> volumeIdsByteStrings = response.getVolumeIdsList();
+    List<byte[]> volumeIds = new ArrayList<byte[]>(volumeIdsByteStrings.size());
+    for (ByteString bs : volumeIdsByteStrings) {
+      volumeIds.add(bs.toByteArray());
+    }
+    // Array of indexes into the list of volumes, one per block
+    List<Integer> volumeIndexes = response.getVolumeIndexesList();
+    // Parsed HdfsVolumeId values, one per block
+    return new HdfsBlocksMetadata(blocks.toArray(new ExtendedBlock[] {}), 
+        volumeIds, volumeIndexes);
+  }
+}

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS31 INS78 INS83 INS43 INS42 INS44 INS44 INS43 INS8 INS42 INS42 INS74 INS42 INS74 INS42 INS42 INS60 INS60 INS70 INS70 INS60 INS60 INS54 INS60 INS60 INS70 INS60 INS41 INS43 INS43 INS43 INS74 INS74 INS59 INS74 INS59 INS44 INS42 INS8 INS44 INS42 INS8 INS43 INS59 INS43 INS59 INS8 INS12 INS74 INS59 INS74 INS59 INS44 INS42 INS8 INS74 INS59 INS14 INS42 INS42 INS42 INS43 INS43 INS43 INS43 INS42 INS14 INS43 INS43 INS42 INS14 INS43 INS42 INS21 INS74 INS42 INS21 INS42 INS42 INS32 INS42 INS42 INS21 INS44 INS8 INS43 INS43 INS42 INS32 INS43 INS5 INS42 INS14 INS43 INS42 INS21 INS43 INS43 INS42 INS32 INS43 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS74 INS32 INS42 INS42 INS74 INS32 INS42 INS32 INS43 INS43 INS32 INS32 INS42 INS7 INS43 INS42 INS53 INS42 INS42 INS42 INS42 INS42 INS39 INS85 INS74 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS3 INS43 INS43 INS42 INS42 INS43 INS43 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS32 INS42 INS32 INS43 INS5 INS42 INS42 INS42 INS42 INS32 INS5 INS4 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS39 INS85 INS42 INS42 INS43 INS85 INS42 INS42 INS42