HDFS-8328. Follow-on to update decode for DataNode striped blocks reconstruction. (yliu)

-import org.apache.hadoop.io.erasurecode.rawcoder.RSRawEncoder;
-import org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder;
+import static org.apache.hadoop.hdfs.util.StripedBlockUtil.convertIndex4Decode;
+
-
-  private RawErasureEncoder newEncoder(int numDataUnits, int numParityUnits) {
-    return new RSRawEncoder(numDataUnits, numParityUnits);
-  }
-    private RawErasureEncoder encoder;
-    // position in striped block
+    private final int minRequiredSources;
+    // position in striped internal block
+    // The buffers and indices for striped blocks whose length is 0
+    private ByteBuffer[] zeroStripeBuffers;
+    private short[] zeroStripeIndices;
+
+      final int cellsNum = (int)((blockGroup.getNumBytes() - 1) / cellSize + 1);
+      minRequiredSources = Math.min(cellsNum, dataBlkNum);
-      Preconditions.checkArgument(liveIndices.length >= dataBlkNum,
+      Preconditions.checkArgument(liveIndices.length >= minRequiredSources,
+      if (minRequiredSources < dataBlkNum) {
+        zeroStripeBuffers = 
+            new ByteBuffer[dataBlkNum - minRequiredSources];
+        zeroStripeIndices = new short[dataBlkNum - minRequiredSources];
+      }
+
+      Preconditions.checkArgument(targetIndices.length <= parityBlkNum,
+          "Too much missed striped blocks.");
+
+    private ByteBuffer allocateBuffer(int length) {
+      return ByteBuffer.allocate(length);
+    }
+
+    /**
+     * StripedReader is used to read from one source DN, it contains a block
+     * reader, buffer and striped block index.
+     * Only allocate StripedReader once for one source, and the StripedReader
+     * has the same array order with sources. Typically we only need to allocate
+     * minimum number (minRequiredSources) of StripedReader, and allocate
+     * new for new source DN if some existing DN invalid or slow.
+     * If some source DN is corrupt, set the corresponding blockReader to 
+     * null and will never read from it again.
+     *  
+     * @param i the array index of sources
+     * @param offsetInBlock offset for the internal block
+     * @return StripedReader
+     */
+    private StripedReader addStripedReader(int i, long offsetInBlock) {
+      StripedReader reader = new StripedReader(liveIndices[i]);
+      stripedReaders.add(reader);
+
+      BlockReader blockReader = newBlockReader(
+          getBlock(blockGroup, liveIndices[i]), offsetInBlock, sources[i]);
+      if (blockReader != null) {
+        initChecksumAndBufferSizeIfNeeded(blockReader);
+        reader.blockReader = blockReader;
+      }
+      reader.buffer = allocateBuffer(bufferSize);
+      return reader;
+    }
+
-        // Store the indices of successfully read source
-        // This will be updated after doing real read.
-        int[] success = new int[dataBlkNum];
+        // Store the array indices of source DNs we have read successfully.
+        // In each iteration of read, the success list may be updated if
+        // some source DN is corrupted or slow. And use the updated success
+        // list of DNs for next iteration read.
+        int[] success = new int[minRequiredSources];
-        for (int i = 0; i < sources.length && nsuccess < dataBlkNum; i++) {
-          StripedReader reader = new StripedReader(liveIndices[i]);
-          stripedReaders.add(reader);
-
-          BlockReader blockReader = newBlockReader(
-              getBlock(blockGroup, liveIndices[i]), 0, sources[i]);
-          if (blockReader != null) {
-            initChecksumAndBufferSizeIfNeeded(blockReader);
-            reader.blockReader = blockReader;
-            reader.buffer = ByteBuffer.allocate(bufferSize);
+        for (int i = 0; 
+            i < sources.length && nsuccess < minRequiredSources; i++) {
+          StripedReader reader = addStripedReader(i, 0);
+          if (reader.blockReader != null) {
-        if (nsuccess < dataBlkNum) {
+        if (nsuccess < minRequiredSources) {
+        if (zeroStripeBuffers != null) {
+          for (int i = 0; i < zeroStripeBuffers.length; i++) {
+            zeroStripeBuffers[i] = allocateBuffer(bufferSize);
+          }
+        }
+
-          targetBuffers[i] = ByteBuffer.allocate(bufferSize);
+          targetBuffers[i] = allocateBuffer(bufferSize);
-        // Store whether the target is success
+        // targetsStatus store whether some target is success, it will record
+        // any failed target once, if some target failed (invalid DN or transfer
+        // failed), will not transfer data to it any more.
-          // step1: read minimum striped buffer size data required by recovery.
-          nsuccess = readMinimumStripedData4Recovery(success);
+          // step1: read from minimum source DNs required for reconstruction.
+          //   The returned success list is the source DNs we do real read from
+          success = readMinimumStripedData4Recovery(success);
-          if (nsuccess < dataBlkNum) {
-            String error = "Can't read data from minimum number of sources "
-                + "required by recovery, block id: " + blockGroup.getBlockId();
-            throw new IOException(error);
-          }
-
-          // step2: encode/decode to recover targets
+          // step2: decode to reconstruct targets
-    // assume liveIndices is not ordered.
-      for (int i = 0; i < dataBlkNum + parityBlkNum && m < targets.length; i++) {
+      int k = 0;
+      for (int i = 0; i < dataBlkNum + parityBlkNum; i++) {
-          targetIndices[m++] = (short)i;
+          if (getBlockLen(blockGroup, i) > 0) {
+            if (m < targets.length) {
+              targetIndices[m++] = (short)i;
+            }
+          } else {
+            zeroStripeIndices[k++] = (short)i;
+          }
-    /**
-     * Read minimum striped buffer size data required by recovery.
-     * <code>success</code> list will be updated after read.
-     * 
-     * Initially we only read from <code>dataBlkNum</code> sources, 
-     * if timeout or failure for some source, we will try to schedule 
-     * read from a new source. 
-     */
-    private int readMinimumStripedData4Recovery(int[] success) {
+    private long getReadLength(int index) {
+      long blockLen = getBlockLen(blockGroup, index);
+      long remaining = blockLen - positionInBlock;
+      return remaining > bufferSize ? bufferSize : remaining;
+    }
+    /**
+     * Read from minimum source DNs required for reconstruction in the iteration.
+     * First try the success list which we think they are the best DNs
+     * If source DN is corrupt or slow, try to read some other source DN, 
+     * and will update the success list. 
+     * 
+     * Remember the updated success list and return it for following 
+     * operations and next iteration read.
+     * 
+     * @param success the initial success list of source DNs we think best
+     * @return updated success list of source DNs we do real read
+     * @throws IOException
+     */
+    private int[] readMinimumStripedData4Recovery(final int[] success)
+        throws IOException {
+      int nsuccess = 0;
+      int[] newSuccess = new int[minRequiredSources];
-      for (int i = 0; i < dataBlkNum; i++) {
+      /*
+       * Read from minimum source DNs required, the success list contains
+       * source DNs which we think best.
+       */
+      for (int i = 0; i < minRequiredSources; i++) {
-        Callable<Void> readCallable = readFromBlock(
-            reader.blockReader, reader.buffer);
-        Future<Void> f = readService.submit(readCallable);
-        futures.put(f, success[i]);
+        if (getReadLength(liveIndices[success[i]]) > 0) {
+          Callable<Void> readCallable = readFromBlock(
+              reader.blockReader, reader.buffer);
+          Future<Void> f = readService.submit(readCallable);
+          futures.put(f, success[i]);
+        } else {
+          // If the read length is 0, we don't need to do real read
+          reader.buffer.position(0);
+          newSuccess[nsuccess++] = success[i];
+        }
-      int nsuccess = 0;
+          int resultIndex = -1;
-            success[nsuccess++] = result.index;
-            if (nsuccess >= dataBlkNum) {
+            resultIndex = result.index;
+          } else if (result.state == StripingChunkReadResult.FAILED) {
+            // If read failed for some source DN, we should not use it anymore 
+            // and schedule read from another source DN.
+            StripedReader failedReader = stripedReaders.get(result.index);
+            closeBlockReader(failedReader.blockReader);
+            failedReader.blockReader = null;
+            resultIndex = scheduleNewRead(used);
+          } else if (result.state == StripingChunkReadResult.TIMEOUT) {
+            // If timeout, we also schedule a new read.
+            resultIndex = scheduleNewRead(used);
+          }
+          if (resultIndex >= 0) {
+            newSuccess[nsuccess++] = resultIndex;
+            if (nsuccess >= minRequiredSources) {
-              // number of sources required for recovery.
+              // number of source DNs required by reconstruction.
-          } else if (result.state == StripingChunkReadResult.FAILED) {
-            // If read failed for some source, we should not use it anymore 
-            // and schedule read from a new source.
-            StripedReader failedReader = stripedReaders.get(result.index);
-            closeBlockReader(failedReader.blockReader);
-            failedReader.blockReader = null;
-            scheduleNewRead(used);
-          } else if (result.state == StripingChunkReadResult.TIMEOUT) {
-            // If timeout, we also schedule a new read.
-            scheduleNewRead(used);
-      return nsuccess;
-    }
-
-    /**
-     * Return true if need to do encoding to recovery missed striped block.
-     */
-    private boolean shouldEncode(int[] success) {
-      for (int i = 0; i < success.length; i++) {
-        if (stripedReaders.get(success[i]).index >= dataBlkNum) {
-          return false;
-        }
+      if (nsuccess < minRequiredSources) {
+        String error = "Can't read data from minimum number of sources "
+            + "required by reconstruction, block id: " + blockGroup.getBlockId();
+        throw new IOException(error);
-      return true;
+
+      return newSuccess;
-    // Initialize encoder
-    private void initEncoderIfNecessary() {
-      if (encoder == null) {
-        encoder = newEncoder(dataBlkNum, parityBlkNum);
-      }
-    }
-    
+    private int[] getErasedIndices(boolean[] targetsStatus) {
+      int[] result = new int[targets.length];
+      int m = 0;
+      for (int i = 0; i < targets.length; i++) {
+        if (targetsStatus[i]) {
+          result[m++] = convertIndex4Decode(targetIndices[i], 
+              dataBlkNum, parityBlkNum);
+        }
+      }
+      return Arrays.copyOf(result, m);
+    }
+
-      if (shouldEncode(success)) {
-        initEncoderIfNecessary();
-        ByteBuffer[] dataBuffers = new ByteBuffer[dataBlkNum];
-        ByteBuffer[] parityBuffers = new ByteBuffer[parityBlkNum];
-        for (int i = 0; i < dataBlkNum; i++) {
-          StripedReader reader = stripedReaders.get(i);
-          ByteBuffer buffer = reader.buffer;
+      initDecoderIfNecessary();
+      ByteBuffer[] inputs = new ByteBuffer[dataBlkNum + parityBlkNum];
+      for (int i = 0; i < success.length; i++) {
+        StripedReader reader = stripedReaders.get(success[i]);
+        ByteBuffer buffer = reader.buffer;
+        paddingBufferToLen(buffer, toRecoverLen);
+        inputs[convertIndex4Decode(reader.index, dataBlkNum, parityBlkNum)] = 
+            (ByteBuffer)buffer.flip();
+      }
+      if (success.length < dataBlkNum) {
+        for (int i = 0; i < zeroStripeBuffers.length; i++) {
+          ByteBuffer buffer = zeroStripeBuffers[i];
-          dataBuffers[i] = (ByteBuffer)buffer.flip();
-        }
-        for (int i = dataBlkNum; i < stripedReaders.size(); i++) {
-          StripedReader reader = stripedReaders.get(i);
-          parityBuffers[reader.index - dataBlkNum] = cleanBuffer(reader.buffer);
-        }
-        for (int i = 0; i < targets.length; i++) {
-          parityBuffers[targetIndices[i] - dataBlkNum] = targetBuffers[i];
-        }
-        for (int i = 0; i < parityBlkNum; i++) {
-          if (parityBuffers[i] == null) {
-            parityBuffers[i] = ByteBuffer.allocate(toRecoverLen);
-          } else {
-            parityBuffers[i].limit(toRecoverLen);
-          }
-        }
-        encoder.encode(dataBuffers, parityBuffers);
-      } else {
-        /////////// TODO: wait for HADOOP-11847 /////////////
-        ////////// The current decode method always try to decode parityBlkNum number of data blocks. ////////////
-        initDecoderIfNecessary();
-        ByteBuffer[] inputs = new ByteBuffer[dataBlkNum + parityBlkNum];
-        for (int i = 0; i < success.length; i++) {
-          StripedReader reader = stripedReaders.get(success[i]);
-          ByteBuffer buffer = reader.buffer;
-          paddingBufferToLen(buffer, toRecoverLen);
-          int index = reader.index < dataBlkNum ? 
-              reader.index + parityBlkNum : reader.index - dataBlkNum;
+          int index = convertIndex4Decode(zeroStripeIndices[i], dataBlkNum,
+              parityBlkNum);
-        int[] indices4Decode = new int[parityBlkNum];
-        int m = 0;
-        for (int i = 0; i < dataBlkNum + parityBlkNum; i++) {
-          if (inputs[i] == null) {
-            inputs[i] = ByteBuffer.allocate(toRecoverLen);
-            indices4Decode[m++] = i;
-          }
+      }
+      int[] erasedIndices = getErasedIndices(targetsStatus);
+      ByteBuffer[] outputs = new ByteBuffer[erasedIndices.length];
+      int m = 0;
+      for (int i = 0; i < targetBuffers.length; i++) {
+        if (targetsStatus[i]) {
+          outputs[m++] = targetBuffers[i];
+          outputs[i].limit(toRecoverLen);
-        ByteBuffer[] outputs = new ByteBuffer[parityBlkNum];
-        m = 0;
-        // targetIndices is subset of indices4Decode
-        for (int i = 0; i < parityBlkNum; i++) {
-          if (m < targetIndices.length && 
-              (indices4Decode[i] - parityBlkNum) == targetIndices[m]) {
-            outputs[i] = targetBuffers[m++];
-            outputs[i].limit(toRecoverLen);
-          } else {
-            outputs[i] = ByteBuffer.allocate(toRecoverLen);
-          }
-        }
-        
-        decoder.decode(inputs, indices4Decode, outputs);
-        
-        for (int i = 0; i < targets.length; i++) {
-          if (targetsStatus[i]) {
-            long blockLen = getBlockLen(blockGroup, targetIndices[i]);
-            long remaining = blockLen - positionInBlock;
-            if (remaining < 0) {
-              targetBuffers[i].limit(0);
-            } else if (remaining < toRecoverLen) {
-              targetBuffers[i].limit((int)remaining);
-            }
+      }
+      decoder.decode(inputs, erasedIndices, outputs);
+
+      for (int i = 0; i < targets.length; i++) {
+        if (targetsStatus[i]) {
+          long blockLen = getBlockLen(blockGroup, targetIndices[i]);
+          long remaining = blockLen - positionInBlock;
+          if (remaining < 0) {
+            targetBuffers[i].limit(0);
+          } else if (remaining < toRecoverLen) {
+            targetBuffers[i].limit((int)remaining);
-    /** 
-     * Schedule read from a new source, we first try un-initial source, 
-     * then try un-used source in this round and bypass failed source.
+    /**
+     * Schedule a read from some new source DN if some DN is corrupted
+     * or slow, this is called from the read iteration.
+     * Initially we may only have <code>minRequiredSources</code> number of 
+     * StripedReader.
+     * If the position is at the end of target block, don't need to do 
+     * real read, and return the array index of source DN, otherwise -1.
+     * 
+     * @param used the used source DNs in this iteration.
+     * @return the array index of source DN if don't need to do real read.
-    private void scheduleNewRead(BitSet used) {
+    private int scheduleNewRead(BitSet used) {
+      // step1: initially we may only have <code>minRequiredSources</code>
+      // number of StripedReader, and there may be some source DNs we never 
+      // read before, so will try to create StripedReader for one new source DN
+      // and try to read from it. If found, go to step 3.
-      while (m < sources.length && reader == null) {
-        reader = new StripedReader(liveIndices[m]);
-        BlockReader blockReader = newBlockReader(
-            getBlock(blockGroup, liveIndices[m]), positionInBlock, sources[m]);
-        stripedReaders.add(reader);
-        if (blockReader != null) {
-          assert blockReader.getDataChecksum().equals(checksum);
-          reader.blockReader = blockReader;
-          reader.buffer = ByteBuffer.allocate(bufferSize);
+      while (reader == null && m < sources.length) {
+        reader = addStripedReader(m, positionInBlock);
+        if (getReadLength(liveIndices[m]) > 0) {
+          if (reader.blockReader == null) {
+            reader = null;
+            m++;
+          }
-          m++;
-          reader = null;
+          used.set(m);
+          return m;
+      // step2: if there is no new source DN we can use, try to find a source 
+      // DN we ever read from but because some reason, e.g., slow, it
+      // is not in the success DN list at the begin of this iteration, so 
+      // we have not tried it in this iteration. Now we have a chance to 
+      // revisit it again.
-        StripedReader r = stripedReaders.get(i);
-        if (r.blockReader != null && !used.get(i)) {
-          closeBlockReader(r.blockReader);
-          r.blockReader = newBlockReader(
-              getBlock(blockGroup, liveIndices[i]), positionInBlock,
-              sources[i]);
-          if (r.blockReader != null) {
-            m = i;
-            reader = r;
+        if (!used.get(i)) {
+          StripedReader r = stripedReaders.get(i);
+          if (getReadLength(liveIndices[i]) > 0) {
+            closeBlockReader(r.blockReader);
+            r.blockReader = newBlockReader(
+                getBlock(blockGroup, liveIndices[i]), positionInBlock,
+                sources[i]);
+            if (r.blockReader != null) {
+              m = i;
+              reader = r;
+            }
+          } else {
+            used.set(i);
+            r.buffer.position(0);
+            return i;
+      // step3: schedule if find a correct source DN and need to do real read.
+
+      return -1;
-        long startOffset, DatanodeInfo dnInfo) {
+        long offsetInBlock, DatanodeInfo dnInfo) {
+      if (offsetInBlock >= block.getNumBytes()) {
+        return null;
+      }
-            "dummy", block, blockToken, startOffset, block.getNumBytes(), true,
+            "dummy", block, blockToken, offsetInBlock, 
+            block.getNumBytes() - offsetInBlock, true,
+      if (zeroStripeBuffers != null) {
+        for (int i = 0; i < zeroStripeBuffers.length; i++) {
+          zeroStripeBuffers[i].clear();
+        }
+      }
+
-    private final short index;
+    private final short index; // internal block index

MOV26 UPD40 MOV31 INS23 INS23 INS23 INS31 INS31 INS31 MOV83 INS83 INS39 INS59 INS83 MOV5 INS59 INS83 INS5 INS59 INS83 INS43 INS42 INS44 INS8 MOV29 MOV83 MOV43 UPD42 MOV42 MOV44 INS44 MOV8 INS83 INS39 INS42 INS44 INS8 INS5 INS43 MOV60 INS5 UPD42 INS44 INS8 MOV8 MOV60 UPD39 INS42 INS42 INS39 INS85 INS42 INS60 INS21 INS25 INS21 UPD42 MOV42 INS39 INS42 INS41 INS65 INS65 INS65 INS39 UPD42 INS39 INS42 INS21 INS41 INS60 INS39 INS42 INS60 INS60 MOV41 INS65 INS65 INS65 INS39 INS85 INS83 INS42 INS60 MOV25 INS39 INS85 INS5 INS42 MOV60 INS60 MOV24 INS41 MOV24 INS25 INS60 INS65 INS65 INS41 UPD42 INS25 INS25 INS83 INS39 INS59 INS7 INS27 INS8 INS32 INS32 INS66 UPD66 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS66 INS42 INS66 INS66 INS7 INS42 INS39 INS59 MOV27 INS8 INS39 INS59 INS39 INS59 INS16 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 INS42 INS66 INS66 INS42 INS5 INS59 UPD42 INS39 INS85 MOV5 INS39 INS59 INS8 INS32 INS27 INS8 INS5 INS59 MOV5 UPD66 INS66 INS66 INS66 INS66 UPD66 INS42 INS66 INS66 MOV27 INS38 INS27 INS8 INS27 INS8 INS42 INS11 INS42 INS32 INS42 INS42 INS21 INS21 INS42 INS42 INS27 INS45 INS42 INS42 INS42 INS40 INS32 INS24 INS25 INS42 INS34 INS25 INS42 INS32 INS42 INS27 INS27 INS42 INS42 INS39 INS85 INS42 INS3 UPD42 INS25 UPD42 UPD42 INS42 INS34 INS25 UPD42 MOV42 UPD42 MOV42 INS42 UPD42 MOV42 INS40 INS40 INS42 MOV24 INS39 INS85 INS42 INS32 INS40 UPD42 INS21 INS25 INS25 INS34 INS42 MOV32 INS41 INS42 INS33 INS24 INS39 INS36 INS42 INS42 INS42 INS42 UPD42 INS7 INS7 INS40 INS42 INS42 INS42 INS42 MOV5 MOV58 MOV27 MOV37 INS8 INS27 INS8 MOV58 MOV37 MOV38 INS8 UPD42 MOV42 INS42 INS42 UPD42 MOV42 INS42 INS42 INS42 INS5 INS42 INS27 INS8 INS8 MOV5 INS40 INS2 INS8 UPD42 MOV42 UPD42 MOV42 MOV5 INS40 INS2 INS7 INS27 INS8 MOV8 MOV38 INS8 INS33 MOV58 INS27 MOV37 INS8 INS27 INS42 INS3 INS42 INS3 INS60 INS25 UPD42 INS42 INS33 MOV24 INS25 INS39 INS85 INS32 INS34 MOV60 MOV60 MOV21 INS21 INS21 INS60 INS25 INS42 INS42 MOV21 MOV32 UPD40 UPD42 MOV42 MOV42 MOV42 INS32 INS32 INS34 INS25 INS21 INS41 MOV60 MOV25 UPD42 INS27 INS42 INS40 INS21 INS27 INS34 MOV5 INS27 INS5 INS27 MOV5 UPD42 UPD42 INS43 INS59 INS27 INS8 MOV58 INS27 MOV37 INS8 INS27 MOV8 INS8 INS42 INS2 INS32 INS7 INS39 INS59 INS8 INS27 MOV8 UPD45 MOV42 INS42 INS32 UPD43 UPD42 MOV42 INS42 MOV42 UPD42 MOV42 MOV2 UPD27 MOV27 MOV8 MOV21 INS32 INS42 INS27 INS8 INS32 INS42 INS32 INS36 INS42 INS42 INS42 INS39 INS85 INS42 INS42 INS42 INS42 INS32 INS40 INS33 MOV21 INS42 INS40 INS21 UPD42 INS32 INS34 INS21 INS42 MOV2 INS40 INS42 INS34 INS2 INS2 INS42 INS38 INS21 INS42 INS34 INS32 INS42 INS42 INS42 INS40 INS42 INS42 UPD42 UPD42 INS2 INS32 MOV2 INS40 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS32 INS34 INS21 INS21 INS41 INS42 INS42 INS2 INS42 INS27 INS42 INS42 INS34 INS7 UPD42 INS42 INS42 INS42 MOV27 INS7 INS42 INS37 INS42 INS42 INS34 INS7 INS21 UPD42 MOV37 INS42 MOV2 INS42 INS42 UPD42 MOV42 MOV42 INS42 INS2 INS42 INS42 UPD42 INS42 INS2 INS32 INS32 INS42 INS42 INS42 INS32 INS34 INS2 INS32 INS2 INS11 INS42 INS42 INS40 INS7 MOV21 INS42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS34 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS37 INS39 INS42 INS42 MOV32 INS7 UPD42 INS42 INS42 MOV32 DEL40 DEL26 DEL83 DEL42 DEL43 DEL42 DEL39 DEL42 DEL44 DEL39 DEL42 DEL44 DEL42 DEL43 DEL42 DEL42 DEL14 DEL41 DEL8 DEL31 DEL43 DEL42 DEL59 DEL23 DEL39 DEL85 DEL5 DEL34 DEL40 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL27 DEL9 DEL39 DEL21 DEL40 DEL39 DEL42 DEL40 DEL27 DEL42 DEL32 DEL42 DEL22 DEL27 DEL8 DEL25 DEL8 DEL24 DEL9 DEL41 DEL8 DEL31 DEL39 DEL42 DEL42 DEL27 DEL8 DEL42 DEL33 DEL27 DEL42 DEL32 DEL7 DEL21 DEL8 DEL25 DEL8 DEL42 DEL42 DEL42 DEL42 DEL42 DEL43 DEL42 DEL40 DEL59 DEL60 DEL40 DEL42 DEL27 DEL40 DEL42 DEL27 DEL40 DEL42 DEL27 DEL16 DEL42 DEL42 DEL42 DEL27 DEL27 DEL42 DEL42 DEL2 DEL33 DEL27 DEL42 DEL42 DEL2 DEL42 DEL32 DEL7 DEL21 DEL42 DEL2 DEL42 DEL7 DEL21 DEL8 DEL25 DEL8 DEL24 DEL42 DEL42 DEL34 DEL7 DEL21 DEL42 DEL42 DEL40 DEL27 DEL42 DEL42 DEL2 DEL42 DEL27 DEL36 DEL42 DEL42 DEL2 DEL27 DEL27 DEL42 DEL42 DEL2 DEL2 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL8 DEL42 DEL42 DEL32 DEL42 DEL32 DEL21 DEL42 DEL42 DEL3 DEL59 DEL60 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL43 DEL85 DEL5 DEL42 DEL3 DEL59 DEL60 DEL39 DEL42 DEL42 DEL59 DEL58 DEL42 DEL42 DEL42 DEL32 DEL27 DEL42 DEL37 DEL42 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL40 DEL42 DEL27 DEL2 DEL42 DEL40 DEL32 DEL7 DEL21 DEL8 DEL24 DEL39 DEL42 DEL34 DEL59 DEL58 DEL42 DEL42 DEL27 DEL42 DEL37 DEL42 DEL42 DEL2 DEL33 DEL27 DEL42 DEL42 DEL2 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL8 DEL42 DEL42 DEL2 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL24 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL42 DEL32 DEL42 DEL32 DEL6 DEL40 DEL42 DEL7 DEL21 DEL40 DEL42 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL43 DEL14 DEL7 DEL21 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL42 DEL2 DEL32 DEL42 DEL42 DEL2 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL21 DEL25 DEL40 DEL33 DEL27 DEL27