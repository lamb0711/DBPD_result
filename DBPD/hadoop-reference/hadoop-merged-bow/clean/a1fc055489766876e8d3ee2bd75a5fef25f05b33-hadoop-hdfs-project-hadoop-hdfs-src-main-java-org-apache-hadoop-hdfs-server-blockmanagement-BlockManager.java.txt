HDFS-1623. High Availability Framework for HDFS NN. Contributed by Todd Lipcon, Aaron T. Myers, Eli Collins, Uma Maheswara Rao G, Bikas Saha, Suresh Srinivas, Jitendra Nath Pandey, Hari Mankude, Brandon Li, Sanjay Radia, Mingjie Lai, and Gregory Chanan


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1296534 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.Queue;
+import java.util.Set;
+import org.apache.hadoop.hdfs.server.blockmanagement.PendingDataNodeMessages.ReportedBlockInfo;
+import com.google.common.collect.Sets;
+  private static final String QUEUE_REASON_CORRUPT_STATE =
+    "it has the wrong state or generation stamp";
+
+  private static final String QUEUE_REASON_FUTURE_GENSTAMP =
+    "generation stamp is in the future";
+
+  
+  private final PendingDataNodeMessages pendingDNMessages =
+    new PendingDataNodeMessages();
+  private volatile long postponedMisreplicatedBlocksCount = 0L;
+  /** Used by metrics */
+  public long getPostponedMisreplicatedBlocksCount() {
+    return postponedMisreplicatedBlocksCount;
+  }
+  /** Used by metrics */
+  public int getPendingDataNodeMessageCount() {
+    return pendingDNMessages.count();
+  }
+  
+  /**
+   * After a failover, over-replicated blocks may not be handled
+   * until all of the replicas have done a block report to the
+   * new active. This is to make sure that this NameNode has been
+   * notified of all block deletions that might have been pending
+   * when the failover happened.
+   */
+  private final Set<Block> postponedMisreplicatedBlocks = Sets.newHashSet();
-        List<DatanodeDescriptor> containingNodes =
-                                          new ArrayList<DatanodeDescriptor>();
-        List<DatanodeDescriptor> containingLiveReplicasNodes =
-          new ArrayList<DatanodeDescriptor>();
-        
-        NumberReplicas numReplicas = new NumberReplicas();
-        // source node returned is not used
-        chooseSourceDatanode(block, containingNodes,
-            containingLiveReplicasNodes, numReplicas);
-        assert containingLiveReplicasNodes.size() == numReplicas.liveReplicas();
-        int usableReplicas = numReplicas.liveReplicas() +
-                             numReplicas.decommissionedReplicas();
-       
-        if (block instanceof BlockInfo) {
-          String fileName = ((BlockInfo)block).getINode().getFullPathName();
-          out.print(fileName + ": ");
-        }
-        // l: == live:, d: == decommissioned c: == corrupt e: == excess
-        out.print(block + ((usableReplicas > 0)? "" : " MISSING") + 
-                  " (replicas:" +
-                  " l: " + numReplicas.liveReplicas() +
-                  " d: " + numReplicas.decommissionedReplicas() +
-                  " c: " + numReplicas.corruptReplicas() +
-                  " e: " + numReplicas.excessReplicas() + ") "); 
-
-        Collection<DatanodeDescriptor> corruptNodes = 
-                                      corruptReplicas.getNodes(block);
-        
-        for (Iterator<DatanodeDescriptor> jt = blocksMap.nodeIterator(block);
-             jt.hasNext();) {
-          DatanodeDescriptor node = jt.next();
-          String state = "";
-          if (corruptNodes != null && corruptNodes.contains(node)) {
-            state = "(corrupt)";
-          } else if (node.isDecommissioned() || 
-              node.isDecommissionInProgress()) {
-            state = "(decommissioned)";
-          }          
-          out.print(" " + node + state + " : ");
-        }
-        out.println("");
+        dumpBlockMeta(block, out);
+    
+    // Dump any postponed over-replicated blocks
+    out.println("Mis-replicated blocks that have been postponed:");
+    for (Block block : postponedMisreplicatedBlocks) {
+      dumpBlockMeta(block, out);
+    }
+  
+  /**
+   * Dump the metadata for the given block in a human-readable
+   * form.
+   */
+  private void dumpBlockMeta(Block block, PrintWriter out) {
+    List<DatanodeDescriptor> containingNodes =
+                                      new ArrayList<DatanodeDescriptor>();
+    List<DatanodeDescriptor> containingLiveReplicasNodes =
+      new ArrayList<DatanodeDescriptor>();
+    
+    NumberReplicas numReplicas = new NumberReplicas();
+    // source node returned is not used
+    chooseSourceDatanode(block, containingNodes,
+        containingLiveReplicasNodes, numReplicas);
+    assert containingLiveReplicasNodes.size() == numReplicas.liveReplicas();
+    int usableReplicas = numReplicas.liveReplicas() +
+                         numReplicas.decommissionedReplicas();
+    
+    if (block instanceof BlockInfo) {
+      String fileName = ((BlockInfo)block).getINode().getFullPathName();
+      out.print(fileName + ": ");
+    }
+    // l: == live:, d: == decommissioned c: == corrupt e: == excess
+    out.print(block + ((usableReplicas > 0)? "" : " MISSING") + 
+              " (replicas:" +
+              " l: " + numReplicas.liveReplicas() +
+              " d: " + numReplicas.decommissionedReplicas() +
+              " c: " + numReplicas.corruptReplicas() +
+              " e: " + numReplicas.excessReplicas() + ") "); 
+
+    Collection<DatanodeDescriptor> corruptNodes = 
+                                  corruptReplicas.getNodes(block);
+    
+    for (Iterator<DatanodeDescriptor> jt = blocksMap.nodeIterator(block);
+         jt.hasNext();) {
+      DatanodeDescriptor node = jt.next();
+      String state = "";
+      if (corruptNodes != null && corruptNodes.contains(node)) {
+        state = "(corrupt)";
+      } else if (node.isDecommissioned() || 
+          node.isDecommissionInProgress()) {
+        state = "(decommissioned)";
+      }
+      
+      if (node.areBlockContentsStale()) {
+        state += " (block deletions maybe out of date)";
+      }
+      out.print(" " + node + state + " : ");
+    }
+    out.println("");
+  }
-      completeBlock(fileINode,fileINode.numBlocks()-1);
+      completeBlock(fileINode,fileINode.numBlocks()-1, false);
-      final int blkIndex) throws IOException {
-    return completeBlock(fileINode, blkIndex, false);
-  }
-
-  public BlockInfo completeBlock(final INodeFile fileINode, 
-      final int blkIndex, final boolean force) throws IOException {
+      final int blkIndex, boolean force) throws IOException {
-    if(!force && ucBlock.numNodes() < minReplication)
+    int numNodes = ucBlock.numNodes();
+    if (!force && numNodes < minReplication)
+    
+    // Since safe-mode only counts complete blocks, and we now have
+    // one more complete block, we need to adjust the total up, and
+    // also count it as safe, if we have at least the minimum replica
+    // count. (We may not have the minimum replica count yet if this is
+    // a "forced" completion when a file is getting closed by an
+    // OP_CLOSE edit on the standby).
+    namesystem.adjustSafeModeBlockTotals(0, 1);
+    namesystem.incrementSafeBlockCount(
+        Math.min(numNodes, minReplication));
+    
-      final BlockInfo block) throws IOException {
+      final BlockInfo block, boolean force) throws IOException {
-        return completeBlock(fileINode, idx);
+        return completeBlock(fileINode, idx, force);
+  
+  /**
+   * Force the given block in the given file to be marked as complete,
+   * regardless of whether enough replicas are present. This is necessary
+   * when tailing edit logs as a Standby.
+   */
+  public BlockInfo forceCompleteBlock(final INodeFile fileINode,
+      final BlockInfoUnderConstruction block) throws IOException {
+    block.commitBlock(block);
+    return completeBlock(fileINode, block, true);
+  }
+  
+    
+    // Adjust safe-mode totals, since under-construction blocks don't
+    // count in safe-mode.
+    namesystem.adjustSafeModeBlockTotals(
+        // decrement safe if we had enough
+        targets.length >= minReplication ? -1 : 0,
+        // always decrement total blocks
+        -1);
+    int j = 0;
-      int j = 0;
+    assert j == machines.length :
+      "isCorrupt: " + isCorrupt + 
+      " numMachines: " + numMachines +
+      " numNodes: " + numNodes +
+      " numCorrupt: " + numCorruptNodes +
+      " numCorruptRepls: " + numCorruptReplicas;
+    
+    // If the DN hasn't block-reported since the most recent
+    // failover, then we may have been holding up on processing
+    // over-replicated blocks because of it. But we can now
+    // process those blocks.
+    if (node.areBlockContentsStale()) {
+      rescanPostponedMisreplicatedBlocks();
+    }
-    namesystem.writeLock();
-    try {
-      final BlockInfo storedBlock = getStoredBlock(blk.getLocalBlock());
-      if (storedBlock == null) {
-        // Check if the replica is in the blockMap, if not
-        // ignore the request for now. This could happen when BlockScanner
-        // thread of Datanode reports bad block before Block reports are sent
-        // by the Datanode on startup
-        NameNode.stateChangeLog.info("BLOCK* findAndMarkBlockAsCorrupt: "
-            + blk + " not found.");
-        return;
-      }
-      markBlockAsCorrupt(storedBlock, dn, reason);
-    } finally {
-      namesystem.writeUnlock();
+    assert namesystem.hasWriteLock();
+    final BlockInfo storedBlock = getStoredBlock(blk.getLocalBlock());
+    if (storedBlock == null) {
+      // Check if the replica is in the blockMap, if not
+      // ignore the request for now. This could happen when BlockScanner
+      // thread of Datanode reports bad block before Block reports are sent
+      // by the Datanode on startup
+      NameNode.stateChangeLog.info("BLOCK* findAndMarkBlockAsCorrupt: "
+          + blk + " not found.");
+      return;
+    markBlockAsCorrupt(storedBlock, dn, reason);
-    // Check how many copies we have of the block. If we have at least one
-    // copy on a live node, then we can delete it.
-    int count = countNodes(blk).liveReplicas();
-    if (count >= 1) {
+    // Check how many copies we have of the block
+    NumberReplicas nr = countNodes(blk);
+    if (nr.replicasOnStaleNodes() > 0) {
+      NameNode.stateChangeLog.info("BLOCK* invalidateBlocks: postponing " +
+          "invalidation of block " + blk + " on " + dn + " because " +
+          nr.replicasOnStaleNodes() + " replica(s) are located on nodes " +
+          "with potentially out-of-date block reports.");
+      postponeBlock(blk);
+
+    } else if (nr.liveReplicas() >= 1) {
+      // If we have at least one copy on a live node, then we can delete it.
+  private void postponeBlock(Block blk) {
+    if (postponedMisreplicatedBlocks.add(blk)) {
+      postponedMisreplicatedBlocksCount++;
+    }
+  }
+  
+  
-  private int computeReplicationWork(int blocksToProcess) throws IOException {
+  int computeReplicationWork(int blocksToProcess) throws IOException {
-            if(srcNode == null) // block can not be replicated from any node
+            if(srcNode == null) { // block can not be replicated from any node
+              LOG.debug("Block " + block + " cannot be repl from any node");
+          }
-      numReplicas.initialize(live, decommissioned, corrupt, excess);
+      numReplicas.initialize(live, decommissioned, corrupt, excess, 0);
-      if (namesystem.isInStartupSafeMode() && node.numBlocks() > 0) {
+      if (namesystem.isInStartupSafeMode() && !node.isFirstBlockReport()) {
+      
+      // Now that we have an up-to-date block report, we know that any
+      // deletions from a previous NN iteration have been accounted for.
+      boolean staleBefore = node.areBlockContentsStale();
+      node.receivedBlockReport();
+      if (staleBefore && !node.areBlockContentsStale()) {
+        LOG.info("BLOCK* processReport: " +
+            "Received first block report from " + node +
+            " after becoming active. Its block contents are no longer" +
+            " considered stale.");
+        rescanPostponedMisreplicatedBlocks();
+      }
+      
+  /**
+   * Rescan the list of blocks which were previously postponed.
+   */
+  private void rescanPostponedMisreplicatedBlocks() {
+    for (Iterator<Block> it = postponedMisreplicatedBlocks.iterator();
+         it.hasNext();) {
+      Block b = it.next();
+      
+      BlockInfo bi = blocksMap.getStoredBlock(b);
+      if (bi == null) {
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("BLOCK* rescanPostponedMisreplicatedBlocks: " +
+              "Postponed mis-replicated block " + b + " no longer found " +
+              "in block map.");
+        }
+        it.remove();
+        postponedMisreplicatedBlocksCount--;
+        continue;
+      }
+      MisReplicationResult res = processMisReplicatedBlock(bi);
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("BLOCK* rescanPostponedMisreplicatedBlocks: " +
+            "Re-scanned block " + b + ", result is " + res);
+      }
+      if (res != MisReplicationResult.POSTPONE) {
+        it.remove();
+        postponedMisreplicatedBlocksCount--;
+      }
+    }
+  }
+  
+    boolean isStandby = namesystem.isInStandbyState();
+    
+      
+      if (isStandby &&
+          namesystem.isGenStampInFuture(iblk.getGenerationStamp())) {
+        queueReportedBlock(node, iblk, reportedState,
+            QUEUE_REASON_FUTURE_GENSTAMP);
+        continue;
+      }
+      
-        markBlockAsCorrupt(c.blockInfo, node, c.reason);
+        if (namesystem.isInStandbyState()) {
+          // In the Standby, we may receive a block report for a file that we
+          // just have an out-of-date gen-stamp or state for, for example.
+          queueReportedBlock(node, iblk, reportedState,
+              QUEUE_REASON_CORRUPT_STATE);
+        } else {
+          markBlockAsCorrupt(c.blockInfo, node, c.reason);
+        }
-   * @return
+   * @return the up-to-date stored block, if it should be kept.
+   *         Otherwise, null.
+    if (namesystem.isInStandbyState() &&
+        namesystem.isGenStampInFuture(block.getGenerationStamp())) {
+      queueReportedBlock(dn, block, reportedState,
+          QUEUE_REASON_FUTURE_GENSTAMP);
+      return null;
+    }
+    
-      assert storedBlock.findDatanode(dn) < 0 : "Block " + block
-        + " in invalidated blocks set should not appear in DN " + dn;
+/*  TODO: following assertion is incorrect, see HDFS-2668
+assert storedBlock.findDatanode(dn) < 0 : "Block " + block
+        + " in recentInvalidatesSet should not appear in DN " + dn; */
-      toCorrupt.add(c);
+      if (namesystem.isInStandbyState()) {
+        // If the block is an out-of-date generation stamp or state,
+        // but we're the standby, we shouldn't treat it as corrupt,
+        // but instead just queue it for later processing.
+        queueReportedBlock(dn, storedBlock, reportedState,
+            QUEUE_REASON_CORRUPT_STATE);
+      } else {
+        toCorrupt.add(c);
+      }
+  /**
+   * Queue the given reported block for later processing in the
+   * standby node. {@see PendingDataNodeMessages}.
+   * @param reason a textual reason to report in the debug logs
+   */
+  private void queueReportedBlock(DatanodeDescriptor dn, Block block,
+      ReplicaState reportedState, String reason) {
+    assert namesystem.isInStandbyState();
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Queueing reported block " + block +
+          " in state " + reportedState + 
+          " from datanode " + dn + " for later processing " +
+          "because " + reason + ".");
+    }
+    pendingDNMessages.enqueueReportedBlock(dn, block, reportedState);
+  }
+
+  /**
+   * Try to process any messages that were previously queued for the given
+   * block. This is called from FSEditLogLoader whenever a block's state
+   * in the namespace has changed or a new block has been created.
+   */
+  public void processQueuedMessagesForBlock(Block b) throws IOException {
+    Queue<ReportedBlockInfo> queue = pendingDNMessages.takeBlockQueue(b);
+    if (queue == null) {
+      // Nothing to re-process
+      return;
+    }
+    processQueuedMessages(queue);
+  }
+  
+  private void processQueuedMessages(Iterable<ReportedBlockInfo> rbis)
+      throws IOException {
+    for (ReportedBlockInfo rbi : rbis) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Processing previouly queued message " + rbi);
+      }
+      processAndHandleReportedBlock(
+          rbi.getNode(), rbi.getBlock(), rbi.getReportedState(), null);
+    }
+  }
+  
+  /**
+   * Process any remaining queued datanode messages after entering
+   * active state. At this point they will not be re-queued since
+   * we are the definitive master node and thus should be up-to-date
+   * with the namespace information.
+   */
+  public void processAllPendingDNMessages() throws IOException {
+    assert !namesystem.isInStandbyState() :
+      "processAllPendingDNMessages() should be called after exiting " +
+      "standby state!";
+    int count = pendingDNMessages.count();
+    if (count > 0) {
+      LOG.info("Processing " + count + " messages from DataNodes " +
+          "that were previously queued during standby state.");
+    }
+    processQueuedMessages(pendingDNMessages.takeAll());
+    assert pendingDNMessages.count() == 0;
+  }
+
-        && numCurrentReplica >= minReplication)
-      storedBlock = completeBlock(storedBlock.getINode(), storedBlock);
-
-    // check whether safe replication is reached for the block
-    // only complete blocks are counted towards that
-    if(storedBlock.isComplete())
+        && numCurrentReplica >= minReplication) {
+      completeBlock(storedBlock.getINode(), storedBlock, false);
+    } else if (storedBlock.isComplete()) {
+      // check whether safe replication is reached for the block
+      // only complete blocks are counted towards that.
+      // In the case that the block just became complete above, completeBlock()
+      // handles the safe block count maintenance.
+    }
-        numLiveReplicas >= minReplication)
-      storedBlock = completeBlock(fileINode, storedBlock);
-
-    // check whether safe replication is reached for the block
-    // only complete blocks are counted towards that
-    // Is no-op if not in safe mode.
-    if(storedBlock.isComplete())
+        numLiveReplicas >= minReplication) {
+      storedBlock = completeBlock(fileINode, storedBlock, false);
+    } else if (storedBlock.isComplete()) {
+      // check whether safe replication is reached for the block
+      // only complete blocks are counted towards that
+      // Is no-op if not in safe mode.
+      // In the case that the block just became complete above, completeBlock()
+      // handles the safe block count maintenance.
-
+    }
+    
-    long nrInvalid = 0, nrOverReplicated = 0, nrUnderReplicated = 0,
+    long nrInvalid = 0, nrOverReplicated = 0, nrUnderReplicated = 0, nrPostponed = 0,
-      INodeFile fileINode = block.getINode();
-      if (fileINode == null) {
-        // block does not belong to any file
-        nrInvalid++;
-        addToInvalidates(block);
-        continue;
+      MisReplicationResult res = processMisReplicatedBlock(block);
+      if (LOG.isTraceEnabled()) {
+        LOG.trace("block " + block + ": " + res);
-      if (!block.isComplete()) {
-        // Incomplete blocks are never considered mis-replicated --
-        // they'll be reached when they are completed or recovered.
-        nrUnderConstruction++;
-        continue;
-      }
-      // calculate current replication
-      short expectedReplication = fileINode.getReplication();
-      NumberReplicas num = countNodes(block);
-      int numCurrentReplica = num.liveReplicas();
-      // add to under-replicated queue if need to be
-      if (isNeededReplication(block, expectedReplication, numCurrentReplica)) {
-        if (neededReplications.add(block, numCurrentReplica, num
-            .decommissionedReplicas(), expectedReplication)) {
-          nrUnderReplicated++;
-        }
-      }
-
-      if (numCurrentReplica > expectedReplication) {
-        // over-replicated block
+      switch (res) {
+      case UNDER_REPLICATED:
+        nrUnderReplicated++;
+        break;
+      case OVER_REPLICATED:
-        processOverReplicatedBlock(block, expectedReplication, null, null);
+        break;
+      case INVALID:
+        nrInvalid++;
+        break;
+      case POSTPONE:
+        nrPostponed++;
+        postponeBlock(block);
+        break;
+      case UNDER_CONSTRUCTION:
+        nrUnderConstruction++;
+        break;
+      case OK:
+        break;
+      default:
+        throw new AssertionError("Invalid enum value: " + res);
-
+    
-    LOG.info("Number of  over-replicated blocks = " + nrOverReplicated);
+    LOG.info("Number of  over-replicated blocks = " + nrOverReplicated +
+        ((nrPostponed > 0) ? ( " (" + nrPostponed + " postponed)") : ""));
+  /**
+   * Process a single possibly misreplicated block. This adds it to the
+   * appropriate queues if necessary, and returns a result code indicating
+   * what happened with it.
+   */
+  private MisReplicationResult processMisReplicatedBlock(BlockInfo block) {
+    INodeFile fileINode = block.getINode();
+    if (fileINode == null) {
+      // block does not belong to any file
+      addToInvalidates(block);
+      return MisReplicationResult.INVALID;
+    }
+    if (!block.isComplete()) {
+      // Incomplete blocks are never considered mis-replicated --
+      // they'll be reached when they are completed or recovered.
+      return MisReplicationResult.UNDER_CONSTRUCTION;
+    }
+    // calculate current replication
+    short expectedReplication = fileINode.getReplication();
+    NumberReplicas num = countNodes(block);
+    int numCurrentReplica = num.liveReplicas();
+    // add to under-replicated queue if need to be
+    if (isNeededReplication(block, expectedReplication, numCurrentReplica)) {
+      if (neededReplications.add(block, numCurrentReplica, num
+          .decommissionedReplicas(), expectedReplication)) {
+        return MisReplicationResult.UNDER_REPLICATED;
+      }
+    }
+
+    if (numCurrentReplica > expectedReplication) {
+      if (num.replicasOnStaleNodes() > 0) {
+        // If any of the replicas of this block are on nodes that are
+        // considered "stale", then these replicas may in fact have
+        // already been deleted. So, we cannot safely act on the
+        // over-replication until a later point in time, when
+        // the "stale" nodes have block reported.
+        return MisReplicationResult.POSTPONE;
+      }
+      
+      // over-replicated block
+      processOverReplicatedBlock(block, expectedReplication, null, null);
+      return MisReplicationResult.OVER_REPLICATED;
+    }
+    
+    return MisReplicationResult.OK;
+  }
+  
+      if (cur.areBlockContentsStale()) {
+        LOG.info("BLOCK* processOverReplicatedBlock: " +
+            "Postponing processing of over-replicated block " +
+            block + " since datanode " + cur + " does not yet have up-to-date " +
+            "block information.");
+        postponeBlock(block);
+        return;
+      }
-
+    processAndHandleReportedBlock(node, block, ReplicaState.FINALIZED,
+        delHintNode);
+  }
+  
+  private void processAndHandleReportedBlock(DatanodeDescriptor node, Block block,
+      ReplicaState reportedState, DatanodeDescriptor delHintNode)
+      throws IOException {
-    processReportedBlock(node, block, ReplicaState.FINALIZED,
+    processReportedBlock(node, block, reportedState,
-  /** The given node is reporting that it received/deleted certain blocks. */
-  public void blockReceivedAndDeleted(final DatanodeID nodeID, 
+  /**
+   * The given node is reporting incremental information about some blocks.
+   * This includes blocks that are starting to be received, completed being
+   * received, or deleted.
+   */
+  public void processIncrementalBlockReport(final DatanodeID nodeID, 
-     final ReceivedDeletedBlockInfo receivedAndDeletedBlocks[]
+     final ReceivedDeletedBlockInfo blockInfos[]
+    int receiving = 0;
-            .warn("BLOCK* blockReceivedDeleted"
+            .warn("BLOCK* processIncrementalBlockReport"
-            "Got blockReceivedDeleted message from unregistered or dead node");
+            "Got incremental block report from unregistered or dead node");
-      for (int i = 0; i < receivedAndDeletedBlocks.length; i++) {
-        if (receivedAndDeletedBlocks[i].isDeletedBlock()) {
-          removeStoredBlock(
-              receivedAndDeletedBlocks[i].getBlock(), node);
+      for (ReceivedDeletedBlockInfo rdbi : blockInfos) {
+        switch (rdbi.getStatus()) {
+        case DELETED_BLOCK:
+          removeStoredBlock(rdbi.getBlock(), node);
-        } else {
-          addBlock(node, receivedAndDeletedBlocks[i].getBlock(),
-              receivedAndDeletedBlocks[i].getDelHints());
+          break;
+        case RECEIVED_BLOCK:
+          addBlock(node, rdbi.getBlock(), rdbi.getDelHints());
+          break;
+        case RECEIVING_BLOCK:
+          receiving++;
+          processAndHandleReportedBlock(node, rdbi.getBlock(),
+              ReplicaState.RBW, null);
+          break;
+        default:
+          String msg = 
+            "Unknown block status code reported by " + nodeID.getName() +
+            ": " + rdbi;
+          NameNode.stateChangeLog.warn(msg);
+          assert false : msg; // if assertions are enabled, throw.
+          break;
-          NameNode.stateChangeLog.debug("BLOCK* block"
-              + (receivedAndDeletedBlocks[i].isDeletedBlock() ? "Deleted"
-                  : "Received") + ": " + receivedAndDeletedBlocks[i].getBlock()
+          NameNode.stateChangeLog.debug("BLOCK* block "
+              + (rdbi.getStatus()) + ": " + rdbi.getBlock()
-          .debug("*BLOCK* NameNode.blockReceivedAndDeleted: " + "from "
-              + nodeID.getName() + " received: " + received + ", "
+          .debug("*BLOCK* NameNode.processIncrementalBlockReport: " + "from "
+              + nodeID.getName()
+              +  " receiving: " + receiving + ", "
+              + " received: " + received + ", "
-   * Return the number of nodes that are live and decommissioned.
+   * Return the number of nodes hosting a given block, grouped
+   * by the state of those replicas.
-    int count = 0;
+    int decommissioned = 0;
+    int stale = 0;
-        count++;
+        decommissioned++;
+      if (node.areBlockContentsStale()) {
+        stale++;
+      }
-    return new NumberReplicas(live, count, corrupt, excess);
+    return new NumberReplicas(live, decommissioned, corrupt, excess, stale);
-    return blocksMap.size() - (int)invalidateBlocks.numBlocks();
+    return blocksMap.size();
+    assert namesystem.hasWriteLock();
+    // No need to ACK blocks that are being removed entirely
+    // from the namespace, since the removal of the associated
+    // file already removes them from the block map below.
+    if (postponedMisreplicatedBlocks.remove(block)) {
+      postponedMisreplicatedBlocksCount--;
+    }
+      if (!namesystem.isPopulatingReplQueues()) {
+        return;
+      }
-      if (namesystem.isInSafeMode())
+      if (namesystem.isInSafeMode()) {
+        LOG.debug("In safemode, not computing replication work");
+      }
+  /**
+   * Clear all queues that hold decisions previously made by
+   * this NameNode.
+   */
+  public void clearQueues() {
+    neededReplications.clear();
+    pendingReplications.clear();
+    excessReplicateMap.clear();
+    invalidateBlocks.clear();
+    datanodeManager.clearPendingQueues();
+  };
+  
+
+
+  /**
+   * A simple result enum for the result of
+   * {@link BlockManager#processMisReplicatedBlock(BlockInfo)}.
+   */
+  enum MisReplicationResult {
+    /** The block should be invalidated since it belongs to a deleted file. */
+    INVALID,
+    /** The block is currently under-replicated. */
+    UNDER_REPLICATED,
+    /** The block is currently over-replicated. */
+    OVER_REPLICATED,
+    /** A decision can't currently be made about this block. */
+    POSTPONE,
+    /** The block is under construction, so should be ignored */
+    UNDER_CONSTRUCTION,
+    /** The block is properly replicated */
+    OK
+  }
+

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS23 INS23 INS23 INS23 INS31 INS31 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS71 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS43 INS59 INS83 INS83 INS39 INS59 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS83 INS74 INS59 MOV29 INS83 INS39 INS42 INS44 INS8 INS29 UPD83 UPD42 MOV44 MOV8 MOV29 UPD83 INS44 INS29 INS83 MOV43 INS42 MOV44 INS44 MOV43 MOV8 MOV8 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS43 INS8 INS83 INS39 INS42 INS44 INS43 INS8 INS29 INS83 INS39 INS42 INS43 INS8 MOV29 INS83 INS39 INS42 INS8 INS29 UPD83 INS43 INS42 MOV44 MOV8 MOV29 MOV78 INS39 INS42 INS44 INS44 MOV44 INS43 INS8 INS83 UPD42 INS44 INS44 UPD42 INS29 INS83 INS39 INS42 INS8 INS29 INS42 INS72 INS72 INS72 INS72 INS72 INS72 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS14 INS42 INS34 INS65 INS41 INS65 INS41 INS65 INS43 INS43 INS42 INS32 INS43 INS42 MOV6 MOV60 MOV60 MOV21 MOV21 MOV21 INS51 INS21 INS70 MOV21 MOV21 MOV21 INS65 INS60 INS21 INS21 INS39 INS42 INS65 INS83 INS43 INS42 INS21 INS21 MOV60 INS6 INS25 INS6 INS25 INS43 INS42 INS25 INS65 INS24 INS60 INS25 INS65 INS65 INS43 INS42 INS43 INS42 INS43 INS42 INS43 INS42 INS6 INS25 INS21 INS65 INS43 INS42 INS42 INS60 INS25 INS21 INS74 INS42 INS42 INS70 INS65 INS42 INS6 INS60 INS25 INS21 INS6 MOV6 MOV60 MOV21 INS70 MOV21 MOV21 MOV21 INS21 MOV21 INS65 INS42 INS41 INS43 INS42 INS43 INS42 INS42 MOV21 MOV60 MOV25 MOV21 INS21 INS43 INS42 INS43 INS42 UPD42 INS60 INS54 INS60 INS6 INS25 INS65 INS21 INS21 INS21 INS21 INS21 INS65 INS29 INS42 INS29 INS42 INS29 INS42 INS29 INS42 INS29 INS42 INS29 INS42 INS43 INS66 INS42 INS66 INS32 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS42 INS42 INS42 INS42 INS8 INS32 INS44 INS42 INS8 INS66 INS66 INS39 INS59 INS32 INS32 INS66 INS66 INS66 INS42 INS32 INS32 INS27 INS27 INS32 INS8 INS32 INS43 INS27 INS8 MOV25 INS42 INS32 INS8 INS66 INS58 INS32 INS8 INS39 INS59 INS66 INS66 INS27 INS8 INS8 INS66 INS66 INS65 INS66 INS42 INS66 INS42 INS42 INS42 INS42 INS32 INS32 INS8 INS32 INS66 INS66 INS66 INS42 INS74 INS59 INS27 INS8 INS32 INS43 INS43 INS44 INS42 INS8 INS66 INS66 INS66 INS66 INS38 INS27 INS39 INS59 INS27 INS8 INS32 INS27 INS8 INS25 INS8 MOV25 INS59 INS44 MOV32 INS8 INS32 INS66 INS66 INS66 INS40 INS42 INS42 INS32 INS42 INS42 UPD66 INS66 INS66 INS39 INS59 INS8 MOV8 UPD66 INS66 INS39 INS59 MOV32 INS32 INS32 INS8 INS66 INS66 INS32 INS32 INS32 INS32 INS32 INS66 INS65 INS66 INS65 INS65 INS65 INS65 INS65 INS65 INS42 INS42 INS42 MOV21 INS70 INS42 INS42 INS45 INS43 INS42 INS21 INS25 INS42 MOV32 INS42 INS42 INS34 INS34 INS42 INS42 INS32 INS42 INS42 INS42 UPD42 UPD9 INS42 INS42 INS16 INS38 INS42 INS40 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS42 INS42 INS21 INS42 INS42 INS42 UPD42 MOV32 INS32 INS34 INS21 INS21 INS42 INS42 INS42 INS21 INS60 INS21 INS25 INS74 INS59 INS42 INS42 INS60 INS60 INS25 INS60 INS25 INS25 INS42 INS32 INS25 INS32 INS32 INS21 INS41 INS25 MOV41 INS66 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS32 INS42 INS33 INS41 INS42 INS42 INS42 INS42 INS43 INS42 INS25 INS21 INS32 INS45 INS45 INS42 INS32 INS42 INS34 INS21 INS42 INS32 INS32 INS34 MOV21 MOV32 INS8 INS21 INS8 INS42 INS34 INS43 INS42 INS60 INS25 INS50 INS42 INS42 INS27 INS41 INS41 INS25 INS41 INS25 INS42 INS42 INS42 INS40 INS42 INS42 UPD42 MOV42 MOV34 MOV60 MOV25 INS70 UPD42 INS42 INS34 INS25 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS25 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS68 INS66 INS66 INS66 INS66 INS66 INS66 INS44 INS42 INS8 INS42 INS32 INS32 INS8 INS9 INS42 INS42 INS42 INS42 INS42 INS27 INS38 INS34 INS34 INS32 INS42 INS42 INS32 INS32 INS32 INS37 INS34 INS39 INS59 INS32 INS27 INS8 INS43 INS43 INS42 INS32 INS43 INS59 INS43 INS59 INS27 INS8 INS43 INS59 INS32 INS8 INS27 INS8 INS42 INS42 INS27 INS8 INS8 INS42 INS42 INS42 INS42 INS32 INS32 INS33 INS32 INS8 MOV8 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS8 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 MOV32 MOV21 MOV7 MOV21 INS42 INS43 INS59 INS32 INS8 INS42 INS49 MOV21 INS10 INS49 MOV21 INS10 INS49 MOV21 INS10 INS49 INS21 INS21 INS10 INS49 MOV21 INS10 INS49 INS10 INS49 INS53 INS45 INS42 INS36 INS40 INS40 INS27 INS8 INS40 INS32 INS8 INS44 INS42 INS8 INS32 INS8 INS37 INS38 INS8 INS8 INS42 INS42 INS69 INS43 UPD42 MOV42 INS21 INS42 INS42 INS42 INS42 INS42 INS21 INS40 INS42 INS34 INS42 INS40 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS38 INS42 INS32 INS42 INS42 INS42 INS38 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS33 INS25 INS21 INS21 INS18 INS42 INS42 INS32 INS42 INS42 INS21 INS42 INS40 INS21 INS21 INS42 INS32 INS21 INS18 INS25 INS18 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS27 INS42 INS42 INS21 INS42 INS32 INS32 INS32 INS33 INS42 INS42 INS27 INS9 INS42 INS42 INS32 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS37 INS32 INS42 INS42 INS14 INS16 INS41 INS32 INS34 INS41 INS42 INS42 INS21 INS21 INS41 INS43 INS42 INS50 MOV25 INS42 INS42 INS21 INS42 INS32 INS41 INS21 MOV41 INS43 INS42 INS32 INS7 INS42 INS27 INS42 INS45 INS42 INS45 INS32 INS45 INS45 INS32 INS42 INS42 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS8 INS32 INS37 INS42 INS42 INS32 INS32 INS37 INS42 INS42 INS32 INS32 INS32 INS8 MOV8 INS32 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS45 INS42 INS45 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS42 INS45 INS45 INS9 INS42 INS42 INS32 INS42 INS42 INS42 INS43 INS27 INS36 INS36 INS45 INS40 INS42 INS42 INS40 INS32 INS32 INS42 INS32 INS49 INS21 MOV21 INS10 INS49 INS21 MOV21 INS10 INS49 INS21 INS21 INS10 INS49 INS60 INS21 INS6 INS10 INS32 INS45 INS42 INS45 INS37 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS45 INS45 INS45 INS42 INS42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS45 INS42 INS27 INS27 INS42 INS42 INS27 INS42 INS42 UPD45 INS42 UPD42 MOV42 INS42 MOV32 INS42 MOV32 INS42 INS37 INS32 INS43 INS59 INS32 INS9 INS42 UPD45 INS42 INS42 INS42 INS42 INS42 INS45 INS27 INS42 INS45 INS45 INS32 INS27 INS42 INS45 INS42 INS32 INS45 INS42 INS45 INS42 INS45 INS42 INS42 INS34 INS45 INS42 INS45 INS27 INS42 INS45 INS42 INS45 INS45 UPD45 INS42 INS42 INS42 INS32 INS40 INS33 INS42 INS42 INS27 INS40 INS42 INS42 UPD42 INS45 INS45 INS42 INS42 INS27 INS45 INS45 INS42 INS42 INS42 INS42 INS42 INS45 INS45 INS42 INS42 INS42 INS42 INS42 INS45 MOV32 INS45 INS42 INS8 INS27 INS42 INS45 INS45 UPD45 INS21 INS18 INS45 INS45 INS32 INS42 INS32 INS42 UPD42 MOV42 INS42 INS42 INS27 INS45 INS42 INS45 DEL42 DEL42 DEL70 DEL8 DEL51 DEL8 DEL83 DEL42 DEL83 DEL39 DEL44 DEL31 DEL83 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL32 DEL21 DEL8 DEL54 DEL8 DEL39 DEL42 DEL32 DEL42 DEL83 DEL18 DEL32 DEL34 DEL27 DEL18 DEL42 DEL42 DEL42 DEL32 DEL34 DEL27 DEL45 DEL42 DEL45 DEL42 DEL27 DEL6 DEL42 DEL7 DEL21 DEL25 DEL18 DEL18 DEL39 DEL42 DEL70 DEL42 DEL42 DEL45 DEL42 DEL27 DEL32 DEL21 DEL8 DEL40 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL32 DEL45 DEL45 DEL16 DEL42 DEL42 DEL2 DEL39 DEL59 DEL58 DEL42 DEL40 DEL27 DEL42 DEL37 DEL42 DEL42 DEL2 DEL32 DEL21 DEL8 DEL21 DEL8 DEL25 DEL8 DEL24 DEL8 DEL54 DEL39 DEL42 DEL42 DEL32 DEL11 DEL27