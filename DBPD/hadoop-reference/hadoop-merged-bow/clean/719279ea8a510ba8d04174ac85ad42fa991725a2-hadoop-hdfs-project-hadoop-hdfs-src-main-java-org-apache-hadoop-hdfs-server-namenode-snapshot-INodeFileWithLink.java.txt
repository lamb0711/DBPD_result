HDFS-4092. Update file deletion logic for snapshot so that the current inode is removed from the circular linked list; and if some blocks at the end of the block list no longer belong to any other inode, collect them and update the block list.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1402287 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.List;
+
+import org.apache.hadoop.hdfs.protocol.Block;
+import org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo;
+
+  /**
+   * {@inheritDoc}
+   * 
+   * Remove the current inode from the circular linked list.
+   * If some blocks at the end of the block list no longer belongs to
+   * any other inode, collect them and update the block list.
+   */
+  @Override
+  protected int collectSubtreeBlocksAndClear(List<Block> v) {
+    if (next == this) {
+      //this is the only remaining inode.
+      super.collectSubtreeBlocksAndClear(v);
+    } else {
+      //There are other inode(s) using the blocks.
+      //Compute max file size excluding this and find the last inode. 
+      long max = next.computeFileSize(true);
+      INodeFileWithLink last = next;
+      for(INodeFileWithLink i = next.getNext(); i != this; i = i.getNext()) {
+        final long size = i.computeFileSize(true);
+        if (size > max) {
+          max = size;
+        }
+        last = i;
+      }
+
+      collectBlocksBeyondMaxAndClear(max, v);
+      
+      //remove this from the circular linked list.
+      last.next = this.next;
+      this.next = null;
+      //clear parent
+      parent = null;
+    }
+    return 1;
+  }
+
+  private void collectBlocksBeyondMaxAndClear(final long max, final List<Block> v) {
+    if (blocks != null) {
+      //find the minimum n such that the size of the first n blocks > max
+      int n = 0;
+      for(long size = 0; n < blocks.length && max > size; n++) {
+        size += blocks[n].getNumBytes();
+      }
+
+      //starting from block[n], the data is beyond max.
+      if (n < blocks.length) {
+        //resize the array.  
+        final BlockInfo[] newBlocks;
+        if (n == 0) {
+          newBlocks = null;
+        } else {
+          newBlocks = new BlockInfo[n];
+          System.arraycopy(blocks, 0, newBlocks, 0, n);
+        }
+        for(INodeFileWithLink i = next; i != this; i = i.getNext()) {
+          i.blocks = newBlocks;
+        }
+
+        //collect the blocks beyond max.  
+        if (v != null) {
+          for(; n < blocks.length; n++) {
+            v.add(blocks[n]);
+          }
+        }
+      }
+      blocks = null;
+    }
+  }

INS26 INS26 INS26 INS40 INS40 INS40 INS31 INS31 INS29 INS78 INS83 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS8 INS65 INS42 INS74 INS42 INS25 INS41 INS83 INS39 INS42 INS83 INS74 INS42 INS25 INS65 INS66 INS66 INS66 INS43 INS43 INS27 INS8 INS8 INS34 INS43 INS43 INS27 INS8 INS42 INS42 INS42 INS52 INS21 INS60 INS60 INS24 INS21 INS21 INS21 INS21 INS42 INS42 INS42 INS33 INS60 INS24 INS25 INS21 INS48 INS39 INS59 INS43 INS59 INS58 INS27 INS7 INS8 INS32 INS7 INS7 INS7 INS39 INS59 INS58 INS27 INS37 INS8 INS27 INS8 INS7 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS43 INS59 INS42 INS52 INS42 INS32 INS60 INS25 INS21 INS42 INS42 INS42 INS40 INS22 INS22 INS33 INS42 INS33 INS42 INS34 INS39 INS59 INS27 INS27 INS42 INS21 INS42 INS40 INS60 INS25 INS24 INS25 INS42 INS33 INS42 INS42 INS9 INS42 INS42 INS32 INS42 INS42 INS83 INS39 INS59 INS27 INS8 INS7 INS52 INS42 INS52 INS42 INS42 INS34 INS42 INS40 INS42 INS42 INS7 INS83 INS5 INS59 INS27 INS8 INS8 INS58 INS27 INS7 INS8 INS27 INS8 INS42 INS42 INS42 INS32 INS42 INS42 INS21 INS42 INS42 INS42 INS32 INS43 INS85 INS42 INS42 INS34 INS21 INS21 INS21 INS43 INS59 INS42 INS52 INS42 INS32 INS21 INS42 INS33 INS24 INS42 INS42 INS9 INS7 INS2 INS42 INS42 INS7 INS7 INS32 INS42 INS42 INS42 INS42 INS42 INS7 INS27 INS37 INS8 INS42 INS42 INS42 INS42 INS42 INS33 INS42 INS3 INS42 INS42 INS42 INS34 INS42 INS34 INS42 INS40 INS42 INS42 INS40 INS42 INS21 INS5 INS42 INS32 INS43 INS85 INS42 INS42 INS2 INS42 INS42 INS42