HDFS-2191.  Move datanodeMap from FSNamesystem to DatanodeManager.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151339 13f79535-47bb-0310-9956-ffa450edef68

+import java.io.PrintWriter;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import org.apache.hadoop.hdfs.protocol.Block;
+import org.apache.hadoop.hdfs.protocol.ExtendedBlock;
+import org.apache.hadoop.hdfs.protocol.UnregisteredNodeException;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.BlockTargetPair;
+import org.apache.hadoop.hdfs.server.common.Util;
+import org.apache.hadoop.hdfs.server.protocol.BlockCommand;
+import org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand;
+import org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeCommand;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol;
+import org.apache.hadoop.util.CyclicIteration;
+  /**
+   * Stores the datanode -> block map.  
+   * <p>
+   * Done by storing a set of {@link DatanodeDescriptor} objects, sorted by 
+   * storage id. In order to keep the storage map consistent it tracks 
+   * all storages ever registered with the namenode.
+   * A descriptor corresponding to a specific storage id can be
+   * <ul> 
+   * <li>added to the map if it is a new storage id;</li>
+   * <li>updated with a new datanode started as a replacement for the old one 
+   * with the same storage id; and </li>
+   * <li>removed if and only if an existing datanode is restarted to serve a
+   * different storage id.</li>
+   * </ul> <br>
+   * The list of the {@link DatanodeDescriptor}s in the map is checkpointed
+   * in the namespace image file. Only the {@link DatanodeInfo} part is 
+   * persistent, the list of blocks is restored from the datanode block
+   * reports. 
+   * <p>
+   * Mapping: StorageID -> DatanodeDescriptor
+   */
+  private final NavigableMap<String, DatanodeDescriptor> datanodeMap
+      = new TreeMap<String, DatanodeDescriptor>();
+
-  private final HostsFileReader hostsReader; 
+  private final HostsFileReader hostsReader;
+
+  /** The period to wait for datanode heartbeat.*/
+  private final long heartbeatExpireInterval;
+  /** Ask Datanode only up to this many blocks to delete. */
+  final int blockInvalidateLimit;
+    
+    final long heartbeatIntervalSeconds = conf.getLong(
+        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,
+        DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_DEFAULT);
+    final int heartbeatRecheckInterval = conf.getInt(
+        DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY, 
+        DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT); // 5 minutes
+    this.heartbeatExpireInterval = 2 * heartbeatRecheckInterval
+        + 10 * 1000 * heartbeatIntervalSeconds;
+    this.blockInvalidateLimit = Math.max(20*(int)(heartbeatIntervalSeconds),
+        DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);
+    LOG.info(DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY
+        + "=" + this.blockInvalidateLimit);
-  
+
+  CyclicIteration<String, DatanodeDescriptor> getDatanodeCyclicIteration(
+      final String firstkey) {
+    return new CyclicIteration<String, DatanodeDescriptor>(
+        datanodeMap, firstkey);
+  }
+
+  /** Get a datanode descriptor given corresponding storageID */
+  DatanodeDescriptor getDatanode(final String storageID) {
+    return datanodeMap.get(storageID);
+  }
+
+  /**
+   * Get data node by storage ID.
+   * 
+   * @param nodeID
+   * @return DatanodeDescriptor or null if the node is not found.
+   * @throws UnregisteredNodeException
+   */
+  public DatanodeDescriptor getDatanode(DatanodeID nodeID
+      ) throws UnregisteredNodeException {
+    final DatanodeDescriptor node = getDatanode(nodeID.getStorageID());
+    if (node == null) 
+      return null;
+    if (!node.getName().equals(nodeID.getName())) {
+      final UnregisteredNodeException e = new UnregisteredNodeException(
+          nodeID, node);
+      NameNode.stateChangeLog.fatal("BLOCK* NameSystem.getDatanode: "
+                                    + e.getLocalizedMessage());
+      throw e;
+    }
+    return node;
+  }
+
+  /** Prints information about all datanodes. */
+  void datanodeDump(final PrintWriter out) {
+    synchronized (datanodeMap) {
+      out.println("Metasave: Number of datanodes: " + datanodeMap.size());
+      for(Iterator<DatanodeDescriptor> it = datanodeMap.values().iterator(); it.hasNext();) {
+        DatanodeDescriptor node = it.next();
+        out.println(node.dumpDatanode());
+      }
+    }
+  }
+
+  /** Remove a dead datanode. */
+  public void removeDeadDatanode(final DatanodeID nodeID) {
+    synchronized(namesystem.heartbeats) {
+      synchronized(datanodeMap) {
+        DatanodeDescriptor d;
+        try {
+          d = getDatanode(nodeID);
+        } catch(IOException e) {
+          d = null;
+        }
+        if (d != null && isDatanodeDead(d)) {
+          NameNode.stateChangeLog.info(
+              "BLOCK* removeDeadDatanode: lost heartbeat from " + d.getName());
+          namesystem.removeDatanode(d);
+        }
+      }
+    }
+  }
+
+  /** Is the datanode dead? */
+  public boolean isDatanodeDead(DatanodeDescriptor node) {
+    return (node.getLastUpdate() <
+            (Util.now() - heartbeatExpireInterval));
+  }
+
-    synchronized (namesystem.datanodeMap) {
-      host2DatanodeMap.remove(
-          namesystem.datanodeMap.put(node.getStorageID(), node));
+    synchronized(datanodeMap) {
+      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));
-    synchronized (namesystem.datanodeMap) {
-      host2DatanodeMap.remove(namesystem.datanodeMap.remove(key));
+    synchronized (datanodeMap) {
+      host2DatanodeMap.remove(datanodeMap.remove(key));
-      if (namesystem.datanodeMap.get(newID) != null)
+      if (datanodeMap.get(newID) != null)
-    DatanodeDescriptor nodeS = namesystem.datanodeMap.get(nodeReg.getStorageID());
+    DatanodeDescriptor nodeS = datanodeMap.get(nodeReg.getStorageID());
-    for(DatanodeDescriptor node : namesystem.datanodeMap.values()) {
+    for(DatanodeDescriptor node : datanodeMap.values()) {
+  /** @return the number of live datanodes. */
+  public int getNumLiveDataNodes() {
+    int numLive = 0;
+    synchronized (datanodeMap) {
+      for(DatanodeDescriptor dn : datanodeMap.values()) {
+        if (!isDatanodeDead(dn) ) {
+          numLive++;
+        }
+      }
+    }
+    return numLive;
+  }
+
+  /** @return the number of dead datanodes. */
+  public int getNumDeadDataNodes() {
+    int numDead = 0;
+    synchronized (datanodeMap) {   
+      for(DatanodeDescriptor dn : datanodeMap.values()) {
+        if (isDatanodeDead(dn) ) {
+          numDead++;
+        }
+      }
+    }
+    return numDead;
+  }
+
+  /** Fetch live and dead datanodes. */
+  public void fetchDatanodess(final List<DatanodeDescriptor> live, 
+      final List<DatanodeDescriptor> dead) {
+    final List<DatanodeDescriptor> results =
+        getDatanodeListForReport(DatanodeReportType.ALL);    
+    for(DatanodeDescriptor node : results) {
+      if (isDatanodeDead(node))
+        dead.add(node);
+      else
+        live.add(node);
+    }
+  }
+
-    synchronized (namesystem.datanodeMap) {
-      nodes = new ArrayList<DatanodeDescriptor>(namesystem.datanodeMap.size() + 
+    synchronized(datanodeMap) {
+      nodes = new ArrayList<DatanodeDescriptor>(datanodeMap.size() + 
-      Iterator<DatanodeDescriptor> it = namesystem.datanodeMap.values().iterator();
+      Iterator<DatanodeDescriptor> it = datanodeMap.values().iterator();
-        boolean isDead = namesystem.isDatanodeDead(dn);
+        final boolean isDead = isDatanodeDead(dn);
+  
+  private void setDatanodeDead(DatanodeDescriptor node) throws IOException {
+    node.setLastUpdate(0);
+  }
+
+  /** Handle heartbeat from datanodes. */
+  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,
+      final String blockPoolId,
+      long capacity, long dfsUsed, long remaining, long blockPoolUsed,
+      int xceiverCount, int maxTransfers, int failedVolumes
+      ) throws IOException {
+    synchronized (namesystem.heartbeats) {
+      synchronized (datanodeMap) {
+        DatanodeDescriptor nodeinfo = null;
+        try {
+          nodeinfo = getDatanode(nodeReg);
+        } catch(UnregisteredNodeException e) {
+          return new DatanodeCommand[]{DatanodeCommand.REGISTER};
+        }
+        
+        // Check if this datanode should actually be shutdown instead. 
+        if (nodeinfo != null && nodeinfo.isDisallowed()) {
+          setDatanodeDead(nodeinfo);
+          throw new DisallowedDatanodeException(nodeinfo);
+        }
+         
+        if (nodeinfo == null || !nodeinfo.isAlive) {
+          return new DatanodeCommand[]{DatanodeCommand.REGISTER};
+        }
+
+        namesystem.updateStats(nodeinfo, false);
+        nodeinfo.updateHeartbeat(capacity, dfsUsed, remaining, blockPoolUsed,
+            xceiverCount, failedVolumes);
+        namesystem.updateStats(nodeinfo, true);
+        
+        //check lease recovery
+        BlockInfoUnderConstruction[] blocks = nodeinfo
+            .getLeaseRecoveryCommand(Integer.MAX_VALUE);
+        if (blocks != null) {
+          BlockRecoveryCommand brCommand = new BlockRecoveryCommand(
+              blocks.length);
+          for (BlockInfoUnderConstruction b : blocks) {
+            brCommand.add(new RecoveringBlock(
+                new ExtendedBlock(blockPoolId, b), b.getExpectedLocations(), b
+                    .getBlockRecoveryId()));
+          }
+          return new DatanodeCommand[] { brCommand };
+        }
+
+        final List<DatanodeCommand> cmds = new ArrayList<DatanodeCommand>(3);
+        //check pending replication
+        List<BlockTargetPair> pendingList = nodeinfo.getReplicationCommand(
+              maxTransfers);
+        if (pendingList != null) {
+          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,
+              pendingList));
+        }
+        //check block invalidation
+        Block[] blks = nodeinfo.getInvalidateBlocks(blockInvalidateLimit);
+        if (blks != null) {
+          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,
+              blockPoolId, blks));
+        }
+        
+        namesystem.addKeyUpdateCommand(cmds, nodeinfo);
+        if (!cmds.isEmpty()) {
+          return cmds.toArray(new DatanodeCommand[cmds.size()]);
+        }
+      }
+    }
+
+    return null;
+  }

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS29 INS83 INS83 INS74 INS59 INS29 INS83 INS83 INS39 INS59 INS29 INS83 INS39 INS59 INS74 INS42 INS44 INS8 INS29 INS43 INS42 INS44 INS8 INS29 INS83 INS43 INS42 INS44 INS43 INS8 INS29 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS44 INS44 INS8 INS83 INS39 INS42 INS44 INS43 INS8 INS29 INS83 INS5 INS42 INS44 INS44 INS44 INS44 INS44 INS44 INS44 INS44 INS44 INS43 INS8 INS65 INS43 INS43 INS43 INS42 INS14 INS65 INS42 INS65 INS42 INS60 INS60 INS21 INS21 INS21 INS43 INS43 INS43 INS83 INS43 INS42 INS41 INS65 INS42 INS83 INS43 INS42 INS41 INS65 INS65 INS65 INS65 INS42 INS43 INS42 INS42 INS60 INS25 INS25 INS41 INS65 INS83 INS43 INS42 INS51 INS65 INS83 INS43 INS42 INS51 INS65 INS43 INS42 INS41 INS65 INS60 INS51 INS41 INS65 INS60 INS51 INS41 INS65 INS83 INS74 INS42 INS83 INS74 INS42 INS60 INS70 INS43 INS42 INS42 INS21 INS65 INS43 INS85 INS43 INS42 INS83 INS43 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS42 INS51 INS41 INS66 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS65 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS42 INS74 INS66 INS66 INS83 INS39 INS59 INS83 INS39 INS59 INS7 INS7 INS32 INS42 INS42 INS42 INS42 INS14 INS66 INS42 INS32 INS66 INS42 INS66 INS42 INS42 INS83 INS43 INS59 INS27 INS41 INS38 INS8 INS42 INS66 INS42 INS42 INS8 INS66 INS42 INS40 INS8 INS66 INS42 INS36 INS42 INS42 INS66 INS39 INS59 INS42 INS8 INS42 INS66 INS39 INS59 INS42 INS8 INS42 INS66 INS43 INS43 INS43 INS43 INS83 INS74 INS59 INS44 INS42 INS8 INS42 INS42 INS32 INS66 INS42 INS42 INS42 INS40 INS8 INS33 INS42 INS42 INS42 INS43 INS43 INS43 INS42 INS32 INS42 INS32 INS22 INS27 INS22 INS32 INS42 INS42 INS27 INS74 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS33 INS33 INS32 INS60 INS21 INS53 INS21 INS24 INS51 INS27 INS42 INS42 INS34 INS70 INS42 INS34 INS70 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS32 INS43 INS42 INS25 INS42 INS42 INS34 INS51 INS42 INS42 INS42 INS42 INS42 INS40 INS40 INS42 INS42 INS40 INS40 INS52 INS42 INS27 INS27 INS52 INS42 INS42 INS42 INS27 INS40 INS40 INS45 INS22 INS43 INS43 INS43 INS42 INS32 INS32 INS42 INS32 INS83 INS43 INS59 INS32 INS42 INS32 INS58 INS32 INS8 INS42 INS8 INS32 INS36 INS42 INS44 INS32 INS8 INS44 INS32 INS8 INS42 INS42 INS42 INS40 INS42 INS32 INS21 INS21 INS42 INS8 INS34 INS42 INS34 INS34 INS42 INS34 INS11 INS52 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS14 INS40 INS42 INS27 INS42 INS42 INS27 INS74 INS59 INS42 INS42 INS60 INS21 INS60 INS54 INS25 INS42 INS42 INS27 INS43 INS42 INS42 INS42 INS25 INS43 INS42 INS42 INS42 INS25 INS42 INS42 INS32 INS32 INS60 INS54 INS25 INS25 INS21 INS21 INS21 INS60 INS25 INS60 INS60 INS25 INS60 INS25 INS21 INS25 INS39 INS36 INS43 INS42 INS42 INS45 INS32 INS45 INS32 INS43 INS43 INS42 INS32 INS43 INS59 INS32 INS43 INS59 INS8 INS12 INS27 INS8 INS32 INS42 INS42 INS42 INS42 INS42 INS38 INS8 INS42 INS32 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS83 INS43 INS59 INS8 INS12 INS27 INS8 INS27 INS8 INS32 INS32 INS32 INS5 INS59 INS27 INS8 INS83 INS74 INS59 INS74 INS59 INS27 INS8 INS5 INS59 INS27 INS8 INS32 INS38 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS21 INS44 INS8 INS27 INS32 INS21 INS21 INS42 INS42 INS32 INS21 INS42 INS42 INS21 INS42 INS42 INS42 INS33 INS21 INS44 INS8 INS27 INS32 INS21 INS53 INS27 INS38 INS41 INS42 INS42 INS42 INS9 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS9 INS43 INS85 INS42 INS32 INS42 INS33 INS60 INS70 INS41 INS43 INS43 INS42 INS14 INS43 INS43 INS42 INS32 INS42 INS33 INS21 INS43 INS85 INS42 INS32 INS42 INS33 INS21 INS42 INS42 INS42 INS42 INS32 INS41 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS43 INS42 INS21 INS42 INS33 INS42 INS42 INS32 INS32 INS42 INS42 INS37 INS37 INS42 INS7 INS43 INS42 INS41 INS42 INS33 INS42 INS42 INS32 INS14 INS42 INS33 INS40 INS3 INS42 INS42 INS42 INS40 INS43 INS59 INS44 INS42 INS8 INS3 INS42 INS42 INS74 INS34 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS32 INS42 INS7 INS40 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS3 INS42 INS42 INS43 INS42 INS5 INS4 INS42 INS42 INS14 INS43 INS42 INS21 INS5 INS4 INS43 INS43 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS3 INS42 INS42 INS42 INS33 INS45 INS32 INS42 INS42 INS5 INS4 INS42 INS43 INS85 INS40 INS43 INS40 INS42 INS32 INS43 INS85 INS42 INS42 INS42 INS43 INS40 INS42 INS42 INS43 INS40 INS42 INS42 INS5 INS32 INS42 INS42 INS43 INS85 INS40 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS42 INS43 INS85 INS42 INS42 INS42 INS43 INS14 INS32 INS32 INS42 INS42 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 DEL40 DEL40 DEL40 DEL40 DEL40 DEL40 DEL40 DEL40 DEL40 DEL40 DEL42