HDFS-5318. Support read-only and read-write paths to shared replicas. (Contributed by Eric Sirianni)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1569951 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.server.protocol.DatanodeStorage.State;
-    assert containingLiveReplicasNodes.size() == numReplicas.liveReplicas();
+    
+    // containingLiveReplicasNodes can include READ_ONLY_SHARED replicas which are 
+    // not included in the numReplicas.liveReplicas() count
+    assert containingLiveReplicasNodes.size() >= numReplicas.liveReplicas();
-    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {
+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {
-            assert liveReplicaNodes.size() == numReplicas.liveReplicas();
+            // liveReplicaNodes can include READ_ONLY_SHARED replicas which are 
+            // not included in the numReplicas.liveReplicas() count
+            assert liveReplicaNodes.size() >= numReplicas.liveReplicas();
+
+      int countableReplica = storage.getState() == State.NORMAL ? 1 : 0; 
-        corrupt++;
+        corrupt += countableReplica;
-        decommissioned++;
+        decommissioned += countableReplica;
-        excess++;
+        excess += countableReplica;
-        live++;
+        live += countableReplica;
-    for(DatanodeStorageInfo storage : blocksMap.getStorages(block)) {
+    for(DatanodeStorageInfo storage : blocksMap.getStorages(block, State.NORMAL)) {
-    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {
+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {
-    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {
+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {

INS26 INS40 UPD27 INS40 INS60 INS40 INS40 INS40 INS39 INS59 INS42 INS16 INS7 INS27 INS34 INS34 INS42 INS42 INS7 INS32 INS40 INS42 INS42 INS42 INS42 INS7 INS7 INS42 INS42 INS42 INS42 UPD27 DEL42 DEL37 DEL42 DEL37 DEL42 DEL37 DEL42 DEL37