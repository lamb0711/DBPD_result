Merge r1471229 through r1476009 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1476011 13f79535-47bb-0310-9956-ffa450edef68

-    } finally {
-      //close
-      in.close();                               // close input
+      
+      in.close();
+      in = null;
+      
+      collector = null;
+    } finally {
+      closeQuietly(in);
+      closeQuietly(collector);
-    input.initialize(split, mapperContext);
-    mapper.run(mapperContext);
-    mapPhase.complete();
-    setPhase(TaskStatus.Phase.SORT);
-    statusUpdate(umbilical);
-    input.close();
-    output.close(mapperContext);
+    try {
+      input.initialize(split, mapperContext);
+      mapper.run(mapperContext);
+      mapPhase.complete();
+      setPhase(TaskStatus.Phase.SORT);
+      statusUpdate(umbilical);
+      input.close();
+      input = null;
+      output.close(mapperContext);
+      output = null;
+    } finally {
+      closeQuietly(input);
+      closeQuietly(output, mapperContext);
+    }
+  private <INKEY,INVALUE,OUTKEY,OUTVALUE>
+  void closeQuietly(RecordReader<INKEY, INVALUE> c) {
+    if (c != null) {
+      try {
+        c.close();
+      } catch (IOException ie) {
+        // Ignore
+        LOG.info("Ignoring exception during close for " + c, ie);
+      }
+    }
+  }
+  
+  private <OUTKEY, OUTVALUE>
+  void closeQuietly(MapOutputCollector<OUTKEY, OUTVALUE> c) {
+    if (c != null) {
+      try {
+        c.close();
+      } catch (Exception ie) {
+        // Ignore
+        LOG.info("Ignoring exception during close for " + c, ie);
+      }
+    }
+  }
+  
+  private <INKEY, INVALUE, OUTKEY, OUTVALUE>
+  void closeQuietly(
+      org.apache.hadoop.mapreduce.RecordReader<INKEY, INVALUE> c) {
+    if (c != null) {
+      try {
+        c.close();
+      } catch (Exception ie) {
+        // Ignore
+        LOG.info("Ignoring exception during close for " + c, ie);
+      }
+    }
+  }
+
+  private <INKEY, INVALUE, OUTKEY, OUTVALUE>
+  void closeQuietly(
+      org.apache.hadoop.mapreduce.RecordWriter<OUTKEY, OUTVALUE> c,
+      org.apache.hadoop.mapreduce.Mapper<INKEY,INVALUE,OUTKEY,OUTVALUE>.Context
+          mapperContext) {
+    if (c != null) {
+      try {
+        c.close(mapperContext);
+      } catch (Exception ie) {
+        // Ignore
+        LOG.info("Ignoring exception during close for " + c, ie);
+      }
+    }
+  }

INS31 INS31 INS31 INS31 INS83 INS73 INS73 INS73 INS73 INS39 INS42 INS44 INS8 INS83 INS73 INS73 INS39 INS42 INS44 INS8 INS83 INS73 INS73 INS73 INS73 INS39 INS42 INS44 INS8 INS83 INS73 INS73 INS73 INS73 INS39 INS42 INS44 INS44 INS8 INS54 INS42 INS42 INS42 INS42 INS74 INS42 INS25 INS42 INS42 INS74 INS42 INS25 INS42 INS42 INS42 INS42 INS74 INS42 INS25 INS42 INS42 INS42 INS42 INS74 INS42 INS75 INS42 INS25 INS8 INS8 INS43 INS43 INS43 INS27 INS8 INS43 INS43 INS43 INS27 INS8 INS43 INS43 INS43 INS27 INS8 INS43 INS43 INS43 INS74 INS42 INS27 INS8 INS21 INS21 INS21 INS21 MOV21 MOV21 MOV21 MOV21 MOV21 MOV21 INS21 MOV21 INS21 INS21 INS21 INS42 INS42 INS42 INS42 INS33 INS54 INS42 INS42 INS42 INS42 INS33 INS54 INS40 INS42 INS42 INS42 INS33 INS54 INS40 INS42 INS42 INS43 INS43 INS43 INS43 INS43 INS42 INS33 INS54 INS32 INS7 INS32 INS7 INS7 INS7 INS32 INS32 INS8 INS12 INS8 INS12 INS8 INS12 INS40 INS42 INS42 INS42 INS42 INS8 INS12 INS42 MOV42 INS42 INS33 INS42 INS42 INS42 INS33 INS42 UPD42 UPD42 INS42 INS33 INS42 INS33 INS42 INS42 INS42 INS42 INS42 INS21 INS44 INS8 INS21 INS44 INS8 INS21 INS44 INS8 INS21 INS44 INS8 INS32 INS43 INS42 INS21 INS32 INS43 INS42 INS21 INS32 INS43 INS42 INS21 INS32 INS43 INS42 INS21 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42