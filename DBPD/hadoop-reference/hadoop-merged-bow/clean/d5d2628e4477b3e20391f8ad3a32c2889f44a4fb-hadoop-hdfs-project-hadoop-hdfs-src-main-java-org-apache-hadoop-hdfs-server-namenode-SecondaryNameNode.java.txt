Merge r1360400 through r1399945 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1399950 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.server.namenode.FileJournalManager.EditLogFile;
+import org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager.StoragePurger;
+import org.apache.hadoop.util.Time;
+import com.google.common.base.Preconditions;
-  private final long starttime = System.currentTimeMillis();
+  private final long starttime = Time.now();
+  private Thread checkpointThread;
+
+
+  @VisibleForTesting
+  FSNamesystem getFSNamesystem() {
+    return namesystem;
+  }
+    if (checkpointThread != null) {
+      checkpointThread.interrupt();
+      try {
+        checkpointThread.join(10000);
+      } catch (InterruptedException e) {
+        LOG.info("Interrupted waiting to join on checkpointer thread");
+        Thread.currentThread().interrupt(); // maintain status
+      }
+    }
+  @Override
-        long now = System.currentTimeMillis();
+        long now = Time.now();
-        terminate(1);
+        terminate(1, e);
+              LOG.info("Image has changed. Downloading updated image from NN.");
-    // Make sure we're talking to the same NN!
-    if (checkpointImage.getNamespaceID() != 0) {
-      // If the image actually has some data, make sure we're talking
-      // to the same NN as we did before.
-      sig.validateStorageInfo(checkpointImage);
-    } else {
-      // if we're a fresh 2NN, just take the storage info from the server
-      // we first talk to.
+    if ((checkpointImage.getNamespaceID() == 0) ||
+        (sig.isSameCluster(checkpointImage) &&
+         !sig.storageVersionMatches(checkpointImage.getStorage()))) {
+      // if we're a fresh 2NN, or if we're on the same cluster and our storage
+      // needs an upgrade, just take the storage info from the server.
+    sig.validateStorageInfo(checkpointImage);
-    // Since we've successfully checkpointed, we can remove some old
-    // image files
-    checkpointImage.purgeOldStorage();
-    
+    } else if (opts.shouldPrintHelp()) {
+      opts.usage();
+      System.exit(0);
-    // Create a never ending deamon
-    Daemon checkpointThread = new Daemon(secondary);
-    checkpointThread.start();
+    secondary.startCheckpointThread();
+  public void startCheckpointThread() {
+    Preconditions.checkState(checkpointThread == null,
+        "Should not already have a thread");
+    Preconditions.checkState(shouldRun, "shouldRun should be true");
+    
+    checkpointThread = new Daemon(this);
+    checkpointThread.start();
+  }
+
+
+    private final Option helpOpt;
+    private boolean shouldPrintHelp;
+      helpOpt = new Option("h", "help", false, "get help information");
+      options.addOption(helpOpt);
+    public boolean shouldPrintHelp() {
+      return shouldPrintHelp;
+    }
+    
+      if (cmdLine.hasOption(helpOpt.getOpt())
+          || cmdLine.hasOption(helpOpt.getLongOpt())) {
+        shouldPrintHelp = true;
+        return;
+      }
+      
+      String header = "The Secondary NameNode is a helper "
+          + "to the primary NameNode. The Secondary is responsible "
+          + "for supporting periodic checkpoints of the HDFS metadata. "
+          + "The current design allows only one Secondary NameNode "
+          + "per HDFS cluster.";
-      formatter.printHelp("secondarynamenode", options);
+      formatter.printHelp("secondarynamenode", header, options, "", false);
+    
+    private static class CheckpointLogPurger implements LogsPurgeable {
+      
+      private NNStorage storage;
+      private StoragePurger purger
+          = new NNStorageRetentionManager.DeletionStoragePurger();
+      
+      public CheckpointLogPurger(NNStorage storage) {
+        this.storage = storage;
+      }
+
+      @Override
+      public void purgeLogsOlderThan(long minTxIdToKeep) throws IOException {
+        Iterator<StorageDirectory> iter = storage.dirIterator();
+        while (iter.hasNext()) {
+          StorageDirectory dir = iter.next();
+          List<EditLogFile> editFiles = FileJournalManager.matchEditLogs(
+              dir.getCurrentDir());
+          for (EditLogFile f : editFiles) {
+            if (f.getLastTxId() < minTxIdToKeep) {
+              purger.purgeLog(f);
+            }
+          }
+        }
+      }
+
+      @Override
+      public void selectInputStreams(Collection<EditLogInputStream> streams,
+          long fromTxId, boolean inProgressOk) {
+        Iterator<StorageDirectory> iter = storage.dirIterator();
+        while (iter.hasNext()) {
+          StorageDirectory dir = iter.next();
+          List<EditLogFile> editFiles;
+          try {
+            editFiles = FileJournalManager.matchEditLogs(
+                dir.getCurrentDir());
+          } catch (IOException ioe) {
+            throw new RuntimeException(ioe);
+          }
+          FileJournalManager.addStreamsToCollectionFromFiles(editFiles, streams,
+              fromTxId, inProgressOk);
+        }
+      }
+      
+    }
+    
+      
+      // Replace the archival manager with one that can actually work on the
+      // 2NN's edits storage.
+      this.archivalManager = new NNStorageRetentionManager(conf, storage,
+          new CheckpointLogPurger(storage));
-     * Recover from an unsuccessful checkpoint is necessary.
+     * Recover from an unsuccessful checkpoint if necessary.
+    // The following has the side effect of purging old fsimages/edit logs.

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS23 INS31 INS31 INS83 INS43 INS59 INS78 INS43 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS23 INS23 INS31 INS55 INS42 INS42 INS42 INS42 INS41 INS25 INS42 MOV21 INS21 INS21 INS21 INS21 MOV21 INS83 INS83 INS43 INS59 INS83 INS39 INS59 INS83 INS39 INS42 INS8 INS83 INS83 INS42 INS43 INS23 INS23 INS31 INS31 INS31 UPD42 UPD42 INS42 INS27 INS8 INS27 INS25 INS32 INS32 INS32 INS7 INS42 INS42 INS42 INS21 INS21 INS41 INS25 INS60 INS42 INS83 INS43 INS59 INS83 INS43 INS59 INS83 INS42 INS44 INS8 INS78 INS83 INS39 INS42 INS44 INS43 INS8 INS78 INS83 INS39 INS42 INS44 INS44 INS44 INS8 INS21 INS42 INS33 INS21 INS54 INS36 INS36 INS32 INS8 INS42 INS42 INS42 INS42 INS27 INS45 INS42 INS42 INS42 INS45 INS42 MOV14 INS7 INS32 INS42 INS27 INS8 INS43 INS59 INS42 INS42 INS42 INS42 INS14 INS43 INS42 INS21 INS42 INS39 INS42 INS42 INS60 INS61 INS42 INS74 INS42 INS39 INS42 INS39 INS42 INS60 INS61 INS7 UPD66 INS32 INS8 INS12 UPD27 MOV27 INS27 INS42 INS42 INS21 INS21 INS42 INS33 INS52 INS42 INS14 INS42 INS42 INS42 INS32 INS32 INS21 INS41 INS42 INS42 INS27 INS42 INS45 INS9 INS43 INS42 INS7 INS74 INS59 INS32 INS8 INS43 INS43 INS74 INS59 INS32 INS8 INS22 INS14 INS42 INS42 INS21 INS44 INS8 INS32 INS38 INS32 INS32 INS43 INS45 INS45 INS9 INS45 INS42 INS42 INS32 INS42 INS42 INS32 INS7 INS45 INS45 INS45 INS45 INS45 INS40 INS22 INS42 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS60 INS70 INS42 INS42 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS60 INS54 INS21 INS52 INS42 INS43 INS42 INS42 INS14 INS32 INS43 INS42 INS21 INS21 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS34 INS42 INS42 INS42 INS42 INS42 INS42 INS9 INS52 INS42 INS42 INS42 INS42 INS42 INS43 INS59 INS74 INS59 INS44 INS42 INS8 INS42 INS42 INS42 INS42 INS43 INS59 INS74 INS59 INS8 INS12 INS32 INS42 INS43 INS42 INS42 INS42 INS34 INS42 INS32 INS32 INS42 INS42 INS32 INS42 INS42 INS32 INS43 INS43 INS42 INS32 INS43 INS42 INS25 INS42 INS42 INS32 INS43 INS43 INS42 INS21 INS44 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS32 INS42 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS27 INS8 INS42 INS42 INS42 INS42 INS7 INS43 INS42 INS53 INS42 INS42 INS42 INS42 INS32 INS42 INS21 INS42 INS32 INS42 INS14 INS42 INS42 INS32 INS42 INS42 INS32 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS32 INS42 INS42 INS45 DEL8 DEL42 DEL42 DEL32 DEL21 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42