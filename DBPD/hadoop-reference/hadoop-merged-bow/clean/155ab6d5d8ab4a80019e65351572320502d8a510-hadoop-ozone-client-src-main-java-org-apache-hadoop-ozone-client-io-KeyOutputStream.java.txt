HDDS-1098. Introduce Retry Policy in Ozone Client. Contributed by Shashikant Banerjee.

+import org.apache.hadoop.io.retry.RetryPolicies;
+import org.apache.hadoop.io.retry.RetryPolicy;
+import java.io.InterruptedIOException;
+  private final RetryPolicy retryPolicy;
+  private int retryCount;
+    this.retryPolicy = RetryPolicies.TRY_ONCE_THEN_FAIL;
+    retryCount = 0;
-      String uploadID, int partNumber, boolean isMultipart) {
+      String uploadID, int partNumber, boolean isMultipart, int maxRetryCount) {
+    this.retryPolicy = OzoneClientUtils.createRetryPolicy(maxRetryCount);
+    this.retryCount = 0;
-        Throwable t = checkForException(ioe);
-        if (t != null) {
-          // for the current iteration, totalDataWritten - currentPos gives the
-          // amount of data already written to the buffer
+        // for the current iteration, totalDataWritten - currentPos gives the
+        // amount of data already written to the buffer
-          // In the retryPath, the total data to be written will always be equal
-          // to or less than the max length of the buffer allocated.
-          // The len specified here is the combined sum of the data length of
-          // the buffers
-          Preconditions.checkState(!retry || len <= streamBufferMaxSize);
-          writeLen = retry ? (int) len :
-              (int) (current.getWrittenDataLength() - currentPos);
-          LOG.debug("writeLen {}, total len {}", writeLen, len);
-          handleException(current, currentStreamIndex, t);
-        } else {
-          throw ioe;
-        }
+        // In the retryPath, the total data to be written will always be equal
+        // to or less than the max length of the buffer allocated.
+        // The len specified here is the combined sum of the data length of
+        // the buffers
+        Preconditions.checkState(!retry || len <= streamBufferMaxSize);
+        writeLen = retry ? (int) len :
+            (int) (current.getWrittenDataLength() - currentPos);
+        LOG.debug("writeLen {}, total len {}", writeLen, len);
+        handleException(current, currentStreamIndex, ioe);
-      int streamIndex, Throwable exception) throws IOException {
+      int streamIndex, IOException exception) throws IOException {
+    Throwable t = checkForException(exception);
-    if (checkIfContainerIsClosed(exception)) {
+    if (checkIfContainerIsClosed(t)) {
-    } else if (retryFailure || exception instanceof TimeoutException) {
+    } else if (retryFailure || t instanceof TimeoutException) {
-      handleWrite(null, 0, bufferedDataLen, true);
+      handleRetry(exception, bufferedDataLen);
+  private void handleRetry(IOException exception, long len) throws IOException {
+    RetryPolicy.RetryAction action;
+    try {
+      action = retryPolicy
+          .shouldRetry(exception, retryCount, 0, true);
+    } catch (Exception e) {
+      throw e instanceof IOException ? (IOException) e : new IOException(e);
+    }
+    if (action.action == RetryPolicy.RetryAction.RetryDecision.FAIL) {
+      if (action.reason != null) {
+        LOG.error("Retry request failed. " + action.reason,
+            exception);
+      }
+      throw exception;
+    }
+
+    // Throw the exception if the thread is interrupted
+    if (Thread.currentThread().isInterrupted()) {
+      LOG.warn("Interrupted while trying for retry");
+      throw exception;
+    }
+    Preconditions.checkArgument(
+        action.action == RetryPolicy.RetryAction.RetryDecision.RETRY);
+    if (action.delayMillis > 0) {
+      try {
+        Thread.sleep(action.delayMillis);
+      } catch (InterruptedException e) {
+        throw (IOException) new InterruptedIOException(
+            "Interrupted: action=" + action + ", retry policy=" + retryPolicy)
+            .initCause(e);
+      }
+    }
+    retryCount++;
+    LOG.trace("Retrying Write request. Already tried "
+        + retryCount + " time(s); retry policy is " + retryPolicy);
+    handleWrite(null, 0, len, true);
+  }
-  private Throwable checkForException(IOException ioe) {
+  private Throwable checkForException(IOException ioe) throws IOException {
-    return null;
+    throw ioe;
-    int size = streamEntries.size();
-    int streamIndex =
-        currentStreamIndex >= size ? size - 1 : currentStreamIndex;
-    BlockOutputStreamEntry entry = streamEntries.get(streamIndex);
-    if (entry != null) {
-      try {
-        Collection<DatanodeDetails> failedServers = entry.getFailedServers();
-
-        // failed servers can be null in case there is no data written in the
-        // stream
-        if (failedServers != null && !failedServers.isEmpty()) {
-          excludeList.addDatanodes(failedServers);
-        }
-        if (close) {
-          entry.close();
-        } else {
-          entry.flush();
-        }
-      } catch (IOException ioe) {
-        Throwable t = checkForException(ioe);
-        if (t != null) {
-          // This call will allocate a new streamEntry and write the Data.
-          // Close needs to be retried on the newly allocated streamEntry as
-          // as well.
-          handleException(entry, streamIndex, t);
-          handleFlushOrClose(close);
-        } else {
-          throw ioe;
+    while (true) {
+      int size = streamEntries.size();
+      int streamIndex =
+          currentStreamIndex >= size ? size - 1 : currentStreamIndex;
+      BlockOutputStreamEntry entry = streamEntries.get(streamIndex);
+      if (entry != null) {
+        try {
+          Collection<DatanodeDetails> failedServers = entry.getFailedServers();
+          // failed servers can be null in case there is no data written in the
+          // stream
+          if (failedServers != null && !failedServers.isEmpty()) {
+            excludeList.addDatanodes(failedServers);
+          }
+          if (close) {
+            entry.close();
+          } else {
+            entry.flush();
+          }
+        } catch (IOException ioe) {
+          handleException(entry, streamIndex, ioe);
+          continue;
+      break;
+    private int maxRetryCount;
+    public Builder setMaxRetryCount(int maxCount) {
+      this.maxRetryCount = maxCount;
+      return this;
+    }
+
-          bytesPerChecksum, multipartUploadID, multipartNumber, isMultipartKey);
+          bytesPerChecksum, multipartUploadID, multipartNumber, isMultipartKey,
+          maxRetryCount);

INS26 INS26 INS26 INS40 INS40 INS40 INS23 INS23 INS31 INS83 INS83 INS43 INS59 INS83 INS39 INS59 INS44 INS83 INS39 INS42 INS44 INS44 INS43 INS8 INS43 INS23 INS31 INS42 INS42 INS42 INS21 INS21 INS39 INS42 INS21 INS21 INS43 INS60 INS43 INS42 INS39 INS42 INS42 INS60 INS54 INS25 INS25 INS21 INS25 INS21 INS21 INS21 INS42 MOV53 INS61 INS83 INS39 INS59 INS83 INS43 INS42 INS44 INS8 INS7 INS7 INS7 INS7 INS42 MOV43 INS59 INS42 INS43 INS59 INS8 INS12 INS27 INS8 INS32 INS8 INS32 INS27 INS8 INS37 INS32 INS32 INS9 INS8 INS42 INS42 INS39 INS42 INS21 INS41 INS22 INS40 INS42 INS34 INS22 INS32 INS22 INS34 INS42 INS32 UPD42 INS40 INS42 INS21 INS44 INS8 INS40 INS40 INS25 INS53 INS32 INS42 INS21 INS53 INS42 INS42 INS27 INS40 INS34 INS54 INS42 INS42 INS42 INS27 INS42 INS33 INS34 INS42 INS9 MOV60 MOV60 MOV60 MOV25 INS10 INS7 INS52 INS52 INS42 INS52 INS42 INS42 INS42 INS42 INS52 INS42 INS42 INS42 INS7 INS43 INS42 INS53 INS27 INS8 INS42 INS42 INS42 INS32 INS42 INS40 INS40 INS8 INS12 INS45 INS42 INS45 INS42 INS22 INS42 INS42 MOV8 UPD42 UPD42 INS42 INS42 INS32 INS42 INS16 INS40 INS33 INS21 INS42 INS42 INS45 INS21 INS44 INS8 INS52 INS42 INS42 INS42 INS42 INS42 INS34 INS9 INS62 INS11 INS14 INS32 INS32 INS43 INS42 INS53 INS42 INS43 INS43 INS42 INS43 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS40 INS42 INS11 INS8 UPD42 INS42 INS42 INS42 INS45 INS40 INS43 INS32 MOV21 INS18 INS42 INS14 INS42 INS42 INS43 INS27 UPD42 INS42 INS45 INS42 INS45 INS42 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL33 DEL27 DEL42 DEL53 DEL8 DEL25 DEL8 DEL33 DEL34 DEL9 DEL33 DEL41 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL33 DEL27 DEL42 DEL42 DEL32 DEL21 DEL8 DEL8 DEL25 DEL8