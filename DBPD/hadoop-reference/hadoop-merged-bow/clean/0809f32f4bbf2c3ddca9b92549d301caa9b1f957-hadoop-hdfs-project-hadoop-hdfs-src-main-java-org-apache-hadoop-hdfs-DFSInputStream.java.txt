Merge r1569890 through r1571508 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571509 13f79535-47bb-0310-9956-ffa450edef68

-import java.io.FileInputStream;
-import java.net.Socket;
+import java.util.Collection;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
-import org.apache.commons.io.IOUtils;
-import org.apache.hadoop.hdfs.server.datanode.BlockMetadataHeader;
-import org.apache.hadoop.net.unix.DomainSocket;
-import org.apache.hadoop.security.AccessControlException;
-      DNAddrPair retval = chooseDataNode(targetBlock);
+      DNAddrPair retval = chooseDataNode(targetBlock, null);
-      
-  private DNAddrPair chooseDataNode(LocatedBlock block)
-    throws IOException {
+
+  private DNAddrPair chooseDataNode(LocatedBlock block,
+      Collection<DatanodeInfo> ignoredNodes) throws IOException {
-        DatanodeInfo chosenNode = bestNode(nodes, deadNodes);
-        final String dnAddr =
-            chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);
-        if (DFSClient.LOG.isDebugEnabled()) {
-          DFSClient.LOG.debug("Connecting to datanode " + dnAddr);
-        }
-        InetSocketAddress targetAddr = NetUtils.createSocketAddr(dnAddr);
-        return new DNAddrPair(chosenNode, targetAddr);
+        return getBestNodeDNAddrPair(nodes, ignoredNodes);
+        String errMsg =
+          getBestNodeDNAddrPairErrorString(nodes, deadNodes, ignoredNodes);
-          throw new BlockMissingException(src, "Could not obtain block: " + blockInfo,
-                                          block.getStartOffset());
+          String description = "Could not obtain block: " + blockInfo;
+          DFSClient.LOG.warn(description + errMsg
+              + ". Throwing a BlockMissingException");
+          throw new BlockMissingException(src, description,
+              block.getStartOffset());
-            + " from any node: " + ie
+            + " from any node: " + ie + errMsg
-  } 
-      
+  }
+
+  /**
+   * Get the best node.
+   * @param nodes Nodes to choose from.
+   * @param ignoredNodes Do not chose nodes in this array (may be null)
+   * @return The DNAddrPair of the best node.
+   * @throws IOException
+   */
+  private DNAddrPair getBestNodeDNAddrPair(final DatanodeInfo[] nodes,
+      Collection<DatanodeInfo> ignoredNodes) throws IOException {
+    DatanodeInfo chosenNode = bestNode(nodes, deadNodes, ignoredNodes);
+    final String dnAddr =
+        chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);
+    if (DFSClient.LOG.isDebugEnabled()) {
+      DFSClient.LOG.debug("Connecting to datanode " + dnAddr);
+    }
+    InetSocketAddress targetAddr = NetUtils.createSocketAddr(dnAddr);
+    return new DNAddrPair(chosenNode, targetAddr);
+  }
+
+  private static String getBestNodeDNAddrPairErrorString(
+      DatanodeInfo nodes[], AbstractMap<DatanodeInfo,
+      DatanodeInfo> deadNodes, Collection<DatanodeInfo> ignoredNodes) {
+    StringBuilder errMsgr = new StringBuilder(
+        " No live nodes contain current block ");
+    errMsgr.append("Block locations:");
+    for (DatanodeInfo datanode : nodes) {
+      errMsgr.append(" ");
+      errMsgr.append(datanode.toString());
+    }
+    errMsgr.append(" Dead nodes: ");
+    for (DatanodeInfo datanode : deadNodes.keySet()) {
+      errMsgr.append(" ");
+      errMsgr.append(datanode.toString());
+    }
+    if (ignoredNodes != null) {
+      errMsgr.append(" Ignored nodes: ");
+      for (DatanodeInfo datanode : ignoredNodes) {
+        errMsgr.append(" ");
+        errMsgr.append(datanode.toString());
+      }
+    }
+    return errMsgr.toString();
+  }
+
-    //
-    // Connect to best DataNode for desired Block, with potential offset
-    //
+    block = getBlockAt(block.getStartOffset(), false);
+    while (true) {
+      DNAddrPair addressPair = chooseDataNode(block, null);
+      try {
+        actualGetFromOneDataNode(addressPair, block, start, end, buf, offset,
+            corruptedBlockMap);
+        return;
+      } catch (IOException e) {
+        // Ignore. Already processed inside the function.
+        // Loop through to try the next node.
+      }
+    }
+  }
+
+  private Callable<ByteBuffer> getFromOneDataNode(final DNAddrPair datanode,
+      final LocatedBlock block, final long start, final long end,
+      final ByteBuffer bb,
+      final Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap,
+      final CountDownLatch latch) {
+    return new Callable<ByteBuffer>() {
+      @Override
+      public ByteBuffer call() throws Exception {
+        byte[] buf = bb.array();
+        int offset = bb.position();
+        actualGetFromOneDataNode(datanode, block, start, end, buf, offset,
+            corruptedBlockMap);
+        latch.countDown();
+        return bb;
+      }
+    };
+  }
+
+  private void actualGetFromOneDataNode(final DNAddrPair datanode,
+      LocatedBlock block, final long start, final long end, byte[] buf,
+      int offset, Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap)
+      throws IOException {
+    DFSClientFaultInjector.get().startFetchFromDatanode();
-    
+
-      // or fetchBlockAt(). Always get the latest list of locations at the 
+      // or fetchBlockAt(). Always get the latest list of locations at the
-      DNAddrPair retval = chooseDataNode(block);
-      DatanodeInfo chosenNode = retval.info;
-      InetSocketAddress targetAddr = retval.addr;
+      DatanodeInfo chosenNode = datanode.info;
+      InetSocketAddress targetAddr = datanode.addr;
-          
+
-        DFSClient.LOG.warn("fetchBlockByteRange(). Got a checksum exception for " +
-                 src + " at " + block.getBlock() + ":" + 
-                 e.getPos() + " from " + chosenNode);
+        String msg = "fetchBlockByteRange(). Got a checksum exception for "
+            + src + " at " + block.getBlock() + ":" + e.getPos() + " from "
+            + chosenNode;
+        DFSClient.LOG.warn(msg);
+        addToDeadNodes(chosenNode);
+        throw new IOException(msg);
-          fetchBlockAt(block.getStartOffset());
+          try {
+            fetchBlockAt(block.getStartOffset());
+          } catch (IOException fbae) {
+            // ignore IOE, since we can retry it later in a loop
+          }
-          DFSClient.LOG.warn("Failed to connect to " + targetAddr + 
-              " for file " + src + " for block " + block.getBlock() + ":" + e);
-          if (DFSClient.LOG.isDebugEnabled()) {
-            DFSClient.LOG.debug("Connection failure ", e);
-          }
+          String msg = "Failed to connect to " + targetAddr + " for file "
+              + src + " for block " + block.getBlock() + ":" + e;
+          DFSClient.LOG.warn("Connection failure: " + msg, e);
+          addToDeadNodes(chosenNode);
+          throw new IOException(msg);
-      // Put chosen node into dead list, continue
-      addToDeadNodes(chosenNode);
+    }
+  }
+
+  /**
+   * Like {@link #fetchBlockByteRange(LocatedBlock, long, long, byte[],
+   * int, Map)} except we start up a second, parallel, 'hedged' read
+   * if the first read is taking longer than configured amount of
+   * time.  We then wait on which ever read returns first.
+   * 
+   * @param block
+   * @param start
+   * @param end
+   * @param buf
+   * @param offset
+   * @param corruptedBlockMap
+   * @throws IOException
+   */
+  private void hedgedFetchBlockByteRange(LocatedBlock block, long start,
+      long end, byte[] buf, int offset,
+      Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap)
+      throws IOException {
+    ArrayList<Future<ByteBuffer>> futures = null;
+    ArrayList<DatanodeInfo> ignored = new ArrayList<DatanodeInfo>();
+    ByteBuffer bb = null;
+    int len = (int) (end - start + 1);
+    block = getBlockAt(block.getStartOffset(), false);
+    // Latch shared by all outstanding reads.  First to finish closes
+    CountDownLatch hasReceivedResult = new CountDownLatch(1);
+    while (true) {
+      DNAddrPair chosenNode = null;
+      Future<ByteBuffer> future = null;
+      // futures is null if there is no request already executing.
+      if (futures == null) {
+        // chooseDataNode is a commitment.  If no node, we go to
+        // the NN to reget block locations.  Only go here on first read.
+        chosenNode = chooseDataNode(block, ignored);
+        bb = ByteBuffer.wrap(buf, offset, len);
+        future = getHedgedReadFuture(chosenNode, block, start, end, bb,
+          corruptedBlockMap, hasReceivedResult);
+        try {
+          future.get(dfsClient.getHedgedReadTimeout(), TimeUnit.MILLISECONDS);
+          return;
+        } catch (TimeoutException e) {
+          if (DFSClient.LOG.isDebugEnabled()) {
+            DFSClient.LOG.debug("Waited " + dfsClient.getHedgedReadTimeout() +
+              "ms to read from " + chosenNode.info + "; spawning hedged read");
+          }
+          // Ignore this node on next go around.
+          ignored.add(chosenNode.info);
+          dfsClient.getHedgedReadMetrics().incHedgedReadOps();
+          futures = new ArrayList<Future<ByteBuffer>>();
+          futures.add(future);
+          continue; // no need to refresh block locations
+        } catch (InterruptedException e) {
+          // Ignore
+        } catch (ExecutionException e) {
+          // Ignore already logged in the call.
+        }
+      } else {
+        // We are starting up a 'hedged' read.  We have a read already
+        // ongoing. Call getBestNodeDNAddrPair instead of chooseDataNode.
+        // If no nodes to do hedged reads against, pass.
+        try {
+          chosenNode = getBestNodeDNAddrPair(block.getLocations(), ignored);
+          bb = ByteBuffer.allocate(len);
+          future = getHedgedReadFuture(chosenNode, block, start, end, bb,
+            corruptedBlockMap, hasReceivedResult);
+          futures.add(future);
+        } catch (IOException ioe) {
+          if (DFSClient.LOG.isDebugEnabled()) {
+            DFSClient.LOG.debug("Failed getting node for hedged read: " +
+              ioe.getMessage());
+          }
+        }
+        // if not succeeded. Submit callables for each datanode in a loop, wait
+        // for a fixed interval and get the result from the fastest one.
+        try {
+          ByteBuffer result = getFirstToComplete(futures, hasReceivedResult);
+          // cancel the rest.
+          cancelAll(futures);
+          if (result.array() != buf) { // compare the array pointers
+            dfsClient.getHedgedReadMetrics().incHedgedReadWins();
+            System.arraycopy(result.array(), result.position(), buf, offset,
+                len);
+          } else {
+            dfsClient.getHedgedReadMetrics().incHedgedReadOps();
+          }
+          return;
+        } catch (InterruptedException ie) {
+          // Ignore
+        } catch (ExecutionException e) {
+          // exception already handled in the call method. getFirstToComplete
+          // will remove the failing future from the list. nothing more to do.
+        }
+        // We got here if exception.  Ignore this node on next go around.
+        ignored.add(chosenNode.info);
+      }
+      // executed if we get an error from a data node
+      block = getBlockAt(block.getStartOffset(), false);
+    }
+  }
+
+  private Future<ByteBuffer> getHedgedReadFuture(final DNAddrPair chosenNode,
+      final LocatedBlock block, long start,
+      final long end, final ByteBuffer bb,
+      final Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap,
+      final CountDownLatch hasReceivedResult) {
+    Callable<ByteBuffer> getFromDataNodeCallable =
+        getFromOneDataNode(chosenNode, block, start, end, bb,
+          corruptedBlockMap, hasReceivedResult);
+    return dfsClient.getHedgedReadsThreadPool().submit(getFromDataNodeCallable);
+  }
+
+  private ByteBuffer getFirstToComplete(ArrayList<Future<ByteBuffer>> futures,
+      CountDownLatch latch) throws ExecutionException, InterruptedException {
+    latch.await();
+    for (Future<ByteBuffer> future : futures) {
+      if (future.isDone()) {
+        try {
+          return future.get();
+        } catch (ExecutionException e) {
+          // already logged in the Callable
+          futures.remove(future);
+          throw e;
+        }
+      }
+    }
+    throw new InterruptedException("latch has counted down to zero but no"
+        + "result available yet, for safety try to request another one from"
+        + "outside loop, this should be rare");
+  }
+
+  private void cancelAll(List<Future<ByteBuffer>> futures) {
+    for (Future<ByteBuffer> future : futures) {
+      // Unfortunately, hdfs reads do not take kindly to interruption.
+      // Threads return a variety of interrupted-type exceptions but
+      // also complaints about invalid pbs -- likely because read
+      // is interrupted before gets whole pb.  Also verbose WARN
+      // logging.  So, for now, do not interrupt running read.
+      future.cancel(false);
-        fetchBlockByteRange(blk, targetStart, 
-            targetStart + bytesToRead - 1, buffer, offset, corruptedBlockMap);
+        if (dfsClient.isHedgedReadsEnabled()) {
+          hedgedFetchBlockByteRange(blk, targetStart, targetStart + bytesToRead
+              - 1, buffer, offset, corruptedBlockMap);
+        } else {
+          fetchBlockByteRange(blk, targetStart, targetStart + bytesToRead - 1,
+              buffer, offset, corruptedBlockMap);
+        }
-  static DatanodeInfo bestNode(DatanodeInfo nodes[], 
-                               AbstractMap<DatanodeInfo, DatanodeInfo> deadNodes)
-                               throws IOException {
-    if (nodes != null) { 
+  static DatanodeInfo bestNode(DatanodeInfo nodes[],
+      AbstractMap<DatanodeInfo, DatanodeInfo> deadNodes,
+      Collection<DatanodeInfo> ignoredNodes) throws IOException {
+    if (nodes != null) {
-        if (!deadNodes.containsKey(nodes[i])) {
+        if (!deadNodes.containsKey(nodes[i])
+            && (ignoredNodes == null || !ignoredNodes.contains(nodes[i]))) {

MOV26 MOV26 MOV26 MOV26 MOV26 INS26 UPD40 UPD40 UPD40 UPD40 INS40 UPD40 UPD40 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS44 INS29 INS83 INS43 INS42 INS44 INS44 INS43 MOV8 INS83 INS83 INS43 INS42 INS44 INS44 INS44 INS8 INS83 INS39 INS42 INS44 MOV44 MOV44 INS44 INS44 INS44 INS43 INS8 INS83 INS74 INS42 INS44 INS44 INS44 INS44 INS44 INS44 INS44 INS8 INS42 INS44 INS44 INS44 INS29 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS44 INS44 INS43 INS8 INS83 INS74 INS42 INS44 INS44 INS44 INS44 INS44 INS44 INS44 INS8 INS83 INS43 INS42 INS44 INS44 INS43 INS43 INS8 INS83 INS39 INS42 INS44 INS8 INS44 INS74 INS42 INS65 INS65 INS65 INS65 INS65 INS42 INS83 INS5 INS42 INS74 INS42 INS42 INS42 INS43 INS42 INS85 INS74 INS42 INS74 INS42 INS60 INS21 INS70 INS21 INS70 INS25 INS41 INS43 INS42 INS5 INS42 INS39 INS42 INS74 INS42 INS42 INS21 INS61 INS43 INS43 INS83 INS43 INS42 INS83 INS43 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS43 INS42 INS83 INS74 INS42 INS83 INS43 INS42 INS41 INS83 INS43 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS21 INS65 INS65 INS65 INS65 INS65 INS65 INS65 INS65 INS43 INS42 INS39 INS42 INS39 INS42 INS5 INS42 INS39 INS42 INS74 INS42 INS42 INS60 INS60 INS60 INS60 INS21 INS60 INS61 INS43 INS43 INS83 INS43 INS42 INS83 INS43 INS42 INS39 INS42 INS83 INS39 INS42 INS83 INS43 INS42 INS83 INS74 INS42 INS83 INS43 INS42 INS60 INS41 INS42 INS74 INS42 INS43 INS42 INS42 INS42 INS21 INS70 INS53 INS74 INS42 INS70 INS74 INS42 INS43 INS43 INS66 INS42 INS66 INS42 INS66 INS66 INS42 MOV43 INS85 INS43 INS43 INS43 INS42 INS43 INS43 INS43 INS43 INS43 INS43 INS59 INS32 INS44 INS42 INS8 INS32 INS44 INS32 INS8 INS27 INS8 INS32 INS42 INS39 INS85 INS43 INS43 INS74 INS7 INS9 INS8 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS74 INS42 INS14 INS42 INS32 INS66 INS65 INS66 INS66 INS66 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS39 INS85 INS43 INS43 INS74 INS74 INS59 INS74 INS59 INS43 INS59 INS39 INS59 INS7 INS43 INS59 INS9 INS8 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS74 INS42 INS74 INS59 INS32 INS43 INS74 INS42 INS32 INS44 INS42 INS8 INS14 INS43 INS74 INS44 INS42 INS8 INS43 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS45 MOV43 INS42 INS21 INS21 INS42 INS42 INS45 INS43 INS42 INS42 INS42 INS21 INS21 INS42 INS33 INS21 INS70 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS32 INS60 INS54 INS42 INS42 INS43 INS43 INS74 INS1 INS32 INS42 INS60 INS68 INS42 INS42 INS43 INS43 INS43 INS74 INS42 INS33 INS43 INS43 INS42 INS14 INS42 INS42 INS33 INS42 INS11 INS42 INS32 INS42 INS42 INS14 INS60 INS60 INS25 INS21 INS42 INS42 INS43 INS43 INS43 INS43 INS42 INS32 INS32 INS42 INS42 INS42 INS43 INS43 INS42 INS42 INS74 INS42 INS25 INS43 INS27 INS42 INS43 INS43 INS74 INS42 INS21 INS42 INS42 INS8 INS42 INS43 INS45 INS32 INS32 INS42 INS32 INS32 INS32 INS44 INS42 INS8 INS42 INS42 INS42 INS32 INS9 MOV43 INS59 INS8 INS12 INS42 INS42 INS43 INS43 INS31 INS42 INS42 INS43 MOV59 INS42 INS69 INS69 INS69 INS69 INS69 INS69 INS42 INS42 INS42 INS43 INS43 INS42 INS42 INS74 INS39 INS36 INS42 INS32 INS9 INS43 INS34 INS43 INS59 INS74 INS59 INS27 INS8 INS8 INS7 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS32 INS8 INS42 INS45 INS45 INS45 INS42 INS42 INS43 INS43 INS32 INS8 INS41 INS42 INS42 INS42 INS45 INS42 INS42 INS32 INS42 INS42 INS45 INS42 INS42 INS32 INS42 INS42 INS45 INS43 INS42 INS21 INS21 INS42 INS42 INS42 INS32 INS21 INS41 INS44 INS8 INS42 INS42 INS78 INS83 INS43 INS42 INS43 INS8 INS42 UPD40 UPD40 INS43 INS39 INS39 INS5 INS39 INS43 INS42 INS42 INS43 INS43 INS27 INS42 INS42 INS42 INS42 INS42 INS33 INS43 INS43 INS42 INS33 INS42 INS33 INS21 INS21 INS21 INS54 INS54 INS54 INS21 INS42 INS32 INS42 INS42 INS42 INS42 INS54 INS42 INS42 INS42 INS42 INS9 INS25 INS33 INS32 INS60 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS33 INS32 INS43 INS42 INS42 INS42 INS42 INS60 INS60 INS21 INS21 INS41 INS60 MOV21 INS53 INS42 INS39 INS85 INS42 INS42 INS42 INS27 INS34 INS42 INS42 INS7 INS7 INS7 INS8 INS12 INS12 INS12 INS8 INS12 INS8 INS12 INS12 INS32 INS42 INS32 INS9 INS8 INS12 INS32 INS8 MOV8 INS27 INS42 INS42 INS42 INS43 INS59 INS42 INS42 INS45 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS5 INS59 INS39 INS59 INS32 INS32 INS42 INS43 INS59 INS14 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS32 INS21 INS41 INS44 INS8 INS44 INS8 INS44 INS8 INS21 INS21 INS21 INS21 INS44 INS8 INS60 INS21 INS25 INS41 INS44 INS8 INS44 INS8 INS42 INS42 INS40 INS42 INS42 INS41 INS44 INS8 INS42 INS42 INS21 MOV38 INS36 INS42 INS42 INS32 INS60 INS21 INS42 INS42 INS39 INS85 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV27 INS42 INS43 INS42 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS43 INS42 INS25 INS21 INS21 INS21 INS21 INS18 INS43 INS42 INS43 INS42 INS7 INS7 INS7 INS32 INS43 INS42 INS25 INS43 INS59 INS32 INS27 INS8 INS8 INS43 INS42 INS43 INS42 INS32 INS43 INS42 INS21 INS53 INS32 INS27 INS42 INS42 INS42 INS42 INS43 INS59 INS32 INS42 INS42 INS42 INS42 INS42 INS42 MOV21 INS54 INS18 INS60 MOV21 INS53 INS42 INS42 INS32 INS40 INS42 MOV32 INS8 INS32 INS32 INS7 INS32 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS32 INS8 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS21 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS38 INS42 INS42 MOV27 INS40 INS42 INS27 INS42 MOV8 INS12 INS43 INS59 INS14 INS42 INS42 INS21 INS42 INS42 INS40 INS32 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS32 INS42 INS42 INS42 INS27 INS34 INS42 INS33 INS32 INS42 INS42 INS45 INS44 INS8 INS42 INS42 MOV27 INS27 INS42 UPD42 UPD42 INS43 INS42 INS32 INS42 INS42 INS74 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS2 INS43 INS42 INS45 INS42 INS42 INS40 INS42 INS27 INS43 INS74 INS40 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS32 INS45 INS40 INS45 INS42 INS43 INS43 INS45 INS32 INS42 INS42 INS42 INS42 INS42 INS42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL60 DEL18 DEL40 DEL45 DEL8 DEL25