HDFS-9040. Erasure coding: coordinate data streamers in DFSStripedOutputStream. Contributed by Jing Zhao and Walter Su.

+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
-import org.apache.hadoop.hdfs.client.impl.DfsClientConf;
+import org.apache.hadoop.hdfs.protocol.ClientProtocol;
+import org.apache.hadoop.hdfs.protocol.DatanodeID;
+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
+import org.apache.hadoop.hdfs.protocol.LocatedStripedBlock;
+import org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage;
+import org.apache.hadoop.hdfs.util.StripedBlockUtil;
+import org.apache.hadoop.util.Time;
-      queues = new ArrayList<>(numQueue);
+      List<BlockingQueue<T>> list = new ArrayList<>(numQueue);
-        queues.add(new LinkedBlockingQueue<T>(queueSize));
+        list.add(new LinkedBlockingQueue<T>(queueSize));
-    }
-
-    boolean isEmpty() {
-      for(int i = 0; i < queues.size(); i++) {
-        if (!queues.get(i).isEmpty()) {
-          return false;
-        }
-      }
-      return true;
-    }
-
-    int numQueues() {
-      return queues.size();
+      queues = Collections.synchronizedList(list);
+    T takeWithTimeout(int i) throws InterruptedIOException {
+      try {
+        return queues.get(i).poll(100, TimeUnit.MILLISECONDS);
+      } catch (InterruptedException e) {
+        throw DFSUtil.toInterruptedIOException("take interrupted, i=" + i, e);
+      }
+    }
+
+
+    void clear() {
+      for (BlockingQueue<T> q : queues) {
+        q.clear();
+      }
+    }
-  class Coordinator {
+  static class Coordinator {
+    /**
+     * The next internal block to write to for each streamers. The
+     * DFSStripedOutputStream makes the {@link ClientProtocol#addBlock} RPC to
+     * get a new block group. The block group is split to internal blocks, which
+     * are then distributed into the queue for streamers to retrieve.
+     */
+    /**
+     * Used to sync among all the streamers before allocating a new block. The
+     * DFSStripedOutputStream uses this to make sure every streamer has finished
+     * writing the previous block.
+     */
+    /**
+     * The following data structures are used for syncing while handling errors
+     */
-    private final MultipleBlockingQueue<ExtendedBlock> updateBlocks;
+    private final Map<StripedDataStreamer, Boolean> updateStreamerMap;
+    private final MultipleBlockingQueue<Boolean> streamerUpdateResult;
-    Coordinator(final DfsClientConf conf, final int numDataBlocks,
-        final int numAllBlocks) {
+    Coordinator(final int numAllBlocks) {
-      endBlocks = new MultipleBlockingQueue<>(numDataBlocks, 1);
-
+      endBlocks = new MultipleBlockingQueue<>(numAllBlocks, 1);
-      updateBlocks = new MultipleBlockingQueue<>(numAllBlocks, 1);
+      updateStreamerMap = Collections.synchronizedMap(
+          new HashMap<StripedDataStreamer, Boolean>(numAllBlocks));
+      streamerUpdateResult = new MultipleBlockingQueue<>(numAllBlocks, 1);
-    MultipleBlockingQueue<ExtendedBlock> getUpdateBlocks() {
-      return updateBlocks;
-    }
-
-    StripedDataStreamer getStripedDataStreamer(int i) {
-      return DFSStripedOutputStream.this.getStripedDataStreamer(i);
-    }
-
-    ExtendedBlock takeEndBlock(int i) throws InterruptedIOException {
-      return endBlocks.take(i);
+    void offerStreamerUpdateResult(int i, boolean success) {
+      streamerUpdateResult.offer(i, success);
-    boolean hasAllEndBlocks() {
-      for(int i = 0; i < endBlocks.numQueues(); i++) {
-        if (endBlocks.peek(i) == null) {
-          return false;
-        }
-      }
-      return true;
+    boolean takeStreamerUpdateResult(int i) throws InterruptedIOException {
+      return streamerUpdateResult.take(i);
-    void setBytesEndBlock(int i, long newBytes, ExtendedBlock block) {
-      ExtendedBlock b = endBlocks.peek(i);
-      if (b == null) {
-        // streamer just has failed, put end block and continue
-        b = block;
-        offerEndBlock(i, b);
-      }
-      b.setNumBytes(newBytes);
+    void updateStreamer(StripedDataStreamer streamer,
+        boolean success) {
+      assert !updateStreamerMap.containsKey(streamer);
+      updateStreamerMap.put(streamer, success);
-    /** @return a block representing the entire block group. */
-    ExtendedBlock getBlockGroup() {
-      final StripedDataStreamer s0 = getStripedDataStreamer(0);
-      final ExtendedBlock b0 = s0.getBlock();
-      if (b0 == null) {
-        return null;
-      }
-
-      final boolean atBlockGroupBoundary = s0.getBytesCurBlock() == 0 && b0.getNumBytes() > 0;
-
-      final ExtendedBlock block = new ExtendedBlock(b0);
-      long numBytes = atBlockGroupBoundary? b0.getNumBytes(): s0.getBytesCurBlock();
-      for (int i = 1; i < numAllBlocks; i++) {
-        final StripedDataStreamer si = getStripedDataStreamer(i);
-        final ExtendedBlock bi = si.getBlock();
-        if (bi != null && bi.getGenerationStamp() > block.getGenerationStamp()) {
-          block.setGenerationStamp(bi.getGenerationStamp());
-        }
-        if (i < numDataBlocks) {
-          numBytes += atBlockGroupBoundary? bi.getNumBytes(): si.getBytesCurBlock();
-        }
-      }
-      block.setNumBytes(numBytes);
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("getBlockGroup: " + block + ", numBytes=" + block.getNumBytes());
-      }
-      return block;
+    void clearFailureStates() {
+      newBlocks.clear();
+      updateStreamerMap.clear();
+      streamerUpdateResult.clear();
-
-  @Override
-  ExtendedBlock getBlock() {
-    return coordinator.getBlockGroup();
-  }
+  private ExtendedBlock currentBlockGroup;
+  private final String[] favoredNodes;
+  private final List<StripedDataStreamer> failedStreamers;
-    super(dfsClient, src, stat, flag, progress, checksum, favoredNodes);
+    super(dfsClient, src, stat, flag, progress, checksum, favoredNodes, false);
+    this.favoredNodes = favoredNodes;
+    failedStreamers = new ArrayList<>();
-    coordinator = new Coordinator(dfsClient.getConf(),
-        numDataBlocks, numAllBlocks);
+    coordinator = new Coordinator(numAllBlocks);
-    List<StripedDataStreamer> s = new ArrayList<>(numAllBlocks);
+    streamers = new ArrayList<>(numAllBlocks);
-      s.add(streamer);
+      streamers.add(streamer);
-    streamers = Collections.unmodifiableList(s);
-    return (StripedDataStreamer)streamer;
+    return (StripedDataStreamer) streamer;
-    int oldIdx = streamers.indexOf(streamer);
-    if (oldIdx >= 0) {
-      currentPackets[oldIdx] = currentPacket;
+    if (streamer != null) {
+      int oldIdx = streamers.indexOf(getCurrentStreamer());
+      if (oldIdx >= 0) {
+        currentPackets[oldIdx] = currentPacket;
+      }
-    streamer = streamers.get(newIdx);
+    streamer = getStripedDataStreamer(newIdx);
-
-  private void checkStreamers(boolean setExternalError) throws IOException {
-    int count = 0;
+  /**
+   * check all the existing StripedDataStreamer and find newly failed streamers.
+   * @return The newly failed streamers.
+   * @throws IOException if less than {@link #numDataBlocks} streamers are still
+   *                     healthy.
+   */
+  private Set<StripedDataStreamer> checkStreamers() throws IOException {
+    Set<StripedDataStreamer> newFailed = new HashSet<>();
-      if (!s.isFailed()) {
-        if (setExternalError && s.getBlock() != null) {
-          s.getErrorState().initExternalError();
-        }
-        count++;
+      if (!s.isHealthy() && !failedStreamers.contains(s)) {
+        newFailed.add(s);
+
+    final int failCount = failedStreamers.size() + newFailed.size();
-      LOG.debug("count=" + count);
+      LOG.debug("healthy streamer count=" + (numAllBlocks - failCount));
+      LOG.debug("original failed streamers: " + failedStreamers);
+      LOG.debug("newly failed streamers: " + newFailed);
-    if (count < numDataBlocks) {
-      throw new IOException("Failed: the number of remaining blocks = "
-          + count + " < the number of data blocks = " + numDataBlocks);
+    if (failCount > (numAllBlocks - numDataBlocks)) {
+      throw new IOException("Failed: the number of failed blocks = "
+          + failCount + " > the number of data blocks = "
+          + (numAllBlocks - numDataBlocks));
+    return newFailed;
-    handleStreamerFailure(err, e, true);
+    LOG.warn("Failed: " + err + ", " + this, e);
+    getCurrentStreamer().getErrorState().setInternalError();
+    getCurrentStreamer().close(true);
+    checkStreamers();
+    currentPacket = null;
-  private void handleStreamerFailure(String err, Exception e,
-      boolean setExternalError) throws IOException {
-    LOG.warn("Failed: " + err + ", " + this, e);
-    getCurrentStreamer().setFailed(true);
-    checkStreamers(setExternalError);
-    currentPacket = null;
+  private void replaceFailedStreamers() {
+    assert streamers.size() == numAllBlocks;
+    for (short i = 0; i < numAllBlocks; i++) {
+      final StripedDataStreamer oldStreamer = getStripedDataStreamer(i);
+      if (!oldStreamer.isHealthy()) {
+        StripedDataStreamer streamer = new StripedDataStreamer(oldStreamer.stat,
+            dfsClient, src, oldStreamer.progress,
+            oldStreamer.checksum4WriteBlock, cachingStrategy, byteArrayManager,
+            favoredNodes, i, coordinator);
+        streamers.set(i, streamer);
+        currentPackets[i] = null;
+        if (i == 0) {
+          this.streamer = streamer;
+        }
+        streamer.start();
+      }
+    }
+  }
+
+  private void waitEndBlocks(int i) throws IOException {
+    while (getStripedDataStreamer(i).isHealthy()) {
+      final ExtendedBlock b = coordinator.endBlocks.takeWithTimeout(i);
+      if (b != null) {
+        StripedBlockUtil.checkBlocks(currentBlockGroup, i, b);
+        return;
+      }
+    }
+  }
+
+  private void allocateNewBlock() throws IOException {
+    if (currentBlockGroup != null) {
+      for (int i = 0; i < numAllBlocks; i++) {
+        // sync all the healthy streamers before writing to the new block
+        waitEndBlocks(i);
+      }
+    }
+    failedStreamers.clear();
+    // replace failed streamers
+    replaceFailedStreamers();
+
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Allocating new block group. The previous block group: "
+          + currentBlockGroup);
+    }
+
+    // TODO collect excludedNodes from all the data streamers
+    final LocatedBlock lb = addBlock(null, dfsClient, src, currentBlockGroup,
+        fileId, favoredNodes);
+    assert lb.isStriped();
+    if (lb.getLocations().length < numDataBlocks) {
+      throw new IOException("Failed to get " + numDataBlocks
+          + " nodes from namenode: blockGroupSize= " + numAllBlocks
+          + ", blocks.length= " + lb.getLocations().length);
+    }
+    // assign the new block to the current block group
+    currentBlockGroup = lb.getBlock();
+
+    final LocatedBlock[] blocks = StripedBlockUtil.parseStripedBlockGroup(
+        (LocatedStripedBlock) lb, cellSize, numDataBlocks,
+        numAllBlocks - numDataBlocks);
+    for (int i = 0; i < blocks.length; i++) {
+      StripedDataStreamer si = getStripedDataStreamer(i);
+      if (si.isHealthy()) { // skipping failed data streamer
+        if (blocks[i] == null) {
+          // Set exception and close streamer as there is no block locations
+          // found for the parity block.
+          LOG.warn("Failed to get block location for parity block, index=" + i);
+          si.getLastException().set(
+              new IOException("Failed to get following block, i=" + i));
+          si.getErrorState().setInternalError();
+          si.close(true);
+        } else {
+          coordinator.getFollowingBlocks().offer(i, blocks[i]);
+        }
+      }
+    }
+  }
+
+  private boolean shouldEndBlockGroup() {
+    return currentBlockGroup != null &&
+        currentBlockGroup.getNumBytes() == blockSize * numDataBlocks;
-    final long oldBytes = current.getBytesCurBlock();
-    if (!current.isFailed()) {
+    if (currentBlockGroup == null || shouldEndBlockGroup()) {
+      // the incoming data should belong to a new block. Allocate a new block.
+      allocateNewBlock();
+    }
+
+    currentBlockGroup.setNumBytes(currentBlockGroup.getNumBytes() + len);
+    if (current.isHealthy()) {
-    if (current.isFailed()) {
-      final long newBytes = oldBytes + len;
-      coordinator.setBytesEndBlock(index, newBytes, current.getBlock());
-      current.setBytesCurBlock(newBytes);
-    }
-
+        // check failure state for all the streamers. Bump GS if necessary
+        checkStreamerFailures();
+
+        // if this is the end of the block group, end each internal block
+        if (shouldEndBlockGroup()) {
+          for (int i = 0; i < numAllBlocks; i++) {
+            final StripedDataStreamer s = setCurrentStreamer(i);
+            if (s.isHealthy()) {
+              try {
+                endBlock();
+              } catch (IOException ignored) {}
+            }
+          }
+        }
+  @Override
+  void enqueueCurrentPacketFull() throws IOException {
+    LOG.debug("enqueue full {}, src={}, bytesCurBlock={}, blockSize={},"
+            + " appendChunk={}, {}", currentPacket, src, getStreamer()
+            .getBytesCurBlock(), blockSize, getStreamer().getAppendChunk(),
+        getStreamer());
+    enqueueCurrentPacket();
+    adjustChunkBoundary();
+    // no need to end block here
+  }
+
+  private Set<StripedDataStreamer> markExternalErrorOnStreamers() {
+    Set<StripedDataStreamer> healthySet = new HashSet<>();
+    for (StripedDataStreamer streamer : streamers) {
+      if (streamer.isHealthy() &&
+          streamer.getStage() == BlockConstructionStage.DATA_STREAMING) {
+        streamer.setExternalError();
+        healthySet.add(streamer);
+      }
+    }
+    return healthySet;
+  }
+
+  /**
+   * Check and handle data streamer failures. This is called only when we have
+   * written a full stripe (i.e., enqueue all packets for a full stripe), or
+   * when we're closing the outputstream.
+   */
+  private void checkStreamerFailures() throws IOException {
+    Set<StripedDataStreamer> newFailed = checkStreamers();
+    if (newFailed.size() > 0) {
+      // for healthy streamers, wait till all of them have fetched the new block
+      // and flushed out all the enqueued packets.
+      flushAllInternals();
+    }
+    // get all the current failed streamers after the flush
+    newFailed = checkStreamers();
+    while (newFailed.size() > 0) {
+      failedStreamers.addAll(newFailed);
+      coordinator.clearFailureStates();
+
+      // mark all the healthy streamers as external error
+      Set<StripedDataStreamer> healthySet = markExternalErrorOnStreamers();
+
+      // we have newly failed streamers, update block for pipeline
+      final ExtendedBlock newBG = updateBlockForPipeline(healthySet);
+
+      // wait till all the healthy streamers to
+      // 1) get the updated block info
+      // 2) create new block outputstream
+      newFailed = waitCreatingNewStreams(healthySet);
+      if (newFailed.size() + failedStreamers.size() >
+          numAllBlocks - numDataBlocks) {
+        throw new IOException(
+            "Data streamers failed while creating new block streams: "
+                + newFailed + ". There are not enough healthy streamers.");
+      }
+      for (StripedDataStreamer failedStreamer : newFailed) {
+        assert !failedStreamer.isHealthy();
+      }
+
+      // TODO we can also succeed if all the failed streamers have not taken
+      // the updated block
+      if (newFailed.size() == 0) {
+        // reset external error state of all the streamers
+        for (StripedDataStreamer streamer : healthySet) {
+          assert streamer.isHealthy();
+          streamer.getErrorState().reset();
+        }
+        updatePipeline(newBG);
+      }
+      for (int i = 0; i < numAllBlocks; i++) {
+        coordinator.offerStreamerUpdateResult(i, newFailed.size() == 0);
+      }
+    }
+  }
+
+  private int checkStreamerUpdates(Set<StripedDataStreamer> failed,
+      Set<StripedDataStreamer> streamers) {
+    for (StripedDataStreamer streamer : streamers) {
+      if (!coordinator.updateStreamerMap.containsKey(streamer)) {
+        if (!streamer.isHealthy() &&
+            coordinator.getNewBlocks().peek(streamer.getIndex()) != null) {
+          // this streamer had internal error before getting updated block
+          failed.add(streamer);
+        }
+      }
+    }
+    return coordinator.updateStreamerMap.size() + failed.size();
+  }
+
+  private Set<StripedDataStreamer> waitCreatingNewStreams(
+      Set<StripedDataStreamer> healthyStreamers) throws IOException {
+    Set<StripedDataStreamer> failed = new HashSet<>();
+    final int expectedNum = healthyStreamers.size();
+    final long socketTimeout = dfsClient.getConf().getSocketTimeout();
+    // the total wait time should be less than the socket timeout, otherwise
+    // a slow streamer may cause other streamers to timeout. here we wait for
+    // half of the socket timeout
+    long remaingTime = socketTimeout > 0 ? socketTimeout/2 : Long.MAX_VALUE;
+    final long waitInterval = 1000;
+    synchronized (coordinator) {
+      while (checkStreamerUpdates(failed, healthyStreamers) < expectedNum
+          && remaingTime > 0) {
+        try {
+          long start = Time.monotonicNow();
+          coordinator.wait(waitInterval);
+          remaingTime -= Time.monotonicNow() - start;
+        } catch (InterruptedException e) {
+          throw DFSUtil.toInterruptedIOException("Interrupted when waiting" +
+              " for results of updating striped streamers", e);
+        }
+      }
+    }
+    synchronized (coordinator) {
+      for (StripedDataStreamer streamer : healthyStreamers) {
+        if (!coordinator.updateStreamerMap.containsKey(streamer)) {
+          // close the streamer if it is too slow to create new connection
+          streamer.setStreamerAsClosed();
+          failed.add(streamer);
+        }
+      }
+    }
+    for (Map.Entry<StripedDataStreamer, Boolean> entry :
+        coordinator.updateStreamerMap.entrySet()) {
+      if (!entry.getValue()) {
+        failed.add(entry.getKey());
+      }
+    }
+    for (StripedDataStreamer failedStreamer : failed) {
+      healthyStreamers.remove(failedStreamer);
+    }
+    return failed;
+  }
+
+  /**
+   * Call {@link ClientProtocol#updateBlockForPipeline} and assign updated block
+   * to healthy streamers.
+   * @param healthyStreamers The healthy data streamers. These streamers join
+   *                         the failure handling.
+   */
+  private ExtendedBlock updateBlockForPipeline(
+      Set<StripedDataStreamer> healthyStreamers) throws IOException {
+    final LocatedBlock updated = dfsClient.namenode.updateBlockForPipeline(
+        currentBlockGroup, dfsClient.clientName);
+    final long newGS = updated.getBlock().getGenerationStamp();
+    ExtendedBlock newBlock = new ExtendedBlock(currentBlockGroup);
+    newBlock.setGenerationStamp(newGS);
+    final LocatedBlock[] updatedBlks = StripedBlockUtil.parseStripedBlockGroup(
+        (LocatedStripedBlock) updated, cellSize, numDataBlocks,
+        numAllBlocks - numDataBlocks);
+
+    for (int i = 0; i < numAllBlocks; i++) {
+      StripedDataStreamer si = getStripedDataStreamer(i);
+      if (healthyStreamers.contains(si)) {
+        final LocatedBlock lb = new LocatedBlock(new ExtendedBlock(newBlock),
+            null, null, null, -1, updated.isCorrupt(), null);
+        lb.setBlockToken(updatedBlks[i].getBlockToken());
+        coordinator.getNewBlocks().offer(i, lb);
+      }
+    }
+    return newBlock;
+  }
+
+  private void updatePipeline(ExtendedBlock newBG) throws IOException {
+    final DatanodeInfo[] newNodes = new DatanodeInfo[numAllBlocks];
+    final String[] newStorageIDs = new String[numAllBlocks];
+    for (int i = 0; i < numAllBlocks; i++) {
+      final StripedDataStreamer streamer = getStripedDataStreamer(i);
+      final DatanodeInfo[] nodes = streamer.getNodes();
+      final String[] storageIDs = streamer.getStorageIDs();
+      if (streamer.isHealthy() && nodes != null && storageIDs != null) {
+        newNodes[i] = nodes[0];
+        newStorageIDs[i] = storageIDs[0];
+      } else {
+        newNodes[i] = new DatanodeInfo(DatanodeID.EMPTY_DATANODE_ID);
+        newStorageIDs[i] = "";
+      }
+    }
+    dfsClient.namenode.updatePipeline(dfsClient.clientName, currentBlockGroup,
+        newBG, newNodes, newStorageIDs);
+    currentBlockGroup = newBG;
+  }
+
-  /**
-   * Simply add bytesCurBlock together. Note that this result is not accurately
-   * the size of the block group.
-   */
-  private long getCurrentSumBytes() {
-    long sum = 0;
-    for (int i = 0; i < numDataBlocks; i++) {
-      sum += streamers.get(i).getBytesCurBlock();
-    }
-    return sum;
-  }
-
-    final long currentBlockGroupBytes = getCurrentSumBytes();
-    if (currentBlockGroupBytes % stripeDataSize() == 0) {
+    final long currentBlockGroupBytes = currentBlockGroup == null ?
+        0 : currentBlockGroup.getNumBytes();
+    final long lastStripeSize = currentBlockGroupBytes % stripeDataSize();
+    if (lastStripeSize == 0) {
-    final int firstCellSize =
-        (int)(getStripedDataStreamer(0).getBytesCurBlock() % cellSize);
-    final int parityCellSize = firstCellSize > 0 && firstCellSize < cellSize?
-        firstCellSize : cellSize;
+    final long parityCellSize = lastStripeSize < cellSize?
+        lastStripeSize : cellSize;
-  void writeParity(int index, ByteBuffer buffer, byte[] checksumBuf
-      ) throws IOException {
+  void writeParity(int index, ByteBuffer buffer, byte[] checksumBuf)
+      throws IOException {
-    if (!current.isFailed()) {
+    if (current.isHealthy()) {
-
-    if (current.isFailed()) {
-      final long newBytes = oldBytes + len;
-      current.setBytesCurBlock(newBytes);
-    }
-      streamers.get(i).release();
+      getStripedDataStreamer(i).release();
-      try {
-        flushBuffer();
-      } catch(Exception e) {
-        handleStreamerFailure("flushBuffer " + getCurrentStreamer(), e);
-      }
+      flushBuffer();
+      // flush all the data packets
+      flushAllInternals();
+      // check failures
+      checkStreamerFailures();
+
-        if (!s.isFailed()) {
+        if (s.isHealthy()) {
-            // flush all data to Datanode
+            // flush the last "close" packet to Datanode
-            handleStreamerFailure("flushInternal " + s, e, false);
+            // TODO for both close and endBlock, we currently do not handle
+            // failures when sending the last packet. We actually do not need to
+            // bump GS for this kind of failure. Thus counting the total number
+            // of failures may be good enough.
-      final ExtendedBlock lastBlock = coordinator.getBlockGroup();
-        completeFile(lastBlock);
+        completeFile(currentBlockGroup);
-      if (!si.isFailed() && currentPacket != null) {
+      if (si.isHealthy() && currentPacket != null) {
-          handleStreamerFailure("enqueueAllCurrentPackets, i=" + i, e, false);
+          handleStreamerFailure("enqueueAllCurrentPackets, i=" + i, e);
+
+  void flushAllInternals() throws IOException {
+    int current = getCurrentIndex();
+
+    for (int i = 0; i < numAllBlocks; i++) {
+      final StripedDataStreamer s = setCurrentStreamer(i);
+      if (s.isHealthy()) {
+        try {
+          // flush all data to Datanode
+          flushInternal();
+        } catch(Exception e) {
+          handleStreamerFailure("flushInternal " + s, e);
+        }
+      }
+    }
+    setCurrentStreamer(current);
+  }
+
+  static void sleep(long ms, String op) throws InterruptedIOException {
+    try {
+      Thread.sleep(ms);
+    } catch(InterruptedException ie) {
+      throw DFSUtil.toInterruptedIOException(
+          "Sleep interrupted during " + op, ie);
+    }
+  }
+
+  @Override
+  ExtendedBlock getBlock() {
+    return currentBlockGroup;
+  }

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 MOV31 MOV31 MOV31 MOV31 MOV31 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 MOV31 MOV31 INS55 INS23 INS23 INS23 MOV31 MOV31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 MOV29 INS83 MOV42 MOV23 MOV23 MOV23 MOV23 INS23 MOV31 MOV31 MOV31 MOV31 INS31 INS31 MOV31 INS31 INS83 MOV43 INS59 INS83 INS83 INS5 INS59 INS83 INS83 MOV74 INS59 MOV24 INS29 INS83 INS74 INS42 MOV43 INS8 MOV21 INS83 UPD39 UPD42 INS83 MOV39 UPD42 MOV42 MOV44 INS43 INS8 INS83 INS39 INS42 INS43 INS8 INS83 INS39 INS42 INS8 MOV78 INS39 INS42 INS43 INS8 INS83 INS74 INS42 INS8 INS29 INS83 INS39 INS42 INS43 INS8 INS83 INS39 INS42 INS44 INS44 INS8 INS83 INS74 INS42 INS44 INS43 INS8 INS29 INS83 MOV43 INS42 INS44 MOV43 INS8 UPD42 INS43 MOV78 UPD42 INS8 UPD39 UPD42 INS43 INS83 UPD42 INS44 INS44 INS43 INS8 INS78 MOV43 INS42 INS8 MOV21 INS43 INS42 INS44 INS43 UPD39 INS42 INS8 INS29 INS29 INS29 UPD74 INS83 INS83 UPD74 MOV74 INS59 MOV21 MOV21 INS39 INS42 MOV44 INS44 INS8 INS39 INS42 MOV44 MOV43 MOV8 INS39 INS42 INS44 INS39 INS42 INS8 INS42 INS43 INS85 INS42 INS42 INS21 INS21 INS25 INS65 INS65 INS65 INS43 INS43 INS60 INS70 INS60 INS25 INS25 INS41 INS21 INS6 UPD39 UPD42 INS42 INS61 INS42 INS25 INS21 INS21 INS25 MOV60 INS6 INS25 INS21 MOV60 INS24 INS41 INS25 MOV21 INS42 INS21 INS21 INS21 INS43 INS43 INS60 INS70 INS41 INS65 INS42 INS60 INS25 INS21 INS61 INS74 INS42 INS74 INS42 INS70 INS41 INS43 INS43 INS74 INS42 INS42 INS60 INS60 INS60 INS60 INS60 INS51 INS51 INS70 INS70 MOV41 INS65 INS65 INS74 INS42 INS60 INS60 INS60 INS21 INS60 INS24 INS41 MOV43 UPD42 INS42 INS60 INS60 INS24 INS21 INS21 INS60 INS25 MOV21 INS24 MOV21 INS42 INS21 INS39 INS42 INS43 INS42 INS42 INS54 INS42 INS41 INS60 INS42 INS39 INS42 INS42 INS54 INS70 INS65 INS65 INS65 UPD43 MOV43 UPD43 UPD42 INS43 INS42 INS21 INS39 INS42 INS21 MOV43 INS42 UPD39 UPD42 INS6 INS21 INS21 INS21 INS21 INS42 INS9 INS7 INS7 INS27 INS8 INS66 INS66 INS42 INS66 INS65 INS66 INS66 INS42 INS42 INS74 INS59 MOV44 INS42 INS8 INS83 INS39 INS59 MOV32 INS8 INS27 INS8 INS42 INS32 INS27 INS58 MOV27 MOV37 INS8 INS32 INS8 INS27 INS8 INS32 INS32 MOV32 INS8 UPD43 INS32 INS27 INS8 INS7 INS5 MOV58 INS27 MOV37 INS8 INS27 INS27 INS8 INS32 INS32 INS32 INS32 INS42 INS42 INS74 INS59 INS44 INS42 INS8 INS42 INS66 INS66 INS66 INS74 INS59 INS27 INS8 INS7 INS27 INS8 INS43 INS43 INS43 INS43 INS44 INS42 INS8 INS27 INS42 INS42 INS43 INS43 INS74 INS59 INS83 INS39 INS59 INS83 INS39 INS59 INS39 INS59 INS83 INS39 INS59 INS42 INS8 INS42 INS8 INS44 INS32 INS8 INS44 INS42 INS8 UPD42 INS66 INS65 INS66 INS66 INS42 INS66 INS66 INS43 INS43 INS83 INS43 INS59 INS83 INS39 INS59 MOV43 INS59 INS32 INS83 INS5 INS59 INS58 INS27 INS37 INS8 INS42 INS83 INS5 INS59 INS83 INS5 INS59 INS58 INS27 INS37 INS8 INS32 INS7 MOV83 UPD39 MOV39 INS59 INS27 MOV8 UPD39 INS32 INS58 INS27 INS37 INS8 UPD39 INS32 INS42 INS8 INS12 INS42 INS74 INS59 MOV8 INS12 INS44 INS42 INS8 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS66 INS66 INS66 UPD42 UPD42 INS42 INS7 INS32 INS32 INS38 INS32 INS32 INS32 INS32 INS22 INS42 INS42 INS14 MOV14 INS42 INS33 MOV60 MOV25 INS67 INS43 INS43 INS42 INS14 INS25 INS42 INS27 MOV21 INS21 INS21 INS21 INS42 INS36 INS53 INS32 UPD42 UPD42 INS42 INS32 INS42 INS39 INS59 INS60 MOV25 INS32 INS42 MOV60 MOV25 INS42 INS33 INS24 INS42 INS42 INS42 INS21 UPD42 UPD42 INS42 INS42 INS22 INS42 INS53 INS42 INS32 INS43 INS85 UPD42 INS42 INS40 MOV60 INS25 INS27 INS27 INS27 INS32 INS21 UPD42 UPD42 INS27 MOV42 UPD42 MOV42 INS25 INS42 INS42 INS27 INS42 UPD42 MOV42 INS32 INS42 INS32 INS32 INS42 INS42 INS43 INS43 INS42 INS14 INS43 INS42 INS25 INS43 INS43 INS42 INS32 INS32 MOV34 INS21 INS42 INS32 MOV32 MOV34 INS21 INS21 INS60 MOV60 INS21 INS25 INS70 INS25 MOV24 INS42 INS42 INS42 INS42 INS43 INS42 INS25 INS32 INS32 INS42 INS42 INS43 INS43 INS42 INS14 INS42 INS32 INS42 INS32 INS42 INS16 INS42 INS34 INS61 INS70 INS74 INS42 INS40 INS42 MOV25 INS43 INS42 INS21 INS67 INS42 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS14 INS42 INS42 INS42 INS43 INS85 INS42 INS32 INS39 INS59 INS42 INS42 INS42 INS60 INS25 INS43 INS85 INS42 INS3 INS43 INS85 INS42 INS3 INS39 INS59 INS42 INS42 INS42 INS60 INS60 INS60 INS25 INS40 INS42 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS16 UPD42 MOV42 MOV27 INS42 INS34 MOV42 UPD42 MOV42 INS39 INS59 INS42 INS42 INS42 MOV21 MOV21 MOV21 INS21 UPD42 INS32 UPD42 INS60 INS25 INS42 INS42 INS21 INS44 INS8 INS43 INS74 INS42 MOV14 INS32 MOV41 INS44 INS8 INS74 INS42 INS21 INS67 UPD42 INS42 INS32 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 INS42 INS52 INS42 INS74 UPD42 INS42 INS42 INS42 INS74 INS27 INS8 INS32 INS32 INS32 INS32 INS32 INS27 INS14 INS32 INS42 INS42 INS42 INS42 INS34 INS83 INS43 INS59 INS38 INS8 INS42 INS42 INS83 MOV43 UPD27 MOV58 INS27 MOV37 INS8 INS32 UPD42 INS33 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS14 INS42 INS42 INS42 UPD42 INS42 INS11 INS42 INS42 INS27 INS43 INS32 INS8 INS42 INS33 INS32 INS27 INS42 INS33 UPD42 MOV42 INS32 INS32 INS42 MOV27 INS8 INS45 INS45 INS32 MOV42 INS32 INS42 INS42 INS42 INS42 INS74 INS42 INS27 INS8 INS42 INS42 INS42 INS42 INS42 INS32 INS42 UPD42 UPD42 INS32 INS32 INS74 INS59 MOV43 INS7 INS27 INS8 INS44 INS42 INS8 INS27 INS8 INS42 INS38 INS8 INS40 INS42 INS42 INS42 INS42 INS42 INS74 INS42 INS42 MOV32 INS42 INS27 INS27 INS40 INS27 INS8 INS44 INS42 INS8 INS43 INS43 INS43 INS38 INS42 INS32 INS42 INS42 INS40 INS42 INS42 INS40 INS32 INS42 MOV43 INS42 INS42 INS42 INS42 INS11 INS42 INS42 INS27 INS42 INS34 INS43 INS59 INS32 INS8 INS42 INS5 INS42 INS42 INS5 INS42 UPD42 MOV42 MOV34 INS83 INS43 INS59 INS83 INS5 INS59 INS83 INS5 INS59 MOV27 MOV8 INS8 INS27 INS34 INS32 INS27 UPD42 INS42 INS34 INS32 INS32 INS42 INS83 INS43 INS59 INS32 INS8 INS32 INS43 INS42 INS53 INS42 INS43 INS43 INS42 INS42 INS42 MOV32 INS43 INS42 INS53 INS43 INS43 INS32 INS42 INS42 INS42 INS42 INS14 INS74 UPD42 INS42 INS42 INS42 INS43 UPD42 INS43 INS38 INS38 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 MOV43 INS27 UPD42 MOV42 INS42 INS42 INS32 INS32 INS60 INS21 INS21 INS25 INS21 INS21 INS41 INS42 INS42 MOV21 INS42 INS42 INS27 INS42 INS42 INS43 INS27 INS43 INS42 INS42 INS42 INS42 INS42 INS42 MOV25 INS42 INS42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 MOV21 MOV21 MOV21 INS21 INS25 INS42 INS42 INS43 INS32 INS27 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS32 INS42 INS32 INS42 INS32 INS27 INS27 INS53 INS43 INS42 INS6 INS32 INS34 INS70 INS21 INS32 MOV25 INS43 INS42 INS34 INS42 INS34 INS27 INS27 INS54 INS43 INS42 INS25 INS40 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS60 INS21 INS21 INS43 INS85 INS43 INS85 INS42 INS42 INS32 INS43 INS85 INS42 INS32 INS43 INS85 INS42 INS32 INS27 INS21 MOV21 INS21 INS42 INS33 INS42 UPD42 MOV42 UPD42 MOV42 MOV42 INS32 UPD42 UPD42 MOV42 UPD42 MOV42 INS32 INS42 INS42 INS32 UPD42 MOV42 INS42 INS54 INS42 INS42 INS42 INS42 INS32 INS42 INS42 UPD42 UPD42 INS34 INS40 INS42 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS74 INS42 INS43 INS42 MOV32 INS42 INS32 INS32 INS32 INS45 INS36 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS36 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS43 INS59 INS32 INS7 INS27 MOV8 INS32 INS40 UPD42 INS32 INS45 INS42 INS42 INS45 INS42 INS45 INS42 INS45 INS22 INS42 INS8 INS32 INS32 INS8 INS42 INS42 INS42 INS32 INS40 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS14 INS42 INS38 INS42 INS42 INS44 INS42 INS8 INS32 INS40 UPD42 MOV42 UPD42 MOV42 INS42 INS32 INS42 INS42 INS34 INS8 INS12 INS42 INS38 INS8 INS42 INS42 INS42 INS42 INS42 INS83 INS43 INS59 INS32 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS27 INS42 INS7 INS7 INS7 INS7 UPD42 MOV42 UPD42 MOV42 INS32 MOV42 UPD42 MOV42 UPD42 MOV42 MOV42 INS8 MOV12 INS42 INS42 INS27 INS42 UPD42 MOV42 INS42 INS27 UPD42 MOV42 INS43 INS43 INS43 INS42 UPD42 MOV42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS27 INS27 INS42 INS42 INS14 UPD42 MOV42 UPD42 MOV42 MOV42 INS42 INS2 INS33 INS42 INS34 INS21 INS42 INS42 INS42 INS42 UPD42 MOV42 MOV42 MOV42 UPD42 UPD42 INS32 INS42 INS2 INS21 INS21 INS21 INS21 INS21 INS42 INS42 INS24 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS27 INS32 INS43 INS42 INS6 INS21 INS42 INS42 UPD42 MOV42 UPD42 MOV42 MOV42 INS27 INS38 UPD27 INS42 INS42 INS42 INS60 INS21 INS21 INS44 INS8 INS32 INS21 MOV21 UPD42 UPD42 INS32 INS42 INS42 INS14 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS33 INS2 INS2 INS2 INS2 INS2 INS14 INS2 INS45 MOV42 UPD42 MOV42 UPD42 INS21 INS45 INS42 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS40 INS42 INS42 INS40 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS42 INS42 INS42 INS42 INS32 INS32 INS32 INS32 INS32 INS58 INS27 INS37 INS8 INS42 INS45 INS42 INS45 UPD42 MOV42 UPD42 MOV42 INS42 INS32 INS32 INS32 INS34 INS32 INS32 INS33 INS39 INS59 INS32 INS7 INS43 INS42 INS53 INS40 INS42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 INS43 INS14 INS33 INS33 INS33 INS38 INS32 INS33 INS2 INS42 MOV42 UPD42 MOV42 INS42 INS42 INS42 INS34 INS42 INS42 INS42 INS34 INS42 INS42 INS43 INS40 INS42 INS42 INS12 INS32 INS42 INS22 INS42 INS42 INS42 INS27 INS32 INS42 INS14 INS32 INS42 INS42 INS42 INS9 INS32 INS42 INS42 INS2 INS39 INS59 INS42 INS42 INS42 INS60 MOV25 INS42 INS42 INS32 INS42 INS42 UPD42 MOV42 INS42 INS42 INS32 INS42 INS32 UPD42 UPD42 UPD42 MOV42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS27 INS42 INS32 INS42 INS42 UPD42 UPD42 UPD42 INS42 MOV43 INS42 INS34 INS42 INS42 INS42 INS42 INS42 MOV44 INS8 INS42 INS52 INS42 INS45 INS42 INS42 INS42 INS43 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 INS83 INS43 INS59 INS32 INS8 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS32 INS42 INS42 INS42 INS27 INS42 INS42 INS45 INS42 INS42 INS42 INS32 INS42 INS42 INS54 UPD42 MOV42 UPD42 MOV42 INS45 INS45 INS42 INS42 INS8 INS12 INS21 INS44 INS8 INS32 INS43 INS42 INS42 INS42 DEL39 DEL42 DEL9 DEL38 DEL8 DEL25 DEL42 DEL32 DEL27 DEL24 DEL9 DEL41 DEL42 DEL32 DEL41 DEL8 DEL83 DEL42 DEL43 DEL42 DEL44 DEL83 DEL39 DEL42 DEL44 DEL42 DEL42 DEL42 DEL52 DEL32 DEL41 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL31 DEL42 DEL44 DEL8 DEL31 DEL66 DEL65 DEL29 DEL42 DEL43 DEL42 DEL83 DEL39 DEL42 DEL32 DEL27 DEL27 DEL27 DEL59 DEL60 DEL39 DEL42 DEL42 DEL32 DEL32 DEL16 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL58 DEL83 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL27 DEL42 DEL42 DEL32 DEL32 DEL16 DEL7 DEL21 DEL8 DEL25 DEL8 DEL24 DEL8 DEL31 DEL55 DEL42 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL41 DEL8 DEL39 DEL42 DEL44 DEL9 DEL41 DEL32 DEL33 DEL27 DEL42 DEL32 DEL27 DEL8 DEL9 DEL41 DEL42 DEL42 DEL42 DEL7 DEL21 DEL32 DEL21 DEL42 DEL34 DEL42 DEL83 DEL42 DEL33 DEL41 DEL42 DEL42 DEL32 DEL83 DEL39 DEL42 DEL42 DEL32 DEL59 DEL60 DEL32 DEL38 DEL42 DEL32 DEL83 DEL39 DEL42 DEL42 DEL42 DEL27 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL42 DEL42 DEL14 DEL32 DEL42 DEL33 DEL27 DEL32 DEL32 DEL42 DEL32 DEL45 DEL42 DEL45 DEL32 DEL27 DEL42 DEL32 DEL41 DEL8 DEL39 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL37 DEL39 DEL59 DEL60 DEL42 DEL32 DEL38 DEL25 DEL8 DEL25 DEL8 DEL70 DEL42 DEL42 DEL45 DEL42 DEL27 DEL32 DEL21 DEL8 DEL25 DEL42 DEL42 DEL27 DEL45 DEL42 DEL45 DEL42 DEL27 DEL14 DEL53 DEL8 DEL25 DEL32 DEL34 DEL27 DEL25 DEL39 DEL42 DEL34 DEL32 DEL42 DEL32 DEL42 DEL27 DEL36 DEL11 DEL59 DEL60 DEL42 DEL34 DEL27 DEL27 DEL27 DEL32 DEL38 DEL42 DEL42 DEL32 DEL83 DEL39 DEL42 DEL42 DEL42 DEL27 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL25 DEL83 DEL9 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL8 DEL8 DEL8 DEL12 DEL54 DEL42 DEL45 DEL27 DEL42 DEL32 DEL32 DEL38 DEL83 DEL42 DEL42 DEL32 DEL59 DEL60 DEL32 DEL38 DEL9 DEL66 DEL66 DEL65 DEL29 DEL83 DEL34 DEL9 DEL42 DEL42 DEL32 DEL32 DEL7 DEL21 DEL42 DEL41 DEL8