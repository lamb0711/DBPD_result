Merge trunk into HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1166495 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.protocol.HdfsConstants;
-   * Create a plan to load the image from the set of inspected storage directories.
+   * Get the image files which should be loaded into the filesystem.
-  abstract LoadPlan createLoadPlan() throws IOException;
-  
+  abstract FSImageFile getLatestImage() throws IOException;
+
+  /** 
+   * Get the minimum tx id which should be loaded with this set of images.
+   */
+  abstract long getMaxSeenTxId();
+
-   * A plan to load the namespace from disk, providing the locations from which to load
-   * the image and a set of edits files.
-   */
-  abstract static class LoadPlan {
-    /**
-     * Execute atomic move sequence in the chosen storage directories,
-     * in order to recover from an interrupted checkpoint.
-     * @return true if some recovery action was taken
-     */
-    abstract boolean doRecovery() throws IOException;
-
-    /**
-     * @return the file from which to load the image data
-     */
-    abstract File getImageFile();
-    
-    /**
-     * @return a list of flies containing edits to replay
-     */
-    abstract List<File> getEditsFiles();
-    
-    /**
-     * @return the storage directory containing the VERSION file that should be
-     * loaded.
-     */
-    abstract StorageDirectory getStorageDirectoryForProperties();
-    
-    @Override
-    public String toString() {
-      StringBuilder sb = new StringBuilder();
-      sb.append("Will load image file: ").append(getImageFile()).append("\n");
-      sb.append("Will load edits files:").append("\n");
-      for (File f : getEditsFiles()) {
-        sb.append("  ").append(f).append("\n");
-      }
-      sb.append("Will load metadata from: ")
-        .append(getStorageDirectoryForProperties())
-        .append("\n");
-      return sb.toString();
-    }
-  }
-
-  /**
-      assert txId >= 0 : "Invalid txid on " + file +": " + txId;
+      assert txId >= 0 || txId == HdfsConstants.INVALID_TXID 
+        : "Invalid txid on " + file +": " + txId;

INS26 INS40 MOV31 UPD43 UPD42 UPD39 UPD42 UPD42 UPD66 UPD66 INS27 MOV27 INS27 INS42 INS40 DEL66 DEL66 DEL65 DEL42 DEL43 DEL66 DEL66 DEL65 DEL29 DEL83 DEL83 DEL42 DEL66 DEL65 DEL29 DEL83 DEL42 DEL43 DEL42 DEL31 DEL66 DEL65 DEL29 DEL83 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL31 DEL66 DEL66 DEL65 DEL29 DEL83 DEL42 DEL43 DEL42 DEL31 DEL42 DEL78 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL42 DEL43 DEL14 DEL59 DEL60 DEL42 DEL42 DEL45 DEL32 DEL42 DEL42 DEL32 DEL32 DEL42 DEL45 DEL32 DEL21 DEL42 DEL42 DEL45 DEL32 DEL42 DEL45 DEL32 DEL21 DEL42 DEL43 DEL42 DEL44 DEL42 DEL32 DEL42 DEL42 DEL45 DEL32 DEL42 DEL42 DEL32 DEL42 DEL45 DEL32 DEL21 DEL8 DEL70 DEL42 DEL42 DEL45 DEL32 DEL42 DEL42 DEL32 DEL32 DEL42 DEL45 DEL32 DEL21 DEL42 DEL42 DEL32 DEL41 DEL8 DEL31 DEL55