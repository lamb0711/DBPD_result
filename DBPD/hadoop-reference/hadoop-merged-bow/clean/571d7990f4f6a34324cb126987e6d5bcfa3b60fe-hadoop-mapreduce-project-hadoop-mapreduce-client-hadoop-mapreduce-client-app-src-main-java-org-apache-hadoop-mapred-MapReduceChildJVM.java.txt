Merge trunk into HA branch


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1196458 13f79535-47bb-0310-9956-ffa450edef68

-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
+import org.apache.hadoop.yarn.util.Apps;
-    MRApps.addToEnvironment(
+    Apps.addToEnvironment(
-    MRApps.setEnvFromInputString(environment, mapredChildEnv);
-    MRApps.setEnvFromInputString(
+    Apps.setEnvFromInputString(environment, mapredChildEnv);
+    Apps.setEnvFromInputString(
-    // Set logging level
+    // Set logging level in the environment.
+    // This is so that, if the child forks another "bin/hadoop" (common in
+    // streaming) it will have the correct loglevel.
-    setupLog4jProperties(logProps, logSize);
+    setupLog4jProperties(task, logProps, logSize);
+    environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, 
+        	conf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());
-  private static void setupLog4jProperties(Vector<String> vargs,
+  private static void setupLog4jProperties(Task task,
+      Vector<String> vargs,
-    vargs.add("-Dlog4j.configuration=container-log4j.properties");
-    vargs.add("-D" + MRJobConfig.TASK_LOG_DIR + "=" + ApplicationConstants.LOG_DIR_EXPANSION_VAR);
-    vargs.add("-D" + MRJobConfig.TASK_LOG_SIZE + "=" + logSize);
+    String logLevel = getChildLogLevel(task.conf, task.isMapTask()); 
+    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);
-    setupLog4jProperties(vargs, logSize);
+    setupLog4jProperties(task, vargs, logSize);

UPD40 INS44 INS21 INS43 INS42 INS60 INS32 INS42 INS43 INS59 UPD42 UPD42 UPD42 INS42 INS42 INS42 INS40 INS32 INS42 INS42 INS32 UPD42 UPD42 INS42 INS42 INS42 INS42 INS32 INS42 UPD42 MOV42 INS40 INS32 INS42 INS42 INS40 INS42 INS42 DEL40 DEL26 DEL42 DEL42 DEL45 DEL32 DEL21 DEL42 DEL45 DEL40 DEL45 DEL40 DEL27 DEL32 DEL21 DEL45 DEL40 DEL45 DEL42 DEL27