HDDS-675. Add blocking buffer and use watchApi for flush/close in OzoneClient. Contributed by Shashikant Banerjee.

-import org.apache.hadoop.io.retry.RetryPolicy;
+import org.apache.hadoop.ozone.OzoneConsts;
-import org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos;
-import org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls;
-import java.io.InterruptedIOException;
+import java.util.concurrent.TimeoutException;
-  private long byteOffset;
-  private final RetryPolicy retryPolicy;
+  private final long streamBufferFlushSize;
+  private final long streamBufferMaxSize;
+  private final long watchTimeout;
+  private final long blockSize;
+  private ByteBuffer buffer;
-    retryPolicy = null;
+    streamBufferFlushSize = 0;
+    streamBufferMaxSize = 0;
+    buffer = ByteBuffer.allocate(1);
+    watchTimeout = 0;
+    blockSize = 0;
+      LOG.debug("block written " + streamEntry.blockID + ", length "
+          + streamEntry.currentPosition + " bcsID " + streamEntry.blockID
+          .getBlockCommitSequenceId());
-  public ChunkGroupOutputStream(
-      OpenKeySession handler, XceiverClientManager xceiverClientManager,
+  public ChunkGroupOutputStream(OpenKeySession handler,
+      XceiverClientManager xceiverClientManager,
-      OzoneManagerProtocolClientSideTranslatorPB omClient,
-      int chunkSize, String requestId, ReplicationFactor factor,
-      ReplicationType type, RetryPolicy retryPolicy) throws IOException {
+      OzoneManagerProtocolClientSideTranslatorPB omClient, int chunkSize,
+      String requestId, ReplicationFactor factor, ReplicationType type,
+      long bufferFlushSize, long bufferMaxSize, long size, long watchTimeout) {
-    this.byteOffset = 0;
-    this.keyArgs = new OmKeyArgs.Builder()
-        .setVolumeName(info.getVolumeName())
-        .setBucketName(info.getBucketName())
-        .setKeyName(info.getKeyName())
-        .setType(type)
-        .setFactor(factor)
-        .setDataSize(info.getDataSize()).build();
+    this.keyArgs = new OmKeyArgs.Builder().setVolumeName(info.getVolumeName())
+        .setBucketName(info.getBucketName()).setKeyName(info.getKeyName())
+        .setType(type).setFactor(factor).setDataSize(info.getDataSize())
+        .build();
-    this.retryPolicy = retryPolicy;
+    this.streamBufferFlushSize = bufferFlushSize * OzoneConsts.MB;
+    this.streamBufferMaxSize = bufferMaxSize * OzoneConsts.MB;
+    this.blockSize = size * OzoneConsts.MB;
+    this.watchTimeout = watchTimeout;
+
+    Preconditions.checkState(chunkSize > 0);
+    Preconditions.checkState(streamBufferFlushSize > 0);
+    Preconditions.checkState(streamBufferMaxSize > 0);
+    Preconditions.checkState(blockSize > 0);
+    Preconditions.checkState(streamBufferFlushSize % chunkSize == 0);
+    Preconditions.checkState(streamBufferMaxSize % streamBufferFlushSize == 0);
+    Preconditions.checkState(blockSize % streamBufferMaxSize == 0);
+
+    // This byteBuffer will be used to cache data until all the blockCommits
+    // (putBlock) gets replicated to all/majority servers. The idea here is to
+    // allocate the buffer of size blockSize so that as and when a chunk is
+    // is replicated to all servers, as a part of discarding the buffer, we
+    // don't necessarily need to run compaction(buffer.compact() on the buffer
+    // to actually discard the acknowledged data. Compaction is inefficient so
+    // it would be a better choice to avoid compaction on the happy I/O path.
+    this.buffer = ByteBuffer.allocate((int) blockSize);
-        chunkSize, subKeyInfo.getLength()));
+        chunkSize, subKeyInfo.getLength(), streamBufferFlushSize,
+        streamBufferMaxSize, watchTimeout, buffer));
-    return byteOffset;
+    return getKeyLength();
-    handleWrite(b, off, len);
+    handleWrite(b, off, len, false, buffer.position());
-  private void handleWrite(byte[] b, int off, int len) throws IOException {
+  private void handleWrite(byte[] b, int off, int len, boolean retry,
+      int pos) throws IOException {
-    if ((off < 0) || (off > b.length) || (len < 0) ||
-        ((off + len) > b.length) || ((off + len) < 0)) {
+    if ((off < 0) || (off > b.length) || (len < 0) || ((off + len) > b.length)
+        || ((off + len) < 0)) {
+    int initialPos;
-          LOG.error("Try to allocate more blocks for write failed, already " +
-              "allocated " + succeededAllocates + " blocks for this write.");
+          LOG.error("Try to allocate more blocks for write failed, already "
+              + "allocated " + succeededAllocates + " blocks for this write.");
+      initialPos = pos < buffer.position() ? pos : buffer.position();
-        current.write(b, off, writeLen);
+        if (retry) {
+          current.writeOnRetry(len);
+        } else {
+          current.write(b, off, writeLen);
+        }
-        if (checkIfContainerIsClosed(ioe)) {
-          handleCloseContainerException(current, currentStreamIndex);
-          continue;
+        if (checkIfContainerIsClosed(ioe) || checkIfTimeoutException(ioe)) {
+          // for the current iteration, current pos - initialPos gives the
+          // amount of data already written to the buffer
+          writeLen = buffer.position() - initialPos;
+          handleException(current, currentStreamIndex);
-      byteOffset += writeLen;
-    }
-  }
-
-  private long getCommittedBlockLength(ChunkOutputStreamEntry streamEntry)
-      throws IOException {
-    long blockLength;
-    ContainerProtos.GetCommittedBlockLengthResponseProto responseProto;
-    RetryPolicy.RetryAction action;
-    int numRetries = 0;
-    while (true) {
-      try {
-        responseProto = ContainerProtocolCalls
-            .getCommittedBlockLength(streamEntry.xceiverClient,
-                streamEntry.blockID, requestID);
-        blockLength = responseProto.getBlockLength();
-        return blockLength;
-      } catch (StorageContainerException sce) {
-        try {
-          action = retryPolicy.shouldRetry(sce, numRetries, 0, true);
-        } catch (Exception e) {
-          throw e instanceof IOException ? (IOException) e : new IOException(e);
-        }
-        if (action.action == RetryPolicy.RetryAction.RetryDecision.FAIL) {
-          if (action.reason != null) {
-            LOG.error(
-                "GetCommittedBlockLength request failed. " + action.reason,
-                sce);
-          }
-          throw sce;
-        }
-
-        // Throw the exception if the thread is interrupted
-        if (Thread.currentThread().isInterrupted()) {
-          LOG.warn("Interrupted while trying for connection");
-          throw sce;
-        }
-        Preconditions.checkArgument(
-            action.action == RetryPolicy.RetryAction.RetryDecision.RETRY);
-        try {
-          Thread.sleep(action.delayMillis);
-        } catch (InterruptedException e) {
-          throw (IOException) new InterruptedIOException(
-              "Interrupted: action=" + action + ", retry policy=" + retryPolicy)
-              .initCause(e);
-        }
-        numRetries++;
-        LOG.trace("Retrying GetCommittedBlockLength request. Already tried "
-            + numRetries + " time(s); retry policy is " + retryPolicy);
-        continue;
-      }
-   * @throws IOException Throws IOexception if Write fails
+   * @throws IOException Throws IOException if Write fails
-  private void handleCloseContainerException(ChunkOutputStreamEntry streamEntry,
+  private void handleException(ChunkOutputStreamEntry streamEntry,
-    long committedLength = 0;
-    ByteBuffer buffer = streamEntry.getBuffer();
-    if (buffer == null) {
-      // the buffer here will be null only when closeContainerException is
-      // hit while calling putKey during close on chunkOutputStream.
-      // Since closeContainer auto commit pending keys, no need to do
-      // anything here.
-      return;
-    }
+    int lastSuccessfulFlushIndex = streamEntry.getLastSuccessfulFlushIndex();
+    int currentPos = buffer.position();
-    // update currentStreamIndex in case of closed container exception. The
-    // current stream entry cannot be used for further writes because
-    // container is closed.
-    currentStreamIndex += 1;
-
-    // In case where not a single chunk of data has been written to the Datanode
-    // yet. This block does not yet exist on the datanode but cached on the
-    // outputStream buffer. No need to call GetCommittedBlockLength here
-    // for this block associated with the stream here.
-    if (streamEntry.currentPosition >= chunkSize
-        || streamEntry.currentPosition != buffer.position()) {
-      committedLength = getCommittedBlockLength(streamEntry);
-      // update the length of the current stream
-      streamEntry.currentPosition = committedLength;
+    // In case of a failure, read the data from the position till the last
+    // acknowledgement happened.
+    if (lastSuccessfulFlushIndex > 0) {
+      buffer.position(lastSuccessfulFlushIndex);
+      buffer.limit(currentPos);
+      buffer.compact();
+      //set the correct length for the current stream
+      streamEntry.currentPosition = lastSuccessfulFlushIndex;
-      // allocate new block and write this data in the datanode. The cached
-      // data in the buffer does not exceed chunkSize.
-      Preconditions.checkState(buffer.position() < chunkSize);
-      // readjust the byteOffset value to the length actually been written.
-      byteOffset -= buffer.position();
-      handleWrite(buffer.array(), 0, buffer.position());
+      // allocate new block and write this data in the datanode.
+      currentStreamIndex += 1;
+      handleWrite(buffer.array(), 0, buffer.position(), true,
+          lastSuccessfulFlushIndex);
-    // just clean up the current stream. Since the container is already closed,
-    // it will be auto committed. No need to call close again here.
+    // just clean up the current stream.
-    // This case will arise when while writing the first chunk itself fails.
-    // In such case, the current block associated with the stream has no data
-    // written. Remove it from the current stream list.
-    if (committedLength == 0) {
+    if (lastSuccessfulFlushIndex == 0) {
-      Preconditions.checkArgument(currentStreamIndex != 0);
-    return checkIfContainerNotOpenException(ioe) || Optional.of(ioe.getCause())
-        .filter(e -> e instanceof StorageContainerException)
-        .map(e -> (StorageContainerException) e)
-        .filter(sce -> sce.getResult() == Result.CLOSED_CONTAINER_IO)
-        .isPresent();
+    if (ioe.getCause() != null) {
+      return checkIfContainerNotOpenException(ioe) || Optional
+          .of(ioe.getCause())
+          .filter(e -> e instanceof StorageContainerException)
+          .map(e -> (StorageContainerException) e)
+          .filter(sce -> sce.getResult() == Result.CLOSED_CONTAINER_IO)
+          .isPresent();
+    }
+    return false;
+  private boolean checkIfTimeoutException(IOException ioe) {
+    if (ioe.getCause() != null) {
+      return Optional.of(ioe.getCause())
+          .filter(e -> e instanceof TimeoutException).isPresent();
+    } else {
+      return false;
+    }
+  }
+
-        if (checkIfContainerIsClosed(ioe)) {
+        if (checkIfContainerIsClosed(ioe) || checkIfTimeoutException(ioe)) {
-          handleCloseContainerException(entry, streamIndex);
+          handleException(entry, streamIndex);
-    handleFlushOrClose(true);
-    if (keyArgs != null) {
-      // in test, this could be null
-      removeEmptyBlocks();
-      Preconditions.checkState(byteOffset == getKeyLength());
-      keyArgs.setDataSize(byteOffset);
-      keyArgs.setLocationInfoList(getLocationInfoList());
-      omClient.commitKey(keyArgs, openID);
-    } else {
-      LOG.warn("Closing ChunkGroupOutputStream, but key args is null");
+    try {
+      handleFlushOrClose(true);
+      if (keyArgs != null) {
+        // in test, this could be null
+        removeEmptyBlocks();
+        keyArgs.setDataSize(getKeyLength());
+        keyArgs.setLocationInfoList(getLocationInfoList());
+        omClient.commitKey(keyArgs, openID);
+      } else {
+        LOG.warn("Closing ChunkGroupOutputStream, but key args is null");
+      }
+    } catch (IOException ioe) {
+      throw ioe;
+    } finally {
+      if (buffer != null) {
+        buffer.clear();
+      }
+      buffer = null;
-    private RetryPolicy retryPolicy;
+    private long streamBufferFlushSize;
+    private long streamBufferMaxSize;
+    private long blockSize;
+    private long watchTimeout;
-    public ChunkGroupOutputStream build() throws IOException {
-      return new ChunkGroupOutputStream(openHandler, xceiverManager, scmClient,
-          omClient, chunkSize, requestID, factor, type, retryPolicy);
-    }
-
-    public Builder setRetryPolicy(RetryPolicy rPolicy) {
-      this.retryPolicy = rPolicy;
+    public Builder setStreamBufferFlushSize(long size) {
+      this.streamBufferFlushSize = size;
+    public Builder setStreamBufferMaxSize(long size) {
+      this.streamBufferMaxSize = size;
+      return this;
+    }
+
+    public Builder setBlockSize(long size) {
+      this.blockSize = size;
+      return this;
+    }
+
+    public Builder setWatchTimeout(long timeout) {
+      this.watchTimeout = timeout;
+      return this;
+    }
+
+    public ChunkGroupOutputStream build() throws IOException {
+      return new ChunkGroupOutputStream(openHandler, xceiverManager, scmClient,
+          omClient, chunkSize, requestID, factor, type, streamBufferFlushSize,
+          streamBufferMaxSize, blockSize, watchTimeout);
+    }
+    private final long streamBufferFlushSize;
+    private final long streamBufferMaxSize;
+    private final long watchTimeout;
+    private ByteBuffer buffer;
+
-        long length) {
+        long length, long streamBufferFlushSize, long streamBufferMaxSize,
+        long watchTimeout, ByteBuffer buffer) {
+      this.streamBufferFlushSize = streamBufferFlushSize;
+      this.streamBufferMaxSize = streamBufferMaxSize;
+      this.watchTimeout = watchTimeout;
+      this.buffer = buffer;
+      streamBufferFlushSize = 0;
+      streamBufferMaxSize = 0;
+      buffer = null;
+      watchTimeout = 0;
-        this.outputStream = new ChunkOutputStream(blockID,
-            key, xceiverClientManager, xceiverClient,
-            requestId, chunkSize);
+        this.outputStream =
+            new ChunkOutputStream(blockID, key, xceiverClientManager,
+                xceiverClient, requestId, chunkSize, streamBufferFlushSize,
+                streamBufferMaxSize, watchTimeout, buffer);
-    ByteBuffer getBuffer() throws IOException {
+    int getLastSuccessfulFlushIndex() throws IOException {
-        return out.getBuffer();
+        blockID = out.getBlockID();
+        return out.getLastSuccessfulFlushIndex();
+      } else if (outputStream == null) {
+        // For a pre allocated block for which no write has been initiated,
+        // the OutputStream will be null here.
+        // In such cases, the default blockCommitSequenceId will be 0
+        return 0;
-    public void cleanup() {
+    void cleanup() {
+    void writeOnRetry(int len) throws IOException {
+      checkStream();
+      if (this.outputStream instanceof ChunkOutputStream) {
+        ChunkOutputStream out = (ChunkOutputStream) this.outputStream;
+        out.writeOnRetry(len);
+        this.currentPosition += len;
+      } else {
+        throw new IOException("Invalid Output Stream for Key: " + key);
+      }
+    }

MOV26 MOV23 UPD40 UPD40 INS23 INS23 INS23 INS31 INS31 INS83 INS39 INS83 INS83 INS39 INS59 INS83 INS83 INS39 INS59 INS83 INS43 INS59 INS44 INS44 INS44 MOV21 MOV78 INS83 INS39 INS42 INS8 INS44 INS44 UPD42 INS8 INS83 INS39 INS42 INS44 INS8 INS8 INS23 INS23 INS23 INS23 INS31 INS31 INS31 INS31 INS23 INS23 INS23 INS23 INS31 UPD42 UPD42 INS42 UPD42 MOV42 INS42 UPD42 MOV42 INS21 INS21 INS21 INS21 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS41 INS39 INS42 INS39 INS42 INS60 INS60 INS60 INS25 INS41 UPD43 MOV43 UPD42 MOV42 INS25 MOV25 MOV21 INS54 MOV83 INS39 INS59 INS83 INS39 MOV59 INS83 INS39 INS59 INS83 INS39 INS59 MOV83 MOV43 UPD42 MOV42 INS44 INS8 INS83 INS43 INS42 INS44 INS8 INS83 INS43 INS42 INS44 INS8 INS43 UPD42 INS83 MOV43 INS42 MOV43 INS8 INS83 INS83 INS39 INS59 INS83 INS83 INS39 INS59 INS83 INS83 INS39 INS59 INS83 MOV43 INS59 INS44 INS44 INS44 INS44 INS39 UPD42 INS39 INS42 INS44 MOV43 INS8 INS7 INS7 INS7 INS7 INS7 INS7 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS7 INS32 INS39 INS59 MOV21 UPD66 UPD39 MOV39 MOV59 INS39 INS59 INS27 INS27 MOV8 INS9 UPD42 INS27 INS8 INS8 MOV8 INS12 INS8 INS42 UPD42 INS42 INS42 INS39 INS42 INS21 MOV41 INS42 INS39 INS42 INS21 INS41 INS42 INS39 INS42 INS21 INS41 INS42 INS39 INS42 INS41 INS41 INS42 INS42 INS42 INS42 INS39 INS42 INS39 INS42 INS39 INS42 MOV43 INS42 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS39 INS42 INS21 INS25 UPD42 INS34 INS42 INS34 INS42 INS32 INS42 INS34 INS42 INS34 INS21 INS22 INS27 INS22 INS27 INS27 UPD42 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS22 INS32 UPD42 MOV42 INS9 INS32 INS42 UPD42 INS42 MOV32 UPD42 MOV42 INS34 INS21 INS21 MOV21 UPD42 INS32 INS33 INS32 MOV33 INS41 INS41 INS44 INS8 INS25 INS21 INS7 INS7 INS52 INS7 INS52 INS52 INS14 INS7 INS7 INS7 INS7 INS7 INS7 INS7 INS7 INS25 INS32 INS62 INS8 INS8 INS42 INS42 INS34 INS32 INS52 INS42 INS42 INS40 INS52 INS42 INS42 INS40 UPD42 INS42 INS40 UPD42 INS42 INS34 INS42 INS34 INS42 INS34 INS42 INS34 INS27 INS34 INS27 INS34 INS27 INS34 INS52 INS42 INS42 INS42 INS11 INS42 INS42 INS42 INS42 INS42 INS42 UPD7 INS8 UPD42 INS32 INS32 INS32 UPD7 INS42 INS42 INS42 INS42 INS32 INS9 INS43 INS42 INS53 INS27 INS8 INS7 INS22 INS42 INS22 INS42 INS22 INS42 UPD42 MOV43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS22 INS42 INS22 INS42 INS22 INS42 INS22 INS42 INS42 INS34 INS42 INS34 INS42 INS33 INS42 INS34 INS21 INS27 INS8 INS42 INS22 INS43 INS60 INS21 INS21 INS53 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS39 INS42 INS42 INS16 INS25 INS42 INS42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 INS40 UPD42 INS9 INS42 INS32 UPD42 MOV42 INS42 INS42 INS42 INS33 INS21 INS42 INS33 INS52 INS42 INS52 INS42 INS52 INS42 UPD42 INS52 INS42 INS52 INS42 INS52 INS42 INS52 INS42 INS7 INS42 INS33 INS41 INS52 INS42 INS42 INS43 INS59 INS32 INS7 INS14 INS45 INS40 INS45 INS40 INS45 INS32 INS27 INS42 INS32 INS42 INS8 MOV8 INS32 UPD42 MOV42 INS86 INS32 INS42 INS32 UPD42 INS34 INS42 INS42 INS11 INS42 INS42 INS42 INS22 INS42 INS43 INS27 INS40 INS42 INS42 MOV32 INS42 INS42 INS21 INS27 UPD42 MOV42 UPD42 MOV42 MOV32 INS59 INS62 INS27 MOV32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS22 INS52 INS42 INS42 INS45 INS42 INS32 MOV32 INS32 INS21 UPD42 UPD42 INS42 INS42 INS43 MOV32 INS32 INS42 INS52 INS42 INS42 INS42 INS42 INS42 INS42 INS7 UPD42 MOV42 INS42 INS42 INS42 INS27 UPD42 UPD42 MOV32 INS42 DEL40 DEL26 DEL40 DEL26 DEL42 DEL43 DEL33 DEL42 DEL43 DEL42 DEL42 DEL43 DEL34 DEL83 DEL39 DEL42 DEL42 DEL41 DEL8 DEL31 DEL42 DEL42 DEL18 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL44 DEL39 DEL59 DEL60 DEL40 DEL43 DEL59 DEL60 DEL40 DEL43 DEL42 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL60 DEL9 DEL42 DEL42 DEL42 DEL40 DEL40 DEL42 DEL32 DEL7 DEL21 DEL42 DEL42 DEL32 DEL7 DEL21 DEL42 DEL41 DEL8 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL42 DEL34 DEL9 DEL32 DEL7 DEL21 DEL8 DEL44 DEL42 DEL42 DEL43 DEL62 DEL42 DEL43 DEL42 DEL11 DEL42 DEL43 DEL42 DEL14 DEL16 DEL53 DEL8 DEL12 DEL54 DEL40 DEL40 DEL27 DEL40 DEL27 DEL45 DEL40 DEL27 DEL42 DEL32 DEL21 DEL8 DEL25 DEL42 DEL53 DEL8 DEL25 DEL32 DEL42 DEL42 DEL45 DEL32 DEL21 DEL42 DEL53 DEL8 DEL25 DEL42 DEL42 DEL40 DEL40 DEL27 DEL32 DEL21 DEL42 DEL42 DEL40 DEL32 DEL21 DEL8 DEL42 DEL43 DEL42 DEL44 DEL43 DEL42 DEL43 DEL45 DEL42 DEL45 DEL42 DEL27 DEL14 DEL42 DEL32 DEL11 DEL53 DEL8 DEL12 DEL54 DEL42 DEL37 DEL21 DEL42 DEL42 DEL45 DEL42 DEL45 DEL42 DEL27 DEL32 DEL21 DEL18 DEL8 DEL12 DEL54 DEL8 DEL61 DEL8 DEL31 DEL42 DEL34 DEL59 DEL60 DEL60 DEL42 DEL33 DEL27 DEL41 DEL8 DEL25 DEL40 DEL27 DEL40 DEL27 DEL27 DEL42 DEL32 DEL7 DEL21 DEL40 DEL42 DEL7 DEL42 DEL42 DEL42 DEL27 DEL32 DEL21 DEL42 DEL42 DEL42 DEL34 DEL27 DEL32 DEL21 DEL42 DEL42 DEL42 DEL27 DEL32 DEL21 DEL42 DEL42 DEL43 DEL23 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL14 DEL41 DEL8 DEL31 DEL42 DEL43 DEL42 DEL83