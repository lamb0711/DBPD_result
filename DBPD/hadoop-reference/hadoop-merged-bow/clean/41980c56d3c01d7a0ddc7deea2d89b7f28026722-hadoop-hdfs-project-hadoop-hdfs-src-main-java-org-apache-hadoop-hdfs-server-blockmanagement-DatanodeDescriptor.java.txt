HDFS-7208. NN doesn't schedule replication when a DN storage fails.  Contributed by Ming Ma

+import java.util.HashSet;
+import java.util.Set;
+  // HB processing can use it to tell if it is the first HB since DN restarted
+  private boolean heartbeatedSinceRegistration = false;
+
-    updateHeartbeat(StorageReport.EMPTY_ARRAY, 0L, 0L, 0, 0);
+    updateHeartbeatState(StorageReport.EMPTY_ARRAY, 0L, 0L, 0, 0);
-    updateHeartbeat(StorageReport.EMPTY_ARRAY, 0L, 0L, 0, 0);
+    updateHeartbeatState(StorageReport.EMPTY_ARRAY, 0L, 0L, 0, 0);
+    updateHeartbeatState(reports, cacheCapacity, cacheUsed, xceiverCount,
+        volFailures);
+    heartbeatedSinceRegistration = true;
+  }
+
+  /**
+   * process datanode heartbeat or stats initialization.
+   */
+  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,
+      long cacheUsed, int xceiverCount, int volFailures) {
+    Set<DatanodeStorageInfo> failedStorageInfos = null;
+
+    // Decide if we should check for any missing StorageReport and mark it as
+    // failed. There are different scenarios.
+    // 1. When DN is running, a storage failed. Given the current DN
+    //    implementation doesn't add recovered storage back to its storage list
+    //    until DN restart, we can assume volFailures won't decrease
+    //    during the current DN registration session.
+    //    When volumeFailures == this.volumeFailures, it implies there is no
+    //    state change. No need to check for failed storage. This is an
+    //    optimization.
+    // 2. After DN restarts, volFailures might not increase and it is possible
+    //    we still have new failed storage. For example, admins reduce
+    //    available storages in configuration. Another corner case
+    //    is the failed volumes might change after restart; a) there
+    //    is one good storage A, one restored good storage B, so there is
+    //    one element in storageReports and that is A. b) A failed. c) Before
+    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN
+    //    restarts, storageReports has one element which is B.
+    boolean checkFailedStorages = (volFailures > this.volumeFailures) ||
+        !heartbeatedSinceRegistration;
+
+    if (checkFailedStorages) {
+      LOG.info("Number of failed storage changes from "
+          + this.volumeFailures + " to " + volFailures);
+      failedStorageInfos = new HashSet<DatanodeStorageInfo>(
+          storageMap.values());
+    }
+      if (checkFailedStorages) {
+        failedStorageInfos.remove(storage);
+      }
+
+    if (checkFailedStorages) {
+      updateFailedStorage(failedStorageInfos);
+    }
+  }
+
+  private void updateFailedStorage(
+      Set<DatanodeStorageInfo> failedStorageInfos) {
+    for (DatanodeStorageInfo storageInfo : failedStorageInfos) {
+      if (storageInfo.getState() != DatanodeStorage.State.FAILED) {
+        LOG.info(storageInfo + " failed.");
+        storageInfo.setState(DatanodeStorage.State.FAILED);
+      }
+    }
+    heartbeatedSinceRegistration = false;

INS26 INS26 INS40 INS40 INS23 INS31 INS31 INS83 INS39 INS59 MOV29 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS44 INS8 INS29 UPD42 INS83 INS39 INS42 INS44 INS8 INS42 INS9 INS5 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS21 INS21 INS65 INS60 INS60 INS25 INS25 INS74 INS42 INS70 INS21 INS43 INS85 INS32 INS7 INS66 INS74 INS59 INS39 INS59 INS42 INS8 INS42 INS8 INS43 INS43 INS44 INS42 INS8 INS7 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS9 INS43 INS43 INS42 INS33 INS42 INS27 INS21 INS21 INS25 INS21 INS42 INS42 INS43 INS42 INS25 INS42 INS9 INS42 INS42 INS36 INS38 INS32 INS7 INS42 INS8 INS32 INS42 INS27 INS8 INS27 INS42 INS42 INS42 INS27 INS42 INS14 INS21 INS42 INS42 INS32 INS40 INS21 INS21 INS42 INS22 INS45 INS22 INS45 INS42 INS74 INS32 INS32 INS42 INS42 INS32 INS32 INS52 INS42 INS52 INS42 INS43 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS40 INS42 INS42 INS42 INS45