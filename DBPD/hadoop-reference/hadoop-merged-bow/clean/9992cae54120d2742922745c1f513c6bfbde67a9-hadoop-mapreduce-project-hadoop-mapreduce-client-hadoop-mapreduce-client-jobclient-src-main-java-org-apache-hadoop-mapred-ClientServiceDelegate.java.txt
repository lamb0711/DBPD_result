Reverting the previous trunk merge since it added other unintended changes in addition


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1177127 13f79535-47bb-0310-9956-ffa450edef68

-public class ClientServiceDelegate {
+class ClientServiceDelegate {
-  public ClientServiceDelegate(Configuration conf, ResourceMgrDelegate rm, 
+  ClientServiceDelegate(Configuration conf, ResourceMgrDelegate rm, 
-  private NotRunningJob getNotRunningJob(ApplicationReport applicationReport, 
-      JobState state) {
+  private NotRunningJob getNotRunningJob(String user, JobState state) {
-      String user = 
-          (applicationReport == null) ? 
-              UNKNOWN_USER : applicationReport.getUser();
-        notRunningJob = new NotRunningJob(applicationReport, state);
+        notRunningJob = new NotRunningJob(user, state);
-        return checkAndGetHSProxy(null, JobState.NEW);
+        return checkAndGetHSProxy(UNKNOWN_USER, JobState.NEW);
-          return checkAndGetHSProxy(null, JobState.RUNNING);
+          return checkAndGetHSProxy(UNKNOWN_USER, JobState.RUNNING);
-      return getNotRunningJob(application, JobState.NEW);
+      return getNotRunningJob(user, JobState.NEW);
-      return getNotRunningJob(application, JobState.FAILED);
+      return getNotRunningJob(user, JobState.FAILED);
-      return getNotRunningJob(application, JobState.KILLED);
+      return getNotRunningJob(user, JobState.KILLED);
-      realProxy = checkAndGetHSProxy(application, JobState.SUCCEEDED);
+      realProxy = checkAndGetHSProxy(user, JobState.SUCCEEDED);
-  private MRClientProtocol checkAndGetHSProxy(
-      ApplicationReport applicationReport, JobState state) {
+  private MRClientProtocol checkAndGetHSProxy(String user, JobState state) {
-      return getNotRunningJob(applicationReport, state);
+      return getNotRunningJob(user, state);
-  public org.apache.hadoop.mapreduce.Counters getJobCounters(JobID arg0) throws IOException,
+  org.apache.hadoop.mapreduce.Counters getJobCounters(JobID arg0) throws IOException,
-  public TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1, int arg2)
+  TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1, int arg2)
-  public String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)
+  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)
-  public JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {
+  JobStatus getJobStatus(JobID oldJobID) throws YarnRemoteException {
-    GetJobReportRequest request = 
-        recordFactory.newRecordInstance(GetJobReportRequest.class);
+    GetJobReportRequest request = recordFactory.newRecordInstance(GetJobReportRequest.class);
-    return TypeConverter.fromYarn(report, jobFile);
+    //TODO: add tracking url in JobReport
+    return TypeConverter.fromYarn(report, jobFile, "");
-  public org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(JobID oldJobID, TaskType taskType)
+  org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(JobID oldJobID, TaskType taskType)
-    GetTaskReportsRequest request = 
-        recordFactory.newRecordInstance(GetTaskReportsRequest.class);
+    GetTaskReportsRequest request = recordFactory.newRecordInstance(GetTaskReportsRequest.class);
-  public boolean killTask(TaskAttemptID taskAttemptID, boolean fail)
+  boolean killTask(TaskAttemptID taskAttemptID, boolean fail)
-  public boolean killJob(JobID oldJobID)
+  boolean killJob(JobID oldJobID)

MOV43 MOV43 INS42 UPD43 UPD42 UPD42 MOV21 MOV21 MOV21 INS45 UPD42 UPD42 UPD42 UPD42 UPD42 INS42 UPD42 INS42 DEL83 DEL83 DEL42 DEL43 DEL42 DEL42 DEL42 DEL33 DEL27 DEL36 DEL42 DEL42 DEL42 DEL32 DEL16 DEL59 DEL60 DEL33 DEL33 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83