HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68

-import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_LIST_CACHE_DESCRIPTORS_NUM_RESPONSES;
-import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_LIST_CACHE_DESCRIPTORS_NUM_RESPONSES_DEFAULT;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_LIST_CACHE_DESCRIPTORS_NUM_RESPONSES;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_CACHING_ENABLED_KEY;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_CACHING_ENABLED_DEFAULT;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_LIST_CACHE_DESCRIPTORS_NUM_RESPONSES_DEFAULT;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_PATH_BASED_CACHE_REFRESH_INTERVAL_MS;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_PATH_BASED_CACHE_REFRESH_INTERVAL_MS_DEFAULT;
+import java.io.Closeable;
+import java.util.Collection;
+import java.util.LinkedList;
+import org.apache.commons.io.IOUtils;
+import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.hdfs.protocol.AddPathBasedCacheDirectiveException.InvalidPoolNameError;
-import org.apache.hadoop.hdfs.protocol.AddPathBasedCacheDirectiveException.PoolWritePermissionDeniedError;
+import org.apache.hadoop.hdfs.protocol.Block;
+import org.apache.hadoop.hdfs.protocol.BlockListAsLongs;
+import org.apache.hadoop.hdfs.protocol.BlockListAsLongs.BlockReportIterator;
-import org.apache.hadoop.hdfs.protocol.PathBasedCacheDescriptor;
+import org.apache.hadoop.hdfs.protocol.DatanodeID;
+import org.apache.hadoop.hdfs.protocol.LocatedBlock;
+import org.apache.hadoop.hdfs.protocol.PathBasedCacheDescriptor;
+import org.apache.hadoop.hdfs.protocol.AddPathBasedCacheDirectiveException.InvalidPoolNameError;
+import org.apache.hadoop.hdfs.protocol.AddPathBasedCacheDirectiveException.UnexpectedAddPathBasedCacheDirectiveException;
+import org.apache.hadoop.hdfs.protocol.AddPathBasedCacheDirectiveException.PoolWritePermissionDeniedError;
-import org.apache.hadoop.hdfs.protocol.RemovePathBasedCacheDescriptorException.RemovePermissionDeniedException;
+import org.apache.hadoop.hdfs.protocol.RemovePathBasedCacheDescriptorException.RemovePermissionDeniedException;
+import org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo;
+import org.apache.hadoop.hdfs.server.blockmanagement.BlockManager;
+import org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList;
+import org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type;
+import org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState;
+import org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics;
+import org.apache.hadoop.util.GSet;
+import org.apache.hadoop.util.LightWeightGSet;
+import org.apache.hadoop.util.Time;
-import com.google.common.base.Preconditions;
+import com.google.common.annotations.VisibleForTesting;
+ *
+ * This class is instantiated by the FSNamesystem when caching is enabled.
+ * It maintains the mapping of cached blocks to datanodes via processing
+ * datanode cache reports. Based on these reports and addition and removal of
+ * caching directives, we will schedule caching and uncaching work.
+@InterfaceAudience.LimitedPrivate({"HDFS"})
+  // TODO: add pending / underCached / schedule cached blocks stats.
+
+  /**
+   * The FSNamesystem that contains this CacheManager.
+   */
+  private final FSNamesystem namesystem;
+
+  /**
+   * The BlockManager associated with the FSN that owns this CacheManager.
+   */
+  private final BlockManager blockManager;
+
+   * The entry ID to use for a new entry.  Entry IDs always increase, and are
+   * never reused.
+   */
+  private long nextEntryId;
+
+  /**
-   * The entry ID to use for a new entry.
-   */
-  private long nextEntryId;
-
-  /**
-  final private FSNamesystem namesystem;
-  final private FSDirectory dir;
+  /**
+   * Interval between scans in milliseconds.
+   */
+  private final long scanIntervalMs;
-  CacheManager(FSNamesystem namesystem, FSDirectory dir, Configuration conf) {
-    clear();
+  /**
+   * Whether caching is enabled.
+   *
+   * If caching is disabled, we will not process cache reports or store
+   * information about what is cached where.  We also do not start the
+   * CacheReplicationMonitor thread.  This will save resources, but provide
+   * less functionality.
+   *     
+   * Even when caching is disabled, we still store path-based cache
+   * information.  This information is stored in the edit log and fsimage.  We
+   * don't want to lose it just because a configuration setting was turned off.
+   * However, we will not act on this information if caching is disabled.
+   */
+  private final boolean enabled;
+
+  /**
+   * Whether the CacheManager is active.
+   * 
+   * When the CacheManager is active, it tells the DataNodes what to cache
+   * and uncache.  The CacheManager cannot become active if enabled = false.
+   */
+  private boolean active = false;
+
+  /**
+   * All cached blocks.
+   */
+  private final GSet<CachedBlock, CachedBlock> cachedBlocks;
+
+  /**
+   * The CacheReplicationMonitor.
+   */
+  private CacheReplicationMonitor monitor;
+
+  CacheManager(FSNamesystem namesystem, Configuration conf,
+      BlockManager blockManager) {
-    this.dir = dir;
-    maxListCachePoolsResponses = conf.getInt(
+    this.blockManager = blockManager;
+    this.nextEntryId = 1;
+    this.maxListCachePoolsResponses = conf.getInt(
-    maxListCacheDescriptorsResponses = conf.getInt(
+    this.maxListCacheDescriptorsResponses = conf.getInt(
-  }
-
-  synchronized void clear() {
-    entriesById.clear();
-    entriesByPath.clear();
-    cachePools.clear();
-    nextEntryId = 1;
+    scanIntervalMs = conf.getLong(
+        DFS_NAMENODE_PATH_BASED_CACHE_REFRESH_INTERVAL_MS,
+        DFS_NAMENODE_PATH_BASED_CACHE_REFRESH_INTERVAL_MS_DEFAULT);
+    this.enabled = conf.getBoolean(DFS_NAMENODE_CACHING_ENABLED_KEY,
+        DFS_NAMENODE_CACHING_ENABLED_DEFAULT);
+    this.cachedBlocks = !enabled ? null :
+        new LightWeightGSet<CachedBlock, CachedBlock>(
+            LightWeightGSet.computeCapacity(0.25, "cachedBlocks"));
-   * Returns the next entry ID to be used for a PathBasedCacheEntry
+   * Activate the cache manager.
+   * 
+   * When the cache manager is active, tell the datanodes where to cache files.
-  synchronized long getNextEntryId() {
-    Preconditions.checkArgument(nextEntryId != Long.MAX_VALUE);
+  public void activate() {
+    assert namesystem.hasWriteLock();
+    if (enabled && (!active)) {
+      LOG.info("Activating CacheManager.  " +
+          "Starting replication monitor thread...");
+      active = true;
+      monitor = new CacheReplicationMonitor(namesystem, this,
+         scanIntervalMs);
+      monitor.start();
+    }
+  }
+
+  /**
+   * Deactivate the cache manager.
+   * 
+   * When the cache manager is inactive, it does not tell the datanodes where to
+   * cache files.
+   */
+  public void deactivate() {
+    assert namesystem.hasWriteLock();
+    if (active) {
+      LOG.info("Deactivating CacheManager.  " +
+          "stopping CacheReplicationMonitor thread...");
+      active = false;
+      IOUtils.closeQuietly(monitor);
+      monitor = null;
+      LOG.info("CacheReplicationMonitor thread stopped and deactivated.");
+    }
+  }
+
+  /**
+   * Return true only if the cache manager is active.
+   * Must be called under the FSN read or write lock.
+   */
+  public boolean isActive() {
+    return active;
+  }
+
+  public TreeMap<Long, PathBasedCacheEntry> getEntriesById() {
+    assert namesystem.hasReadOrWriteLock();
+    return entriesById;
+  }
+  
+  @VisibleForTesting
+  public GSet<CachedBlock, CachedBlock> getCachedBlocks() {
+    assert namesystem.hasReadOrWriteLock();
+    return cachedBlocks;
+  }
+
+  private long getNextEntryId() throws IOException {
+    assert namesystem.hasWriteLock();
+    if (nextEntryId == Long.MAX_VALUE) {
+      throw new IOException("No more available IDs");
+    }
-  /**
-   * Returns the PathBasedCacheEntry corresponding to a PathBasedCacheEntry.
-   * 
-   * @param directive Lookup directive
-   * @return Corresponding PathBasedCacheEntry, or null if not present.
-   */
-  private synchronized PathBasedCacheEntry
-      findEntry(PathBasedCacheDirective directive) {
+  private PathBasedCacheEntry findEntry(PathBasedCacheDirective directive) {
+    assert namesystem.hasReadOrWriteLock();
-  /**
-   * Add a new PathBasedCacheEntry, skipping any validation checks. Called
-   * directly when reloading CacheManager state from FSImage.
-   * 
-   * @throws IOException if unable to cache the entry
-   */
-  private void unprotectedAddEntry(PathBasedCacheEntry entry)
-      throws IOException {
-    assert namesystem.hasWriteLock();
-    // Add it to the various maps
-    entriesById.put(entry.getEntryId(), entry);
-    String path = entry.getPath();
-    List<PathBasedCacheEntry> entryList = entriesByPath.get(path);
-    if (entryList == null) {
-      entryList = new ArrayList<PathBasedCacheEntry>(1);
-      entriesByPath.put(path, entryList);
-    }
-    entryList.add(entry);
-    // Set the path as cached in the namesystem
-    try {
-      INode node = dir.getINode(entry.getPath());
-      if (node != null && node.isFile()) {
-        INodeFile file = node.asFile();
-        // TODO: adjustable cache replication factor
-        namesystem.setCacheReplicationInt(entry.getPath(),
-            file.getBlockReplication());
-      } else {
-        LOG.warn("Path " + entry.getPath() + " is not a file");
-      }
-    } catch (IOException ioe) {
-      LOG.info("unprotectedAddEntry " + entry +": failed to cache file: " +
-          ioe.getClass().getName() +": " + ioe.getMessage());
-      throw ioe;
-    }
-  }
-
-  /**
-   * Add a new PathBasedCacheDirective if valid, returning a corresponding
-   * PathBasedCacheDescriptor to the user.
-   * 
-   * @param directive Directive describing the cache entry being added
-   * @param pc Permission checker used to validate that the calling user has
-   *          access to the destination cache pool
-   * @return Corresponding PathBasedCacheDescriptor for the new cache entry
-   * @throws IOException if the directive is invalid or was otherwise
-   *           unsuccessful
-   */
-  public synchronized PathBasedCacheDescriptor addDirective(
+  public PathBasedCacheDescriptor addDirective(
+    assert namesystem.hasWriteLock();
-
-    // Success!
-    PathBasedCacheDescriptor d = unprotectedAddDirective(directive);
-    LOG.info("addDirective " + directive + ": added cache directive "
-        + directive);
-    return d;
-  }
-
-  /**
-   * Assigns a new entry ID to a validated PathBasedCacheDirective and adds
-   * it to the CacheManager. Called directly when replaying the edit log.
-   * 
-   * @param directive Directive being added
-   * @return PathBasedCacheDescriptor for the directive
-   * @throws IOException
-   */
-  PathBasedCacheDescriptor unprotectedAddDirective(
-      PathBasedCacheDirective directive) throws IOException {
-    assert namesystem.hasWriteLock();
-    CachePool pool = cachePools.get(directive.getPool());
-    entry = new PathBasedCacheEntry(getNextEntryId(),
-        directive.getPath().toUri().getPath(),
-        directive.getReplication(), pool);
+    try {
+      entry = new PathBasedCacheEntry(getNextEntryId(),
+          directive.getPath().toUri().getPath(),
+          directive.getReplication(), pool);
+    } catch (IOException ioe) {
+      throw new UnexpectedAddPathBasedCacheDirectiveException(directive);
+    }
+    LOG.info("addDirective " + directive + ": added cache directive "
+        + directive);
-    unprotectedAddEntry(entry);
-
+    // Success!
+    // First, add it to the various maps
+    entriesById.put(entry.getEntryId(), entry);
+    String path = directive.getPath().toUri().getPath();
+    List<PathBasedCacheEntry> entryList = entriesByPath.get(path);
+    if (entryList == null) {
+      entryList = new ArrayList<PathBasedCacheEntry>(1);
+      entriesByPath.put(path, entryList);
+    }
+    entryList.add(entry);
+    if (monitor != null) {
+      monitor.kick();
+    }
-  /**
-   * Remove the PathBasedCacheEntry corresponding to a descriptor ID from
-   * the CacheManager.
-   * 
-   * @param id of the PathBasedCacheDescriptor
-   * @param pc Permissions checker used to validated the request
-   * @throws IOException
-   */
-  public synchronized void removeDescriptor(long id, FSPermissionChecker pc)
+  public void removeDescriptor(long id, FSPermissionChecker pc)
+    assert namesystem.hasWriteLock();
-    unprotectedRemoveDescriptor(id);
-  }
-
-  /**
-   * Unchecked internal method used to remove a PathBasedCacheEntry from the
-   * CacheManager. Called directly when replaying the edit log.
-   * 
-   * @param id of the PathBasedCacheDescriptor corresponding to the entry that
-   *          is being removed
-   * @throws IOException
-   */
-  void unprotectedRemoveDescriptor(long id) throws IOException {
-    assert namesystem.hasWriteLock();
-    PathBasedCacheEntry existing = entriesById.get(id);
-
-    // Set the path as uncached in the namesystem
-    try {
-      INode node = dir.getINode(existing.getDescriptor().getPath().toUri().
-          getPath());
-      if (node != null && node.isFile()) {
-        namesystem.setCacheReplicationInt(existing.getDescriptor().getPath().
-            toUri().getPath(), (short) 0);
-      }
-    } catch (IOException e) {
-      LOG.warn("removeDescriptor " + id + ": failure while setting cache"
-          + " replication factor", e);
-      throw e;
+    if (monitor != null) {
+      monitor.kick();
-  public synchronized BatchedListEntries<PathBasedCacheDescriptor> 
+  public BatchedListEntries<PathBasedCacheDescriptor> 
+    assert namesystem.hasReadOrWriteLock();
-   * 
-   * @param info The info for the cache pool to create.
-   * @return the created CachePool
+   *
+   * @param info    The info for the cache pool to create.
+   * @return        Information about the cache pool we created.
-  public synchronized CachePoolInfo addCachePool(CachePoolInfo info)
+  public CachePoolInfo addCachePool(CachePoolInfo info)
+    assert namesystem.hasWriteLock();
-    return pool.getInfo(true);
-  }
-
-  /**
-   * Internal unchecked method used to add a CachePool. Called directly when
-   * reloading CacheManager state from the FSImage or edit log.
-   * 
-   * @param pool to be added
-   */
-  void unprotectedAddCachePool(CachePoolInfo info) {
-    assert namesystem.hasWriteLock();
-    CachePool pool = CachePool.createFromInfo(info);
-    cachePools.put(pool.getPoolName(), pool);
+    return pool.getInfo(true);
-  public synchronized void modifyCachePool(CachePoolInfo info)
+  public void modifyCachePool(CachePoolInfo info)
+    assert namesystem.hasWriteLock();
-  public synchronized void removeCachePool(String poolName)
+  public void removeCachePool(String poolName)
+    assert namesystem.hasWriteLock();
+    if (monitor != null) {
+      monitor.kick();
+    }
-  public synchronized BatchedListEntries<CachePoolInfo>
+  public BatchedListEntries<CachePoolInfo>
+    assert namesystem.hasReadOrWriteLock();
-  /*
-   * FSImage related serialization and deserialization code
-   */
+  public void setCachedLocations(LocatedBlock block) {
+    if (!enabled) {
+      return;
+    }
+    CachedBlock cachedBlock =
+        new CachedBlock(block.getBlock().getBlockId(),
+            (short)0, false);
+    cachedBlock = cachedBlocks.get(cachedBlock);
+    if (cachedBlock == null) {
+      return;
+    }
+    List<DatanodeDescriptor> datanodes = cachedBlock.getDatanodes(Type.CACHED);
+    for (DatanodeDescriptor datanode : datanodes) {
+      block.addCachedLoc(datanode);
+    }
+  }
+
+  public final void processCacheReport(final DatanodeID datanodeID,
+      final BlockListAsLongs report) throws IOException {
+    if (!enabled) {
+      LOG.info("Ignoring cache report from " + datanodeID +
+          " because " + DFS_NAMENODE_CACHING_ENABLED_KEY + " = false. " +
+          "number of blocks: " + report.getNumberOfBlocks());
+      return;
+    }
+    namesystem.writeLock();
+    final long startTime = Time.monotonicNow();
+    final long endTime;
+    try {
+      final DatanodeDescriptor datanode = 
+          blockManager.getDatanodeManager().getDatanode(datanodeID);
+      if (datanode == null || !datanode.isAlive) {
+        throw new IOException(
+            "processCacheReport from dead or unregistered datanode: " + datanode);
+      }
+      processCacheReportImpl(datanode, report);
+    } finally {
+      endTime = Time.monotonicNow();
+      namesystem.writeUnlock();
+    }
+
+    // Log the block report processing stats from Namenode perspective
+    final NameNodeMetrics metrics = NameNode.getNameNodeMetrics();
+    if (metrics != null) {
+      metrics.addCacheBlockReport((int) (endTime - startTime));
+    }
+    LOG.info("Processed cache report from "
+        + datanodeID + ", blocks: " + report.getNumberOfBlocks()
+        + ", processing time: " + (endTime - startTime) + " msecs");
+  }
+
+  private void processCacheReportImpl(final DatanodeDescriptor datanode,
+      final BlockListAsLongs report) {
+    CachedBlocksList cached = datanode.getCached();
+    cached.clear();
+    BlockReportIterator itBR = report.getBlockReportIterator();
+    while (itBR.hasNext()) {
+      Block block = itBR.next();
+      ReplicaState iState = itBR.getCurrentReplicaState();
+      if (iState != ReplicaState.FINALIZED) {
+        LOG.error("Cached block report contained unfinalized block " + block);
+        continue;
+      }
+      BlockInfo blockInfo = blockManager.getStoredBlock(block);
+      if (blockInfo.getGenerationStamp() < block.getGenerationStamp()) {
+        // The NameNode will eventually remove or update the out-of-date block.
+        // Until then, we pretend that it isn't cached.
+        LOG.warn("Genstamp in cache report disagrees with our genstamp for " +
+          block + ": expected genstamp " + blockInfo.getGenerationStamp());
+        continue;
+      }
+      Collection<DatanodeDescriptor> corruptReplicas =
+          blockManager.getCorruptReplicas(blockInfo);
+      if ((corruptReplicas != null) && corruptReplicas.contains(datanode)) {
+        // The NameNode will eventually remove or update the corrupt block.
+        // Until then, we pretend that it isn't cached.
+        LOG.warn("Ignoring cached replica on " + datanode + " of " + block +
+            " because it is corrupt.");
+        continue;
+      }
+      CachedBlock cachedBlock =
+          new CachedBlock(block.getBlockId(), (short)0, false);
+      CachedBlock prevCachedBlock = cachedBlocks.get(cachedBlock);
+      // Use the existing CachedBlock if it's present; otherwise,
+      // insert a new one.
+      if (prevCachedBlock != null) {
+        cachedBlock = prevCachedBlock;
+      } else {
+        cachedBlocks.put(cachedBlock);
+      }
+      if (!cachedBlock.isPresent(datanode.getCached())) {
+        datanode.getCached().add(cachedBlock);
+      }
+      if (cachedBlock.isPresent(datanode.getPendingCached())) {
+        datanode.getPendingCached().remove(cachedBlock);
+      }
+    }
+  }
-  public synchronized void saveState(DataOutput out, String sdPath)
+  public void saveState(DataOutput out, String sdPath)
-  public synchronized void loadState(DataInput in) throws IOException {
+  public void loadState(DataInput in) throws IOException {
+    assert namesystem.hasWriteLock();
-  private synchronized void savePools(DataOutput out,
+  private void savePools(DataOutput out,
-  private synchronized void saveEntries(DataOutput out, String sdPath)
+  private void saveEntries(DataOutput out, String sdPath)
+      out.writeShort(entry.getReplication());
-  private synchronized void loadPools(DataInput in)
+  private void loadPools(DataInput in)
-      CachePoolInfo info = CachePoolInfo.readFrom(in);
-      unprotectedAddCachePool(info);
+      addCachePool(CachePoolInfo.readFrom(in));
-  private synchronized void loadEntries(DataInput in) throws IOException {
+  private void loadEntries(DataInput in) throws IOException {
+      if (pool != null) {
+        throw new IOException("Entry refers to pool " + poolName +
+            ", which does not exist.");
+      }
-        new PathBasedCacheEntry(entryId, path, replication, pool);
-      unprotectedAddEntry(entry);
+          new PathBasedCacheEntry(entryId, path, replication, pool);
+      if (entriesById.put(entry.getEntryId(), entry) != null) {
+        throw new IOException("An entry with ID " + entry.getEntryId() +
+            " already exists");
+      }
+      List<PathBasedCacheEntry> entries = entriesByPath.get(entry.getPath());
+      if (entries == null) {
+        entries = new LinkedList<PathBasedCacheEntry>();
+        entriesByPath.put(entry.getPath(), entries);
+      }
+      entries.add(entry);
-

MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 MOV23 MOV23 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS79 INS23 INS23 INS23 INS23 INS23 INS23 MOV44 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS40 INS4 INS29 INS83 INS29 INS83 INS83 INS43 INS59 INS29 INS83 MOV83 INS39 INS59 INS29 MOV83 INS83 INS39 INS59 INS29 INS83 INS39 INS59 INS29 INS83 INS83 INS74 INS59 INS29 INS83 UPD43 MOV43 MOV59 MOV21 MOV21 INS29 UPD83 UPD42 UPD83 UPD39 UPD42 INS8 MOV29 UPD83 MOV83 UPD39 MOV39 UPD42 MOV42 INS8 INS83 INS74 INS42 INS8 INS78 INS83 INS74 INS42 INS8 INS83 INS39 INS42 MOV43 INS8 INS83 INS39 INS42 INS44 INS8 INS83 INS83 INS39 INS42 INS44 INS44 MOV43 INS8 INS83 MOV39 UPD42 MOV42 MOV44 INS44 INS8 INS66 INS66 INS66 INS66 INS45 INS65 INS65 INS42 INS42 INS65 INS42 INS65 INS42 INS65 INS42 INS9 INS65 INS43 INS43 INS43 INS42 INS65 UPD42 UPD42 UPD43 UPD42 INS21 INS21 INS21 INS65 INS6 INS25 INS6 INS25 INS41 INS43 INS43 INS43 INS6 INS41 INS42 INS43 INS43 INS43 INS6 INS41 MOV6 INS25 MOV41 INS6 MOV6 MOV60 INS54 MOV21 INS60 MOV60 MOV25 MOV21 INS25 MOV41 MOV6 INS60 MOV60 MOV25 INS25 INS25 MOV21 INS6 MOV6 INS21 INS6 INS6 INS25 INS6 INS43 INS42 INS25 MOV60 INS21 INS25 MOV60 INS70 INS83 INS43 INS42 INS83 INS43 INS42 INS25 INS21 INS60 INS60 INS54 INS60 INS25 INS21 INS83 INS43 INS42 INS83 INS43 INS42 MOV60 INS21 MOV60 INS61 INS6 INS66 INS66 UPD66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS42 INS66 UPD42 INS7 INS7 INS7 INS7 INS66 INS66 INS32 INS27 INS8 UPD66 INS66 INS66 INS32 INS42 INS8 UPD66 UPD66 INS42 INS42 INS42 MOV42 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS27 INS8 INS32 INS8 INS12 MOV43 MOV59 INS27 INS8 INS43 INS59 INS59 INS27 INS8 INS27 INS8 INS32 UPD66 UPD66 INS32 INS32 INS32 INS27 INS8 INS32 INS42 INS38 INS8 UPD43 INS7 INS27 INS8 INS74 INS44 INS42 INS8 INS42 INS42 INS38 INS8 INS32 INS83 INS39 INS59 INS83 INS39 INS59 INS8 INS8 INS83 INS43 INS59 INS27 INS8 INS32 INS42 INS42 UPD43 INS32 UPD43 INS32 INS8 INS32 INS22 INS42 INS22 INS34 INS22 INS22 INS42 INS32 INS32 INS22 INS16 UPD42 MOV42 UPD42 MOV42 INS42 INS36 MOV21 INS21 MOV21 INS21 INS42 INS42 INS21 INS21 MOV21 INS21 INS21 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS40 INS53 INS42 INS42 UPD42 MOV42 MOV21 MOV44 INS8 UPD42 INS32 INS42 INS33 INS21 INS42 INS42 INS42 INS42 MOV32 INS42 INS32 MOV32 MOV34 INS21 MOV42 MOV42 INS42 INS33 INS21 INS42 INS42 INS42 INS42 INS42 INS42 MOV27 INS42 INS42 INS42 INS42 INS42 INS33 INS21 INS42 INS42 INS42 INS41 UPD42 UPD42 INS14 INS42 INS32 INS42 INS33 INS41 INS43 INS43 UPD42 INS43 INS42 MOV21 INS42 MOV21 INS41 INS42 INS42 INS42 INS32 INS42 MOV60 INS25 INS21 INS21 INS21 INS42 INS42 INS32 INS42 INS33 MOV21 INS42 INS42 INS27 UPD42 UPD42 INS42 INS42 UPD42 UPD42 INS32 INS42 INS42 INS60 INS60 MOV25 INS60 INS25 INS60 INS25 INS60 MOV60 INS25 INS25 INS25 INS42 INS42 INS21 INS25 INS25 INS60 INS25 INS52 INS42 INS52 INS42 INS52 INS42 INS52 INS42 UPD42 MOV42 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 INS42 INS52 INS42 INS38 INS33 INS14 INS38 INS7 INS32 INS32 INS7 INS7 INS32 INS14 INS53 INS32 INS42 INS32 INS42 INS42 INS42 MOV42 INS32 INS32 INS32 INS43 INS32 MOV11 INS9 UPD42 MOV42 UPD42 MOV42 INS42 INS42 UPD42 MOV42 UPD42 UPD42 INS40 INS42 INS42 INS42 INS83 UPD43 INS27 INS8 INS32 INS7 INS32 UPD42 MOV42 UPD42 MOV42 INS45 INS42 INS45 INS32 INS45 INS36 INS45 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 INS43 MOV59 INS43 INS59 UPD27 INS43 INS59 INS27 INS8 INS74 INS59 INS27 INS8 INS43 INS59 UPD43 INS27 INS8 INS8 INS38 INS8 INS32 INS8 INS32 INS27 INS8 INS27 INS8 INS74 INS59 INS27 INS8 INS42 INS74 INS32 INS42 UPD42 UPD42 INS27 INS42 INS9 INS42 INS14 INS42 INS42 INS42 INS42 INS27 INS42 INS9 UPD42 UPD42 INS42 INS42 INS33 INS42 INS42 INS45 MOV43 INS45 INS14 INS32 INS42 INS42 INS42 INS42 INS42 INS42 MOV42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 UPD42 UPD42 UPD42 MOV42 UPD42 UPD42 INS27 INS38 INS53 INS42 INS42 INS42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 UPD42 INS42 INS11 UPD42 MOV42 UPD42 MOV42 INS27 UPD42 MOV42 UPD42 INS42 INS42 INS32 INS42 INS40 INS18 INS42 INS42 INS32 INS32 INS32 INS21 INS18 INS43 INS43 INS42 INS32 INS36 INS32 MOV21 INS18 INS42 INS42 INS14 UPD42 UPD42 INS42 INS33 INS21 INS21 INS32 INS21 INS42 INS42 INS32 MOV21 INS42 INS42 INS32 UPD42 MOV32 INS42 INS33 INS53 INS32 INS33 INS53 INS43 INS43 INS42 MOV32 INS42 INS33 INS21 INS21 UPD42 INS42 INS43 INS43 INS43 INS42 INS42 INS34 INS45 INS45 INS45 INS43 INS42 INS52 INS42 INS45 INS45 INS43 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS42 UPD45 UPD42 UPD45 INS42 UPD45 INS45 INS32 UPD42 MOV42 UPD42 MOV42 INS42 INS33 INS40 INS14 UPD42 MOV42 INS42 INS39 INS36 INS42 INS42 UPD42 UPD42 UPD42 MOV42 INS42 UPD42 MOV42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS32 INS42 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS27 UPD42 MOV42 INS42 INS42 INS43 INS32 INS11 INS9 UPD42 UPD42 UPD42 INS7 INS32 INS42 INS42 MOV32 INS32 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS32 INS42 INS14 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS7 MOV32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 UPD42 UPD42 MOV42 UPD42 MOV42 MOV43 INS27 INS27 UPD42 UPD42 INS27 UPD42 MOV42 UPD42 MOV42 INS27 INS42 INS33 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 INS39 INS34 INS42 INS42 UPD42 MOV42 MOV42 INS42 UPD42 UPD42 INS32 INS42 INS42 INS32 INS42 INS42 INS43 INS27 INS42 INS42 INS43 INS27 INS42 INS14 UPD42 UPD42 INS42 INS45 INS42 INS42 INS42 INS45 INS42 INS45 UPD42 MOV42 INS45 MOV32 UPD45 UPD42 UPD45 INS42 UPD45 UPD42 MOV42 INS42 UPD42 MOV42 UPD42 MOV42 INS42 INS45 INS42 INS45 INS42 INS45 INS32 INS45 INS74 INS42 INS42 UPD42 UPD42 INS42 INS42 INS43 INS43 INS42 INS42 DEL83 DEL23 DEL42 DEL42 DEL32 DEL42 DEL42 DEL34 DEL32 DEL21 DEL42 DEL42 DEL32 DEL21 DEL42 DEL40 DEL27 DEL8 DEL42 DEL66 DEL65 DEL66 DEL65 DEL42 DEL66 DEL65 DEL66 DEL65 DEL29 DEL83 DEL43 DEL42 DEL44 DEL42 DEL32 DEL59 DEL60 DEL42 DEL33 DEL27 DEL32 DEL27 DEL21 DEL8 DEL8 DEL25 DEL8 DEL42 DEL53 DEL8 DEL12 DEL54 DEL8 DEL31 DEL66 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL66 DEL66 DEL65 DEL66 DEL65 DEL42 DEL66 DEL66 DEL65 DEL29 DEL83 DEL60 DEL32 DEL42 DEL66 DEL66 DEL65 DEL42 DEL66 DEL65 DEL66 DEL65 DEL42 DEL65 DEL29 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL8 DEL31 DEL66 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL65 DEL29 DEL83 DEL66 DEL66 DEL65 DEL42 DEL66 DEL66 DEL65 DEL42 DEL65 DEL29 DEL42 DEL43 DEL42 DEL42 DEL32 DEL32 DEL32 DEL32 DEL32 DEL59 DEL60 DEL33 DEL27 DEL27 DEL42 DEL42 DEL32 DEL32 DEL42 DEL32 DEL32 DEL32 DEL21 DEL8 DEL25 DEL8 DEL42 DEL44 DEL42 DEL53 DEL8 DEL12 DEL54 DEL8 DEL31 DEL83 DEL83 DEL66 DEL66 DEL65 DEL42 DEL66 DEL65 DEL29 DEL39 DEL42 DEL43 DEL42 DEL44 DEL32 DEL21 DEL8 DEL31 DEL83 DEL83 DEL83 DEL43 DEL45 DEL42 DEL32 DEL45 DEL27 DEL42 DEL42 DEL32 DEL42 DEL32 DEL32 DEL42 DEL39 DEL42 DEL42 DEL42 DEL83 DEL83 DEL83 DEL83 DEL83 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL83 DEL42 DEL42 DEL32