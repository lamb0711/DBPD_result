YARN-736. Add a multi-resource fair sharing metric. (sandyr via tucu)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1496153 13f79535-47bb-0310-9956-ffa450edef68

-    computeFairShares(schedulables, totalResources);
-  }
-
-  /**
-   * Number of iterations for the binary search in computeFairShares. This is
-   * equivalent to the number of bits of precision in the output. 25 iterations
-   * gives precision better than 0.1 slots in clusters with one million slots.
-   */
-  private static final int COMPUTE_FAIR_SHARES_ITERATIONS = 25;
-
-  /**
-   * Given a set of Schedulables and a number of slots, compute their weighted
-   * fair shares. The min shares and demands of the Schedulables are assumed to
-   * be set beforehand. We compute the fairest possible allocation of shares to
-   * the Schedulables that respects their min shares and demands.
-   * 
-   * To understand what this method does, we must first define what weighted
-   * fair sharing means in the presence of minimum shares and demands. If there
-   * were no minimum shares and every Schedulable had an infinite demand (i.e.
-   * could launch infinitely many tasks), then weighted fair sharing would be
-   * achieved if the ratio of slotsAssigned / weight was equal for each
-   * Schedulable and all slots were assigned. Minimum shares and demands add two
-   * further twists: - Some Schedulables may not have enough tasks to fill all
-   * their share. - Some Schedulables may have a min share higher than their
-   * assigned share.
-   * 
-   * To deal with these possibilities, we define an assignment of slots as being
-   * fair if there exists a ratio R such that: - Schedulables S where S.demand <
-   * R * S.weight are assigned share S.demand - Schedulables S where S.minShare
-   * > R * S.weight are given share S.minShare - All other Schedulables S are
-   * assigned share R * S.weight - The sum of all the shares is totalSlots.
-   * 
-   * We call R the weight-to-slots ratio because it converts a Schedulable's
-   * weight to the number of slots it is assigned.
-   * 
-   * We compute a fair allocation by finding a suitable weight-to-slot ratio R.
-   * To do this, we use binary search. Given a ratio R, we compute the number of
-   * slots that would be used in total with this ratio (the sum of the shares
-   * computed using the conditions above). If this number of slots is less than
-   * totalSlots, then R is too small and more slots could be assigned. If the
-   * number of slots is more than totalSlots, then R is too large.
-   * 
-   * We begin the binary search with a lower bound on R of 0 (which means that
-   * all Schedulables are only given their minShare) and an upper bound computed
-   * to be large enough that too many slots are given (by doubling R until we
-   * either use more than totalSlots slots or we fulfill all jobs' demands). The
-   * helper method slotsUsedWithWeightToSlotRatio computes the total number of
-   * slots used with a given value of R.
-   * 
-   * The running time of this algorithm is linear in the number of Schedulables,
-   * because slotsUsedWithWeightToSlotRatio is linear-time and the number of
-   * iterations of binary search is a constant (dependent on desired precision).
-   */
-  public static void computeFairShares(
-      Collection<? extends Schedulable> schedulables, Resource totalResources) {
-    // Find an upper bound on R that we can use in our binary search. We start
-    // at R = 1 and double it until we have either used totalSlots slots or we
-    // have met all Schedulables' demands (if total demand < totalSlots).
-    Resource totalDemand = Resources.createResource(0);
-    for (Schedulable sched : schedulables) {
-      Resources.addTo(totalDemand, sched.getDemand());
-    }
-    Resource cap = Resources.min(RESOURCE_CALCULATOR, null, totalDemand,
-        totalResources);
-    double rMax = 1.0;
-    while (Resources.lessThan(RESOURCE_CALCULATOR, null,
-        resUsedWithWeightToResRatio(rMax, schedulables),
-        cap)) {
-      rMax *= 2.0;
-    }
-    // Perform the binary search for up to COMPUTE_FAIR_SHARES_ITERATIONS steps
-    double left = 0;
-    double right = rMax;
-    for (int i = 0; i < COMPUTE_FAIR_SHARES_ITERATIONS; i++) {
-      double mid = (left + right) / 2.0;
-      if (Resources.lessThan(RESOURCE_CALCULATOR, null,
-          resUsedWithWeightToResRatio(mid, schedulables),
-          cap)) {
-        left = mid;
-      } else {
-        right = mid;
-      }
-    }
-    // Set the fair shares based on the value of R we've converged to
-    for (Schedulable sched : schedulables) {
-      sched.setFairShare(computeShare(sched, right));
-    }
-  }
-
-  /**
-   * Compute the number of slots that would be used given a weight-to-slot ratio
-   * w2sRatio, for use in the computeFairShares algorithm as described in #
-   * {@link SchedulingAlgorithms#computeFairShares(Collection, double)}.
-   */
-  private static Resource resUsedWithWeightToResRatio(double w2sRatio,
-      Collection<? extends Schedulable> schedulables) {
-    Resource slotsTaken = Resources.createResource(0);
-    for (Schedulable sched : schedulables) {
-      Resource share = computeShare(sched, w2sRatio);
-      Resources.addTo(slotsTaken, share);
-    }
-    return slotsTaken;
-  }
-
-  /**
-   * Compute the resources assigned to a Schedulable given a particular
-   * res-to-slot ratio r2sRatio, for use in computeFairShares as described in #
-   * {@link SchedulingAlgorithms#computeFairShares(Collection, double)}.
-   */
-  private static Resource computeShare(Schedulable sched, double r2sRatio) {
-    double share = sched.getWeights().getWeight(ResourceType.MEMORY) * r2sRatio;
-    share = Math.max(share, sched.getMinShare().getMemory());
-    share = Math.min(share, sched.getDemand().getMemory());
-    return Resources.createResource((int) share);
+    ComputeFairShares.computeShares(schedulables, totalResources, ResourceType.MEMORY);

UPD42 INS42 INS40 DEL66 DEL66 DEL66 DEL65 DEL29 DEL83 DEL83 DEL83 DEL39 DEL42 DEL34 DEL59 DEL23 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL65 DEL29 DEL83 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL43 DEL76 DEL74 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL42 DEL42 DEL34 DEL32 DEL59 DEL60 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL21 DEL8 DEL70 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL33 DEL42 DEL42 DEL32 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL60 DEL42 DEL42 DEL42 DEL33 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL34 DEL7 DEL21 DEL8 DEL61 DEL39 DEL42 DEL34 DEL59 DEL60 DEL39 DEL42 DEL42 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL58 DEL42 DEL42 DEL27 DEL42 DEL37 DEL39 DEL42 DEL42 DEL42 DEL27 DEL36 DEL34 DEL27 DEL59 DEL60 DEL42 DEL42 DEL42 DEL33 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL7 DEL21 DEL8 DEL42 DEL42 DEL7 DEL21 DEL8 DEL25 DEL8 DEL24 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL21 DEL8 DEL70 DEL8 DEL31 DEL66 DEL66 DEL42 DEL42 DEL42 DEL43 DEL69 DEL39 DEL69 DEL68 DEL65 DEL66 DEL65 DEL29 DEL83 DEL83 DEL42 DEL43 DEL42 DEL39 DEL42 DEL44 DEL42 DEL43 DEL42 DEL43 DEL76 DEL74 DEL42 DEL44 DEL42 DEL43 DEL42 DEL42 DEL42 DEL34 DEL32 DEL59 DEL60 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL70 DEL42 DEL41 DEL8 DEL31 DEL66 DEL66 DEL42 DEL42 DEL42 DEL43 DEL69 DEL39 DEL69 DEL68 DEL65 DEL66 DEL65 DEL29 DEL83 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL39 DEL42 DEL44 DEL39 DEL42 DEL42 DEL42 DEL32 DEL42 DEL40 DEL32 DEL42 DEL27 DEL59 DEL60 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL32 DEL7 DEL21 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL32 DEL7 DEL21 DEL42 DEL42 DEL39 DEL42 DEL11 DEL32 DEL41 DEL8 DEL31