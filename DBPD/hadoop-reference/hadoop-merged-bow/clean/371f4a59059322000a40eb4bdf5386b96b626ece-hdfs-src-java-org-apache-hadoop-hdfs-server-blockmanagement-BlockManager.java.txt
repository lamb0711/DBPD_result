HDFS-2228. Move block and datanode code from FSNamesystem to BlockManager and DatanodeManager.  (szetszwo)


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154899 13f79535-47bb-0310-9956-ffa450edef68

+import org.apache.hadoop.hdfs.protocol.LocatedBlocks;
-import org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier;
+import org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.AccessMode;
+import org.apache.hadoop.hdfs.server.common.Util;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeCommand;
+import org.apache.hadoop.hdfs.server.protocol.KeyUpdateCommand;
-import org.apache.hadoop.security.token.Token;
-  public volatile long scheduledReplicationBlocksCount = 0L;
+  private volatile long scheduledReplicationBlocksCount = 0L;
-  
-  /** returns the isBlockTokenEnabled - true if block token enabled ,else false */
-  public boolean isBlockTokenEnabled() {
-    return isBlockTokenEnabled;
-  }
-  public final BlocksMap blocksMap;
+  final BlocksMap blocksMap;
-  public final int maxReplication;
+  public final short maxReplication;
-  public final int minReplication;
+  public final short minReplication;
-  /**
-   * Get access keys
-   * 
-   * @return current access keys
-   */
-  public ExportedBlockKeys getBlockKeys() {
-    return isBlockTokenEnabled ? blockTokenSecretManager.exportKeys()
-        : ExportedBlockKeys.DUMMY_KEYS;
-  }
-  
-  /** Generate block token for a LocatedBlock. */
-  public void setBlockToken(LocatedBlock l) throws IOException {
-    Token<BlockTokenIdentifier> token = blockTokenSecretManager.generateToken(l
-        .getBlock(), EnumSet.of(BlockTokenSecretManager.AccessMode.READ));
-    l.setBlockToken(token);
-  }
-
-  /** Generate block tokens for the blocks to be returned. */
-  public void setBlockTokens(List<LocatedBlock> locatedBlocks) throws IOException {
-    for(LocatedBlock l : locatedBlocks) {
-      setBlockToken(l);
-    }
-  }
-  
-    this.maxReplication = conf.getInt(DFSConfigKeys.DFS_REPLICATION_MAX_KEY, 
-                                      DFSConfigKeys.DFS_REPLICATION_MAX_DEFAULT);
-    this.minReplication = conf.getInt(DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_KEY,
-                                      DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_DEFAULT);
-    if (minReplication <= 0)
-      throw new IOException(
-                            "Unexpected configuration parameters: dfs.namenode.replication.min = "
-                            + minReplication
-                            + " must be greater than 0");
-    if (maxReplication >= (int)Short.MAX_VALUE)
-      throw new IOException(
-                            "Unexpected configuration parameters: dfs.replication.max = "
-                            + maxReplication + " must be less than " + (Short.MAX_VALUE));
-    if (maxReplication < minReplication)
-      throw new IOException(
-                            "Unexpected configuration parameters: dfs.namenode.replication.min = "
-                            + minReplication
-                            + " must be less than dfs.replication.max = "
-                            + maxReplication);
+
+    final int maxR = conf.getInt(DFSConfigKeys.DFS_REPLICATION_MAX_KEY, 
+                                 DFSConfigKeys.DFS_REPLICATION_MAX_DEFAULT);
+    final int minR = conf.getInt(DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_KEY,
+                                 DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_DEFAULT);
+    if (minR <= 0)
+      throw new IOException("Unexpected configuration parameters: "
+          + DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_KEY
+          + " = " + minR + " <= 0");
+    if (maxR > Short.MAX_VALUE)
+      throw new IOException("Unexpected configuration parameters: "
+          + DFSConfigKeys.DFS_REPLICATION_MAX_KEY
+          + " = " + maxR + " > " + Short.MAX_VALUE);
+    if (minR > maxR)
+      throw new IOException("Unexpected configuration parameters: "
+          + DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_KEY
+          + " = " + minR + " > "
+          + DFSConfigKeys.DFS_REPLICATION_MAX_KEY
+          + " = " + maxR);
+    this.minReplication = (short)minR;
+    this.maxReplication = (short)maxR;
+
-    return getBlockLocation(ucBlock, fileLength - ucBlock.getNumBytes());
+    return createLocatedBlock(ucBlock, fileLength - ucBlock.getNumBytes());
-  public List<LocatedBlock> getBlockLocations(BlockInfo[] blocks, long offset,
-      long length, int nrBlocksToReturn) throws IOException {
+  private List<LocatedBlock> createLocatedBlockList(final BlockInfo[] blocks,
+      final long offset, final long length, final int nrBlocksToReturn
+      ) throws IOException {
-      results.add(getBlockLocation(blocks[curBlk], curPos));
+      results.add(createLocatedBlock(blocks[curBlk], curPos));
-  public LocatedBlock getBlockLocation(final BlockInfo blk, final long pos
+  private LocatedBlock createLocatedBlock(final BlockInfo blk, final long pos
+  /** Create a LocatedBlocks. */
+  public LocatedBlocks createLocatedBlocks(final BlockInfo[] blocks,
+      final long fileSizeExcludeBlocksUnderConstruction,
+      final boolean isFileUnderConstruction,
+      final long offset, final long length, final boolean needBlockToken
+      ) throws IOException {
+    assert namesystem.hasReadOrWriteLock();
+    if (blocks == null) {
+      return null;
+    } else if (blocks.length == 0) {
+      return new LocatedBlocks(0, isFileUnderConstruction,
+          Collections.<LocatedBlock>emptyList(), null, false);
+    } else {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("blocks = " + java.util.Arrays.asList(blocks));
+      }
+      final List<LocatedBlock> locatedblocks = createLocatedBlockList(
+          blocks, offset, length, Integer.MAX_VALUE);
+
+      final BlockInfo last = blocks[blocks.length - 1];
+      final long lastPos = last.isComplete()?
+          fileSizeExcludeBlocksUnderConstruction - last.getNumBytes()
+          : fileSizeExcludeBlocksUnderConstruction;
+      final LocatedBlock lastlb = createLocatedBlock(last, lastPos);
+
+      if (isBlockTokenEnabled && needBlockToken) {
+        for(LocatedBlock lb : locatedblocks) {
+          setBlockToken(lb, AccessMode.READ);
+        }
+        setBlockToken(lastlb, AccessMode.READ);
+      }
+      return new LocatedBlocks(
+          fileSizeExcludeBlocksUnderConstruction, isFileUnderConstruction,
+          locatedblocks, lastlb, last.isComplete());
+    }
+  }
+
+  /** @return current access keys. */
+  public ExportedBlockKeys getBlockKeys() {
+    return isBlockTokenEnabled? blockTokenSecretManager.exportKeys()
+        : ExportedBlockKeys.DUMMY_KEYS;
+  }
+
+  /** Generate a block token for the located block. */
+  public void setBlockToken(final LocatedBlock b,
+      final BlockTokenSecretManager.AccessMode mode) throws IOException {
+    if (isBlockTokenEnabled) {
+      b.setBlockToken(blockTokenSecretManager.generateToken(b.getBlock(), 
+          EnumSet.of(mode)));
+    }    
+  }
+
+  void addKeyUpdateCommand(final List<DatanodeCommand> cmds,
+      final DatanodeDescriptor nodeinfo) {
+    // check access key update
+    if (isBlockTokenEnabled && nodeinfo.needKeyUpdate) {
+      cmds.add(new KeyUpdateCommand(blockTokenSecretManager.exportKeys()));
+      nodeinfo.needKeyUpdate = false;
+    }
+  }
+
+  /**
+   * Clamp the specified replication between the minimum and the maximum
+   * replication levels.
+   */
+  public short adjustReplication(short replication) {
+    return replication < minReplication? minReplication
+        : replication > maxReplication? maxReplication: replication;
+  }
+
-      NameNode.stateChangeLog.warn("BLOCK* NameSystem.getBlocks: "
+      NameNode.stateChangeLog.warn("BLOCK* getBlocks: "
-  void addToInvalidates(Block b, DatanodeInfo dn, boolean log) {
+  private void addToInvalidates(Block b, DatanodeInfo dn, boolean log) {
-        NameNode.stateChangeLog.info("BLOCK* NameSystem.addToInvalidates: "
+        NameNode.stateChangeLog.info("BLOCK* addToInvalidates: "
-  public void addToInvalidates(Block b, DatanodeInfo dn) {
+  void addToInvalidates(Block b, DatanodeInfo dn) {
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.addToInvalidates: "
+      NameNode.stateChangeLog.info("BLOCK* addToInvalidates: "
-  public void findAndMarkBlockAsCorrupt(Block blk,
-                                 DatanodeInfo dn) throws IOException {
-    BlockInfo storedBlock = getStoredBlock(blk);
-    if (storedBlock == null) {
-      // Check if the replica is in the blockMap, if not
-      // ignore the request for now. This could happen when BlockScanner
-      // thread of Datanode reports bad block before Block reports are sent
-      // by the Datanode on startup
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.markBlockAsCorrupt: " +
-                                   "block " + blk + " could not be marked as " +
-                                   "corrupt as it does not exist in blocksMap");
-      return;
+  /**
+   * Mark the block belonging to datanode as corrupt
+   * @param blk Block to be marked as corrupt
+   * @param dn Datanode which holds the corrupt replica
+   */
+  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,
+      final DatanodeInfo dn) throws IOException {
+    namesystem.writeLock();
+    try {
+      final BlockInfo storedBlock = getStoredBlock(blk.getLocalBlock());
+      if (storedBlock == null) {
+        // Check if the replica is in the blockMap, if not
+        // ignore the request for now. This could happen when BlockScanner
+        // thread of Datanode reports bad block before Block reports are sent
+        // by the Datanode on startup
+        NameNode.stateChangeLog.info("BLOCK* findAndMarkBlockAsCorrupt: "
+            + blk + " not found.");
+        return;
+      }
+      markBlockAsCorrupt(storedBlock, dn);
+    } finally {
+      namesystem.writeUnlock();
-    markBlockAsCorrupt(storedBlock, dn);
-      NameNode.stateChangeLog.info("BLOCK NameSystem.markBlockAsCorrupt: " +
+      NameNode.stateChangeLog.info("BLOCK markBlockAsCorrupt: " +
-    NameNode.stateChangeLog.info("DIR* NameSystem.invalidateBlock: "
+    NameNode.stateChangeLog.info("BLOCK* invalidateBlock: "
-      throw new IOException("Cannot invalidate block " + blk +
-                            " because datanode " + dn.getName() +
-                            " does not exist.");
+      throw new IOException("Cannot invalidate block " + blk
+          + " because datanode " + dn.getName() + " does not exist.");
-        NameNode.stateChangeLog.debug("BLOCK* NameSystem.invalidateBlocks: "
-            + blk + " on "
-            + dn.getName() + " listed for deletion.");
+        NameNode.stateChangeLog.debug("BLOCK* invalidateBlocks: "
+            + blk + " on " + dn.getName() + " listed for deletion.");
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.invalidateBlocks: "
-          + blk + " on " + dn.getName()
-          + " is the only copy and was not deleted.");
+      NameNode.stateChangeLog.info("BLOCK* invalidateBlocks: " + blk + " on "
+          + dn.getName() + " is the only copy and was not deleted.");
-   * The given node is reporting all its blocks.  Use this info to
-   * update the (datanode-->blocklist) and (block-->nodelist) tables.
+   * The given datanode is reporting all its blocks.
+   * Update the (machine-->blocklist) and (block-->machinelist) maps.
-  public void processReport(DatanodeDescriptor node, BlockListAsLongs report) 
-  throws IOException {
-    
-    boolean isFirstBlockReport = (node.numBlocks() == 0);
-    if (isFirstBlockReport) {
-      // Initial block reports can be processed a lot more efficiently than
-      // ordinary block reports.  This shortens NN restart times.
-      processFirstBlockReport(node, report);
-      return;
-    } 
+  public void processReport(final DatanodeID nodeID, final String poolId,
+      final BlockListAsLongs newReport) throws IOException {
+    namesystem.writeLock();
+    final long startTime = Util.now(); //after acquiring write lock
+    final long endTime;
+    try {
+      final DatanodeDescriptor node = datanodeManager.getDatanode(nodeID);
+      if (node == null || !node.isAlive) {
+        throw new IOException("ProcessReport from dead or unregistered node: "
+                              + nodeID.getName());
+      }
+      // To minimize startup time, we discard any second (or later) block reports
+      // that we receive while still in startup phase.
+      if (namesystem.isInStartupSafeMode() && node.numBlocks() > 0) {
+        NameNode.stateChangeLog.info("BLOCK* processReport: "
+            + "discarded non-initial block report from " + nodeID.getName()
+            + " because namenode still in startup phase");
+        return;
+      }
+
+      if (node.numBlocks() == 0) {
+        // The first block report can be processed a lot more efficiently than
+        // ordinary block reports.  This shortens restart times.
+        processFirstBlockReport(node, newReport);
+      } else {
+        processReport(node, newReport);
+      }
+    } finally {
+      endTime = Util.now();
+      namesystem.writeUnlock();
+    }
+
+    // Log the block report processing stats from Namenode perspective
+    NameNode.getNameNodeMetrics().addBlockReport((int) (endTime - startTime));
+    NameNode.stateChangeLog.info("BLOCK* processReport: from "
+        + nodeID.getName() + ", blocks: " + newReport.getNumberOfBlocks()
+        + ", processing time: " + (endTime - startTime) + " msecs");
+  }
+
+  private void processReport(final DatanodeDescriptor node,
+      final BlockListAsLongs report) throws IOException {
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.processReport: block "
+      NameNode.stateChangeLog.info("BLOCK* processReport: block "
-  void processFirstBlockReport(DatanodeDescriptor node, BlockListAsLongs report) 
-  throws IOException {
+  private void processFirstBlockReport(final DatanodeDescriptor node,
+      final BlockListAsLongs report) throws IOException {
-  BlockInfo processReportedBlock(DatanodeDescriptor dn, 
-      Block block, ReplicaState reportedState, 
-      Collection<BlockInfo> toAdd, 
-      Collection<Block> toInvalidate, 
-      Collection<BlockInfo> toCorrupt,
-      Collection<StatefulBlockInfo> toUC) {
+  private BlockInfo processReportedBlock(final DatanodeDescriptor dn, 
+      final Block block, final ReplicaState reportedState, 
+      final Collection<BlockInfo> toAdd, 
+      final Collection<Block> toInvalidate, 
+      final Collection<BlockInfo> toCorrupt,
+      final Collection<StatefulBlockInfo> toUC) {
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.addStoredBlock: "
-                                   + "addStoredBlock request received for "
-                                   + block + " on " + node.getName()
-                                   + " size " + block.getNumBytes()
-                                   + " But it does not belong to any file.");
+      NameNode.stateChangeLog.info("BLOCK* addStoredBlock: " + block + " on "
+          + node.getName() + " size " + block.getNumBytes()
+          + " but it does not belong to any file.");
-        NameNode.stateChangeLog.info("BLOCK* NameSystem.addStoredBlock: "
+        NameNode.stateChangeLog.info("BLOCK* addStoredBlock: "
-      NameNode.stateChangeLog.warn("BLOCK* NameSystem.addStoredBlock: "
+      NameNode.stateChangeLog.warn("BLOCK* addStoredBlock: "
+  /** Set replication for the blocks. */
+  public void setReplication(final short oldRepl, final short newRepl,
+      final String src, final Block... blocks) throws IOException {
+    if (newRepl == oldRepl) {
+      return;
+    }
+
+    // update needReplication priority queues
+    for(Block b : blocks) {
+      updateNeededReplications(b, 0, newRepl-oldRepl);
+    }
+      
+    if (oldRepl > newRepl) {
+      // old replication > the new one; need to remove copies
+      LOG.info("Decreasing replication from " + oldRepl + " to " + newRepl
+          + " for " + src);
+      for(Block b : blocks) {
+        processOverReplicatedBlock(b, newRepl, null, null);
+      }
+    } else { // replication factor is increased
+      LOG.info("Increasing replication from " + oldRepl + " to " + newRepl
+          + " for " + src);
+    }
+  }
+
-  public void processOverReplicatedBlock(Block block, short replication,
-      DatanodeDescriptor addedNode, DatanodeDescriptor delNodeHint) {
+  private void processOverReplicatedBlock(final Block block,
+      final short replication, final DatanodeDescriptor addedNode,
+      DatanodeDescriptor delNodeHint) {
-    namesystem.chooseExcessReplicates(nonExcess, block, replication, 
+    chooseExcessReplicates(nonExcess, block, replication, 
-  public void addToExcessReplicate(DatanodeInfo dn, Block block) {
+  /**
+   * We want "replication" replicates for the block, but we now have too many.  
+   * In this method, copy enough nodes from 'srcNodes' into 'dstNodes' such that:
+   *
+   * srcNodes.size() - dstNodes.size() == replication
+   *
+   * We pick node that make sure that replicas are spread across racks and
+   * also try hard to pick one with least free space.
+   * The algorithm is first to pick a node with least free space from nodes
+   * that are on a rack holding more than one replicas of the block.
+   * So removing such a replica won't remove a rack. 
+   * If no such a node is available,
+   * then pick a node with least free space
+   */
+  private void chooseExcessReplicates(Collection<DatanodeDescriptor> nonExcess, 
+                              Block b, short replication,
+                              DatanodeDescriptor addedNode,
+                              DatanodeDescriptor delNodeHint,
+                              BlockPlacementPolicy replicator) {
+    assert namesystem.hasWriteLock();
+    // first form a rack to datanodes map and
+    INodeFile inode = getINode(b);
+    final Map<String, List<DatanodeDescriptor>> rackMap
+        = new HashMap<String, List<DatanodeDescriptor>>();
+    for(final Iterator<DatanodeDescriptor> iter = nonExcess.iterator();
+        iter.hasNext(); ) {
+      final DatanodeDescriptor node = iter.next();
+      final String rackName = node.getNetworkLocation();
+      List<DatanodeDescriptor> datanodeList = rackMap.get(rackName);
+      if (datanodeList == null) {
+        datanodeList = new ArrayList<DatanodeDescriptor>();
+        rackMap.put(rackName, datanodeList);
+      }
+      datanodeList.add(node);
+    }
+    
+    // split nodes into two sets
+    // priSet contains nodes on rack with more than one replica
+    // remains contains the remaining nodes
+    final List<DatanodeDescriptor> priSet = new ArrayList<DatanodeDescriptor>();
+    final List<DatanodeDescriptor> remains = new ArrayList<DatanodeDescriptor>();
+    for(List<DatanodeDescriptor> datanodeList : rackMap.values()) {
+      if (datanodeList.size() == 1 ) {
+        remains.add(datanodeList.get(0));
+      } else {
+        priSet.addAll(datanodeList);
+      }
+    }
+    
+    // pick one node to delete that favors the delete hint
+    // otherwise pick one with least space from priSet if it is not empty
+    // otherwise one node with least space from remains
+    boolean firstOne = true;
+    while (nonExcess.size() - replication > 0) {
+      // check if we can delete delNodeHint
+      final DatanodeInfo cur;
+      if (firstOne && delNodeHint !=null && nonExcess.contains(delNodeHint)
+          && (priSet.contains(delNodeHint)
+              || (addedNode != null && !priSet.contains(addedNode))) ) {
+        cur = delNodeHint;
+      } else { // regular excessive replica removal
+        cur = replicator.chooseReplicaToDelete(inode, b, replication,
+            priSet, remains);
+      }
+      firstOne = false;
+
+      // adjust rackmap, priSet, and remains
+      String rack = cur.getNetworkLocation();
+      final List<DatanodeDescriptor> datanodes = rackMap.get(rack);
+      datanodes.remove(cur);
+      if (datanodes.isEmpty()) {
+        rackMap.remove(rack);
+      }
+      if (priSet.remove(cur)) {
+        if (datanodes.size() == 1) {
+          priSet.remove(datanodes.get(0));
+          remains.add(datanodes.get(0));
+        }
+      } else {
+        remains.remove(cur);
+      }
+
+      nonExcess.remove(cur);
+      addToExcessReplicate(cur, b);
+
+      //
+      // The 'excessblocks' tracks blocks until we get confirmation
+      // that the datanode has deleted them; the only way we remove them
+      // is when we get a "removeBlock" message.  
+      //
+      // The 'invalidate' list is used to inform the datanode the block 
+      // should be deleted.  Items are removed from the invalidate list
+      // upon giving instructions to the namenode.
+      //
+      addToInvalidates(b, cur);
+      NameNode.stateChangeLog.info("BLOCK* chooseExcessReplicates: "
+                +"("+cur.getName()+", "+b+") is added to recentInvalidateSets");
+    }
+  }
+
+  private void addToExcessReplicate(DatanodeInfo dn, Block block) {
-        NameNode.stateChangeLog.debug("BLOCK* NameSystem.chooseExcessReplicates:"
+        NameNode.stateChangeLog.debug("BLOCK* addToExcessReplicate:"
-      NameNode.stateChangeLog.debug("BLOCK* NameSystem.removeStoredBlock: "
+      NameNode.stateChangeLog.debug("BLOCK* removeStoredBlock: "
-          NameNode.stateChangeLog.debug("BLOCK* NameSystem.removeStoredBlock: "
+          NameNode.stateChangeLog.debug("BLOCK* removeStoredBlock: "
-            NameNode.stateChangeLog.debug(
-                "BLOCK* NameSystem.removeStoredBlock: "
+            NameNode.stateChangeLog.debug("BLOCK* removeStoredBlock: "
-  public void addBlock(DatanodeDescriptor node, Block block, String delHint)
+  private void addBlock(DatanodeDescriptor node, Block block, String delHint)
-        NameNode.stateChangeLog.warn("BLOCK* NameSystem.blockReceived: "
-            + block + " is expected to be removed from an unrecorded node "
-            + delHint);
+        NameNode.stateChangeLog.warn("BLOCK* blockReceived: " + block
+            + " is expected to be removed from an unrecorded node " + delHint);
-      NameNode.stateChangeLog.info("BLOCK* NameSystem.addBlock: block "
+      NameNode.stateChangeLog.info("BLOCK* addBlock: block "
+  /** The given node is reporting that it received a certain block. */
+  public void blockReceived(final DatanodeID nodeID, final String poolId,
+      final Block block, final String delHint) throws IOException {
+    namesystem.writeLock();
+    try {
+      final DatanodeDescriptor node = datanodeManager.getDatanode(nodeID);
+      if (node == null || !node.isAlive) {
+        final String s = block + " is received from dead or unregistered node "
+            + nodeID.getName();
+        NameNode.stateChangeLog.warn("BLOCK* blockReceived: " + s);
+        throw new IOException(s);
+      } 
+
+      if (NameNode.stateChangeLog.isDebugEnabled()) {
+        NameNode.stateChangeLog.debug("BLOCK* blockReceived: " + block
+            + " is received from " + nodeID.getName());
+      }
+
+      addBlock(node, block, delHint);
+    } finally {
+      namesystem.writeUnlock();
+    }
+  }
+
-  /* updates a block in under replication queue */
-  public void updateNeededReplications(Block block, int curReplicasDelta,
-      int expectedReplicasDelta) {
+  /** updates a block in under replication queue */
+  private void updateNeededReplications(final Block block,
+      final int curReplicasDelta, int expectedReplicasDelta) {
-  public void removeFromCorruptReplicasMap(Block block) {
-    corruptReplicas.removeFromCorruptReplicasMap(block);
+  /** @return an iterator of the datanodes. */
+  public Iterator<DatanodeDescriptor> datanodeIterator(final Block block) {
+    return blocksMap.nodeIterator(block);
+    // If block is removed from blocksMap remove it from corruptReplicasMap
+    corruptReplicas.removeFromCorruptReplicasMap(block);

MOV26 MOV26 INS26 INS26 INS26 MOV31 MOV31 MOV31 MOV31 MOV31 INS40 UPD40 UPD40 INS40 INS40 INS31 INS31 INS31 INS31 INS31 MOV44 MOV44 INS31 UPD83 UPD39 UPD39 UPD83 UPD42 UPD83 UPD42 INS43 INS42 INS44 INS44 INS44 INS44 INS44 INS44 INS43 INS8 MOV29 MOV83 MOV39 MOV42 MOV44 INS44 MOV43 INS8 INS39 INS42 INS44 INS44 INS8 INS29 INS83 INS39 INS42 INS44 INS8 INS83 INS29 INS83 INS39 INS42 INS44 INS44 MOV43 INS8 INS29 INS83 INS39 INS42 INS44 INS44 MOV44 MOV43 INS8 UPD83 INS83 INS44 INS83 UPD42 INS44 INS44 INS44 INS43 INS8 UPD83 INS44 INS44 INS29 UPD83 UPD42 INS44 MOV44 MOV44 INS44 UPD83 UPD83 INS29 UPD42 INS44 INS44 INS44 INS43 INS8 INS29 UPD83 INS29 INS83 INS74 INS42 INS44 INS8 MOV8 INS60 INS60 INS21 INS21 INS83 INS83 INS83 INS83 INS42 INS83 INS5 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS42 INS6 INS25 INS83 INS43 INS42 INS83 INS43 INS42 INS25 INS83 INS74 INS42 INS83 INS43 INS42 INS25 INS65 INS39 INS42 INS41 INS65 INS65 INS65 INS83 INS43 INS42 INS83 INS43 INS42 INS21 INS54 MOV21 INS65 INS83 INS43 INS42 INS83 INS43 INS42 INS83 UPD42 INS21 INS60 INS60 INS54 INS21 INS21 INS83 INS83 INS83 INS83 INS43 INS42 INS83 INS83 INS83 INS83 UPD42 INS83 INS83 UPD42 INS83 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS43 INS42 INS83 INS43 UPD42 INS42 INS25 INS70 INS25 INS83 INS83 INS39 INS42 INS83 INS43 INS42 INS65 INS74 INS42 UPD42 UPD43 UPD42 INS43 INS42 INS6 INS60 INS24 INS60 INS60 INS70 INS60 INS61 INS65 INS83 INS43 INS42 INS83 INS43 INS42 INS83 INS83 INS43 INS42 INS42 INS21 INS54 INS65 INS83 INS83 INS65 INS43 INS43 INS83 INS43 INS42 INS41 MOV21 INS83 INS39 INS59 INS83 INS39 INS59 UPD27 UPD27 INS7 INS7 UPD66 INS43 INS85 INS32 INS27 INS8 INS25 UPD66 UPD66 INS42 INS40 INS42 INS8 INS43 INS43 INS42 INS27 INS8 INS66 INS66 INS16 INS66 INS42 INS66 INS42 INS66 INS42 INS42 INS32 INS8 INS8 MOV8 INS66 INS66 INS42 INS42 INS32 INS83 INS39 INS59 INS83 INS39 INS59 INS8 INS8 INS32 INS32 INS42 UPD66 INS42 INS42 INS27 INS8 INS44 INS42 INS8 INS27 INS8 INS8 INS42 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS43 INS43 UPD42 INS42 INS32 INS43 INS83 INS74 INS59 INS58 INS32 INS8 INS83 INS74 INS59 INS83 INS74 INS59 INS44 INS32 INS8 INS39 INS59 INS27 INS8 MOV32 INS44 INS66 INS42 INS42 INS42 INS32 INS8 INS8 INS66 INS66 INS42 INS42 INS42 INS32 INS42 MOV32 INS42 MOV32 UPD42 UPD42 INS40 UPD42 UPD42 MOV22 INS11 MOV22 INS11 UPD42 INS42 INS42 INS42 INS42 INS33 INS41 INS27 INS8 INS8 INS21 INS42 INS42 INS42 INS40 MOV21 INS21 INS27 INS42 INS16 INS42 INS42 INS60 INS25 MOV21 INS21 INS42 INS42 INS42 INS32 INS42 INS60 INS25 INS25 INS25 INS21 INS21 INS32 INS42 INS11 INS40 INS42 INS27 INS42 INS42 INS41 INS43 INS42 INS21 INS42 INS42 INS21 MOV70 INS21 INS42 INS42 INS42 INS42 INS42 UPD42 INS43 INS43 INS74 INS42 INS14 INS83 INS74 INS59 INS42 INS42 INS60 INS60 INS60 INS25 INS21 INS43 INS43 INS42 INS14 INS43 INS43 INS42 INS14 INS74 INS42 INS42 INS42 INS25 INS42 INS9 INS27 INS34 INS60 INS25 INS21 INS60 INS60 INS21 INS25 INS25 INS21 INS21 INS21 MOV21 INS43 INS42 INS42 INS42 INS60 INS25 INS25 INS21 INS21 INS42 INS42 INS42 MOV43 MOV43 INS39 INS42 INS39 INS42 INS33 INS40 INS34 MOV41 INS25 INS60 INS60 INS60 INS60 INS25 INS41 INS32 INS7 INS42 INS42 INS27 INS42 INS42 INS8 INS83 MOV43 INS59 MOV27 INS8 INS32 UPD45 INS42 INS42 INS83 INS43 INS59 INS27 INS8 INS27 INS8 MOV27 INS8 INS8 INS7 INS32 INS42 INS42 INS39 INS36 INS45 INS32 INS45 INS32 INS45 INS36 INS45 INS42 INS32 INS32 MOV44 UPD42 INS32 UPD42 UPD42 INS42 INS42 INS43 INS43 INS74 INS43 INS43 INS42 INS32 INS83 INS43 INS59 INS83 INS43 INS59 INS74 INS59 INS27 INS8 INS32 INS42 INS42 INS74 INS42 INS42 INS74 INS43 INS43 INS27 INS8 INS8 INS32 INS42 INS83 INS43 INS59 INS27 INS8 INS8 INS7 INS43 INS59 INS83 INS74 INS59 INS32 INS32 INS8 INS32 INS8 INS8 INS32 INS32 INS32 MOV32 INS42 INS83 INS43 INS59 INS27 INS8 INS32 INS8 INS32 INS32 UPD45 INS40 INS45 UPD42 UPD45 UPD45 INS40 INS45 UPD42 UPD45 INS40 UPD45 INS40 INS45 UPD42 INS45 INS40 UPD45 UPD42 INS14 INS32 INS8 INS83 MOV74 INS59 INS83 INS43 INS59 INS83 INS39 INS59 INS83 INS43 INS59 INS27 INS8 INS14 INS42 INS42 INS32 UPD42 INS42 INS14 INS40 INS9 INS42 INS42 INS21 INS42 INS32 INS21 INS41 INS42 INS42 INS42 INS42 INS32 INS27 INS38 INS53 INS32 INS27 INS21 INS41 INS21 INS21 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS34 INS27 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS43 INS43 INS74 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS43 INS43 INS42 INS32 INS42 INS33 INS21 INS21 INS42 INS42 INS42 INS43 INS43 INS43 INS43 INS42 INS42 INS32 INS34 INS21 INS21 INS42 INS42 INS42 INS42 INS27 INS36 INS21 INS21 INS42 INS9 INS42 INS42 INS32 INS43 INS43 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS25 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV32 INS42 INS42 INS32 INS27 INS38 INS60 INS21 INS53 INS40 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS43 INS34 INS42 INS32 INS33 INS9 INS42 INS42 INS21 INS42 INS32 INS42 INS42 INS2 INS42 INS16 INS42 INS42 INS32 INS42 INS42 INS70 INS21 INS43 INS42 INS42 INS42 INS42 INS32 MOV42 MOV42 MOV32 MOV32 INS43 INS32 UPD45 INS32 UPD45 INS42 INS32 INS32 UPD45 UPD42 UPD45 INS45 INS42 INS42 INS42 INS42 INS33 INS40 INS14 INS42 INS42 INS32 INS34 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 UPD45 UPD45 MOV45 UPD45 INS32 MOV32 INS42 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS42 INS42 INS43 INS43 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS27 INS32 INS27 INS7 INS7 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS27 INS8 INS32 INS32 UPD45 INS42 UPD45 UPD45 MOV32 UPD45 MOV32 INS42 INS42 INS42 INS42 INS33 INS40 INS83 INS43 INS59 INS32 INS14 INS32 INS42 INS42 MOV43 INS42 INS32 INS42 INS42 INS42 INS42 INS40 INS42 INS27 INS32 INS27 INS42 INS42 INS42 INS42 MOV44 INS42 INS8 INS32 INS42 INS42 INS42 UPD42 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS40 INS42 INS27 INS42 INS42 INS40 INS42 INS27 UPD45 INS43 INS27 INS42 INS42 INS40 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 UPD45 INS42 INS42 UPD42 INS42 UPD42 INS33 INS33 INS42 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS32 INS36 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS34 INS21 INS21 INS42 INS42 INS42 UPD45 UPD45 INS42 INS42 MOV42 MOV32 INS42 INS42 INS27 INS40 INS42 INS27 INS43 INS42 INS40 INS42 INS27 INS42 INS42 INS27 INS40 INS34 INS42 INS42 INS42 INS32 UPD42 INS21 INS42 INS42 INS40 INS45 INS42 INS45 MOV32 INS45 INS42 INS45 UPD45 INS42 INS45 INS32 INS27 INS32 INS45 MOV32 INS74 INS42 INS42 INS34 INS42 INS33 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 UPD45 INS42 INS45 INS32 INS45 INS42 INS42 INS45 INS42 INS45 INS32 INS45 INS32 INS42 INS42 INS32 INS42 INS42 INS45 INS45 INS42 INS42 UPD45 INS43 INS43 INS27 INS38 INS42 INS42 INS32 INS42 INS42 INS32 UPD45 UPD45 INS42 INS42 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS40 INS42 INS42 INS42 INS33 INS32 INS42 INS42 INS34 INS42 INS42 INS34 INS42 INS42 INS42 UPD45 DEL83 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL32 DEL59 DEL60 DEL8 DEL31 DEL7 DEL21 DEL7 DEL21 DEL39 DEL40 DEL11 DEL40 DEL36 DEL42 DEL39 DEL42 DEL8 DEL66 DEL65 DEL42 DEL40 DEL83 DEL45 DEL40 DEL42 DEL45 DEL42 DEL45 DEL27 DEL32 DEL21 DEL8 DEL66 DEL66 DEL65 DEL29 DEL39 DEL42 DEL36 DEL59 DEL60 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL41 DEL8 DEL25 DEL45 DEL27 DEL8 DEL42 DEL42 DEL41 DEL8 DEL25 DEL8