MAPREDUCE-5485. Allow repeating job commit by extending OutputCommitter API. Contributed by Junping Du

+    committer = createOutputCommitter(conf);
+
-          //The commit is still pending, commit error
-          shutDownMessage =
-              "Job commit from a prior MRAppMaster attempt is " +
-              "potentially in progress. Preventing multiple commit executions";
-          forcedState = JobStateInternal.ERROR;
+          if (isCommitJobRepeatable()) {
+            // cleanup previous half done commits if committer supports
+            // repeatable job commit.
+            errorHappenedShutDown = false;
+            cleanupInterruptedCommit(conf, fs, startCommitFile);
+          } else {
+            //The commit is still pending, commit error
+            shutDownMessage =
+                "Job commit from a prior MRAppMaster attempt is " +
+                "potentially in progress. Preventing multiple commit executions";
+            forcedState = JobStateInternal.ERROR;
+          }
-    
+
-      committer = createOutputCommitter(conf);
+  private boolean isCommitJobRepeatable() throws IOException {
+    boolean isRepeatable = false;
+    Configuration conf = getConfig();
+    if (committer != null) {
+      final JobContext jobContext = getJobContextFromConf(conf);
+
+      isRepeatable = callWithJobClassLoader(conf,
+          new ExceptionAction<Boolean>() {
+            public Boolean call(Configuration conf) throws IOException {
+              return committer.isCommitJobRepeatable(jobContext);
+            }
+          });
+    }
+    return isRepeatable;
+  }
+
+  private JobContext getJobContextFromConf(Configuration conf) {
+    if (newApiCommitter) {
+      return new JobContextImpl(conf, TypeConverter.fromYarn(getJobId()));
+    } else {
+      return new org.apache.hadoop.mapred.JobContextImpl(
+          new JobConf(conf), TypeConverter.fromYarn(getJobId()));
+    }
+  }
+
+  private void cleanupInterruptedCommit(Configuration conf,
+      FileSystem fs, Path startCommitFile) throws IOException {
+    LOG.info("Delete startJobCommitFile in case commit is not finished as " +
+        "successful or failed.");
+    fs.delete(startCommitFile, false);
+  }
+
-      final JobContext _jobContext;
-      if (newApiCommitter) {
-         _jobContext = new JobContextImpl(
-            conf, TypeConverter.fromYarn(getJobId()));
-      } else {
-          _jobContext = new org.apache.hadoop.mapred.JobContextImpl(
-                new JobConf(conf), TypeConverter.fromYarn(getJobId()));
-      }
+      final JobContext _jobContext = getJobContextFromConf(conf);

INS31 INS31 INS31 INS83 INS39 INS42 INS43 INS8 INS83 INS43 INS42 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS44 INS43 INS8 MOV21 INS42 INS60 INS60 INS25 INS41 INS42 INS43 INS42 MOV25 INS43 INS42 INS43 INS42 INS43 INS42 INS42 INS21 INS21 INS39 INS59 INS43 INS59 INS27 INS8 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS9 INS42 INS42 INS32 INS42 INS33 INS60 INS21 INS41 INS41 INS42 INS42 INS27 INS42 INS42 INS42 INS9 INS42 INS83 INS43 INS59 INS7 MOV14 MOV14 INS45 INS45 INS42 INS42 INS32 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS74 INS1 INS8 INS43 INS43 INS31 INS25 INS42 INS42 INS83 INS43 INS42 INS44 INS43 INS8 INS32 INS8 MOV8 INS42 INS43 INS42 INS42 INS41 INS42 INS21 INS21 INS42 INS32 INS7 INS32 INS42 INS42 INS42 INS42 INS9 INS42 INS42 INS42 INS42 DEL42 DEL7 DEL21 DEL42 DEL7 DEL21