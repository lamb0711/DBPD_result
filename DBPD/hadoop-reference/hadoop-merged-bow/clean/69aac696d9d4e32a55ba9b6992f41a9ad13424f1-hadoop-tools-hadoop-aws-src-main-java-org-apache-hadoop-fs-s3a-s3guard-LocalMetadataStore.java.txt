HADOOP-13649 s3guard: implement time-based (TTL) expiry for LocalMetadataStore (Gabor Bota)

+import com.google.common.cache.Cache;
+import com.google.common.cache.CacheBuilder;
+import org.apache.hadoop.classification.InterfaceStability;
+import java.util.concurrent.TimeUnit;
+ *
+ * Contains cache internally with time based eviction.
-  // TODO HADOOP-13649: use time instead of capacity for eviction.
+  public static final int DEFAULT_CACHE_ENTRY_TTL_MSEC = 10 * 1000;
+  @InterfaceStability.Evolving
+  /**
+   * Time to live in milliseconds.  If zero, time-based expiration is
+   * disabled.
+   */
+  @InterfaceStability.Evolving
+  public static final String CONF_CACHE_ENTRY_TTL =
+      "fs.metadatastore.local.ttl";
+
-  private LruHashMap<Path, PathMetadata> fileHash;
+  private Cache<Path, PathMetadata> fileCache;
-  private LruHashMap<Path, DirListingMetadata> dirHash;
+  private Cache<Path, DirListingMetadata> dirCache;
-    // Start w/ less than max capacity.  Space / time trade off.
-    fileHash = new LruHashMap<>(maxRecords/2, maxRecords);
-    dirHash = new LruHashMap<>(maxRecords/4, maxRecords);
+    int ttl = conf.getInt(CONF_CACHE_ENTRY_TTL, DEFAULT_CACHE_ENTRY_TTL_MSEC);
+
+    CacheBuilder builder = CacheBuilder.newBuilder().maximumSize(maxRecords);
+    if (ttl >= 0) {
+      builder.expireAfterAccess(ttl, TimeUnit.MILLISECONDS);
+    }
+
+    fileCache = builder.build();
+    dirCache = builder.build();
-    deleteHashEntries(path, tombstone);
+    deleteCacheEntries(path, tombstone);
-      deleteHashByAncestor(path, dirHash, tombstone);
-      deleteHashByAncestor(path, fileHash, tombstone);
+      deleteEntryByAncestor(path, dirCache, tombstone);
+      deleteEntryByAncestor(path, fileCache, tombstone);
-      PathMetadata m = fileHash.mruGet(path);
+      PathMetadata m = fileCache.getIfPresent(path);
-    DirListingMetadata dirMeta = dirHash.get(p);
+    DirListingMetadata dirMeta = dirCache.getIfPresent(p);
-    DirListingMetadata listing = dirHash.mruGet(path);
+    DirListingMetadata listing = dirCache.getIfPresent(path);
-      fileHash.put(path, meta);
+      fileCache.put(path, meta);
-       * We also make sure we have an entry in the dirHash, so subsequent
+       * We also make sure we have an entry in the dirCache, so subsequent
-        DirListingMetadata dir = dirHash.mruGet(path);
+        DirListingMetadata dir = dirCache.getIfPresent(path);
-          dirHash.put(path, new DirListingMetadata(path, DirListingMetadata
+          dirCache.put(path, new DirListingMetadata(path, DirListingMetadata
-        DirListingMetadata parent = dirHash.mruGet(parentPath);
+        DirListingMetadata parent = dirCache.getIfPresent(parentPath);
-          dirHash.put(parentPath, parent);
+          dirCache.put(parentPath, parent);
-    dirHash.put(standardize(meta.getPath()), meta);
+    dirCache.put(standardize(meta.getPath()), meta);
-    if (dirHash != null) {
-      dirHash.clear();
+    if (dirCache != null) {
+      dirCache.invalidateAll();
-        fileHash.entrySet().iterator();
+        fileCache.asMap().entrySet().iterator();
-        dirHash.entrySet().iterator();
+        dirCache.asMap().entrySet().iterator();
-        dirHash.put(path, new DirListingMetadata(path, newChildren, false));
+        dirCache.put(path, new DirListingMetadata(path, newChildren, false));
-          DirListingMetadata parent = dirHash.get(path.getParent());
+          DirListingMetadata parent = null;
+          parent = dirCache.getIfPresent(path.getParent());
-  static <T> void deleteHashByAncestor(Path ancestor, Map<Path, T> hash,
+  static <T> void deleteEntryByAncestor(Path ancestor, Cache<Path, T> cache,
-    for (Iterator<Map.Entry<Path, T>> it = hash.entrySet().iterator();
+    for (Iterator<Map.Entry<Path, T>> it = cache.asMap().entrySet().iterator();
-            entry.setValue((T) PathMetadata.tombstone(f));
+            cache.put(f, (T) PathMetadata.tombstone(f));
-            throw new IllegalStateException("Unknown type in hash");
+            throw new IllegalStateException("Unknown type in cache");
-   * Update fileHash and dirHash to reflect deletion of file 'f'.  Call with
+   * Update fileCache and dirCache to reflect deletion of file 'f'.  Call with
-  private void deleteHashEntries(Path path, boolean tombstone) {
+  private void deleteCacheEntries(Path path, boolean tombstone) {
-      fileHash.put(path, PathMetadata.tombstone(path));
+      fileCache.put(path, PathMetadata.tombstone(path));
-      fileHash.remove(path);
+      fileCache.invalidate(path);
-    dirHash.remove(path);
+    dirCache.invalidate(path);
-      DirListingMetadata dir = dirHash.get(parent);
+      DirListingMetadata dir = null;
+      dir = dirCache.getIfPresent(parent);

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS23 INS23 INS83 INS83 INS83 INS39 INS59 INS78 INS29 INS78 INS83 INS83 INS83 INS43 INS59 UPD74 UPD74 UPD42 UPD42 INS66 INS42 INS27 INS40 INS65 INS40 INS42 INS42 INS45 UPD43 MOV43 UPD42 UPD43 MOV43 UPD42 INS60 INS60 INS25 INS21 UPD74 UPD42 INS34 INS34 INS66 INS66 UPD42 UPD42 INS39 INS59 INS43 INS59 INS27 INS8 INS7 MOV43 MOV43 UPD43 UPD66 INS42 INS32 UPD42 MOV42 INS42 INS32 INS42 UPD34 MOV34 INS21 INS42 INS32 UPD42 INS32 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS60 INS21 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS42 INS42 UPD42 UPD42 UPD42 UPD42 MOV43 INS59 INS7 INS42 INS42 INS42 INS42 INS42 INS40 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS32 INS32 UPD42 UPD42 UPD42 MOV42 INS33 INS42 INS32 UPD42 UPD42 MOV43 MOV43 UPD42 MOV42 INS42 UPD42 MOV42 INS42 INS32 UPD42 MOV42 UPD42 MOV42 MOV42 UPD42 INS21 UPD42 MOV42 INS42 UPD42 UPD42 UPD42 UPD42 INS7 UPD42 UPD42 INS33 INS42 MOV32 UPD42 UPD42 UPD42 UPD42 INS42 UPD45 DEL42 DEL43 DEL74 DEL42 DEL27 DEL42 DEL14 DEL7 DEL21 DEL42 DEL43 DEL74 DEL42 DEL34 DEL27 DEL42 DEL14 DEL32 DEL59 DEL60