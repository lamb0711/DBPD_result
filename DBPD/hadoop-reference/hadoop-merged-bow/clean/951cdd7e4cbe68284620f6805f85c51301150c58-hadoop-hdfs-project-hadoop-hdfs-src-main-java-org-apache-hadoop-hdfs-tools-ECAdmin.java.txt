HDFS-14061. Check if the cluster topology supports the EC policy before setting, enabling or adding it. Contributed by Kitti Nanasi.

Signed-off-by: Wei-Chiu Chuang <weichiu@apache.org>

+import org.apache.hadoop.HadoopIllegalArgumentException;
+        ECTopologyVerifierResult result =
+            getECTopologyVerifierResultForPolicy(dfs, ecPolicyName);
+        if (!result.isSupported()) {
+          System.err.println("Warning: The cluster setup does not support " +
+              "EC policy " + ecPolicyName + ". Reason: " +
+              result.getResultMessage());
+        }
-      final ErasureCodingPolicyInfo[] policies =
-          dfs.getClient().getNamenode().getErasureCodingPolicies();
-      final DatanodeInfo[] report = dfs.getClient().getNamenode()
-          .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);
-
-      ECTopologyVerifierResult result = ECTopologyVerifier
-          .getECTopologyVerifierResult(report, policies);
+      ECTopologyVerifierResult result = getECTopologyVerifierResult(dfs);
+  private static ECTopologyVerifierResult getECTopologyVerifierResult(
+      final DistributedFileSystem dfs) throws IOException {
+    final ErasureCodingPolicyInfo[] policies =
+        dfs.getClient().getNamenode().getErasureCodingPolicies();
+    final DatanodeInfo[] report = dfs.getClient().getNamenode()
+        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);
+
+    return ECTopologyVerifier.getECTopologyVerifierResult(report,
+        getEnabledPolicies(policies));
+  }
+
+  private static ECTopologyVerifierResult getECTopologyVerifierResultForPolicy(
+      final DistributedFileSystem dfs, final String policyName)
+      throws IOException {
+    final ErasureCodingPolicy policy =
+        getPolicy(dfs.getClient().getNamenode().getErasureCodingPolicies(),
+            policyName);
+    final DatanodeInfo[] report = dfs.getClient().getNamenode()
+        .getDatanodeReport(HdfsConstants.DatanodeReportType.ALL);
+    return ECTopologyVerifier.getECTopologyVerifierResult(report, policy);
+  }
+
+  private static ErasureCodingPolicy getPolicy(
+      final ErasureCodingPolicyInfo[] policies, final String policyName) {
+    for (ErasureCodingPolicyInfo policy : policies) {
+      if (policyName.equals(policy.getPolicy().getName())) {
+        return policy.getPolicy();
+      }
+    }
+    throw new HadoopIllegalArgumentException("The given erasure coding " +
+        "policy " + policyName + " does not exist.");
+  }
+
+  private static ErasureCodingPolicy[] getEnabledPolicies(
+      final ErasureCodingPolicyInfo[] policies) {
+    return Arrays.asList(policies).stream()
+        .filter(policyInfo -> policyInfo.isEnabled())
+        .map(ErasureCodingPolicyInfo::getPolicy)
+        .toArray(ErasureCodingPolicy[]::new);
+  }
+

INS26 INS40 INS31 INS31 INS31 INS31 INS83 INS83 INS43 INS42 INS44 INS43 INS8 INS83 INS83 INS43 INS42 INS44 INS44 INS43 INS8 INS83 INS83 INS43 INS42 INS44 INS44 INS8 INS83 INS83 INS5 INS42 INS44 INS8 INS42 INS83 INS43 INS42 INS42 MOV60 MOV60 INS41 INS42 INS83 INS43 INS42 INS83 INS43 INS42 INS42 INS60 INS60 INS41 INS42 INS83 INS5 INS42 INS83 INS43 INS42 INS70 INS53 INS43 INS85 INS83 INS5 INS42 INS41 INS42 INS32 INS42 INS42 INS83 INS43 INS59 INS83 INS5 INS59 INS32 INS43 INS85 INS42 INS44 INS42 INS8 INS14 INS42 INS43 INS85 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS43 INS85 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS25 INS43 INS27 INS42 INS32 INS42 INS89 INS60 INS25 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS40 INS42 INS32 INS8 INS42 INS27 INS42 INS45 INS32 INS42 INS90 INS5 INS43 INS59 INS38 INS8 UPD42 INS32 INS42 INS32 INS42 INS42 INS42 INS32 INS41 INS45 INS45 INS32 INS42 INS86 INS42 INS42 INS43 INS85 INS42 INS42 INS32 INS32 INS21 INS32 INS42 INS42 INS42 INS32 INS42 INS32 INS32 INS42 INS59 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS27 INS27 INS42 INS45 INS32 INS45 INS45 INS42 INS42 DEL42 DEL42