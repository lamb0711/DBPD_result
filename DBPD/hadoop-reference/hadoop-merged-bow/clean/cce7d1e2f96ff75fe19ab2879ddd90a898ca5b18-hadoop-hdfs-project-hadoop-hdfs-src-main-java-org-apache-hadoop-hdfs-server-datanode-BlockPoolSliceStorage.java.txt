Merge remote-tracking branch 'origin/trunk' into MR-2841

Conflicts:
	hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java

+import java.util.HashSet;
+import java.util.Set;
+    Set<String> existingStorageDirs = new HashSet<String>();
+    for (int i = 0; i < getNumStorageDirs(); i++) {
+      existingStorageDirs.add(getStorageDir(i).getRoot().getAbsolutePath());
+    }
+
-    this.storageDirs = new ArrayList<StorageDirectory>(dataDirs.size());
+      if (existingStorageDirs.contains(dataDir.getAbsolutePath())) {
+        LOG.info("Storage directory " + dataDir + " has already been used.");
+        it.remove();
+        continue;
+      }
-      doTransition(getStorageDir(idx), nsInfo, startOpt);
+      doTransition(datanode, getStorageDir(idx), nsInfo, startOpt);
+   * Remove storage directories.
+   * @param storageDirs a set of storage directories to be removed.
+   */
+  void removeVolumes(Set<File> storageDirs) {
+    for (Iterator<StorageDirectory> it = this.storageDirs.iterator();
+         it.hasNext(); ) {
+      StorageDirectory sd = it.next();
+      if (storageDirs.contains(sd.getRoot())) {
+        it.remove();
+      }
+    }
+  }
+
+  /**
-  private void doTransition(StorageDirectory sd,
+  private void doTransition(DataNode datanode, StorageDirectory sd,
-    if (startOpt == StartupOption.ROLLBACK) {
+    if (startOpt == StartupOption.ROLLBACK && sd.getPreviousDir().exists()) {
+      // we will already restore everything in the trash by rolling back to
+      // the previous directory, so we must delete the trash to ensure
+      // that it's not restored by BPOfferService.signalRollingUpgrade()
+      if (!FileUtil.fullyDelete(getTrashRootDir(sd))) {
+        throw new IOException("Unable to delete trash directory prior to " +
+            "restoration of previous directory: " + getTrashRootDir(sd));
+      }
-      doUpgrade(sd, nsInfo); // upgrade
+      doUpgrade(datanode, sd, nsInfo); // upgrade
-  void doUpgrade(StorageDirectory bpSd, NamespaceInfo nsInfo) throws IOException {
+  void doUpgrade(DataNode datanode, StorageDirectory bpSd, NamespaceInfo nsInfo)
+      throws IOException {
-        + this.getCTime() + ".\n   new LV = " + nsInfo.getLayoutVersion()
+        + this.getCTime() + ".\n   new LV = " + HdfsConstants.DATANODE_LAYOUT_VERSION
-    linkAllBlocks(bpTmpDir, bpCurDir);
+    linkAllBlocks(datanode, bpTmpDir, bpCurDir);
-  private void linkAllBlocks(File fromDir, File toDir) throws IOException {
+  private void linkAllBlocks(DataNode datanode, File fromDir, File toDir)
+      throws IOException {
-    DataStorage.linkBlocks(new File(fromDir, DataStorage.STORAGE_DIR_FINALIZED), 
+    DataStorage.linkBlocks(datanode, new File(fromDir, DataStorage.STORAGE_DIR_FINALIZED),
-    DataStorage.linkBlocks(new File(fromDir, DataStorage.STORAGE_DIR_RBW), 
+    DataStorage.linkBlocks(datanode, new File(fromDir, DataStorage.STORAGE_DIR_RBW),

INS26 INS26 INS40 INS40 INS31 INS29 INS39 INS42 INS44 INS8 INS44 INS44 INS44 INS60 INS24 INS65 INS65 INS74 INS42 INS24 INS43 INS42 INS43 INS42 INS43 INS42 INS74 INS59 INS58 INS27 INS37 INS8 INS66 INS42 INS66 INS43 INS43 INS58 INS32 INS8 INS42 INS27 INS8 INS42 INS42 INS43 INS43 INS42 INS14 INS39 INS59 INS42 INS32 INS42 MOV21 INS25 INS42 INS42 UPD74 MOV74 INS59 INS42 INS42 INS60 INS25 MOV27 INS32 INS25 MOV21 INS42 INS42 INS42 INS42 INS42 INS74 INS42 INS34 INS42 INS32 INS32 INS8 UPD43 INS42 INS32 INS43 INS59 INS32 INS8 INS32 INS42 INS38 MOV8 INS40 INS43 INS43 UPD42 MOV42 UPD42 MOV42 INS32 INS42 INS42 INS32 INS21 INS21 INS18 INS42 UPD42 MOV22 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS21 INS42 INS42 INS32 INS53 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 INS14 INS32 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS27 INS42 INS42 INS45 INS42 INS45 INS42 INS45 INS45 INS32 INS42 INS42 DEL32 DEL14 DEL7 DEL42 DEL42 DEL32