Merge r1550130 through r1555020 from trunk.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1555021 13f79535-47bb-0310-9956-ffa450edef68

-  /** Get a datanode descriptor given corresponding storageID */
-  DatanodeDescriptor getDatanode(final String storageID) {
-    return datanodeMap.get(storageID);
+  /** Get a datanode descriptor given corresponding DatanodeUUID */
+  DatanodeDescriptor getDatanode(final String datanodeUuid) {
+    if (datanodeUuid == null) {
+      return null;
+    }
+
+    return datanodeMap.get(datanodeUuid);
-    final DatanodeDescriptor node = getDatanode(nodeID.getStorageID());
+    final DatanodeDescriptor node = getDatanode(nodeID.getDatanodeUuid());
+  public DatanodeStorageInfo[] getDatanodeStorageInfos(
+      DatanodeID[] datanodeID, String[] storageIDs)
+          throws UnregisteredNodeException {
+    if (datanodeID.length == 0) {
+      return null;
+    }
+    final DatanodeStorageInfo[] storages = new DatanodeStorageInfo[datanodeID.length];
+    for(int i = 0; i < datanodeID.length; i++) {
+      final DatanodeDescriptor dd = getDatanode(datanodeID[i]);
+      storages[i] = dd.getStorageInfo(storageIDs[i]);
+    }
+    return storages; 
+  }
+
-      host2DatanodeMap.remove(datanodeMap.put(node.getStorageID(), node));
+      host2DatanodeMap.remove(datanodeMap.put(node.getDatanodeUuid(), node));
-    final String key = node.getStorageID();
+    final String key = node.getDatanodeUuid();
-      LOG.info("Start Decommissioning " + node + " with " + 
-          node.numBlocks() +  " blocks");
+      for (DatanodeStorageInfo storage : node.getStorageInfos()) {
+        LOG.info("Start Decommissioning " + node + " " + storage
+            + " with " + storage.numBlocks() + " blocks");
+      }
-   * Generate new storage ID.
-   * 
-   * @return unique storage ID
-   * 
-   * Note: that collisions are still possible if somebody will try 
-   * to bring in a data storage from a different cluster.
-   */
-  private String newStorageID() {
-    String newID = null;
-    while(newID == null) {
-      newID = "DS" + Integer.toString(DFSUtil.getRandom().nextInt());
-      if (datanodeMap.get(newID) != null)
-        newID = null;
-    }
-    return newID;
-  }
-
-  /**
-          + nodeReg + " storage " + nodeReg.getStorageID());
+          + nodeReg + " storage " + nodeReg.getDatanodeUuid());
-      DatanodeDescriptor nodeS = datanodeMap.get(nodeReg.getStorageID());
+      DatanodeDescriptor nodeS = getDatanode(nodeReg.getDatanodeUuid());
-              + nodeReg.getStorageID());
+              + nodeReg.getDatanodeUuid());
-      } 
-  
-      // this is a new datanode serving a new data storage
-      if ("".equals(nodeReg.getStorageID())) {
-        // this data storage has never been registered
-        // it is either empty or was created by pre-storageID version of DFS
-        nodeReg.setStorageID(newStorageID());
-        if (NameNode.stateChangeLog.isDebugEnabled()) {
-          NameNode.stateChangeLog.debug(
-              "BLOCK* NameSystem.registerDatanode: "
-              + "new storageID " + nodeReg.getStorageID() + " assigned.");
-        }
-      
+
-      final String blockPoolId,
-      long capacity, long dfsUsed, long remaining, long blockPoolUsed,
-      long cacheCapacity, long cacheUsed, int xceiverCount, int maxTransfers,
-      int failedVolumes) throws IOException {
+      StorageReport[] reports, final String blockPoolId,
+      long cacheCapacity, long cacheUsed, int xceiverCount, 
+      int maxTransfers, int failedVolumes
+      ) throws IOException {
-        heartbeatManager.updateHeartbeat(nodeinfo, capacity, dfsUsed,
-            remaining, blockPoolUsed, cacheCapacity, cacheUsed, xceiverCount,
-            failedVolumes);
+        heartbeatManager.updateHeartbeat(nodeinfo, reports,
+                                         cacheCapacity, cacheUsed,
+                                         xceiverCount, failedVolumes);
-            DatanodeDescriptor[] expectedLocations = b.getExpectedLocations();
+            final DatanodeStorageInfo[] storages = b.getExpectedStorageLocations();
-            List<DatanodeDescriptor> recoveryLocations =
-                new ArrayList<DatanodeDescriptor>(expectedLocations.length);
-            for (int i = 0; i < expectedLocations.length; i++) {
-              if (!expectedLocations[i].isStale(this.staleInterval)) {
-                recoveryLocations.add(expectedLocations[i]);
+            final List<DatanodeStorageInfo> recoveryLocations =
+                new ArrayList<DatanodeStorageInfo>(storages.length);
+            for (int i = 0; i < storages.length; i++) {
+              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {
+                recoveryLocations.add(storages[i]);
-              if (recoveryLocations.size() != expectedLocations.length) {
+              if (recoveryLocations.size() != storages.length) {
-                    (expectedLocations.length - recoveryLocations.size()));
+                    (storages.length - recoveryLocations.size()));
-                  recoveryLocations.toArray(new DatanodeDescriptor[recoveryLocations.size()]),
+                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations),
-                  expectedLocations,
+                  DatanodeStorageInfo.toDatanodeInfos(storages),
-        dn.markStaleAfterFailover();
+        for(DatanodeStorageInfo storage : dn.getStorageInfos()) {
+          storage.markStaleAfterFailover();
+        }
+  public void clearPendingCachingCommands() {
+    for (DatanodeDescriptor dn : datanodeMap.values()) {
+      dn.getPendingCached().clear();
+      dn.getPendingUncached().clear();
+    }
+  }
+
+

INS31 INS31 UPD83 MOV83 INS5 INS42 INS44 INS44 INS43 INS8 INS44 INS83 INS39 INS42 INS8 UPD42 INS25 INS43 INS85 INS5 INS42 INS5 INS42 INS42 INS25 MOV60 INS24 INS41 INS5 UPD42 MOV42 INS70 UPD66 INS27 INS8 UPD42 MOV42 INS43 INS85 MOV43 INS85 INS27 INS8 INS83 INS5 INS58 INS27 INS37 INS8 INS42 INS43 INS85 INS8 INS44 INS32 INS8 INS42 INS33 INS41 UPD42 INS42 INS40 INS34 INS41 INS43 INS85 UPD42 INS3 INS39 INS59 UPD42 MOV42 INS40 INS42 INS60 MOV21 INS70 INS42 INS70 INS43 INS42 MOV42 UPD42 MOV42 INS21 INS21 INS33 INS33 INS42 INS5 INS40 INS42 INS34 INS83 MOV43 INS59 UPD42 INS44 INS32 INS8 MOV44 MOV32 INS8 INS42 INS32 INS32 UPD42 INS43 INS85 INS42 INS32 INS2 INS32 INS43 INS42 INS42 INS42 MOV21 MOV70 INS32 INS42 INS32 INS42 INS42 INS42 INS2 INS42 INS42 UPD42 MOV42 UPD42 MOV42 INS2 INS42 UPD42 INS44 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 UPD42 UPD42 UPD42 INS43 INS42 INS42 INS42 INS45 INS42 INS42 UPD42 UPD42 INS83 UPD5 INS83 UPD74 UPD42 UPD43 UPD42 INS43 UPD40 UPD42 UPD42 INS42 UPD74 UPD40 UPD43 UPD40 UPD42 INS32 INS42 INS32 MOV2 INS42 UPD42 INS42 MOV42 INS42 INS42 INS42 UPD42 UPD42 UPD40 DEL33 DEL42 DEL45 DEL42 DEL42 DEL32 DEL42 DEL32 DEL32 DEL27 DEL66 DEL65 DEL66 DEL66 DEL66 DEL65 DEL29 DEL43 DEL42 DEL33 DEL27 DEL42 DEL32 DEL33 DEL27 DEL42 DEL33 DEL7 DEL21 DEL25 DEL8 DEL61 DEL42 DEL41 DEL8 DEL31 DEL42 DEL45 DEL42 DEL42 DEL42 DEL32 DEL32 DEL42 DEL42 DEL42 DEL32 DEL32 DEL21 DEL40 DEL42 DEL32 DEL40 DEL42 DEL45 DEL45 DEL27 DEL42 DEL42 DEL32 DEL45 DEL27 DEL32 DEL21 DEL8 DEL25 DEL8 DEL25 DEL39 DEL42 DEL44 DEL39 DEL42 DEL44 DEL39 DEL44 DEL39 DEL42 DEL44 DEL42 DEL42 DEL42 DEL52 DEL42 DEL22 DEL42 DEL42 DEL43 DEL85 DEL5 DEL42 DEL32 DEL3 DEL42 DEL8