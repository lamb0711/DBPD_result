HDFS-8008. Support client-side back off when the datanodes are congested. Contributed by Haohui Mai.

+  // List of congested data nodes. The stream will back off if the DataNodes
+  // are congested
+  private final ArrayList<DatanodeInfo> congestedNodes = new ArrayList<>();
+  private static final int CONGESTION_BACKOFF_MEAN_TIME_IN_MS = 5000;
+  private static final int CONGESTION_BACK_OFF_MAX_TIME_IN_MS =
+      CONGESTION_BACKOFF_MEAN_TIME_IN_MS * 10;
+  private int lastCongestionBackoffTime;
+            try {
+              backOffIfNecessary();
+            } catch (InterruptedException e) {
+              DFSClient.LOG.warn("Caught exception ", e);
+            }
+          ArrayList<DatanodeInfo> congestedNodesFromAck = new ArrayList<>();
+            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) ==
+                PipelineAck.ECN.CONGESTED) {
+              congestedNodesFromAck.add(targets[i]);
+            }
+          if (!congestedNodesFromAck.isEmpty()) {
+            synchronized (congestedNodes) {
+              congestedNodes.clear();
+              congestedNodes.addAll(congestedNodesFromAck);
+            }
+          } else {
+            synchronized (congestedNodes) {
+              congestedNodes.clear();
+              lastCongestionBackoffTime = 0;
+            }
+          }
+
+   * This function sleeps for a certain amount of time when the writing
+   * pipeline is congested. The function calculates the time based on a
+   * decorrelated filter.
+   *
+   * @see
+   * <a href="http://www.awsarchitectureblog.com/2015/03/backoff.html">
+   *   http://www.awsarchitectureblog.com/2015/03/backoff.html</a>
+   */
+  private void backOffIfNecessary() throws InterruptedException {
+    int t = 0;
+    synchronized (congestedNodes) {
+      if (!congestedNodes.isEmpty()) {
+        StringBuilder sb = new StringBuilder("DataNode");
+        for (DatanodeInfo i : congestedNodes) {
+          sb.append(' ').append(i);
+        }
+        int range = Math.abs(lastCongestionBackoffTime * 3 -
+                                CONGESTION_BACKOFF_MEAN_TIME_IN_MS);
+        int base = Math.min(lastCongestionBackoffTime * 3,
+                            CONGESTION_BACKOFF_MEAN_TIME_IN_MS);
+        t = Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,
+                     (int)(base + Math.random() * range));
+        lastCongestionBackoffTime = t;
+        sb.append(" are congested. Backing off for ").append(t).append(" ms");
+        DFSClient.LOG.info(sb.toString());
+        congestedNodes.clear();
+      }
+    }
+    if (t != 0) {
+      Thread.sleep(t);
+    }
+  }
+
+  /**

INS23 INS23 INS23 INS23 INS31 INS83 INS83 INS74 INS59 INS83 INS83 INS83 INS39 INS59 INS83 INS83 INS83 INS39 INS59 INS83 INS39 INS59 INS29 INS83 INS39 INS42 INS43 INS8 INS43 INS43 INS42 INS14 INS42 INS34 INS42 INS27 INS42 INS65 INS65 INS42 INS60 INS51 INS25 INS42 INS42 INS74 INS42 INS34 INS66 INS66 INS66 INS66 INS39 INS59 INS42 INS8 INS27 INS8 INS43 INS42 INS34 INS25 INS42 INS34 INS21 INS42 INS38 INS8 INS32 INS32 INS60 INS70 INS60 INS60 INS21 INS21 INS21 INS21 INS21 INS42 INS42 INS42 INS60 INS25 INS42 INS42 INS43 INS59 INS44 INS42 INS8 INS39 INS59 INS39 INS59 INS7 INS7 INS32 INS32 INS32 INS74 INS59 INS38 INS8 INS8 INS42 INS42 INS14 INS43 INS42 INS21 INS42 INS32 INS42 INS32 INS42 INS32 INS42 INS42 INS32 INS42 INS45 INS40 INS42 INS32 INS42 INS42 INS43 INS43 INS42 INS14 INS25 INS32 INS51 INS51 INS43 INS45 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS11 INS32 INS42 INS42 INS42 INS42 INS54 INS42 INS42 INS74 INS27 INS8 INS42 INS42 INS42 INS8 INS42 INS8 INS42 INS32 INS42 INS42 INS27 INS42 INS42 INS34 INS39 INS36 INS42 INS42 INS45 INS8 INS12 INS43 INS32 INS40 INS21 INS21 INS21 INS21 INS21 INS42 INS42 INS13 INS42 INS34 INS27 INS21 INS44 INS8 INS42 INS42 INS42 INS32 INS32 INS32 INS32 INS32 INS7 INS42 INS27 INS32 INS43 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS2 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS40 INS42 INS45 INS42