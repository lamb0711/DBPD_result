Merge trunk to HDFS-4685.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1550774 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.Map;
+import org.apache.hadoop.hdfs.server.protocol.DatanodeStorage;
+  // Changing this value may break some tests that assume it is 2.
+  public static final int DIRS_PER_DATANODE = 2;
+
-    LOG.info("starting cluster with " + 
-        builder.nnTopology.countNameNodes() + " namenodes.");
-    nameNodes = new NameNodeInfo[builder.nnTopology.countNameNodes()];
+    final int numNameNodes = builder.nnTopology.countNameNodes();
+    LOG.info("starting cluster: numNameNodes=" + numNameNodes
+        + ", numDataNodes=" + builder.numDataNodes);
+    nameNodes = new NameNodeInfo[numNameNodes];
-        File dir1 = getInstanceStorageDir(i, 0);
-        File dir2 = getInstanceStorageDir(i, 1);
-        dir1.mkdirs();
-        dir2.mkdirs();
-        if (!dir1.isDirectory() || !dir2.isDirectory()) { 
-          throw new IOException("Mkdirs failed to create directory for DataNode "
-                                + i + ": " + dir1 + " or " + dir2);
+        StringBuilder sb = new StringBuilder();
+        for (int j = 0; j < DIRS_PER_DATANODE; ++j) {
+          File dir = getInstanceStorageDir(i, j);
+          dir.mkdirs();
+          if (!dir.isDirectory()) {
+            throw new IOException("Mkdirs failed to create directory for DataNode " + dir);
+          }
+          sb.append((j > 0 ? "," : "") + fileAsURI(dir));
-        String dirs = fileAsURI(dir1) + "," + fileAsURI(dir2);
+        String dirs = sb.toString();
-      restartNameNode(i);
+      restartNameNode(i, false);
+    waitActive();
+      LOG.info("dnInfo.length != numDataNodes");
+        LOG.info("!dn.datanode.isDatanodeFullyStarted()");
+        LOG.info("dn.getCapacity() == 0");
+        LOG.info("DataNodeTestUtils.getFSDataset(dn.datanode) == null");
-  public Iterable<Block> getBlockReport(String bpid, int dataNodeIndex) {
+  public Map<DatanodeStorage, BlockListAsLongs> getBlockReport(String bpid, int dataNodeIndex) {
-    return DataNodeTestUtils.getFSDataset(dn).getBlockReport(bpid);
+    return DataNodeTestUtils.getFSDataset(dn).getBlockReports(bpid);
-  public Iterable<Block>[] getAllBlockReports(String bpid) {
+  public List<Map<DatanodeStorage, BlockListAsLongs>> getAllBlockReports(String bpid) {
-    Iterable<Block>[] result = new BlockListAsLongs[numDataNodes];
+    final List<Map<DatanodeStorage, BlockListAsLongs>> result
+        = new ArrayList<Map<DatanodeStorage, BlockListAsLongs>>(numDataNodes);
-     result[i] = getBlockReport(bpid, i);
+      result.add(getBlockReport(bpid, i));

INS26 INS26 INS40 INS40 INS23 INS83 INS83 INS83 INS39 INS59 UPD74 INS74 INS42 INS34 INS60 INS21 INS43 UPD43 UPD43 INS43 INS74 INS83 INS39 INS59 INS32 INS42 UPD42 UPD42 INS42 INS43 UPD43 MOV43 UPD43 MOV43 INS83 INS74 INS42 MOV32 INS42 INS21 MOV41 UPD42 INS42 UPD42 UPD42 INS43 INS74 INS14 UPD45 INS42 UPD45 INS40 INS42 INS32 INS42 INS43 UPD43 MOV43 UPD43 MOV43 INS74 INS42 INS32 INS60 INS24 INS60 INS9 INS42 INS42 INS45 INS21 MOV41 INS21 MOV41 INS21 MOV41 INS42 UPD42 UPD42 INS43 INS74 INS42 INS42 MOV32 UPD43 MOV43 INS59 INS58 INS27 INS38 INS8 MOV43 INS59 INS32 INS32 INS32 INS42 INS43 INS43 INS43 UPD42 UPD42 MOV42 INS14 INS39 INS59 INS42 INS42 INS42 MOV60 MOV21 MOV25 INS21 INS42 INS32 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 INS45 INS42 INS42 MOV42 INS43 INS42 INS34 INS38 INS32 INS42 INS42 INS42 UPD42 UPD42 MOV32 INS42 INS42 INS27 INS42 UPD42 INS36 MOV32 INS16 UPD42 UPD42 INS27 INS45 INS45 INS42 INS34 DEL40 DEL42 DEL32 DEL34 DEL38 DEL42 DEL42 DEL32 DEL38 DEL27 DEL42 DEL45 DEL45 DEL42 DEL42 DEL42 DEL34 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL32 DEL45 DEL27 DEL59 DEL60 DEL74 DEL85 DEL5 DEL74 DEL85 DEL5 DEL85 DEL5 DEL42 DEL3 DEL42 DEL42 DEL2 DEL7