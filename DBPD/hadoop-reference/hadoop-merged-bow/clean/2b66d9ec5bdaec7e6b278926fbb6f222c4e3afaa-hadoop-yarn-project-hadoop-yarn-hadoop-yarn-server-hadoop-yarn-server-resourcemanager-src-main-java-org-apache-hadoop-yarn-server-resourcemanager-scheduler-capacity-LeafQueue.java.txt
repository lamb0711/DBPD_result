YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan

+import java.util.concurrent.ConcurrentHashMap;
-  private int userLimit;
-  private float userLimitFactor;
+  private volatile int userLimit;
+  private volatile float userLimitFactor;
-  protected int maxApplicationsPerUser;
+  protected volatile int maxApplicationsPerUser;
-      new HashMap<ApplicationAttemptId, FiCaSchedulerApp>();
+      new ConcurrentHashMap<>();
-  private OrderingPolicy<FiCaSchedulerApp> pendingOrderingPolicy = null;
+  private final OrderingPolicy<FiCaSchedulerApp> pendingOrderingPolicy;
-  private Map<String, User> users = new HashMap<String, User>();
+  private Map<String, User> users = new ConcurrentHashMap<>();
-  private OrderingPolicy<FiCaSchedulerApp> orderingPolicy = null;
+  private volatile OrderingPolicy<FiCaSchedulerApp> orderingPolicy = null;
-      new HashMap<>();
+      new ConcurrentHashMap<>();
-  protected synchronized void setupQueueConfigs(Resource clusterResource)
+  protected void setupQueueConfigs(Resource clusterResource)
-    super.setupQueueConfigs(clusterResource);
-    
-    this.lastClusterResource = clusterResource;
-    
-    this.cachedResourceLimitsForHeadroom = new ResourceLimits(clusterResource);
-    
-    // Initialize headroom info, also used for calculating application 
-    // master resource limits.  Since this happens during queue initialization
-    // and all queues may not be realized yet, we'll use (optimistic) 
-    // absoluteMaxCapacity (it will be replaced with the more accurate 
-    // absoluteMaxAvailCapacity during headroom/userlimit/allocation events)
-    setQueueResourceLimitsInfo(clusterResource);
+    try {
+      writeLock.lock();
+      super.setupQueueConfigs(clusterResource);
-    CapacitySchedulerConfiguration conf = csContext.getConfiguration();
+      this.lastClusterResource = clusterResource;
-    setOrderingPolicy(conf.<FiCaSchedulerApp>getOrderingPolicy(getQueuePath()));
+      this.cachedResourceLimitsForHeadroom = new ResourceLimits(
+          clusterResource);
-    userLimit = conf.getUserLimit(getQueuePath());
-    userLimitFactor = conf.getUserLimitFactor(getQueuePath());
+      // Initialize headroom info, also used for calculating application
+      // master resource limits.  Since this happens during queue initialization
+      // and all queues may not be realized yet, we'll use (optimistic)
+      // absoluteMaxCapacity (it will be replaced with the more accurate
+      // absoluteMaxAvailCapacity during headroom/userlimit/allocation events)
+      setQueueResourceLimitsInfo(clusterResource);
-    maxApplications = conf.getMaximumApplicationsPerQueue(getQueuePath());
-    if (maxApplications < 0) {
-      int maxSystemApps = conf.getMaximumSystemApplications();
-      maxApplications =
-          (int) (maxSystemApps * queueCapacities.getAbsoluteCapacity());
-    }
-    maxApplicationsPerUser = Math.min(maxApplications,
-        (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor));
-    
-    maxAMResourcePerQueuePercent =
-        conf.getMaximumApplicationMasterResourcePerQueuePercent(getQueuePath());
+      CapacitySchedulerConfiguration conf = csContext.getConfiguration();
-    if (!SchedulerUtils.checkQueueLabelExpression(
-        this.accessibleLabels, this.defaultLabelExpression, null)) {
-      throw new IOException("Invalid default label expression of "
-          + " queue="
-          + getQueueName()
-          + " doesn't have permission to access all labels "
-          + "in default label expression. labelExpression of resource request="
-          + (this.defaultLabelExpression == null ? ""
-              : this.defaultLabelExpression)
-          + ". Queue labels="
-          + (getAccessibleNodeLabels() == null ? "" : StringUtils.join(
-              getAccessibleNodeLabels().iterator(), ',')));
-    }
-    
-    nodeLocalityDelay = conf.getNodeLocalityDelay();
-    rackLocalityFullReset = conf.getRackLocalityFullReset();
+      setOrderingPolicy(
+          conf.<FiCaSchedulerApp>getOrderingPolicy(getQueuePath()));
-    // re-init this since max allocation could have changed
-    this.minimumAllocationFactor =
-        Resources.ratio(resourceCalculator,
-            Resources.subtract(maximumAllocation, minimumAllocation),
-            maximumAllocation);
+      userLimit = conf.getUserLimit(getQueuePath());
+      userLimitFactor = conf.getUserLimitFactor(getQueuePath());
-    StringBuilder aclsString = new StringBuilder();
-    for (Map.Entry<AccessType, AccessControlList> e : acls.entrySet()) {
-      aclsString.append(e.getKey() + ":" + e.getValue().getAclString());
-    }
-
-    StringBuilder labelStrBuilder = new StringBuilder(); 
-    if (accessibleLabels != null) {
-      for (String s : accessibleLabels) {
-        labelStrBuilder.append(s);
-        labelStrBuilder.append(",");
+      maxApplications = conf.getMaximumApplicationsPerQueue(getQueuePath());
+      if (maxApplications < 0) {
+        int maxSystemApps = conf.getMaximumSystemApplications();
+        maxApplications =
+            (int) (maxSystemApps * queueCapacities.getAbsoluteCapacity());
+      maxApplicationsPerUser = Math.min(maxApplications,
+          (int) (maxApplications * (userLimit / 100.0f) * userLimitFactor));
+
+      maxAMResourcePerQueuePercent =
+          conf.getMaximumApplicationMasterResourcePerQueuePercent(
+              getQueuePath());
+
+      if (!SchedulerUtils.checkQueueLabelExpression(this.accessibleLabels,
+          this.defaultLabelExpression, null)) {
+        throw new IOException(
+            "Invalid default label expression of " + " queue=" + getQueueName()
+                + " doesn't have permission to access all labels "
+                + "in default label expression. labelExpression of resource request="
+                + (this.defaultLabelExpression == null ?
+                "" :
+                this.defaultLabelExpression) + ". Queue labels=" + (
+                getAccessibleNodeLabels() == null ?
+                    "" :
+                    StringUtils
+                        .join(getAccessibleNodeLabels().iterator(), ',')));
+      }
+
+      nodeLocalityDelay = conf.getNodeLocalityDelay();
+      rackLocalityFullReset = conf.getRackLocalityFullReset();
+
+      // re-init this since max allocation could have changed
+      this.minimumAllocationFactor = Resources.ratio(resourceCalculator,
+          Resources.subtract(maximumAllocation, minimumAllocation),
+          maximumAllocation);
+
+      StringBuilder aclsString = new StringBuilder();
+      for (Map.Entry<AccessType, AccessControlList> e : acls.entrySet()) {
+        aclsString.append(e.getKey() + ":" + e.getValue().getAclString());
+      }
+
+      StringBuilder labelStrBuilder = new StringBuilder();
+      if (accessibleLabels != null) {
+        for (String s : accessibleLabels) {
+          labelStrBuilder.append(s);
+          labelStrBuilder.append(",");
+        }
+      }
+
+      defaultAppPriorityPerQueue = Priority.newInstance(
+          conf.getDefaultApplicationPriorityConfPerQueue(getQueuePath()));
+
+      LOG.info(
+          "Initializing " + queueName + "\n" + "capacity = " + queueCapacities
+              .getCapacity() + " [= (float) configuredCapacity / 100 ]" + "\n"
+              + "absoluteCapacity = " + queueCapacities.getAbsoluteCapacity()
+              + " [= parentAbsoluteCapacity * capacity ]" + "\n"
+              + "maxCapacity = " + queueCapacities.getMaximumCapacity()
+              + " [= configuredMaxCapacity ]" + "\n" + "absoluteMaxCapacity = "
+              + queueCapacities.getAbsoluteMaximumCapacity()
+              + " [= 1.0 maximumCapacity undefined, "
+              + "(parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]"
+              + "\n" + "userLimit = " + userLimit + " [= configuredUserLimit ]"
+              + "\n" + "userLimitFactor = " + userLimitFactor
+              + " [= configuredUserLimitFactor ]" + "\n" + "maxApplications = "
+              + maxApplications
+              + " [= configuredMaximumSystemApplicationsPerQueue or"
+              + " (int)(configuredMaximumSystemApplications * absoluteCapacity)]"
+              + "\n" + "maxApplicationsPerUser = " + maxApplicationsPerUser
+              + " [= (int)(maxApplications * (userLimit / 100.0f) * "
+              + "userLimitFactor) ]" + "\n" + "usedCapacity = "
+              + queueCapacities.getUsedCapacity() + " [= usedResourcesMemory / "
+              + "(clusterResourceMemory * absoluteCapacity)]" + "\n"
+              + "absoluteUsedCapacity = " + absoluteUsedCapacity
+              + " [= usedResourcesMemory / clusterResourceMemory]" + "\n"
+              + "maxAMResourcePerQueuePercent = " + maxAMResourcePerQueuePercent
+              + " [= configuredMaximumAMResourcePercent ]" + "\n"
+              + "minimumAllocationFactor = " + minimumAllocationFactor
+              + " [= (float)(maximumAllocationMemory - minimumAllocationMemory) / "
+              + "maximumAllocationMemory ]" + "\n" + "maximumAllocation = "
+              + maximumAllocation + " [= configuredMaxAllocation ]" + "\n"
+              + "numContainers = " + numContainers
+              + " [= currentNumContainers ]" + "\n" + "state = " + state
+              + " [= configuredState ]" + "\n" + "acls = " + aclsString
+              + " [= configuredAcls ]" + "\n" + "nodeLocalityDelay = "
+              + nodeLocalityDelay + "\n" + "labels=" + labelStrBuilder
+              .toString() + "\n" + "reservationsContinueLooking = "
+              + reservationsContinueLooking + "\n" + "preemptionDisabled = "
+              + getPreemptionDisabled() + "\n" + "defaultAppPriorityPerQueue = "
+              + defaultAppPriorityPerQueue);
+    } finally {
+      writeLock.unlock();
-
-    defaultAppPriorityPerQueue = Priority.newInstance(conf
-        .getDefaultApplicationPriorityConfPerQueue(getQueuePath()));
-
-    LOG.info("Initializing " + queueName + "\n" +
-        "capacity = " + queueCapacities.getCapacity() +
-        " [= (float) configuredCapacity / 100 ]" + "\n" + 
-        "absoluteCapacity = " + queueCapacities.getAbsoluteCapacity() +
-        " [= parentAbsoluteCapacity * capacity ]" + "\n" +
-        "maxCapacity = " + queueCapacities.getMaximumCapacity() +
-        " [= configuredMaxCapacity ]" + "\n" +
-        "absoluteMaxCapacity = " + queueCapacities.getAbsoluteMaximumCapacity() +
-        " [= 1.0 maximumCapacity undefined, " +
-        "(parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]" + 
-        "\n" +
-        "userLimit = " + userLimit +
-        " [= configuredUserLimit ]" + "\n" +
-        "userLimitFactor = " + userLimitFactor +
-        " [= configuredUserLimitFactor ]" + "\n" +
-        "maxApplications = " + maxApplications +
-        " [= configuredMaximumSystemApplicationsPerQueue or" + 
-        " (int)(configuredMaximumSystemApplications * absoluteCapacity)]" + 
-        "\n" +
-        "maxApplicationsPerUser = " + maxApplicationsPerUser +
-        " [= (int)(maxApplications * (userLimit / 100.0f) * " +
-        "userLimitFactor) ]" + "\n" +
-        "usedCapacity = " + queueCapacities.getUsedCapacity() +
-        " [= usedResourcesMemory / " +
-        "(clusterResourceMemory * absoluteCapacity)]" + "\n" +
-        "absoluteUsedCapacity = " + absoluteUsedCapacity +
-        " [= usedResourcesMemory / clusterResourceMemory]" + "\n" +
-        "maxAMResourcePerQueuePercent = " + maxAMResourcePerQueuePercent +
-        " [= configuredMaximumAMResourcePercent ]" + "\n" +
-        "minimumAllocationFactor = " + minimumAllocationFactor +
-        " [= (float)(maximumAllocationMemory - minimumAllocationMemory) / " +
-        "maximumAllocationMemory ]" + "\n" +
-        "maximumAllocation = " + maximumAllocation +
-        " [= configuredMaxAllocation ]" + "\n" +
-        "numContainers = " + numContainers +
-        " [= currentNumContainers ]" + "\n" +
-        "state = " + state +
-        " [= configuredState ]" + "\n" +
-        "acls = " + aclsString +
-        " [= configuredAcls ]" + "\n" + 
-        "nodeLocalityDelay = " + nodeLocalityDelay + "\n" +
-        "labels=" + labelStrBuilder.toString() + "\n" +
-        "reservationsContinueLooking = " +
-        reservationsContinueLooking + "\n" +
-        "preemptionDisabled = " + getPreemptionDisabled() + "\n" +
-        "defaultAppPriorityPerQueue = " + defaultAppPriorityPerQueue);
-  public synchronized int getMaxApplicationsPerUser() {
+  public int getMaxApplicationsPerUser() {
-  synchronized void setUserLimit(int userLimit) {
+  @VisibleForTesting
+  void setUserLimit(int userLimit) {
-  synchronized void setUserLimitFactor(float userLimitFactor) {
+  @VisibleForTesting
+  void setUserLimitFactor(float userLimitFactor) {
-  public synchronized int getNumApplications() {
-    return getNumPendingApplications() + getNumActiveApplications();
+  public int getNumApplications() {
+    try {
+      readLock.lock();
+      return getNumPendingApplications() + getNumActiveApplications();
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized int getNumPendingApplications() {
-    return pendingOrderingPolicy.getNumSchedulableEntities();
+  public int getNumPendingApplications() {
+    try {
+      readLock.lock();
+      return pendingOrderingPolicy.getNumSchedulableEntities();
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized int getNumActiveApplications() {
-    return orderingPolicy.getNumSchedulableEntities();
+  public int getNumActiveApplications() {
+    try {
+      readLock.lock();
+      return orderingPolicy.getNumSchedulableEntities();
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized int getNumApplications(String user) {
-    return getUser(user).getTotalApplications();
+  public int getNumPendingApplications(String user) {
+    try {
+      readLock.lock();
+      User u = getUser(user);
+      if (null == u) {
+        return 0;
+      }
+      return u.getPendingApplications();
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized int getNumPendingApplications(String user) {
-    return getUser(user).getPendingApplications();
+  public int getNumActiveApplications(String user) {
+    try {
+      readLock.lock();
+      User u = getUser(user);
+      if (null == u) {
+        return 0;
+      }
+      return u.getActiveApplications();
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized int getNumActiveApplications(String user) {
-    return getUser(user).getActiveApplications();
-  }
-
-  @Override
-  public synchronized QueueState getState() {
-    return state;
-  }
-
-  @Private
-  public synchronized int getUserLimit() {
+  public int getUserLimit() {
-  public synchronized float getUserLimitFactor() {
+  public float getUserLimitFactor() {
-  public synchronized List<QueueUserACLInfo> 
+  public List<QueueUserACLInfo>
-    QueueUserACLInfo userAclInfo = 
-      recordFactory.newRecordInstance(QueueUserACLInfo.class);
-    List<QueueACL> operations = new ArrayList<QueueACL>();
-    for (QueueACL operation : QueueACL.values()) {
-      if (hasAccess(operation, user)) {
-        operations.add(operation);
+    try {
+      readLock.lock();
+      QueueUserACLInfo userAclInfo = recordFactory.newRecordInstance(
+          QueueUserACLInfo.class);
+      List<QueueACL> operations = new ArrayList<>();
+      for (QueueACL operation : QueueACL.values()) {
+        if (hasAccess(operation, user)) {
+          operations.add(operation);
+        }
+
+      userAclInfo.setQueueName(getQueueName());
+      userAclInfo.setUserAcls(operations);
+      return Collections.singletonList(userAclInfo);
+    } finally {
+      readLock.unlock();
-    userAclInfo.setQueueName(getQueueName());
-    userAclInfo.setUserAcls(operations);
-    return Collections.singletonList(userAclInfo);
-    return queueName + ": " + 
-        "capacity=" + queueCapacities.getCapacity() + ", " + 
-        "absoluteCapacity=" + queueCapacities.getAbsoluteCapacity() + ", " + 
-        "usedResources=" + queueUsage.getUsed() +  ", " +
-        "usedCapacity=" + getUsedCapacity() + ", " + 
-        "absoluteUsedCapacity=" + getAbsoluteUsedCapacity() + ", " +
-        "numApps=" + getNumApplications() + ", " + 
-        "numContainers=" + getNumContainers();  
-  }
-  
-  @VisibleForTesting
-  public synchronized void setNodeLabelManager(RMNodeLabelsManager mgr) {
-    this.labelManager = mgr;
+    try {
+      readLock.lock();
+      return queueName + ": " + "capacity=" + queueCapacities.getCapacity()
+          + ", " + "absoluteCapacity=" + queueCapacities.getAbsoluteCapacity()
+          + ", " + "usedResources=" + queueUsage.getUsed() + ", "
+          + "usedCapacity=" + getUsedCapacity() + ", " + "absoluteUsedCapacity="
+          + getAbsoluteUsedCapacity() + ", " + "numApps=" + getNumApplications()
+          + ", " + "numContainers=" + getNumContainers();
+    } finally {
+      readLock.unlock();
+    }
+
-  public synchronized User getUser(String userName) {
-    User user = users.get(userName);
-    if (user == null) {
-      user = new User();
-      users.put(userName, user);
+  public User getUser(String userName) {
+    return users.get(userName);
+  }
+
+  // Get and add user if absent
+  private User getUserAndAddIfAbsent(String userName) {
+    try {
+      writeLock.lock();
+      User u = users.get(userName);
+      if (null == u) {
+        u = new User();
+        users.put(userName, u);
+      }
+      return u;
+    } finally {
+      writeLock.unlock();
-    return user;
-  public synchronized ArrayList<UserInfo> getUsers() {
-    ArrayList<UserInfo> usersToReturn = new ArrayList<UserInfo>();
-    for (Map.Entry<String, User> entry : users.entrySet()) {
-      User user = entry.getValue();
-      usersToReturn.add(new UserInfo(entry.getKey(), Resources.clone(user
-          .getAllUsed()), user.getActiveApplications(), user
-          .getPendingApplications(), Resources.clone(user
-          .getConsumedAMResources()), Resources.clone(user
-          .getUserResourceLimit()), user.getResourceUsage()));
+  public ArrayList<UserInfo> getUsers() {
+    try {
+      readLock.lock();
+      ArrayList<UserInfo> usersToReturn = new ArrayList<UserInfo>();
+      for (Map.Entry<String, User> entry : users.entrySet()) {
+        User user = entry.getValue();
+        usersToReturn.add(
+            new UserInfo(entry.getKey(), Resources.clone(user.getAllUsed()),
+                user.getActiveApplications(), user.getPendingApplications(),
+                Resources.clone(user.getConsumedAMResources()),
+                Resources.clone(user.getUserResourceLimit()),
+                user.getResourceUsage()));
+      }
+      return usersToReturn;
+    } finally {
+      readLock.unlock();
-    return usersToReturn;
-  public synchronized void reinitialize(
+  public void reinitialize(
-    // Sanity check
-    if (!(newlyParsedQueue instanceof LeafQueue) || 
-        !newlyParsedQueue.getQueuePath().equals(getQueuePath())) {
-      throw new IOException("Trying to reinitialize " + getQueuePath() + 
-          " from " + newlyParsedQueue.getQueuePath());
+    try {
+      writeLock.lock();
+      // Sanity check
+      if (!(newlyParsedQueue instanceof LeafQueue) || !newlyParsedQueue
+          .getQueuePath().equals(getQueuePath())) {
+        throw new IOException(
+            "Trying to reinitialize " + getQueuePath() + " from "
+                + newlyParsedQueue.getQueuePath());
+      }
+
+      LeafQueue newlyParsedLeafQueue = (LeafQueue) newlyParsedQueue;
+
+      // don't allow the maximum allocation to be decreased in size
+      // since we have already told running AM's the size
+      Resource oldMax = getMaximumAllocation();
+      Resource newMax = newlyParsedLeafQueue.getMaximumAllocation();
+      if (newMax.getMemorySize() < oldMax.getMemorySize()
+          || newMax.getVirtualCores() < oldMax.getVirtualCores()) {
+        throw new IOException("Trying to reinitialize " + getQueuePath()
+            + " the maximum allocation size can not be decreased!"
+            + " Current setting: " + oldMax + ", trying to set it to: "
+            + newMax);
+      }
+
+      setupQueueConfigs(clusterResource);
+
+      // queue metrics are updated, more resource may be available
+      // activate the pending applications if possible
+      activateApplications();
+    } finally {
+      writeLock.unlock();
-
-    LeafQueue newlyParsedLeafQueue = (LeafQueue)newlyParsedQueue;
-
-    // don't allow the maximum allocation to be decreased in size
-    // since we have already told running AM's the size
-    Resource oldMax = getMaximumAllocation();
-    Resource newMax = newlyParsedLeafQueue.getMaximumAllocation();
-    if (newMax.getMemorySize() < oldMax.getMemorySize()
-        || newMax.getVirtualCores() < oldMax.getVirtualCores()) {
-      throw new IOException(
-          "Trying to reinitialize "
-              + getQueuePath()
-              + " the maximum allocation size can not be decreased!"
-              + " Current setting: " + oldMax
-              + ", trying to set it to: " + newMax);
-    }
-
-    setupQueueConfigs(clusterResource);
-
-    // queue metrics are updated, more resource may be available
-    // activate the pending applications if possible
-    activateApplications();
-    synchronized (this) {
-      User user = getUser(userName);
+    try {
+      writeLock.lock();
+
+      // TODO, should use getUser, use this method just to avoid UT failure
+      // which is caused by wrong invoking order, will fix UT separately
+      User user = getUserAndAddIfAbsent(userName);
+
+    } finally {
+      writeLock.unlock();
+
-
-    User user = null;
-    synchronized (this) {
-
+    try {
+      writeLock.lock();
-        String msg = "Queue " + getQueuePath() +
-        " is STOPPED. Cannot accept submission of application: " + applicationId;
+        String msg = "Queue " + getQueuePath()
+            + " is STOPPED. Cannot accept submission of application: "
+            + applicationId;
-        String msg = "Queue " + getQueuePath() + 
-        " already has " + getNumApplications() + " applications," +
-        " cannot accept submission of application: " + applicationId;
+        String msg =
+            "Queue " + getQueuePath() + " already has " + getNumApplications()
+                + " applications,"
+                + " cannot accept submission of application: " + applicationId;
-      user = getUser(userName);
+      User user = getUserAndAddIfAbsent(userName);
-        String msg = "Queue " + getQueuePath() + 
-        " already has " + user.getTotalApplications() + 
-        " applications from user " + userName + 
-        " cannot accept submission of application: " + applicationId;
+        String msg = "Queue " + getQueuePath() + " already has " + user
+            .getTotalApplications() + " applications from user " + userName
+            + " cannot accept submission of application: " + applicationId;
+    } finally {
+      writeLock.unlock();
-  public synchronized Resource calculateAndGetAMResourceLimit() {
+  @VisibleForTesting
+  public Resource calculateAndGetAMResourceLimit() {
-  public synchronized Resource getUserAMResourceLimit() {
+  public Resource getUserAMResourceLimit() {
-  public synchronized Resource getUserAMResourceLimitPerPartition(
+  public Resource getUserAMResourceLimitPerPartition(
-    /*
-     * The user am resource limit is based on the same approach as the user
-     * limit (as it should represent a subset of that). This means that it uses
-     * the absolute queue capacity (per partition) instead of the max and is
-     * modified by the userlimit and the userlimit factor as is the userlimit
-     */
-    float effectiveUserLimit = Math.max(userLimit / 100.0f,
-        1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));
+    try {
+      readLock.lock();
+      /*
+       * The user am resource limit is based on the same approach as the user
+       * limit (as it should represent a subset of that). This means that it uses
+       * the absolute queue capacity (per partition) instead of the max and is
+       * modified by the userlimit and the userlimit factor as is the userlimit
+       */
+      float effectiveUserLimit = Math.max(userLimit / 100.0f,
+          1.0f / Math.max(getActiveUsersManager().getNumActiveUsers(), 1));
-    Resource queuePartitionResource = Resources.multiplyAndNormalizeUp(
-        resourceCalculator,
-        labelManager.getResourceByLabel(nodePartition, lastClusterResource),
-        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);
+      Resource queuePartitionResource = Resources.multiplyAndNormalizeUp(
+          resourceCalculator,
+          labelManager.getResourceByLabel(nodePartition, lastClusterResource),
+          queueCapacities.getAbsoluteCapacity(nodePartition),
+          minimumAllocation);
-    Resource userAMLimit = Resources.multiplyAndNormalizeUp(resourceCalculator,
-        queuePartitionResource,
-        queueCapacities.getMaxAMResourcePercentage(nodePartition)
-            * effectiveUserLimit * userLimitFactor, minimumAllocation);
-    return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
-        userAMLimit, getAMResourceLimitPerPartition(nodePartition))
-        ? userAMLimit
-        : getAMResourceLimitPerPartition(nodePartition);
-  }
-
-  public synchronized Resource calculateAndGetAMResourceLimitPerPartition(
-      String nodePartition) {
-    /*
-     * For non-labeled partition, get the max value from resources currently
-     * available to the queue and the absolute resources guaranteed for the
-     * partition in the queue. For labeled partition, consider only the absolute
-     * resources guaranteed. Multiply this value (based on labeled/
-     * non-labeled), * with per-partition am-resource-percent to get the max am
-     * resource limit for this queue and partition.
-     */
-    Resource queuePartitionResource = Resources.multiplyAndNormalizeUp(
-        resourceCalculator,
-        labelManager.getResourceByLabel(nodePartition, lastClusterResource),
-        queueCapacities.getAbsoluteCapacity(nodePartition), minimumAllocation);
-
-    Resource queueCurrentLimit = Resources.none();
-    // For non-labeled partition, we need to consider the current queue
-    // usage limit.
-    if (nodePartition.equals(RMNodeLabelsManager.NO_LABEL)) {
-      synchronized (queueResourceLimitsInfo) {
-        queueCurrentLimit = queueResourceLimitsInfo.getQueueCurrentLimit();
-      }
+      Resource userAMLimit = Resources.multiplyAndNormalizeUp(
+          resourceCalculator, queuePartitionResource,
+          queueCapacities.getMaxAMResourcePercentage(nodePartition)
+              * effectiveUserLimit * userLimitFactor, minimumAllocation);
+      return Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
+          userAMLimit, getAMResourceLimitPerPartition(nodePartition)) ?
+          userAMLimit :
+          getAMResourceLimitPerPartition(nodePartition);
+    } finally {
+      readLock.unlock();
-    float amResourcePercent = queueCapacities
-        .getMaxAMResourcePercentage(nodePartition);
-
-    // Current usable resource for this queue and partition is the max of
-    // queueCurrentLimit and queuePartitionResource.
-    Resource queuePartitionUsableResource = Resources.max(resourceCalculator,
-        lastClusterResource, queueCurrentLimit, queuePartitionResource);
-
-    Resource amResouceLimit = Resources.multiplyAndNormalizeUp(
-        resourceCalculator, queuePartitionUsableResource, amResourcePercent,
-        minimumAllocation);
-
-    metrics.setAMResouceLimit(amResouceLimit);
-    queueUsage.setAMLimit(nodePartition, amResouceLimit);
-    return amResouceLimit;
-  private synchronized void activateApplications() {
-    // limit of allowed resource usage for application masters
-    Map<String, Resource> userAmPartitionLimit =
-        new HashMap<String, Resource>();
+  public Resource calculateAndGetAMResourceLimitPerPartition(
+      String nodePartition) {
+    try {
+      writeLock.lock();
+      /*
+       * For non-labeled partition, get the max value from resources currently
+       * available to the queue and the absolute resources guaranteed for the
+       * partition in the queue. For labeled partition, consider only the absolute
+       * resources guaranteed. Multiply this value (based on labeled/
+       * non-labeled), * with per-partition am-resource-percent to get the max am
+       * resource limit for this queue and partition.
+       */
+      Resource queuePartitionResource = Resources.multiplyAndNormalizeUp(
+          resourceCalculator,
+          labelManager.getResourceByLabel(nodePartition, lastClusterResource),
+          queueCapacities.getAbsoluteCapacity(nodePartition),
+          minimumAllocation);
-    // AM Resource Limit for accessible labels can be pre-calculated.
-    // This will help in updating AMResourceLimit for all labels when queue
-    // is initialized for the first time (when no applications are present).
-    for (String nodePartition : getNodeLabelsForQueue()) {
-      calculateAndGetAMResourceLimitPerPartition(nodePartition);
-    }
-
-    for (Iterator<FiCaSchedulerApp> fsApp =
-        getPendingAppsOrderingPolicy().getAssignmentIterator();
-        fsApp.hasNext();) {
-      FiCaSchedulerApp application = fsApp.next();
-      ApplicationId applicationId = application.getApplicationId();
-
-      // Get the am-node-partition associated with each application
-      // and calculate max-am resource limit for this partition.
-      String partitionName = application.getAppAMNodePartitionName();
-
-      Resource amLimit = getAMResourceLimitPerPartition(partitionName);
-      // Verify whether we already calculated am-limit for this label.
-      if (amLimit == null) {
-        amLimit = calculateAndGetAMResourceLimitPerPartition(partitionName);
-      }
-      // Check am resource limit.
-      Resource amIfStarted = Resources.add(
-          application.getAMResource(partitionName),
-          queueUsage.getAMUsed(partitionName));
-
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("application "+application.getId() +" AMResource "
-            + application.getAMResource(partitionName)
-            + " maxAMResourcePerQueuePercent " + maxAMResourcePerQueuePercent
-            + " amLimit " + amLimit + " lastClusterResource "
-            + lastClusterResource + " amIfStarted " + amIfStarted
-            + " AM node-partition name " + partitionName);
-      }
-
-      if (!Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
-          amIfStarted, amLimit)) {
-        if (getNumActiveApplications() < 1
-            || (Resources.lessThanOrEqual(resourceCalculator,
-                lastClusterResource, queueUsage.getAMUsed(partitionName),
-                Resources.none()))) {
-          LOG.warn("maximum-am-resource-percent is insufficient to start a"
-              + " single application in queue, it is likely set too low."
-              + " skipping enforcement to allow at least one application"
-              + " to start");
-        } else {
-          application.updateAMContainerDiagnostics(AMState.INACTIVATED,
-              CSAMContainerLaunchDiagnosticsConstants.QUEUE_AM_RESOURCE_LIMIT_EXCEED);
-          LOG.info("Not activating application " + applicationId
-              + " as  amIfStarted: " + amIfStarted + " exceeds amLimit: "
-              + amLimit);
-          continue;
+      Resource queueCurrentLimit = Resources.none();
+      // For non-labeled partition, we need to consider the current queue
+      // usage limit.
+      if (nodePartition.equals(RMNodeLabelsManager.NO_LABEL)) {
+        synchronized (queueResourceLimitsInfo){
+          queueCurrentLimit = queueResourceLimitsInfo.getQueueCurrentLimit();
-      // Check user am resource limit
-      User user = getUser(application.getUser());
-      Resource userAMLimit = userAmPartitionLimit.get(partitionName);
+      float amResourcePercent = queueCapacities.getMaxAMResourcePercentage(
+          nodePartition);
-      // Verify whether we already calculated user-am-limit for this label.
-      if (userAMLimit == null) {
-        userAMLimit = getUserAMResourceLimitPerPartition(partitionName);
-        userAmPartitionLimit.put(partitionName, userAMLimit);
+      // Current usable resource for this queue and partition is the max of
+      // queueCurrentLimit and queuePartitionResource.
+      Resource queuePartitionUsableResource = Resources.max(resourceCalculator,
+          lastClusterResource, queueCurrentLimit, queuePartitionResource);
+
+      Resource amResouceLimit = Resources.multiplyAndNormalizeUp(
+          resourceCalculator, queuePartitionUsableResource, amResourcePercent,
+          minimumAllocation);
+
+      metrics.setAMResouceLimit(amResouceLimit);
+      queueUsage.setAMLimit(nodePartition, amResouceLimit);
+      return amResouceLimit;
+    } finally {
+      writeLock.unlock();
+    }
+  }
+
+  private void activateApplications() {
+    try {
+      writeLock.lock();
+      // limit of allowed resource usage for application masters
+      Map<String, Resource> userAmPartitionLimit =
+          new HashMap<String, Resource>();
+
+      // AM Resource Limit for accessible labels can be pre-calculated.
+      // This will help in updating AMResourceLimit for all labels when queue
+      // is initialized for the first time (when no applications are present).
+      for (String nodePartition : getNodeLabelsForQueue()) {
+        calculateAndGetAMResourceLimitPerPartition(nodePartition);
-      Resource userAmIfStarted = Resources.add(
-          application.getAMResource(partitionName),
-          user.getConsumedAMResources(partitionName));
+      for (Iterator<FiCaSchedulerApp> fsApp =
+           getPendingAppsOrderingPolicy().getAssignmentIterator();
+           fsApp.hasNext(); ) {
+        FiCaSchedulerApp application = fsApp.next();
+        ApplicationId applicationId = application.getApplicationId();
-      if (!Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
-          userAmIfStarted, userAMLimit)) {
-        if (getNumActiveApplications() < 1
-            || (Resources.lessThanOrEqual(resourceCalculator,
-                lastClusterResource, queueUsage.getAMUsed(partitionName),
-                Resources.none()))) {
-          LOG.warn("maximum-am-resource-percent is insufficient to start a"
-              + " single application in queue for user, it is likely set too"
-              + " low. skipping enforcement to allow at least one application"
-              + " to start");
-        } else {
-          application.updateAMContainerDiagnostics(AMState.INACTIVATED,
-              CSAMContainerLaunchDiagnosticsConstants.USER_AM_RESOURCE_LIMIT_EXCEED);
-          LOG.info("Not activating application " + applicationId
-              + " for user: " + user + " as userAmIfStarted: "
-              + userAmIfStarted + " exceeds userAmLimit: " + userAMLimit);
-          continue;
+        // Get the am-node-partition associated with each application
+        // and calculate max-am resource limit for this partition.
+        String partitionName = application.getAppAMNodePartitionName();
+
+        Resource amLimit = getAMResourceLimitPerPartition(partitionName);
+        // Verify whether we already calculated am-limit for this label.
+        if (amLimit == null) {
+          amLimit = calculateAndGetAMResourceLimitPerPartition(partitionName);
-      }
-      user.activateApplication();
-      orderingPolicy.addSchedulableEntity(application);
-      application.updateAMContainerDiagnostics(AMState.ACTIVATED, null);
+        // Check am resource limit.
+        Resource amIfStarted = Resources.add(
+            application.getAMResource(partitionName),
+            queueUsage.getAMUsed(partitionName));
-      queueUsage.incAMUsed(partitionName,
-          application.getAMResource(partitionName));
-      user.getResourceUsage().incAMUsed(partitionName,
-          application.getAMResource(partitionName));
-      user.getResourceUsage().setAMLimit(partitionName, userAMLimit);
-      metrics.incAMUsed(application.getUser(),
-          application.getAMResource(partitionName));
-      metrics.setAMResouceLimitForUser(application.getUser(), userAMLimit);
-      fsApp.remove();
-      LOG.info("Application " + applicationId + " from user: "
-          + application.getUser() + " activated in queue: " + getQueueName());
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("application " + application.getId() + " AMResource "
+              + application.getAMResource(partitionName)
+              + " maxAMResourcePerQueuePercent " + maxAMResourcePerQueuePercent
+              + " amLimit " + amLimit + " lastClusterResource "
+              + lastClusterResource + " amIfStarted " + amIfStarted
+              + " AM node-partition name " + partitionName);
+        }
+
+        if (!Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
+            amIfStarted, amLimit)) {
+          if (getNumActiveApplications() < 1 || (Resources.lessThanOrEqual(
+              resourceCalculator, lastClusterResource,
+              queueUsage.getAMUsed(partitionName), Resources.none()))) {
+            LOG.warn("maximum-am-resource-percent is insufficient to start a"
+                + " single application in queue, it is likely set too low."
+                + " skipping enforcement to allow at least one application"
+                + " to start");
+          } else{
+            application.updateAMContainerDiagnostics(AMState.INACTIVATED,
+                CSAMContainerLaunchDiagnosticsConstants.QUEUE_AM_RESOURCE_LIMIT_EXCEED);
+            LOG.info("Not activating application " + applicationId
+                + " as  amIfStarted: " + amIfStarted + " exceeds amLimit: "
+                + amLimit);
+            continue;
+          }
+        }
+
+        // Check user am resource limit
+        User user = getUser(application.getUser());
+        Resource userAMLimit = userAmPartitionLimit.get(partitionName);
+
+        // Verify whether we already calculated user-am-limit for this label.
+        if (userAMLimit == null) {
+          userAMLimit = getUserAMResourceLimitPerPartition(partitionName);
+          userAmPartitionLimit.put(partitionName, userAMLimit);
+        }
+
+        Resource userAmIfStarted = Resources.add(
+            application.getAMResource(partitionName),
+            user.getConsumedAMResources(partitionName));
+
+        if (!Resources.lessThanOrEqual(resourceCalculator, lastClusterResource,
+            userAmIfStarted, userAMLimit)) {
+          if (getNumActiveApplications() < 1 || (Resources.lessThanOrEqual(
+              resourceCalculator, lastClusterResource,
+              queueUsage.getAMUsed(partitionName), Resources.none()))) {
+            LOG.warn("maximum-am-resource-percent is insufficient to start a"
+                + " single application in queue for user, it is likely set too"
+                + " low. skipping enforcement to allow at least one application"
+                + " to start");
+          } else{
+            application.updateAMContainerDiagnostics(AMState.INACTIVATED,
+                CSAMContainerLaunchDiagnosticsConstants.USER_AM_RESOURCE_LIMIT_EXCEED);
+            LOG.info(
+                "Not activating application " + applicationId + " for user: "
+                    + user + " as userAmIfStarted: " + userAmIfStarted
+                    + " exceeds userAmLimit: " + userAMLimit);
+            continue;
+          }
+        }
+        user.activateApplication();
+        orderingPolicy.addSchedulableEntity(application);
+        application.updateAMContainerDiagnostics(AMState.ACTIVATED, null);
+
+        queueUsage.incAMUsed(partitionName,
+            application.getAMResource(partitionName));
+        user.getResourceUsage().incAMUsed(partitionName,
+            application.getAMResource(partitionName));
+        user.getResourceUsage().setAMLimit(partitionName, userAMLimit);
+        metrics.incAMUsed(application.getUser(),
+            application.getAMResource(partitionName));
+        metrics.setAMResouceLimitForUser(application.getUser(), userAMLimit);
+        fsApp.remove();
+        LOG.info("Application " + applicationId + " from user: " + application
+            .getUser() + " activated in queue: " + getQueueName());
+      }
+    } finally {
+      writeLock.unlock();
-  private synchronized void addApplicationAttempt(FiCaSchedulerApp application,
+  private void addApplicationAttempt(FiCaSchedulerApp application,
-    // Accept 
-    user.submitApplication();
-    getPendingAppsOrderingPolicy().addSchedulableEntity(application);
-    applicationAttemptMap.put(application.getApplicationAttemptId(), application);
+    try {
+      writeLock.lock();
+      // Accept
+      user.submitApplication();
+      getPendingAppsOrderingPolicy().addSchedulableEntity(application);
+      applicationAttemptMap.put(application.getApplicationAttemptId(),
+          application);
-    // Activate applications
-    activateApplications();
-    
-    LOG.info("Application added -" +
-        " appId: " + application.getApplicationId() +
-        " user: " + application.getUser() + "," +
-        " leaf-queue: " + getQueueName() +
-        " #user-pending-applications: " + user.getPendingApplications() +
-        " #user-active-applications: " + user.getActiveApplications() +
-        " #queue-pending-applications: " + getNumPendingApplications() +
-        " #queue-active-applications: " + getNumActiveApplications()
-        );
+      // Activate applications
+      activateApplications();
+
+      LOG.info(
+          "Application added -" + " appId: " + application.getApplicationId()
+              + " user: " + application.getUser() + "," + " leaf-queue: "
+              + getQueueName() + " #user-pending-applications: " + user
+              .getPendingApplications() + " #user-active-applications: " + user
+              .getActiveApplications() + " #queue-pending-applications: "
+              + getNumPendingApplications() + " #queue-active-applications: "
+              + getNumActiveApplications());
+    } finally {
+      writeLock.unlock();
+    }
-    synchronized (this) {
-      removeApplicationAttempt(application, getUser(application.getUser()));
-    }
+    removeApplicationAttempt(application, application.getUser());
-  public synchronized void removeApplicationAttempt(
-      FiCaSchedulerApp application, User user) {
-    String partitionName = application.getAppAMNodePartitionName();
-    boolean wasActive =
-      orderingPolicy.removeSchedulableEntity(application);
-    if (!wasActive) {
-      pendingOrderingPolicy.removeSchedulableEntity(application);
-    } else {
-      queueUsage.decAMUsed(partitionName,
-          application.getAMResource(partitionName));
-      user.getResourceUsage().decAMUsed(partitionName,
-          application.getAMResource(partitionName));
-      metrics.decAMUsed(application.getUser(),
-          application.getAMResource(partitionName));
+  private void removeApplicationAttempt(
+      FiCaSchedulerApp application, String userName) {
+    try {
+      writeLock.lock();
+
+      // TODO, should use getUser, use this method just to avoid UT failure
+      // which is caused by wrong invoking order, will fix UT separately
+      User user = getUserAndAddIfAbsent(userName);
+
+      String partitionName = application.getAppAMNodePartitionName();
+      boolean wasActive = orderingPolicy.removeSchedulableEntity(application);
+      if (!wasActive) {
+        pendingOrderingPolicy.removeSchedulableEntity(application);
+      } else{
+        queueUsage.decAMUsed(partitionName,
+            application.getAMResource(partitionName));
+        user.getResourceUsage().decAMUsed(partitionName,
+            application.getAMResource(partitionName));
+        metrics.decAMUsed(application.getUser(),
+            application.getAMResource(partitionName));
+      }
+      applicationAttemptMap.remove(application.getApplicationAttemptId());
+
+      user.finishApplication(wasActive);
+      if (user.getTotalApplications() == 0) {
+        users.remove(application.getUser());
+      }
+
+      // Check if we can activate more applications
+      activateApplications();
+
+      LOG.info(
+          "Application removed -" + " appId: " + application.getApplicationId()
+              + " user: " + application.getUser() + " queue: " + getQueueName()
+              + " #user-pending-applications: " + user.getPendingApplications()
+              + " #user-active-applications: " + user.getActiveApplications()
+              + " #queue-pending-applications: " + getNumPendingApplications()
+              + " #queue-active-applications: " + getNumActiveApplications());
+    } finally {
+      writeLock.unlock();
-    applicationAttemptMap.remove(application.getApplicationAttemptId());
-
-    user.finishApplication(wasActive);
-    if (user.getTotalApplications() == 0) {
-      users.remove(application.getUser());
-    }
-
-    // Check if we can activate more applications
-    activateApplications();
-
-    LOG.info("Application removed -" +
-        " appId: " + application.getApplicationId() +
-        " user: " + application.getUser() +
-        " queue: " + getQueueName() +
-        " #user-pending-applications: " + user.getPendingApplications() +
-        " #user-active-applications: " + user.getActiveApplications() +
-        " #queue-pending-applications: " + getNumPendingApplications() +
-        " #queue-active-applications: " + getNumActiveApplications()
-    );
-  private synchronized FiCaSchedulerApp getApplication(
+  private FiCaSchedulerApp getApplication(
-  public synchronized CSAssignment assignContainers(Resource clusterResource,
+  public CSAssignment assignContainers(Resource clusterResource,
-    updateCurrentResourceLimits(currentResourceLimits, clusterResource);
+    try {
+      writeLock.lock();
+      updateCurrentResourceLimits(currentResourceLimits, clusterResource);
-    if (LOG.isDebugEnabled()) {
-      LOG.debug("assignContainers: node=" + node.getNodeName()
-          + " #applications=" + orderingPolicy.getNumSchedulableEntities());
-    }
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(
+            "assignContainers: node=" + node.getNodeName() + " #applications="
+                + orderingPolicy.getNumSchedulableEntities());
+      }
-    setPreemptionAllowed(currentResourceLimits, node.getPartition());
+      setPreemptionAllowed(currentResourceLimits, node.getPartition());
-    // Check for reserved resources
-    RMContainer reservedContainer = node.getReservedContainer();
-    if (reservedContainer != null) {
-      FiCaSchedulerApp application =
-          getApplication(reservedContainer.getApplicationAttemptId());
+      // Check for reserved resources
+      RMContainer reservedContainer = node.getReservedContainer();
+      if (reservedContainer != null) {
+        FiCaSchedulerApp application = getApplication(
+            reservedContainer.getApplicationAttemptId());
-      ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,
-          node.getNodeID(), SystemClock.getInstance().getTime(), application);
+        ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,
+            node.getNodeID(), SystemClock.getInstance().getTime(), application);
-      synchronized (application) {
-        CSAssignment assignment =
-            application.assignContainers(clusterResource, node,
-                currentResourceLimits, schedulingMode, reservedContainer);
+        CSAssignment assignment = application.assignContainers(clusterResource,
+            node, currentResourceLimits, schedulingMode, reservedContainer);
-    }
-    // if our queue cannot access this node, just return
-    if (schedulingMode == SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY
-        && !accessibleToPartition(node.getPartition())) {
-      ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
-          getParent().getQueueName(), getQueueName(), ActivityState.REJECTED,
-          ActivityDiagnosticConstant.NOT_ABLE_TO_ACCESS_PARTITION + node
+      // if our queue cannot access this node, just return
+      if (schedulingMode == SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY
+          && !accessibleToPartition(node.getPartition())) {
+        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
+            getParent().getQueueName(), getQueueName(), ActivityState.REJECTED,
+            ActivityDiagnosticConstant.NOT_ABLE_TO_ACCESS_PARTITION + node
+                .getPartition());
+        return CSAssignment.NULL_ASSIGNMENT;
+      }
+
+      // Check if this queue need more resource, simply skip allocation if this
+      // queue doesn't need more resources.
+      if (!hasPendingResourceRequest(node.getPartition(), clusterResource,
+          schedulingMode)) {
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("Skip this queue=" + getQueuePath()
+              + ", because it doesn't need more resource, schedulingMode="
+              + schedulingMode.name() + " node-partition=" + node
-      return CSAssignment.NULL_ASSIGNMENT;
-    }
+        }
+        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
+            getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
+            ActivityDiagnosticConstant.QUEUE_DO_NOT_NEED_MORE_RESOURCE);
+        return CSAssignment.NULL_ASSIGNMENT;
+      }
-    // Check if this queue need more resource, simply skip allocation if this
-    // queue doesn't need more resources.
-    if (!hasPendingResourceRequest(node.getPartition(), clusterResource,
-        schedulingMode)) {
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("Skip this queue=" + getQueuePath()
-            + ", because it doesn't need more resource, schedulingMode="
-            + schedulingMode.name() + " node-partition=" + node.getPartition());
+      for (Iterator<FiCaSchedulerApp> assignmentIterator =
+           orderingPolicy.getAssignmentIterator();
+           assignmentIterator.hasNext(); ) {
+        FiCaSchedulerApp application = assignmentIterator.next();
+
+        ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,
+            node.getNodeID(), SystemClock.getInstance().getTime(), application);
+
+        // Check queue max-capacity limit
+        if (!super.canAssignToThisQueue(clusterResource, node.getPartition(),
+            currentResourceLimits, application.getCurrentReservation(),
+            schedulingMode)) {
+          ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(
+              activitiesManager, node, application, application.getPriority(),
+              ActivityDiagnosticConstant.QUEUE_MAX_CAPACITY_LIMIT);
+          ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
+              getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
+              ActivityDiagnosticConstant.EMPTY);
+          return CSAssignment.NULL_ASSIGNMENT;
+        }
+
+        Resource userLimit = computeUserLimitAndSetHeadroom(application,
+            clusterResource, node.getPartition(), schedulingMode);
+
+        // Check user limit
+        if (!canAssignToUser(clusterResource, application.getUser(), userLimit,
+            application, node.getPartition(), currentResourceLimits)) {
+          application.updateAMContainerDiagnostics(AMState.ACTIVATED,
+              "User capacity has reached its maximum limit.");
+          ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(
+              activitiesManager, node, application, application.getPriority(),
+              ActivityDiagnosticConstant.USER_CAPACITY_MAXIMUM_LIMIT);
+          continue;
+        }
+
+        // Try to schedule
+        CSAssignment assignment = application.assignContainers(clusterResource,
+            node, currentResourceLimits, schedulingMode, null);
+
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("post-assignContainers for application " + application
+              .getApplicationId());
+          application.showRequests();
+        }
+
+        // Did we schedule or reserve a container?
+        Resource assigned = assignment.getResource();
+
+        handleExcessReservedContainer(clusterResource, assignment, node,
+            application);
+        killToPreemptContainers(clusterResource, node, assignment);
+
+        if (Resources.greaterThan(resourceCalculator, clusterResource, assigned,
+            Resources.none())) {
+          // Get reserved or allocated container from application
+          RMContainer reservedOrAllocatedRMContainer =
+              application.getRMContainer(assignment.getAssignmentInformation()
+                  .getFirstAllocatedOrReservedContainerId());
+
+          // Book-keeping
+          // Note: Update headroom to account for current allocation too...
+          allocateResource(clusterResource, application, assigned,
+              node.getPartition(), reservedOrAllocatedRMContainer,
+              assignment.isIncreasedAllocation());
+
+          // Update reserved metrics
+          Resource reservedRes =
+              assignment.getAssignmentInformation().getReserved();
+          if (reservedRes != null && !reservedRes.equals(Resources.none())) {
+            incReservedResource(node.getPartition(), reservedRes);
+          }
+
+          ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
+              getParent().getQueueName(), getQueueName(),
+              ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);
+
+          // Done
+          return assignment;
+        } else if (assignment.getSkippedType()
+            == CSAssignment.SkippedType.OTHER) {
+          ActivitiesLogger.APP.finishSkippedAppAllocationRecording(
+              activitiesManager, application.getApplicationId(),
+              ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);
+          application.updateNodeInfoForAMDiagnostics(node);
+        } else if (assignment.getSkippedType()
+            == CSAssignment.SkippedType.QUEUE_LIMIT) {
+          return assignment;
+        } else{
+          // If we don't allocate anything, and it is not skipped by application,
+          // we will return to respect FIFO of applications
+          ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
+              getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
+              ActivityDiagnosticConstant.RESPECT_FIFO);
+          ActivitiesLogger.APP.finishSkippedAppAllocationRecording(
+              activitiesManager, application.getApplicationId(),
+              ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);
+          return CSAssignment.NULL_ASSIGNMENT;
+        }
-          ActivityDiagnosticConstant.QUEUE_DO_NOT_NEED_MORE_RESOURCE);
+          ActivityDiagnosticConstant.EMPTY);
+
+    } finally {
+      writeLock.unlock();
-
-    for (Iterator<FiCaSchedulerApp> assignmentIterator =
-        orderingPolicy.getAssignmentIterator(); assignmentIterator.hasNext();) {
-      FiCaSchedulerApp application = assignmentIterator.next();
-
-      ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,
-          node.getNodeID(), SystemClock.getInstance().getTime(), application);
-
-      // Check queue max-capacity limit
-      if (!super.canAssignToThisQueue(clusterResource, node.getPartition(),
-          currentResourceLimits, application.getCurrentReservation(),
-          schedulingMode)) {
-        ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(
-            activitiesManager, node,
-            application, application.getPriority(),
-            ActivityDiagnosticConstant.QUEUE_MAX_CAPACITY_LIMIT);
-        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
-            getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
-            ActivityDiagnosticConstant.EMPTY);
-        return CSAssignment.NULL_ASSIGNMENT;
-      }
-
-      Resource userLimit =
-          computeUserLimitAndSetHeadroom(application, clusterResource,
-              node.getPartition(), schedulingMode);
-
-      // Check user limit
-      if (!canAssignToUser(clusterResource, application.getUser(), userLimit,
-          application, node.getPartition(), currentResourceLimits)) {
-        application.updateAMContainerDiagnostics(AMState.ACTIVATED,
-            "User capacity has reached its maximum limit.");
-        ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(
-            activitiesManager, node,
-            application, application.getPriority(),
-            ActivityDiagnosticConstant.USER_CAPACITY_MAXIMUM_LIMIT);
-        continue;
-      }
-
-      // Try to schedule
-      CSAssignment assignment =
-          application.assignContainers(clusterResource, node,
-              currentResourceLimits, schedulingMode, null);
-
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("post-assignContainers for application "
-            + application.getApplicationId());
-        application.showRequests();
-      }
-
-      // Did we schedule or reserve a container?
-      Resource assigned = assignment.getResource();
-      
-      handleExcessReservedContainer(clusterResource, assignment, node,
-          application);
-      killToPreemptContainers(clusterResource, node, assignment);
-
-      if (Resources.greaterThan(resourceCalculator, clusterResource, assigned,
-          Resources.none())) {
-        // Get reserved or allocated container from application
-        RMContainer reservedOrAllocatedRMContainer =
-            application.getRMContainer(assignment.getAssignmentInformation()
-                .getFirstAllocatedOrReservedContainerId());
-
-        // Book-keeping
-        // Note: Update headroom to account for current allocation too...
-        allocateResource(clusterResource, application, assigned,
-            node.getPartition(), reservedOrAllocatedRMContainer,
-            assignment.isIncreasedAllocation());
-
-        // Update reserved metrics
-        Resource reservedRes = assignment.getAssignmentInformation()
-            .getReserved();
-        if (reservedRes != null && !reservedRes.equals(Resources.none())) {
-          incReservedResource(node.getPartition(), reservedRes);
-        }
-
-        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
-            getParent().getQueueName(), getQueueName(), ActivityState.ACCEPTED,
-            ActivityDiagnosticConstant.EMPTY);
-
-        // Done
-        return assignment;
-      } else if (assignment.getSkippedType()
-          == CSAssignment.SkippedType.OTHER) {
-        ActivitiesLogger.APP.finishSkippedAppAllocationRecording(
-            activitiesManager, application.getApplicationId(),
-            ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);
-        application.updateNodeInfoForAMDiagnostics(node);
-      } else if(assignment.getSkippedType()
-          == CSAssignment.SkippedType.QUEUE_LIMIT) {
-        return assignment;
-      } else {
-        // If we don't allocate anything, and it is not skipped by application,
-        // we will return to respect FIFO of applications
-        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
-            getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
-            ActivityDiagnosticConstant.RESPECT_FIFO);
-        ActivitiesLogger.APP.finishSkippedAppAllocationRecording(
-            activitiesManager, application.getApplicationId(),
-            ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);
-        return CSAssignment.NULL_ASSIGNMENT;
-      }
-    }
-    ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,
-        getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,
-        ActivityDiagnosticConstant.EMPTY);
-
-    return CSAssignment.NULL_ASSIGNMENT;
-  @Lock({LeafQueue.class, FiCaSchedulerApp.class})
+  // It doesn't necessarily to hold application's lock here.
+  @Lock({LeafQueue.class})
-  protected synchronized boolean canAssignToUser(Resource clusterResource,
+  protected boolean canAssignToUser(Resource clusterResource,
-    User user = getUser(userName);
+    try {
+      readLock.lock();
+      User user = getUser(userName);
-    currentResourceLimits.setAmountNeededUnreserve(Resources.none());
+      currentResourceLimits.setAmountNeededUnreserve(Resources.none());
-    // Note: We aren't considering the current request since there is a fixed
-    // overhead of the AM, but it's a > check, not a >= check, so...
-    if (Resources
-        .greaterThan(resourceCalculator, clusterResource,
-            user.getUsed(nodePartition),
-            limit)) {
-      // if enabled, check to see if could we potentially use this node instead
-      // of a reserved node if the application has reserved containers
-      if (this.reservationsContinueLooking &&
-          nodePartition.equals(CommonNodeLabelsManager.NO_LABEL)) {
-        if (Resources.lessThanOrEqual(
-            resourceCalculator,
-            clusterResource,
-            Resources.subtract(user.getUsed(),
-                application.getCurrentReservation()), limit)) {
+      // Note: We aren't considering the current request since there is a fixed
+      // overhead of the AM, but it's a > check, not a >= check, so...
+      if (Resources.greaterThan(resourceCalculator, clusterResource,
+          user.getUsed(nodePartition), limit)) {
+        // if enabled, check to see if could we potentially use this node instead
+        // of a reserved node if the application has reserved containers
+        if (this.reservationsContinueLooking && nodePartition.equals(
+            CommonNodeLabelsManager.NO_LABEL)) {
+          if (Resources.lessThanOrEqual(resourceCalculator, clusterResource,
+              Resources.subtract(user.getUsed(),
+                  application.getCurrentReservation()), limit)) {
-          if (LOG.isDebugEnabled()) {
-            LOG.debug("User " + userName + " in queue " + getQueueName()
-                + " will exceed limit based on reservations - " + " consumed: "
-                + user.getUsed() + " reserved: "
-                + application.getCurrentReservation() + " limit: " + limit);
+            if (LOG.isDebugEnabled()) {
+              LOG.debug("User " + userName + " in queue " + getQueueName()
+                  + " will exceed limit based on reservations - "
+                  + " consumed: " + user.getUsed() + " reserved: " + application
+                  .getCurrentReservation() + " limit: " + limit);
+            }
+            Resource amountNeededToUnreserve = Resources.subtract(
+                user.getUsed(nodePartition), limit);
+            // we can only acquire a new container if we unreserve first to
+            // respect user-limit
+            currentResourceLimits.setAmountNeededUnreserve(
+                amountNeededToUnreserve);
+            return true;
-          Resource amountNeededToUnreserve =
-              Resources.subtract(user.getUsed(nodePartition), limit);
-          // we can only acquire a new container if we unreserve first to
-          // respect user-limit
-          currentResourceLimits.setAmountNeededUnreserve(amountNeededToUnreserve);
-          return true;
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("User " + userName + " in queue " + getQueueName()
+              + " will exceed limit - " + " consumed: " + user
+              .getUsed(nodePartition) + " limit: " + limit);
+        }
+        return false;
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("User " + userName + " in queue " + getQueueName()
-            + " will exceed limit - " + " consumed: "
-            + user.getUsed(nodePartition) + " limit: " + limit);
-      }
-      return false;
+      return true;
+    } finally {
+      readLock.unlock();
-    return true;
-    
-    synchronized (this) {
+
+    try {
+      writeLock.lock();
-        removed = app.unreserve(
-            rmContainer.getAllocatedSchedulerKey(), node,
+        removed = app.unreserve(rmContainer.getAllocatedSchedulerKey(), node,
+    } finally {
+      writeLock.unlock();
-    
+
-  private synchronized float calculateUserUsageRatio(Resource clusterResource,
+  private float calculateUserUsageRatio(Resource clusterResource,
-    Resource resourceByLabel =
-        labelManager.getResourceByLabel(nodePartition, clusterResource);
-    float consumed = 0;
-    User user;
-    for (Map.Entry<String, User> entry : users.entrySet()) {
-      user = entry.getValue();
-      consumed += user.resetAndUpdateUsageRatio(resourceCalculator,
-          resourceByLabel, nodePartition);
-    }
-    return consumed;
-  }
-
-  private synchronized void recalculateQueueUsageRatio(Resource clusterResource,
-      String nodePartition) {
-    ResourceUsage queueResourceUsage = this.getQueueResourceUsage();
-
-    if (nodePartition == null) {
-      for (String partition : Sets.union(queueCapacities.getNodePartitionsSet(),
-          queueResourceUsage.getNodePartitionsSet())) {
-        qUsageRatios.setUsageRatio(partition,
-            calculateUserUsageRatio(clusterResource, partition));
+    try {
+      writeLock.lock();
+      Resource resourceByLabel = labelManager.getResourceByLabel(nodePartition,
+          clusterResource);
+      float consumed = 0;
+      User user;
+      for (Map.Entry<String, User> entry : users.entrySet()) {
+        user = entry.getValue();
+        consumed += user.resetAndUpdateUsageRatio(resourceCalculator,
+            resourceByLabel, nodePartition);
-    } else {
-      qUsageRatios.setUsageRatio(nodePartition,
-          calculateUserUsageRatio(clusterResource, nodePartition));
+      return consumed;
+    } finally {
+      writeLock.unlock();
-  private synchronized void updateQueueUsageRatio(String nodePartition,
+  private void recalculateQueueUsageRatio(Resource clusterResource,
+      String nodePartition) {
+    try {
+      writeLock.lock();
+      ResourceUsage queueResourceUsage = this.getQueueResourceUsage();
+
+      if (nodePartition == null) {
+        for (String partition : Sets.union(
+            queueCapacities.getNodePartitionsSet(),
+            queueResourceUsage.getNodePartitionsSet())) {
+          qUsageRatios.setUsageRatio(partition,
+              calculateUserUsageRatio(clusterResource, partition));
+        }
+      } else{
+        qUsageRatios.setUsageRatio(nodePartition,
+            calculateUserUsageRatio(clusterResource, nodePartition));
+      }
+    } finally {
+      writeLock.unlock();
+    }
+  }
+
+  private void updateQueueUsageRatio(String nodePartition,
-
-      synchronized (this) {
-
+      try {
+        writeLock.lock();
-        // happen under scheduler's lock... 
+        // happen under scheduler's lock...
-        } else {
-          removed =
-              application.containerCompleted(rmContainer, containerStatus,
-                  event, node.getPartition());
+        } else{
+          removed = application.containerCompleted(rmContainer, containerStatus,
+              event, node.getPartition());
-          
+
+      } finally {
+        writeLock.unlock();
+
-  synchronized void allocateResource(Resource clusterResource,
+  void allocateResource(Resource clusterResource,
-    super.allocateResource(clusterResource, resource, nodePartition,
-        isIncreasedAllocation);
-    Resource resourceByLabel = labelManager.getResourceByLabel(nodePartition,
-        clusterResource);
-    
-    // handle ignore exclusivity container
-    if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(
-        RMNodeLabelsManager.NO_LABEL)
-        && !nodePartition.equals(RMNodeLabelsManager.NO_LABEL)) {
-      TreeSet<RMContainer> rmContainers = null;
-      if (null == (rmContainers =
-          ignorePartitionExclusivityRMContainers.get(nodePartition))) {
-        rmContainers = new TreeSet<>();
-        ignorePartitionExclusivityRMContainers.put(nodePartition, rmContainers);
+    try {
+      writeLock.lock();
+      super.allocateResource(clusterResource, resource, nodePartition,
+          isIncreasedAllocation);
+      Resource resourceByLabel = labelManager.getResourceByLabel(nodePartition,
+          clusterResource);
+
+      // handle ignore exclusivity container
+      if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(
+          RMNodeLabelsManager.NO_LABEL) && !nodePartition.equals(
+          RMNodeLabelsManager.NO_LABEL)) {
+        TreeSet<RMContainer> rmContainers = null;
+        if (null == (rmContainers = ignorePartitionExclusivityRMContainers.get(
+            nodePartition))) {
+          rmContainers = new TreeSet<>();
+          ignorePartitionExclusivityRMContainers.put(nodePartition,
+              rmContainers);
+        }
+        rmContainers.add(rmContainer);
-      rmContainers.add(rmContainer);
-    }
-    // Update user metrics
-    String userName = application.getUser();
-    User user = getUser(userName);
-    user.assignContainer(resource, nodePartition);
+      // Update user metrics
+      String userName = application.getUser();
-    // Update usage ratios
-    updateQueueUsageRatio(nodePartition,
-        user.updateUsageRatio(resourceCalculator, resourceByLabel,
-            nodePartition));
+      // TODO, should use getUser, use this method just to avoid UT failure
+      // which is caused by wrong invoking order, will fix UT separately
+      User user = getUserAndAddIfAbsent(userName);
-    // Note this is a bit unconventional since it gets the object and modifies
-    // it here, rather then using set routine
-    Resources.subtractFrom(application.getHeadroom(), resource); // headroom
-    metrics.setAvailableResourcesToUser(userName, application.getHeadroom());
-    
-    if (LOG.isDebugEnabled()) {
-      LOG.debug(getQueueName() +
-          " user=" + userName +
-          " used=" + queueUsage.getUsed() + " numContainers=" + numContainers +
-          " headroom = " + application.getHeadroom() +
-          " user-resources=" + user.getUsed()
-          );
+      user.assignContainer(resource, nodePartition);
+
+      // Update usage ratios
+      updateQueueUsageRatio(nodePartition,
+          user.updateUsageRatio(resourceCalculator, resourceByLabel,
+              nodePartition));
+
+      // Note this is a bit unconventional since it gets the object and modifies
+      // it here, rather then using set routine
+      Resources.subtractFrom(application.getHeadroom(), resource); // headroom
+      metrics.setAvailableResourcesToUser(userName, application.getHeadroom());
+
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(getQueueName() + " user=" + userName + " used=" + queueUsage
+            .getUsed() + " numContainers=" + numContainers + " headroom = "
+            + application.getHeadroom() + " user-resources=" + user.getUsed());
+      }
+    } finally {
+      writeLock.unlock();
-  synchronized void releaseResource(Resource clusterResource,
+  void releaseResource(Resource clusterResource,
-    super.releaseResource(clusterResource, resource, nodePartition,
-        isChangeResource);
-    Resource resourceByLabel = labelManager.getResourceByLabel(nodePartition,
-        clusterResource);
-    
-    // handle ignore exclusivity container
-    if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(
-        RMNodeLabelsManager.NO_LABEL)
-        && !nodePartition.equals(RMNodeLabelsManager.NO_LABEL)) {
-      if (ignorePartitionExclusivityRMContainers.containsKey(nodePartition)) {
-        Set<RMContainer> rmContainers =
-            ignorePartitionExclusivityRMContainers.get(nodePartition);
-        rmContainers.remove(rmContainer);
-        if (rmContainers.isEmpty()) {
-          ignorePartitionExclusivityRMContainers.remove(nodePartition);
+    try {
+      writeLock.lock();
+      super.releaseResource(clusterResource, resource, nodePartition,
+          isChangeResource);
+      Resource resourceByLabel = labelManager.getResourceByLabel(nodePartition,
+          clusterResource);
+
+      // handle ignore exclusivity container
+      if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(
+          RMNodeLabelsManager.NO_LABEL) && !nodePartition.equals(
+          RMNodeLabelsManager.NO_LABEL)) {
+        if (ignorePartitionExclusivityRMContainers.containsKey(nodePartition)) {
+          Set<RMContainer> rmContainers =
+              ignorePartitionExclusivityRMContainers.get(nodePartition);
+          rmContainers.remove(rmContainer);
+          if (rmContainers.isEmpty()) {
+            ignorePartitionExclusivityRMContainers.remove(nodePartition);
+          }
-    }
-    // Update user metrics
-    String userName = application.getUser();
-    User user = getUser(userName);
-    user.releaseContainer(resource, nodePartition);
+      // Update user metrics
+      String userName = application.getUser();
+      User user = getUserAndAddIfAbsent(userName);
+      user.releaseContainer(resource, nodePartition);
-    // Update usage ratios
-    updateQueueUsageRatio(nodePartition,
-        user.updateUsageRatio(resourceCalculator, resourceByLabel,
-            nodePartition));
+      // Update usage ratios
+      updateQueueUsageRatio(nodePartition,
+          user.updateUsageRatio(resourceCalculator, resourceByLabel,
+              nodePartition));
-    metrics.setAvailableResourcesToUser(userName, application.getHeadroom());
+      metrics.setAvailableResourcesToUser(userName, application.getHeadroom());
-    if (LOG.isDebugEnabled()) {
-      LOG.debug(getQueueName() +
-          " used=" + queueUsage.getUsed() + " numContainers=" + numContainers +
-          " user=" + userName + " user-resources=" + user.getUsed());
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(
+            getQueueName() + " used=" + queueUsage.getUsed() + " numContainers="
+                + numContainers + " user=" + userName + " user-resources="
+                + user.getUsed());
+      }
+    } finally {
+      writeLock.unlock();
-  public synchronized void updateClusterResource(Resource clusterResource,
+  public void updateClusterResource(Resource clusterResource,
-    updateCurrentResourceLimits(currentResourceLimits, clusterResource);
-    lastClusterResource = clusterResource;
-    
-    // Update headroom info based on new cluster resource value
-    // absoluteMaxCapacity now,  will be replaced with absoluteMaxAvailCapacity
-    // during allocation
-    setQueueResourceLimitsInfo(clusterResource);
+    try {
+      writeLock.lock();
+      updateCurrentResourceLimits(currentResourceLimits, clusterResource);
+      lastClusterResource = clusterResource;
-    // Update user consumedRatios
-    recalculateQueueUsageRatio(clusterResource, null);
+      // Update headroom info based on new cluster resource value
+      // absoluteMaxCapacity now,  will be replaced with absoluteMaxAvailCapacity
+      // during allocation
+      setQueueResourceLimitsInfo(clusterResource);
-    // Update metrics
-    CSQueueUtils.updateQueueStatistics(resourceCalculator, clusterResource,
-        minimumAllocation, this, labelManager, null);
+      // Update user consumedRatios
+      recalculateQueueUsageRatio(clusterResource, null);
-    // queue metrics are updated, more resource may be available
-    // activate the pending applications if possible
-    activateApplications();
+      // Update metrics
+      CSQueueUtils.updateQueueStatistics(resourceCalculator, clusterResource,
+          minimumAllocation, this, labelManager, null);
-    // Update application properties
-    for (FiCaSchedulerApp application :
-      orderingPolicy.getSchedulableEntities()) {
-      synchronized (application) {
+      // queue metrics are updated, more resource may be available
+      // activate the pending applications if possible
+      activateApplications();
+
+      // Update application properties
+      for (FiCaSchedulerApp application : orderingPolicy
+          .getSchedulableEntities()) {
+    } finally {
+      writeLock.unlock();
-    int pendingApplications = 0;
-    int activeApplications = 0;
+    volatile int pendingApplications = 0;
+    volatile int activeApplications = 0;
+    private WriteLock writeLock;
+
+    User() {
+      ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
+      // Nobody uses read-lock now, will add it when necessary
+      writeLock = lock.writeLock();
+    }
-    public synchronized float resetAndUpdateUsageRatio(
+    public float resetAndUpdateUsageRatio(
-      userUsageRatios.setUsageRatio(nodePartition, 0);
-      return updateUsageRatio(resourceCalculator, resource, nodePartition);
+      try {
+        writeLock.lock();
+        userUsageRatios.setUsageRatio(nodePartition, 0);
+        return updateUsageRatio(resourceCalculator, resource, nodePartition);
+      } finally {
+        writeLock.unlock();
+      }
-    public synchronized float updateUsageRatio(
+    public float updateUsageRatio(
-      float delta;
-      float newRatio =
-          Resources.ratio(resourceCalculator, getUsed(nodePartition), resource);
-      delta = newRatio - userUsageRatios.getUsageRatio(nodePartition);
-      userUsageRatios.setUsageRatio(nodePartition, newRatio);
-      return delta;
+      try {
+        writeLock.lock();
+        float delta;
+        float newRatio = Resources.ratio(resourceCalculator,
+            getUsed(nodePartition), resource);
+        delta = newRatio - userUsageRatios.getUsageRatio(nodePartition);
+        userUsageRatios.setUsageRatio(nodePartition, newRatio);
+        return delta;
+      } finally {
+        writeLock.unlock();
+      }
-    public synchronized void submitApplication() {
-      ++pendingApplications;
+    public void submitApplication() {
+      try {
+        writeLock.lock();
+        ++pendingApplications;
+      } finally {
+        writeLock.unlock();
+      }
-    public synchronized void activateApplication() {
-      --pendingApplications;
-      ++activeApplications;
+    public void activateApplication() {
+      try {
+        writeLock.lock();
+        --pendingApplications;
+        ++activeApplications;
+      } finally {
+        writeLock.unlock();
+      }
-    public synchronized void finishApplication(boolean wasActive) {
-      if (wasActive) {
-        --activeApplications;
-      }
-      else {
-        --pendingApplications;
+    public void finishApplication(boolean wasActive) {
+      try {
+        writeLock.lock();
+        if (wasActive) {
+          --activeApplications;
+        } else{
+          --pendingApplications;
+        }
+      } finally {
+        writeLock.unlock();
-    // Careful! Locking order is important! 
-    synchronized (this) {
-      FiCaSchedulerNode node =
-          scheduler.getNode(rmContainer.getContainer().getNodeId());
-      allocateResource(clusterResource, attempt, rmContainer.getContainer()
-          .getResource(), node.getPartition(), rmContainer, false);
+
+    // Careful! Locking order is important!
+    try {
+      writeLock.lock();
+      FiCaSchedulerNode node = scheduler.getNode(
+          rmContainer.getContainer().getNodeId());
+      allocateResource(clusterResource, attempt,
+          rmContainer.getContainer().getResource(), node.getPartition(),
+          rmContainer, false);
+    } finally {
+      writeLock.unlock();
+
-  public synchronized Resource getTotalPendingResourcesConsideringUserLimit(
+  public Resource getTotalPendingResourcesConsideringUserLimit(
-    Map<String, Resource> userNameToHeadroom = new HashMap<String, Resource>();
-    Resource pendingConsideringUserLimit = Resource.newInstance(0, 0);
-    for (FiCaSchedulerApp app : getApplications()) {
-      String userName = app.getUser();
-      if (!userNameToHeadroom.containsKey(userName)) {
-        User user = getUser(userName);
-        Resource headroom = Resources.subtract(
-            computeUserLimit(app, resources, user, partition,
-                SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY),
-                user.getUsed(partition));
-        // Make sure headroom is not negative.
-        headroom = Resources.componentwiseMax(headroom, Resources.none());
-        userNameToHeadroom.put(userName, headroom);
+    try {
+      readLock.lock();
+      Map<String, Resource> userNameToHeadroom =
+          new HashMap<>();
+      Resource pendingConsideringUserLimit = Resource.newInstance(0, 0);
+      for (FiCaSchedulerApp app : getApplications()) {
+        String userName = app.getUser();
+        if (!userNameToHeadroom.containsKey(userName)) {
+          User user = getUser(userName);
+          Resource headroom = Resources.subtract(
+              computeUserLimit(app, resources, user, partition,
+                  SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY),
+              user.getUsed(partition));
+          // Make sure headroom is not negative.
+          headroom = Resources.componentwiseMax(headroom, Resources.none());
+          userNameToHeadroom.put(userName, headroom);
+        }
+        Resource minpendingConsideringUserLimit = Resources.componentwiseMin(
+            userNameToHeadroom.get(userName),
+            app.getAppAttemptResourceUsage().getPending(partition));
+        Resources.addTo(pendingConsideringUserLimit,
+            minpendingConsideringUserLimit);
+        Resources.subtractFrom(userNameToHeadroom.get(userName),
+            minpendingConsideringUserLimit);
-      Resource minpendingConsideringUserLimit =
-          Resources.componentwiseMin(userNameToHeadroom.get(userName),
-                       app.getAppAttemptResourceUsage().getPending(partition));
-      Resources.addTo(pendingConsideringUserLimit,
-          minpendingConsideringUserLimit);
-      Resources.subtractFrom(
-          userNameToHeadroom.get(userName), minpendingConsideringUserLimit);
+      return pendingConsideringUserLimit;
+    } finally {
+      readLock.unlock();
-    return pendingConsideringUserLimit;
+
-  public synchronized void collectSchedulerApplications(
+  public void collectSchedulerApplications(
-    for (FiCaSchedulerApp pendingApp : pendingOrderingPolicy
-        .getSchedulableEntities()) {
-      apps.add(pendingApp.getApplicationAttemptId());
+    try {
+      readLock.lock();
+      for (FiCaSchedulerApp pendingApp : pendingOrderingPolicy
+          .getSchedulableEntities()) {
+        apps.add(pendingApp.getApplicationAttemptId());
+      }
+      for (FiCaSchedulerApp app : orderingPolicy.getSchedulableEntities()) {
+        apps.add(app.getApplicationAttemptId());
+      }
+    } finally {
+      readLock.unlock();
-    for (FiCaSchedulerApp app :
-      orderingPolicy.getSchedulableEntities()) {
-      apps.add(app.getApplicationAttemptId());
-    }
+
-   * will be used by preemption policy, and use of return
-   * ignorePartitionExclusivityRMContainer should protected by LeafQueue
-   * synchronized lock
+   * will be used by preemption policy.
-  public synchronized Map<String, TreeSet<RMContainer>>
+  public Map<String, TreeSet<RMContainer>>
-    return ignorePartitionExclusivityRMContainers;
+    Map<String, TreeSet<RMContainer>> clonedMap = new HashMap<>();
+    try {
+      readLock.lock();
+
+      for (Map.Entry<String, TreeSet<RMContainer>> entry : ignorePartitionExclusivityRMContainers
+          .entrySet()) {
+        clonedMap.put(entry.getKey(), new TreeSet<>(entry.getValue()));
+      }
+
+      return clonedMap;
+
+    } finally {
+      readLock.unlock();
+    }
-  public synchronized OrderingPolicy<FiCaSchedulerApp>
+  public OrderingPolicy<FiCaSchedulerApp>
-  public synchronized void setOrderingPolicy(
+  void setOrderingPolicy(
-    if (null != this.orderingPolicy) {
-      orderingPolicy.addAllSchedulableEntities(this.orderingPolicy
-          .getSchedulableEntities());
+    try {
+      writeLock.lock();
+      if (null != this.orderingPolicy) {
+        orderingPolicy.addAllSchedulableEntities(
+            this.orderingPolicy.getSchedulableEntities());
+      }
+      this.orderingPolicy = orderingPolicy;
+    } finally {
+      writeLock.unlock();
-    this.orderingPolicy = orderingPolicy;
-    synchronized (this) {
+
+    try {
+      writeLock.lock();
-      resourceBeforeDecrease =
-          Resources.clone(rmContainer.getAllocatedResource());
+      resourceBeforeDecrease = Resources.clone(
+          rmContainer.getAllocatedResource());
-      boolean hasIncreaseRequest =
-          app.removeIncreaseRequest(decreaseRequest.getNodeId(),
-              decreaseRequest.getRMContainer().getAllocatedSchedulerKey(),
-              decreaseRequest.getContainerId());
+      boolean hasIncreaseRequest = app.removeIncreaseRequest(
+          decreaseRequest.getNodeId(),
+          decreaseRequest.getRMContainer().getAllocatedSchedulerKey(),
+          decreaseRequest.getContainerId());
-              + " request for the same container "
-              + decreaseRequest.getContainerId()
-              + ", removed the increase request");
+              + " request for the same container " + decreaseRequest
+              .getContainerId() + ", removed the increase request");
-      } else {
+      } else{
-            decreaseRequest.getRMContainer(),
-            true);
+            decreaseRequest.getRMContainer(), true);
-        decreaseRequest.getSchedulerNode()
-            .decreaseContainer(decreaseRequest.getContainerId(), absDelta);
+        decreaseRequest.getSchedulerNode().decreaseContainer(
+            decreaseRequest.getContainerId(), absDelta);
+    } finally {
+      writeLock.unlock();
-  public synchronized OrderingPolicy<FiCaSchedulerApp>
+  public OrderingPolicy<FiCaSchedulerApp>

INS26 INS40 INS31 INS31 INS83 INS83 INS83 INS83 INS83 INS59 INS8 INS78 INS78 INS8 INS8 INS8 MOV78 MOV83 MOV39 UPD42 MOV42 MOV44 INS8 MOV78 MOV83 MOV39 MOV42 MOV44 INS8 INS8 INS8 MOV78 MOV43 UPD42 UPD83 UPD42 INS8 INS8 INS8 MOV78 INS8 INS8 INS8 INS8 MOV8 UPD83 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS23 INS31 INS8 INS8 INS8 INS8 INS42 INS14 INS54 INS42 INS42 INS54 INS54 INS54 INS54 INS54 INS54 INS54 UPD43 UPD42 INS41 INS54 INS54 INS54 INS54 INS54 INS54 INS54 INS54 INS54 MOV21 UPD43 UPD42 INS54 INS54 INS54 INS54 INS54 INS54 INS54 INS54 INS54 INS83 INS83 INS83 INS43 INS59 INS42 INS8 INS8 INS8 INS8 INS8 INS8 INS54 INS54 INS54 INS60 INS54 INS54 INS54 UPD74 UPD74 INS74 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 INS8 INS8 INS8 INS8 MOV8 INS8 MOV8 INS8 UPD42 INS32 MOV8 INS8 MOV8 INS8 MOV8 INS8 INS8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV32 UPD42 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 INS42 INS42 INS60 INS21 INS54 INS54 INS54 INS54 INS54 MOV8 INS8 MOV8 INS8 MOV8 INS8 UPD66 INS74 INS59 INS8 INS8 MOV8 INS8 MOV8 INS8 UPD43 UPD43 INS43 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS60 INS25 MOV41 INS21 INS21 INS60 INS25 INS41 INS21 INS21 INS21 INS21 INS21 INS42 INS42 INS42 INS21 INS21 INS21 INS21 INS21 INS21 INS21 MOV60 MOV21 INS21 INS21 INS60 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 UPD42 INS42 INS21 INS60 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS54 INS21 INS21 INS21 INS21 INS21 INS21 INS43 INS59 INS7 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 MOV8 INS8 INS21 INS21 INS21 INS21 INS21 INS21 INS43 INS43 INS74 INS42 INS14 INS21 INS70 INS41 INS21 INS21 INS21 INS21 INS21 UPD42 UPD42 INS42 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS43 INS59 INS27 INS8 INS32 INS32 INS43 INS59 INS27 INS8 INS32 INS32 INS32 INS32 INS32 INS32 INS32 UPD42 INS32 INS32 INS32 INS32 INS32 INS32 MOV43 INS32 INS32 INS43 INS59 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS43 INS59 INS32 INS32 MOV8 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 MOV8 INS8 INS32 INS32 INS32 INS32 INS32 MOV8 INS32 INS42 INS42 INS14 INS42 INS32 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS32 INS32 INS32 MOV59 INS32 INS32 INS32 INS42 INS42 INS43 INS43 INS74 INS32 INS44 INS32 INS8 INS42 INS32 INS32 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 MOV42 INS42 MOV32 INS33 INS42 INS41 UPD42 MOV42 UPD42 UPD42 MOV42 INS42 UPD42 MOV42 INS42 INS42 INS42 MOV32 INS33 INS42 INS41 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS33 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 MOV60 MOV21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS42 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS42 INS74 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 INS34 UPD74 UPD42 UPD42 MOV42 MOV42 INS42 INS42 INS32 INS32 UPD42 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 MOV43 INS74 INS32 UPD42 UPD42 INS42 INS42 INS42 INS42 INS40 INS43 INS43 INS42 INS42 INS32 INS14 INS42 INS42 INS42 INS42 INS74 INS32 INS43 INS42 INS42 INS42 DEL42 DEL43 DEL42 DEL43 DEL33 DEL42 DEL43 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL42 DEL32 DEL42 DEL78 DEL83 DEL43 DEL42 DEL44 DEL8 DEL31 DEL83 DEL83 DEL39 DEL42 DEL32 DEL41 DEL8 DEL31 DEL83 DEL32 DEL41 DEL8 DEL31 DEL42 DEL78 DEL83 DEL83 DEL42 DEL43 DEL42 DEL42 DEL41 DEL8 DEL31 DEL83 DEL83 DEL83 DEL42 DEL43 DEL83 DEL39 DEL52 DEL42 DEL22 DEL42 DEL7 DEL21 DEL83 DEL33 DEL83 DEL83 DEL52 DEL8 DEL51 DEL42 DEL32 DEL7 DEL21 DEL42 DEL33 DEL59 DEL60 DEL52 DEL51 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL42 DEL42 DEL32 DEL52 DEL51 DEL8 DEL83 DEL83 DEL83 DEL42 DEL51 DEL8 DEL42 DEL43 DEL57 DEL83 DEL52 DEL51 DEL83 DEL83 DEL83 DEL52 DEL51 DEL83 DEL83 DEL83 DEL42 DEL51 DEL8 DEL83 DEL83 DEL83 DEL83 DEL83 DEL52 DEL51 DEL83 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL14 DEL59 DEL83 DEL66 DEL66 DEL83 DEL42 DEL41 DEL8 DEL83 DEL83 DEL83 DEL52 DEL51 DEL83