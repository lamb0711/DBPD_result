Merge trunk into HA branch.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1210547 13f79535-47bb-0310-9956-ffa450edef68

+import java.security.PrivilegedExceptionAction;
+import org.apache.hadoop.security.UserGroupInformation;
+  /**
+   * Ugi of the client. We store this ugi when the client is created and 
+   * then make sure that the same ugi is used to run the various protocols.
+   */
+  UserGroupInformation clientUgi;
+    clientUgi = UserGroupInformation.getCurrentUser();
-    }
-    
+    }   
+    clientUgi = UserGroupInformation.getCurrentUser();
-  public RunningJob submitJob(JobConf conf) throws FileNotFoundException,
+  public RunningJob submitJob(final JobConf conf) throws FileNotFoundException,
-      Job job = Job.getInstance(conf);
-      job.submit();
+      Job job = clientUgi.doAs(new PrivilegedExceptionAction<Job> () {
+        @Override
+        public Job run() throws IOException, ClassNotFoundException, 
+          InterruptedException {
+          Job job = Job.getInstance(conf);
+          job.submit();
+          return job;
+        }
+      });
+      // update our Cluster instance with the one created by Job for submission
+      // (we can't pass our Cluster instance to Job, since Job wraps the config
+      // instance, and the two configs would then diverge)
+      cluster = job.getCluster();
-    } catch (ClassNotFoundException cnfe) {
-      throw new IOException("class not found", cnfe);
+  private Job getJobUsingCluster(final JobID jobid) throws IOException,
+  InterruptedException {
+    return clientUgi.doAs(new PrivilegedExceptionAction<Job>() {
+      public Job run() throws IOException, InterruptedException  {
+       return cluster.getJob(jobid);
+      }
+    });
+  }
-  public RunningJob getJob(JobID jobid) throws IOException {
+  public RunningJob getJob(final JobID jobid) throws IOException {
-      Job job = cluster.getJob(jobid);
+      
+      Job job = getJobUsingCluster(jobid);
-  private TaskReport[] getTaskReports(JobID jobId, TaskType type) throws IOException {
+  private TaskReport[] getTaskReports(final JobID jobId, TaskType type) throws 
+    IOException {
-      Job j = cluster.getJob(jobId);
+      Job j = getJobUsingCluster(jobId);
-  public void displayTasks(JobID jobId, String type, String state) 
+  public void displayTasks(final JobID jobId, String type, String state) 
-      super.displayTasks(cluster.getJob(jobId), type, state);
+      Job job = getJobUsingCluster(jobId);
+      super.displayTasks(job, type, state);
-      ClusterMetrics metrics = cluster.getClusterStatus();
-      return new ClusterStatus(metrics.getTaskTrackerCount(),
-        metrics.getBlackListedTaskTrackerCount(), cluster.getTaskTrackerExpiryInterval(),
-        metrics.getOccupiedMapSlots(),
-        metrics.getOccupiedReduceSlots(), metrics.getMapSlotCapacity(),
-        metrics.getReduceSlotCapacity(),
-        cluster.getJobTrackerStatus(),
-        metrics.getDecommissionedTaskTrackerCount());
-    } catch (InterruptedException ie) {
+      return clientUgi.doAs(new PrivilegedExceptionAction<ClusterStatus>() {
+        public ClusterStatus run()  throws IOException, InterruptedException {
+          ClusterMetrics metrics = cluster.getClusterStatus();
+          return new ClusterStatus(metrics.getTaskTrackerCount(),
+              metrics.getBlackListedTaskTrackerCount(), cluster.getTaskTrackerExpiryInterval(),
+              metrics.getOccupiedMapSlots(),
+              metrics.getOccupiedReduceSlots(), metrics.getMapSlotCapacity(),
+              metrics.getReduceSlotCapacity(),
+              cluster.getJobTrackerStatus(),
+              metrics.getDecommissionedTaskTrackerCount());
+        }
+      });
+    }
+      catch (InterruptedException ie) {
-      ClusterMetrics metrics = cluster.getClusterStatus();
-      return new ClusterStatus(arrayToStringList(cluster.getActiveTaskTrackers()),
-        arrayToBlackListInfo(cluster.getBlackListedTaskTrackers()),
-        cluster.getTaskTrackerExpiryInterval(), metrics.getOccupiedMapSlots(),
-        metrics.getOccupiedReduceSlots(), metrics.getMapSlotCapacity(),
-        metrics.getReduceSlotCapacity(), 
-        cluster.getJobTrackerStatus());
+      return clientUgi.doAs(new PrivilegedExceptionAction<ClusterStatus>() {
+        public ClusterStatus run() throws IOException, InterruptedException {
+        ClusterMetrics metrics = cluster.getClusterStatus();
+        return new ClusterStatus(arrayToStringList(cluster.getActiveTaskTrackers()),
+          arrayToBlackListInfo(cluster.getBlackListedTaskTrackers()),
+          cluster.getTaskTrackerExpiryInterval(), metrics.getOccupiedMapSlots(),
+          metrics.getOccupiedReduceSlots(), metrics.getMapSlotCapacity(),
+          metrics.getReduceSlotCapacity(), 
+          cluster.getJobTrackerStatus());
+        }
+      });
-      org.apache.hadoop.mapreduce.JobStatus[] jobs = cluster.getAllJobStatuses();
+      org.apache.hadoop.mapreduce.JobStatus[] jobs = 
+          clientUgi.doAs(new PrivilegedExceptionAction<
+              org.apache.hadoop.mapreduce.JobStatus[]> () {
+            public org.apache.hadoop.mapreduce.JobStatus[] run() 
+                throws IOException, InterruptedException {
+              return cluster.getAllJobStatuses();
+            }
+          });
-      return cluster.getClusterStatus().getMapSlotCapacity();
+      return clientUgi.doAs(new PrivilegedExceptionAction<Integer>() {
+        @Override
+        public Integer run() throws IOException, InterruptedException {
+          return cluster.getClusterStatus().getMapSlotCapacity();
+        }
+      });
-      return cluster.getClusterStatus().getReduceSlotCapacity();
+      return clientUgi.doAs(new PrivilegedExceptionAction<Integer>() {
+        @Override
+        public Integer run() throws IOException, InterruptedException {
+          return cluster.getClusterStatus().getReduceSlotCapacity();
+        }
+      });
-      return cluster.getSystemDir();
-    } catch (IOException ioe) {
+      return clientUgi.doAs(new PrivilegedExceptionAction<Path>() {
+        @Override
+        public Path run() throws IOException, InterruptedException {
+          return cluster.getSystemDir();
+        }
+      });
+      } catch (IOException ioe) {
-      return getJobQueueInfoArray(cluster.getRootQueues());
+      return clientUgi.doAs(new PrivilegedExceptionAction<JobQueueInfo[]>() {
+        public JobQueueInfo[] run() throws IOException, InterruptedException {
+          return getJobQueueInfoArray(cluster.getRootQueues());
+        }
+      });
-  public JobQueueInfo[] getChildQueues(String queueName) throws IOException {
+  public JobQueueInfo[] getChildQueues(final String queueName) throws IOException {
-      return getJobQueueInfoArray(cluster.getChildQueues(queueName));
+      return clientUgi.doAs(new PrivilegedExceptionAction<JobQueueInfo[]>() {
+        public JobQueueInfo[] run() throws IOException, InterruptedException {
+          return getJobQueueInfoArray(cluster.getChildQueues(queueName));
+        }
+      });
-      return getJobQueueInfoArray(cluster.getQueues());
+      return clientUgi.doAs(new PrivilegedExceptionAction<JobQueueInfo[]>() {
+        public JobQueueInfo[] run() throws IOException, InterruptedException {
+          return getJobQueueInfoArray(cluster.getQueues());
+        }
+      });
-  public JobStatus[] getJobsFromQueue(String queueName) throws IOException {
+  public JobStatus[] getJobsFromQueue(final String queueName) throws IOException {
-      QueueInfo queue = cluster.getQueue(queueName);
+      QueueInfo queue = clientUgi.doAs(new PrivilegedExceptionAction<QueueInfo>() {
+        @Override
+        public QueueInfo run() throws IOException, InterruptedException {
+          return cluster.getQueue(queueName);
+        }
+      });
-  public JobQueueInfo getQueueInfo(String queueName) throws IOException {
+  public JobQueueInfo getQueueInfo(final String queueName) throws IOException {
-      QueueInfo queueInfo = cluster.getQueue(queueName);
+      QueueInfo queueInfo = clientUgi.doAs(new 
+          PrivilegedExceptionAction<QueueInfo>() {
+        public QueueInfo run() throws IOException, InterruptedException {
+          return cluster.getQueue(queueName);
+        }
+      });
-        cluster.getQueueAclsForCurrentUser();
+        clientUgi.doAs(new 
+            PrivilegedExceptionAction
+            <org.apache.hadoop.mapreduce.QueueAclsInfo[]>() {
+              public org.apache.hadoop.mapreduce.QueueAclsInfo[] run() 
+              throws IOException, InterruptedException {
+                return cluster.getQueueAclsForCurrentUser();
+              }
+        });
-    getDelegationToken(Text renewer) throws IOException, InterruptedException {
-    return cluster.getDelegationToken(renewer);
+    getDelegationToken(final Text renewer) throws IOException, InterruptedException {
+    return clientUgi.doAs(new 
+        PrivilegedExceptionAction<Token<DelegationTokenIdentifier>>() {
+      public Token<DelegationTokenIdentifier> run() throws IOException, 
+      InterruptedException {
+        return cluster.getDelegationToken(renewer);
+      }
+    });

INS26 INS26 INS40 INS40 INS23 INS31 INS29 INS43 INS59 INS83 INS43 INS42 MOV44 INS43 INS43 INS8 INS44 INS43 INS43 INS44 MOV44 INS8 INS65 INS42 INS42 INS21 INS21 INS83 INS42 INS83 INS42 INS42 INS41 INS83 INS43 INS42 INS83 INS83 INS42 INS42 INS83 MOV43 INS42 INS83 INS83 INS83 INS41 INS66 INS66 INS7 INS7 INS32 INS42 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS32 INS42 INS32 INS42 INS32 INS60 INS21 INS42 INS42 INS14 INS60 INS41 INS41 INS41 INS41 INS41 INS41 INS41 INS41 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS43 INS59 INS7 INS74 INS1 INS43 INS43 INS59 INS32 INS32 INS5 INS32 INS32 INS32 INS32 INS32 INS32 MOV43 MOV43 INS59 INS5 INS74 INS1 INS42 INS42 INS32 INS42 INS32 INS43 INS43 INS31 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS42 INS14 INS42 INS42 INS14 INS43 INS85 INS32 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS32 INS42 INS32 INS43 INS85 INS32 INS43 INS74 INS31 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS83 MOV43 INS42 INS43 INS43 INS8 INS42 INS42 UPD42 INS42 INS42 INS74 INS1 INS74 INS1 INS40 INS42 INS42 INS14 INS74 INS1 INS74 INS1 INS74 INS1 INS74 INS1 INS74 INS1 INS74 INS1 INS42 INS42 INS14 INS42 INS42 INS14 INS40 INS42 INS42 INS14 INS42 INS43 INS43 INS83 INS74 INS42 INS43 INS43 MOV8 INS74 INS1 INS42 INS42 INS41 INS43 INS43 INS31 INS43 INS43 INS31 INS74 INS1 INS43 INS43 INS31 INS43 INS43 INS31 INS43 INS43 INS31 INS43 INS5 INS31 INS43 INS5 INS31 INS43 INS5 INS31 INS74 INS1 INS74 INS1 INS74 INS1 INS42 INS42 INS43 INS43 INS42 INS42 INS43 INS43 INS31 MOV32 INS42 INS42 INS83 MOV43 INS42 MOV43 INS43 MOV8 INS42 INS42 INS83 INS43 INS42 INS43 INS43 MOV8 INS43 INS5 INS31 INS42 INS42 INS78 INS83 INS43 INS42 INS43 INS43 MOV8 INS42 INS42 INS78 INS83 INS43 INS42 INS43 INS43 MOV8 INS42 INS42 INS78 INS83 INS43 INS42 INS43 INS43 MOV8 INS42 INS43 INS85 INS83 INS5 INS42 INS43 INS43 MOV8 INS42 INS43 INS85 INS83 INS5 INS42 INS43 INS43 MOV8 INS42 INS43 INS85 INS83 INS5 INS42 INS43 INS43 MOV8 INS43 INS43 INS31 INS43 INS43 INS31 INS43 INS5 INS31 INS42 INS42 INS42 INS42 INS78 INS83 INS43 INS42 MOV43 MOV43 INS43 INS8 INS42 INS42 INS42 INS42 INS42 INS43 INS85 INS83 MOV5 INS42 INS43 INS43 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS85 INS42 INS42 INS42 INS43 INS85 INS42 INS42 INS42 INS43 INS85 INS42 INS42 INS42 INS42 INS78 INS83 INS43 INS42 INS43 INS43 INS8 INS42 MOV42 INS83 INS43 INS42 INS43 INS43 INS8 INS42 INS43 INS85 INS83 MOV5 INS42 INS43 INS43 INS8 INS42 INS42 INS42 MOV60 MOV21 INS41 INS40 INS42 INS42 INS41 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS41 INS42 INS42 INS42 INS41 INS40 INS42 INS42 INS41 INS42 MOV32 MOV32 MOV32 MOV32 DEL42 DEL44 DEL45 DEL42 DEL14 DEL53 DEL8 DEL12 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL44 DEL42 DEL59