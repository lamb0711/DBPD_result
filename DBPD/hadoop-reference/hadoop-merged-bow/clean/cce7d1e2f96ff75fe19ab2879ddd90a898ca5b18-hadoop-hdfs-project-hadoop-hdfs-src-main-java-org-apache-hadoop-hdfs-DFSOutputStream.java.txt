Merge remote-tracking branch 'origin/trunk' into MR-2841

Conflicts:
	hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java

+import org.apache.hadoop.crypto.CipherSuite;
+import org.apache.hadoop.fs.FileEncryptionInfo;
-  
+  private FileEncryptionInfo fileEncryptionInfo;
+
-        resetChecksumChunk(freeInCksum);
+        setChecksumBufSize(freeInCksum);
-          addDatanode2ExistingPipeline();
+          try {
+            addDatanode2ExistingPipeline();
+          } catch(IOException ioe) {
+            if (!dfsClient.dtpReplaceDatanodeOnFailure.isBestEffort()) {
+              throw ioe;
+            }
+            DFSClient.LOG.warn("Failed to replace datanode."
+                + " Continue with the remaining datanodes since "
+                + DFSConfigKeys.DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_BEST_EFFORT_KEY
+                + " is set to true.", ioe);
+          }
+
+          // We cannot change the block length in 'block' as it counts the number
+          // of bytes ack'ed.
+          ExtendedBlock blockCopy = new ExtendedBlock(block);
+          blockCopy.setNumBytes(blockSize);
+
-          new Sender(out).writeBlock(block, nodeStorageTypes[0], accessToken,
+          new Sender(out).writeBlock(blockCopy, nodeStorageTypes[0], accessToken,
-    super(checksum, checksum.getBytesPerChecksum(), checksum.getChecksumSize());
+    super(checksum);
+    this.fileEncryptionInfo = stat.getFileEncryptionInfo();
-      DataChecksum checksum, String[] favoredNodes) throws IOException {
+      DataChecksum checksum, String[] favoredNodes,
+      List<CipherSuite> cipherSuites) throws IOException {
-          blockSize);
+          blockSize, cipherSuites);
-                                     SnapshotAccessControlException.class);
+                                     SnapshotAccessControlException.class,
+                                     UnknownCipherSuiteException.class);
-  static DFSOutputStream newStreamForCreate(DFSClient dfsClient, String src,
-      FsPermission masked, EnumSet<CreateFlag> flag, boolean createParent,
-      short replication, long blockSize, Progressable progress, int buffersize,
-      DataChecksum checksum) throws IOException {
-    return newStreamForCreate(dfsClient, src, masked, flag, createParent, replication,
-        blockSize, progress, buffersize, checksum, null);
-  }
-
+    this.fileEncryptionInfo = stat.getFileEncryptionInfo();
-  protected synchronized void writeChunk(byte[] b, int offset, int len, byte[] checksum) 
-                                                        throws IOException {
+  protected synchronized void writeChunk(byte[] b, int offset, int len,
+      byte[] checksum, int ckoff, int cklen) throws IOException {
-    int cklen = checksum.length;
-    if (checksum.length != this.checksum.getChecksumSize()) {
+    if (cklen != this.checksum.getChecksumSize()) {
-                            " but found to be " + checksum.length);
+                            " but found to be " + cklen);
-    currentPacket.writeChecksum(checksum, 0, cklen);
+    currentPacket.writeChecksum(checksum, ckoff, cklen);
-        resetChecksumChunk(bytesPerChecksum);
+        resetChecksumBufSize();
-        /* Record current blockOffset. This might be changed inside
-         * flushBuffer() where a partial checksum chunk might be flushed.
-         * After the flush, reset the bytesCurBlock back to its previous value,
-         * any partial checksum chunk will be sent now and in next packet.
-         */
-        long saveOffset = bytesCurBlock;
-        Packet oldCurrentPacket = currentPacket;
-        flushBuffer(true);
+        int numKept = flushBuffer(true, true);
-            "DFSClient flush() : saveOffset " + saveOffset +  
+            "DFSClient flush() :" +
-          // We already flushed up to this offset.
-          // This means that we haven't written anything since the last flush
-          // (or the beginning of the file). Hence, we should not have any
-          // packet queued prior to this call, since the last flush set
-          // currentPacket = null.
-          assert oldCurrentPacket == null :
-            "Empty flush should not occur with a currentPacket";
-
-        bytesCurBlock = saveOffset;
+        bytesCurBlock -= numKept;
-          Thread.sleep(localTimeout);
+          Thread.sleep(localTimeout);
-  long getInitialLen() {
+  public long getInitialLen() {
+   * @return the FileEncryptionInfo for this stream, or null if not encrypted.
+   */
+  public FileEncryptionInfo getFileEncryptionInfo() {
+    return fileEncryptionInfo;
+  }
+
+  /**

INS26 INS26 INS40 INS40 INS23 INS31 INS83 INS43 INS59 INS44 INS44 INS44 INS83 INS29 INS83 INS43 INS42 MOV8 UPD42 MOV42 INS42 INS46 INS21 INS74 INS42 INS21 INS39 INS42 INS39 INS42 INS65 UPD42 MOV42 MOV42 INS7 INS43 INS43 INS7 UPD27 MOV27 INS66 INS42 INS22 INS32 INS42 INS42 INS22 INS32 INS42 INS42 INS25 INS52 INS42 UPD42 MOV42 UPD42 MOV42 INS52 INS42 INS42 INS42 MOV32 INS8 UPD27 MOV27 INS60 UPD42 INS54 INS60 INS21 INS42 INS57 INS45 INS45 INS42 UPD39 MOV39 INS59 UPD7 MOV21 MOV8 INS12 INS43 INS59 INS32 INS43 UPD42 INS42 INS32 UPD42 INS44 INS8 INS42 INS42 INS14 INS42 INS42 INS42 UPD42 INS42 MOV42 MOV9 INS9 MOV43 INS42 MOV25 INS21 INS43 INS42 INS38 INS8 INS32 INS42 INS27 INS32 INS53 INS40 INS42 INS27 INS42 UPD45 MOV45 MOV45 INS40 INS42 INS42 INS27 INS40 INS45 INS45 INS45 DEL42 DEL42 DEL32 DEL32 DEL46 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL43 DEL74 DEL42 DEL44 DEL39 DEL42 DEL44 DEL39 DEL42 DEL44 DEL39 DEL42 DEL44 DEL43 DEL42 DEL44 DEL39 DEL42 DEL44 DEL42 DEL43 DEL42 DEL44 DEL31 DEL39 DEL42 DEL40 DEL59 DEL60 DEL45 DEL45 DEL40 DEL40 DEL34 DEL42 DEL42 DEL42 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL59 DEL60 DEL32 DEL21 DEL42 DEL42 DEL33 DEL27 DEL45 DEL6 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL33 DEL32