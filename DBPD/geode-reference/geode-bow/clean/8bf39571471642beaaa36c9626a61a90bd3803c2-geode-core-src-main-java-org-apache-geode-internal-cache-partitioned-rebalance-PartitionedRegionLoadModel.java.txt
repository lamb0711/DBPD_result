Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * A model of the load on all of the members for a partitioned region. This
- * model is used to find the best members to create buckets on or move buckets
- * or primaries too. All of the actual work of creating a copy, moving a
- * primary, etc. Is performed by the BucketOperator that is passed to the
+ * A model of the load on all of the members for a partitioned region. This model is used to find
+ * the best members to create buckets on or move buckets or primaries too. All of the actual work of
+ * creating a copy, moving a primary, etc. Is performed by the BucketOperator that is passed to the
- * To use, create a model and populate it using the addMember method. addMember
- * takes a region argument, to indicate which region the data is for. All of the
- * regions added to a single model are assumed to be colocated, and the model
- * adds together the load from each of the individual regions to balance all of
- * the regions together.
+ * To use, create a model and populate it using the addMember method. addMember takes a region
+ * argument, to indicate which region the data is for. All of the regions added to a single model
+ * are assumed to be colocated, and the model adds together the load from each of the individual
+ * regions to balance all of the regions together.
- * Reblancing operations are performed by repeatedly calling model.nextStep
- * until it returns false. Each call to nextStep should perform another
- * operation. The model will make callbacks to the BucketOperator you provide to
- * the contructor perform the actual create or move.
+ * Reblancing operations are performed by repeatedly calling model.nextStep until it returns false.
+ * Each call to nextStep should perform another operation. The model will make callbacks to the
+ * BucketOperator you provide to the contructor perform the actual create or move.
- * While creating redundant copies our moving buckets, this model tries to
- * minimize the standard deviation in the weighted loads for the members. The
- * weighted load for the member is the sum of the load for all of the buckets on
- * the member divided by that members weight.
+ * While creating redundant copies our moving buckets, this model tries to minimize the standard
+ * deviation in the weighted loads for the members. The weighted load for the member is the sum of
+ * the load for all of the buckets on the member divided by that members weight.
-  
+
-   * A comparator that is used to sort buckets in the order
-   * that we should satisfy redundancy - most needy buckets first.
+   * A comparator that is used to sort buckets in the order that we should satisfy redundancy - most
+   * needy buckets first.
-   * A member to represent inconsistent data. For example, if two members think
-   * they are the primary for a bucket, we will set the primary to invalid, so it won't
-   * be a candidate for rebalancing.
+   * A member to represent inconsistent data. For example, if two members think they are the primary
+   * for a bucket, we will set the primary to invalid, so it won't be a candidate for rebalancing.
-  
+
-  
+
-  private final Map<InternalDistributedMember, MemberRollup> members = new HashMap<InternalDistributedMember, MemberRollup>();
-  
+  private final Map<InternalDistributedMember, MemberRollup> members =
+      new HashMap<InternalDistributedMember, MemberRollup>();
+
-  private final Set<String> allColocatedRegions= new HashSet<String>();
-  
+  private final Set<String> allColocatedRegions = new HashSet<String>();
+
-  private SortedSet<BucketRollup> lowRedundancyBuckets= null;
-  private SortedSet<BucketRollup> overRedundancyBuckets= null;
+  private SortedSet<BucketRollup> lowRedundancyBuckets = null;
+  private SortedSet<BucketRollup> overRedundancyBuckets = null;
-  
+
-  /**The average primary load on a member */
+  /** The average primary load on a member */
-  /**The average bucket load on a member */
+  /** The average bucket load on a member */
-   * The minimum improvement in variance that we'll consider worth moving a
-   * primary
+   * The minimum improvement in variance that we'll consider worth moving a primary
-   * The minimum improvement in variance that we'll consider worth moving a
-   * bucket
+   * The minimum improvement in variance that we'll consider worth moving a bucket
-  
+
+   * 
-  public PartitionedRegionLoadModel(BucketOperator operator,
-      int redundancyLevel, int numBuckets, AddressComparor addressComparor,
-      Set<InternalDistributedMember> criticalMembers, PartitionedRegion region) {
+  public PartitionedRegionLoadModel(BucketOperator operator, int redundancyLevel, int numBuckets,
+      AddressComparor addressComparor, Set<InternalDistributedMember> criticalMembers,
+      PartitionedRegion region) {
-  
+
-   * Add a region to the model. All regions that are added are assumed to be colocated.
-   * The first region added to the model should be the parent region. The parent region
-   * is expected to have at least as many members as child regions; it may have more. If
-   * the parent has more members than child regions those members will be considered invalid.
+   * Add a region to the model. All regions that are added are assumed to be colocated. The first
+   * region added to the model should be the parent region. The parent region is expected to have at
+   * least as many members as child regions; it may have more. If the parent has more members than
+   * child regions those members will be considered invalid.
+   * 
-   * @param offlineDetails 
+   * @param offlineDetails
-      Collection<? extends InternalPartitionDetails> memberDetailSet, 
-      OfflineMemberDetails offlineDetails,
-      boolean enforceLocalMaxMemory) {
+      Collection<? extends InternalPartitionDetails> memberDetailSet,
+      OfflineMemberDetails offlineDetails, boolean enforceLocalMaxMemory) {
-    //build up a list of members and an array of buckets for this
-    //region. Each bucket has a reference to all of the members
-    //that host it and each member has a reference to all of the buckets
-    //it hosts
-    Map<InternalDistributedMember, Member> regionMember = new HashMap<InternalDistributedMember, Member>();
+    // build up a list of members and an array of buckets for this
+    // region. Each bucket has a reference to all of the members
+    // that host it and each member has a reference to all of the buckets
+    // it hosts
+    Map<InternalDistributedMember, Member> regionMember =
+        new HashMap<InternalDistributedMember, Member>();
-    for(InternalPartitionDetails memberDetails : memberDetailSet) {
-      InternalDistributedMember memberId = (InternalDistributedMember) memberDetails.getDistributedMember();
+    for (InternalPartitionDetails memberDetails : memberDetailSet) {
+      InternalDistributedMember memberId =
+          (InternalDistributedMember) memberDetails.getDistributedMember();
-      Member member = new Member(memberId,
-          memberDetails.getPRLoad().getWeight(), memberDetails.getConfiguredMaxMemory(), isCritical, enforceLocalMaxMemory);
+      Member member = new Member(memberId, memberDetails.getPRLoad().getWeight(),
+          memberDetails.getConfiguredMaxMemory(), isCritical, enforceLocalMaxMemory);
-      for(int i = 0; i < regionBuckets.length; i++) {
-        if(load.getReadLoad(i) > 0) {
+      for (int i = 0; i < regionBuckets.length; i++) {
+        if (load.getReadLoad(i) > 0) {
-          if(bucket == null) {
+          if (bucket == null) {
-            bucket = new Bucket(i, load.getReadLoad(i), memberDetails.getBucketSize(i), offlineMembers);
+            bucket =
+                new Bucket(i, load.getReadLoad(i), memberDetails.getBucketSize(i), offlineMembers);
-          if(load.getWriteLoad(i) > 0) {
-            if(bucket.getPrimary() == null) {
+          if (load.getWriteLoad(i) > 0) {
+            if (bucket.getPrimary() == null) {
-            } else if(!bucket.getPrimary().equals(member)) {
+            } else if (!bucket.getPrimary().equals(member)) {
-    
-    //add each member for this region to a rollup of all colocated
-    //regions
-    for(Member member: regionMember.values()) {
+
+    // add each member for this region to a rollup of all colocated
+    // regions
+    for (Member member : regionMember.values()) {
-      if(memberSum == null) {
+      if (memberSum == null) {
-      } 
-      
+      }
+
-    
-    //Now, add the region to the rollups of the colocated
-    //regions and buckets
-    for(int i =0; i < this.buckets.length; i++) {
-      if(regionBuckets[i] == null) {
-        //do nothing, this bucket is not hosted for this region.
+
+    // Now, add the region to the rollups of the colocated
+    // regions and buckets
+    for (int i = 0; i < this.buckets.length; i++) {
+      if (regionBuckets[i] == null) {
+        // do nothing, this bucket is not hosted for this region.
-      if(this.buckets[i]==null) {
-        //If this is the first region we have seen that is hosting this bucket, create a bucket rollup
+      if (this.buckets[i] == null) {
+        // If this is the first region we have seen that is hosting this bucket, create a bucket
+        // rollup
-      
-      //Add all of the members hosting the bucket to the rollup
-      for(Member member: regionBuckets[i].getMembersHosting()) {
+
+      // Add all of the members hosting the bucket to the rollup
+      for (Member member : regionBuckets[i].getMembersHosting()) {
-      
-      //set the primary for the rollup
-      if(regionBuckets[i].getPrimary() != null) {
-        if(this.buckets[i].getPrimary() == null) {
+
+      // set the primary for the rollup
+      if (regionBuckets[i].getPrimary() != null) {
+        if (this.buckets[i].getPrimary() == null) {
-        }
-        else{
-          if(!(this.buckets[i].getPrimary() == INVALID_MEMBER)){
-            if (!this.buckets[i].getPrimary().getDistributedMember().equals(
-                regionBuckets[i].getPrimary().getDistributedMember())) {
+        } else {
+          if (!(this.buckets[i].getPrimary() == INVALID_MEMBER)) {
+            if (!this.buckets[i].getPrimary().getDistributedMember()
+                .equals(regionBuckets[i].getPrimary().getDistributedMember())) {
-                logger.debug("PartitionedRegionLoadModel - Setting bucket {} to INVALID because it is the primary on two members.This could just be a race in the collocation of data. member1={} member2={}",
+                logger.debug(
+                    "PartitionedRegionLoadModel - Setting bucket {} to INVALID because it is the primary on two members.This could just be a race in the collocation of data. member1={} member2={}",
-    
-    //TODO rebalance - there is a possibility of adding members
-    //back here, which I don't like. I think maybe all of the regions should be in the
-    //constructor for the load model, and then when the constructor is done
-    //we can do with validation.
-    //If any members don't have this new region, remove them.
-    for(Iterator<Entry<InternalDistributedMember, MemberRollup>> itr = members.entrySet().iterator();itr.hasNext();) {
+
+    // TODO rebalance - there is a possibility of adding members
+    // back here, which I don't like. I think maybe all of the regions should be in the
+    // constructor for the load model, and then when the constructor is done
+    // we can do with validation.
+    // If any members don't have this new region, remove them.
+    for (Iterator<Entry<InternalDistributedMember, MemberRollup>> itr =
+        members.entrySet().iterator(); itr.hasNext();) {
-      if(!memberRollup.getColocatedMembers().keySet().equals(this.allColocatedRegions)) {
+      if (!memberRollup.getColocatedMembers().keySet().equals(this.allColocatedRegions)) {
-        if(logger.isDebugEnabled()) {
-          logger.debug("PartitionedRegionLoadModel - removing member {} from the consideration because it doesn't have all of the colocated regions. Expected={}, was={}",
+        if (logger.isDebugEnabled()) {
+          logger.debug(
+              "PartitionedRegionLoadModel - removing member {} from the consideration because it doesn't have all of the colocated regions. Expected={}, was={}",
-        //This state should never happen
-        if(!memberRollup.getBuckets().isEmpty()) {
-          logger.warn(LocalizedMessage.create(LocalizedStrings.PartitionedRegionLoadModel_INCOMPLETE_COLOCATION,
-              new Object[] { memberRollup, this.allColocatedRegions, memberRollup.getColocatedMembers().keySet(), memberRollup.getBuckets() }));
+        // This state should never happen
+        if (!memberRollup.getBuckets().isEmpty()) {
+          logger.warn(LocalizedMessage.create(
+              LocalizedStrings.PartitionedRegionLoadModel_INCOMPLETE_COLOCATION,
+              new Object[] {memberRollup, this.allColocatedRegions,
+                  memberRollup.getColocatedMembers().keySet(), memberRollup.getBuckets()}));
-        for(Bucket bucket: new HashSet<Bucket>(memberRollup.getBuckets())) {
+        for (Bucket bucket : new HashSet<Bucket>(memberRollup.getBuckets())) {
-  
+
-  
+
-  
+
-  public void setOverRedundancyBuckets(
-      SortedSet<BucketRollup> overRedundancyBuckets) {
+  public void setOverRedundancyBuckets(SortedSet<BucketRollup> overRedundancyBuckets) {
-  
+
-  
+
-  
+
-  
+
-  
+
-  
+
-    //TODO - this model really should not have
-    //a reference to the partitioned region object.
-    //The fixed PR code currently depends on this
-    //partitioned region object and needs
-    //refactoring.
+    // TODO - this model really should not have
+    // a reference to the partitioned region object.
+    // The fixed PR code currently depends on this
+    // partitioned region object and needs
+    // refactoring.
-    
-    for (Map.Entry<String, Bucket> entry : bucket.getColocatedBuckets()
-        .entrySet()) {
-      colocatedRegionSizes.put(entry.getKey(),
-          Long.valueOf(entry.getValue().getBytes()));
+
+    for (Map.Entry<String, Bucket> entry : bucket.getColocatedBuckets().entrySet()) {
+      colocatedRegionSizes.put(entry.getKey(), Long.valueOf(entry.getValue().getBytes()));
-   * This method will find the best node to create a redundant bucket and 
-   * invoke the bucket operator to create a bucket on that node. Because the bucket
-   * operator is asynchronous, the bucket may not be created immediately, but
-   * the model will be updated regardless. Invoke {@link #waitForOperations()}
-   * to wait for those operations to actually complete
+   * This method will find the best node to create a redundant bucket and invoke the bucket operator
+   * to create a bucket on that node. Because the bucket operator is asynchronous, the bucket may
+   * not be created immediately, but the model will be updated regardless. Invoke
+   * {@link #waitForOperations()} to wait for those operations to actually complete
-  public void createRedundantBucket(final BucketRollup bucket,
-      final Member targetMember) {
+  public void createRedundantBucket(final BucketRollup bucket, final Member targetMember) {
-    
-      this.lowRedundancyBuckets.remove(bucket);
-      bucket.addMember(targetMember);
-      //put the bucket back into the list if we still need to satisfy redundancy for
-      //this bucket
-      if(bucket.getRedundancy() < this.requiredRedundancy) {
-        this.lowRedundancyBuckets.add(bucket);
-      }
-      resetAverages();
-    
-    this.operator.createRedundantBucket(targetMember.getMemberId(), bucket.getId(), colocatedRegionSizes, new BucketOperator.Completion() {
-      @Override
-      public void onSuccess() {
+
+    this.lowRedundancyBuckets.remove(bucket);
+    bucket.addMember(targetMember);
+    // put the bucket back into the list if we still need to satisfy redundancy for
+    // this bucket
+    if (bucket.getRedundancy() < this.requiredRedundancy) {
+      this.lowRedundancyBuckets.add(bucket);
+    resetAverages();
-      @Override
-      public void onFailure() {
-        //If the bucket creation failed, we need to undo the changes
-        //we made to the model
-        attemptedBucketCreations.add(move);
-        //remove the bucket from lowRedundancyBuckets before mutating the state
-        lowRedundancyBuckets.remove(bucket);
-        bucket.removeMember(targetMember);
-        if(bucket.getRedundancy() < requiredRedundancy) {
-          lowRedundancyBuckets.add(bucket);
-        }
-        resetAverages();
-      }
-    });
+    this.operator.createRedundantBucket(targetMember.getMemberId(), bucket.getId(),
+        colocatedRegionSizes, new BucketOperator.Completion() {
+          @Override
+          public void onSuccess() {}
+
+          @Override
+          public void onFailure() {
+            // If the bucket creation failed, we need to undo the changes
+            // we made to the model
+            attemptedBucketCreations.add(move);
+            // remove the bucket from lowRedundancyBuckets before mutating the state
+            lowRedundancyBuckets.remove(bucket);
+            bucket.removeMember(targetMember);
+            if (bucket.getRedundancy() < requiredRedundancy) {
+              lowRedundancyBuckets.add(bucket);
+            }
+            resetAverages();
+          }
+        });
-  
-  
-  protected void remoteOverRedundancyBucket(BucketRollup bucket,
-      Member targetMember) {
-    
+
+
+  protected void remoteOverRedundancyBucket(BucketRollup bucket, Member targetMember) {
+
-    
-    if(!this.operator.removeBucket(targetMember.getMemberId(), bucket.getId(), colocatedRegionSizes)) {
+
+    if (!this.operator.removeBucket(targetMember.getMemberId(), bucket.getId(),
+        colocatedRegionSizes)) {
-      //put the bucket back into the list if we still need to satisfy redundancy for
-      //this bucket
-      if(bucket.getOnlineRedundancy() > this.requiredRedundancy) {
+      // put the bucket back into the list if we still need to satisfy redundancy for
+      // this bucket
+      if (bucket.getOnlineRedundancy() > this.requiredRedundancy) {
-  
+
-    for(BucketRollup b: this.buckets) {
-      if(b != null && b.getRedundancy() >= 0 && b.getRedundancy() < this.requiredRedundancy) {
+    for (BucketRollup b : this.buckets) {
+      if (b != null && b.getRedundancy() >= 0 && b.getRedundancy() < this.requiredRedundancy) {
-  
+
-    for(BucketRollup b: this.buckets) {
-      if(b != null && b.getOnlineRedundancy() > this.requiredRedundancy) {
+    for (BucketRollup b : this.buckets) {
+      if (b != null && b.getOnlineRedundancy() > this.requiredRedundancy) {
-   * @param bucket
-   *          the bucket we want to create
-   * @param checkIPAddress
-   *          true if we should only consider members that do not have the same
-   *          IP Address as a member that already hosts the bucket
+   * @param bucket the bucket we want to create
+   * @param checkIPAddress true if we should only consider members that do not have the same IP
+   *        Address as a member that already hosts the bucket
-    
+
-        float cost = (member.getTotalLoad() + bucket.getLoad())
-            / member.getWeight();
+        float cost = (member.getTotalLoad() + bucket.getLoad()) / member.getWeight();
-  
+
-   * @param bucket
-   *          the bucket we want to create
+   * @param bucket the bucket we want to create
-    
+
-      float newLoad = (member.getTotalLoad() - bucket.getLoad())
-      / member.getWeight();
-      if (newLoad > mostLoaded && ! member.equals(bucket.getPrimary())) {
+      float newLoad = (member.getTotalLoad() - bucket.getLoad()) / member.getWeight();
+      if (newLoad > mostLoaded && !member.equals(bucket.getPrimary())) {
-    List<FixedPartitionAttributesImpl> fpas = this.partitionedRegion
-        .getFixedPartitionAttributesImpl();
-    
+    List<FixedPartitionAttributesImpl> fpas =
+        this.partitionedRegion.getFixedPartitionAttributesImpl();
+
-          targetMemberID = this.partitionedRegion.getDistributionManager()
-              .getDistributionManagerId();
+          targetMemberID =
+              this.partitionedRegion.getDistributionManager().getDistributionManagerId();
-    
+
-    boolean successfulMove = this.operator.movePrimary(bestSource.getDistributedMember(), bestTarget
-        .getDistributedMember(), bestBucket.getId());
+    boolean successfulMove = this.operator.movePrimary(bestSource.getDistributedMember(),
+        bestTarget.getDistributedMember(), bestBucket.getId());
-    if(successfulMove) {
+    if (successfulMove) {
-    boolean entryAdded  = this.attemptedPrimaryMoves.add(bestMove);
-    Assert
-    .assertTrue(entryAdded,
+    boolean entryAdded = this.attemptedPrimaryMoves.add(bestMove);
+    Assert.assertTrue(entryAdded,
-    
+
-    Move bestMove= null;
+    Move bestMove = null;
-    for(Member source: this.members.values()) {
-      for(Bucket bucket: source.getPrimaryBuckets()) {
-        for(Member target: bucket.getMembersHosting()) {
-          if(source.equals(target)) {
+    for (Member source : this.members.values()) {
+      for (Bucket bucket : source.getPrimaryBuckets()) {
+        for (Member target : bucket.getMembersHosting()) {
+          if (source.equals(target)) {
-          double improvement = improvement(source.getPrimaryLoad(), source
-              .getWeight(), target.getPrimaryLoad(), target.getWeight(), bucket.getPrimaryLoad(),
-              getPrimaryAverage());
+          double improvement =
+              improvement(source.getPrimaryLoad(), source.getWeight(), target.getPrimaryLoad(),
+                  target.getWeight(), bucket.getPrimaryLoad(), getPrimaryAverage());
-   * Move all primary from other to this 
+   * Move all primary from other to this
-    List<FixedPartitionAttributesImpl> FPAs = this.partitionedRegion
-        .getFixedPartitionAttributesImpl();
-    InternalDistributedMember targetId = this.partitionedRegion
-        .getDistributionManager().getId();
+    List<FixedPartitionAttributesImpl> FPAs =
+        this.partitionedRegion.getFixedPartitionAttributesImpl();
+    InternalDistributedMember targetId = this.partitionedRegion.getDistributionManager().getId();
-              InternalDistributedMember srcDM = (source == null || source == INVALID_MEMBER) ? target
-                  .getDistributedMember() : source.getDistributedMember();
+              InternalDistributedMember srcDM = (source == null || source == INVALID_MEMBER)
+                  ? target.getDistributedMember() : source.getDistributedMember();
-                logger.debug("PRLM#movePrimariesForFPR: For Bucket#{}, moving primary from source {} to target {}",
+                logger.debug(
+                    "PRLM#movePrimariesForFPR: For Bucket#{}, moving primary from source {} to target {}",
-              boolean successfulMove = this.operator.movePrimary(srcDM,
-                  target.getDistributedMember(), bucket.getId());
+              boolean successfulMove =
+                  this.operator.movePrimary(srcDM, target.getDistributedMember(), bucket.getId());
-                  logger.debug("PRLM#movePrimariesForFPR: For Bucket#{}, moving primary source {} to target {}",
+                  logger.debug(
+                      "PRLM#movePrimariesForFPR: For Bucket#{}, moving primary source {} to target {}",
-              } 
+              }
-    if(this.primaryAverage == -1) {
+    if (this.primaryAverage == -1) {
-      for(Member member : this.members.values()) {
+      for (Member member : this.members.values()) {
-      
+
-    
+
-  
+
-    if(this.averageLoad == -1) {
+    if (this.averageLoad == -1) {
-      for(Member member : this.members.values()) {
+      for (Member member : this.members.values()) {
-      
+
-    
+
-   * Calculate the minimum improvement in variance that will we consider worth
-   * while. Currently this is calculated as the improvement in variance that
-   * would occur by removing the smallest bucket from the member with the
-   * largest weight.
+   * Calculate the minimum improvement in variance that will we consider worth while. Currently this
+   * is calculated as the improvement in variance that would occur by removing the smallest bucket
+   * from the member with the largest weight.
-    if((this.minPrimaryImprovement + 1.0) < .0000001) { // i.e. == -1
+    if ((this.minPrimaryImprovement + 1.0) < .0000001) { // i.e. == -1
-      for(Member member : this.members.values()) {
-        if(member.getWeight() > largestWeight) {
+      for (Member member : this.members.values()) {
+        if (member.getWeight() > largestWeight) {
-        for(Bucket bucket: member.getPrimaryBuckets()) {
-          if(bucket.getPrimaryLoad() < smallestBucket || smallestBucket == 0) {
+        for (Bucket bucket : member.getPrimaryBuckets()) {
+          if (bucket.getPrimaryLoad() < smallestBucket || smallestBucket == 0) {
-      double before = variance(getPrimaryAverage() * largestWeight
-          + smallestBucket, largestWeight, getPrimaryAverage());
-      double after = variance(getPrimaryAverage() * largestWeight,
-          largestWeight, getPrimaryAverage());
+      double before = variance(getPrimaryAverage() * largestWeight + smallestBucket, largestWeight,
+          getPrimaryAverage());
+      double after =
+          variance(getPrimaryAverage() * largestWeight, largestWeight, getPrimaryAverage());
-  
+
-   * Calculate the minimum improvement in variance that will we consider worth
-   * while. Currently this is calculated as the improvement in variance that
-   * would occur by removing the smallest bucket from the member with the
-   * largest weight.
+   * Calculate the minimum improvement in variance that will we consider worth while. Currently this
+   * is calculated as the improvement in variance that would occur by removing the smallest bucket
+   * from the member with the largest weight.
-    if((this.minImprovement + 1.0) < .0000001) { // i.e. == -1
+    if ((this.minImprovement + 1.0) < .0000001) { // i.e. == -1
-      for(Member member : this.members.values()) {
-        if(member.getWeight() > largestWeight) {
+      for (Member member : this.members.values()) {
+        if (member.getWeight() > largestWeight) {
-        //find the smallest bucket, ignoring empty buckets.
-        for(Bucket bucket: member.getBuckets()) {
-          if(smallestBucket == 0 || (bucket.getLoad() < smallestBucket && bucket.getBytes() > 0) ) {
+        // find the smallest bucket, ignoring empty buckets.
+        for (Bucket bucket : member.getBuckets()) {
+          if (smallestBucket == 0 || (bucket.getLoad() < smallestBucket && bucket.getBytes() > 0)) {
-      double before = variance(getAverageLoad() * largestWeight
-          + smallestBucket, largestWeight, getAverageLoad());
-      double after = variance(getAverageLoad() * largestWeight,
-          largestWeight, getAverageLoad());
+      double before = variance(getAverageLoad() * largestWeight + smallestBucket, largestWeight,
+          getAverageLoad());
+      double after = variance(getAverageLoad() * largestWeight, largestWeight, getAverageLoad());
-  
+
-   * @param sLoad
-   *          the current load on the source member
-   * @param sWeight
-   *          the weight of the source member
-   * @param tLoad
-   *          the current load on the target member
-   * @param tWeight
-   *          the weight of the target member
-   * @param bucketSize
-   *          the size of the bucket we're considering moving
-   * @param average
-   *          the target weighted load for all members.
-   * @return the change in variance that would occur by making this move.
-   *         Essentially variance_before - variance_after, so a positive change
-   *         is a means the variance is decreasing.
+   * @param sLoad the current load on the source member
+   * @param sWeight the weight of the source member
+   * @param tLoad the current load on the target member
+   * @param tWeight the weight of the target member
+   * @param bucketSize the size of the bucket we're considering moving
+   * @param average the target weighted load for all members.
+   * @return the change in variance that would occur by making this move. Essentially
+   *         variance_before - variance_after, so a positive change is a means the variance is
+   *         decreasing.
-  private double improvement(float sLoad, float sWeight,
-      float tLoad, float tWeight, float bucketSize, float average) {
-    
+  private double improvement(float sLoad, float sWeight, float tLoad, float tWeight,
+      float bucketSize, float average) {
+
-    double vTargetAfter  = variance(tLoad + bucketSize, tWeight, average);
-    
+    double vTargetAfter = variance(tLoad + bucketSize, tWeight, average);
+
-  
+
-    double deviation = (load / weight - average) ;
+    double deviation = (load / weight - average);
-    Move bestMove= null;
+    Move bestMove = null;
-    for(Member source: this.members.values()) {
-      for(Bucket bucket: source.getBuckets()) {
-        for(Member target: this.members.values()) {
-          if(bucket.getMembersHosting().contains(target)) {
+    for (Member source : this.members.values()) {
+      for (Bucket bucket : source.getBuckets()) {
+        for (Member target : this.members.values()) {
+          if (bucket.getMembersHosting().contains(target)) {
-          if(!target.willAcceptBucket(bucket, source, true).willAccept()) {
+          if (!target.willAcceptBucket(bucket, source, true).willAccept()) {
-          double improvement = improvement(source.getTotalLoad(), source
-              .getWeight(), target.getTotalLoad(), target.getWeight(), bucket.getLoad(),
-              getAverageLoad());
+          double improvement = improvement(source.getTotalLoad(), source.getWeight(),
+              target.getTotalLoad(), target.getWeight(), bucket.getLoad(), getAverageLoad());
-            if(!this.attemptedBucketMoves.contains(move)) {
+            if (!this.attemptedBucketMoves.contains(move)) {
-    boolean successfulMove = this.operator.moveBucket(bestSource.getDistributedMember(), bestTarget
-        .getDistributedMember(), bestBucket.getId(), colocatedRegionSizes);
+    boolean successfulMove = this.operator.moveBucket(bestSource.getDistributedMember(),
+        bestTarget.getDistributedMember(), bestBucket.getId(), colocatedRegionSizes);
-    if(successfulMove) {
+    if (successfulMove) {
-      if(bestSource.equals(bestBucket.getPrimary())) { 
+      if (bestSource.equals(bestBucket.getPrimary())) {
-    boolean entryAdded  = this.attemptedBucketMoves.add(bestMove);
-    Assert
-    .assertTrue(entryAdded,
+    boolean entryAdded = this.attemptedBucketMoves.add(bestMove);
+    Assert.assertTrue(entryAdded,
-    
+
+   * 
-    TreeSet<PartitionMemberInfo> result = new TreeSet<PartitionMemberInfo>(); 
-    for(MemberRollup member: this.members.values()) {
+    TreeSet<PartitionMemberInfo> result = new TreeSet<PartitionMemberInfo>();
+    for (MemberRollup member : this.members.values()) {
-      if(colocatedMember != null) {
-        result.add(new PartitionMemberInfoImpl(colocatedMember
-            .getDistributedMember(), colocatedMember
-                .getConfiguredMaxMemory(), colocatedMember.getSize(),
-                colocatedMember.getBucketCount(), colocatedMember
-                    .getPrimaryCount()));
+      if (colocatedMember != null) {
+        result.add(new PartitionMemberInfoImpl(colocatedMember.getDistributedMember(),
+            colocatedMember.getConfiguredMaxMemory(), colocatedMember.getSize(),
+            colocatedMember.getBucketCount(), colocatedMember.getPrimaryCount()));
-  
+
-   * For testing only, calculate the total
-   * variance of the members
+   * For testing only, calculate the total variance of the members
-    
-    for(Member member: this.members.values()) {
+
+    for (Member member : this.members.values()) {
-    
+
-  
+
-   * For testing only, calculate the total
-   * variance of the members
+   * For testing only, calculate the total variance of the members
-    
-    for(Member member: this.members.values()) {
+
+    for (Member member : this.members.values()) {
-    
+
-  
+
-   * Wait for the bucket operator to complete
-   * any pending asynchronous operations.
+   * Wait for the bucket operator to complete any pending asynchronous operations.
-  
+
-    if(this.members.isEmpty()) {
+    if (this.members.isEmpty()) {
-    for(Member member: this.members.values()) {
+    for (Member member : this.members.values()) {
-      int memberIdLength = member.getDistributedMember().toString().length(); 
-      if(longestMemberId < memberIdLength)  {
+      int memberIdLength = member.getDistributedMember().toString().length();
+      if (longestMemberId < memberIdLength) {
-    result.append(String.format("%" + longestMemberId + "s primaries size(MB)  max(MB)", "MemberId"));
-    for(Bucket bucket: allBucketIds) {
+    result
+        .append(String.format("%" + longestMemberId + "s primaries size(MB)  max(MB)", "MemberId"));
+    for (Bucket bucket : allBucketIds) {
-    for(Member member: this.members.values()) {
-      result.append(String.format("\n%" + longestMemberId
-          + "s %9.0f %8.2f %8.2f", member
-          .getDistributedMember(), member
-          .getPrimaryLoad(), member.getSize() / (float)MEGABYTES, member
-          .getConfiguredMaxMemory() / (float)MEGABYTES));
-      for(Bucket bucket: allBucketIds) {
+    for (Member member : this.members.values()) {
+      result.append(String.format("\n%" + longestMemberId + "s %9.0f %8.2f %8.2f",
+          member.getDistributedMember(), member.getPrimaryLoad(),
+          member.getSize() / (float) MEGABYTES,
+          member.getConfiguredMaxMemory() / (float) MEGABYTES));
+      for (Bucket bucket : allBucketIds) {
-        if(member.getPrimaryBuckets().contains(bucket)) {
+        if (member.getPrimaryBuckets().contains(bucket)) {
-        } else if(member.getBuckets().contains(bucket)){
+        } else if (member.getBuckets().contains(bucket)) {
-    
-    result.append(String.format("\n%" + longestMemberId
-        + "s                            ", "#offline", 0, 0, 0));
-    for(Bucket bucket: allBucketIds) {
+
+    result.append(String.format("\n%" + longestMemberId + "s                            ",
+        "#offline", 0, 0, 0));
+    for (Bucket bucket : allBucketIds) {
-   
+
-  
+
-   * Represents the sum of all of the colocated regions on a given
-   * member. Also, holds a map of all of the colocated regions
-   * hosted on this member.
+   * Represents the sum of all of the colocated regions on a given member. Also, holds a map of all
+   * of the colocated regions hosted on this member.
-    public MemberRollup(InternalDistributedMember memberId, boolean isCritical, boolean enforceLocalMaxMemory) {
+    public MemberRollup(InternalDistributedMember memberId, boolean isCritical,
+        boolean enforceLocalMaxMemory) {
-    
+
-      if(!getColocatedMembers().containsKey(region)) {
+      if (!getColocatedMembers().containsKey(region)) {
-     * Update the load on this member rollup with a change 
-     * in size of one of the bucket rollups hosted by this member
+     * Update the load on this member rollup with a change in size of one of the bucket rollups
+     * hosted by this member
-      this.totalPrimaryLoad+= primaryLoad;
+      this.totalPrimaryLoad += primaryLoad;
-      if(super.addBucket(bucket)) {
+      if (super.addBucket(bucket)) {
-        for(Map.Entry<String, Member> entry: getColocatedMembers().entrySet()) {
+        for (Map.Entry<String, Member> entry : getColocatedMembers().entrySet()) {
-          if(colocatedBucket != null) {
+          if (colocatedBucket != null) {
-    
+
-      if(super.removeBucket(bucket)) {
+      if (super.removeBucket(bucket)) {
-        for(Map.Entry<String, Member> entry: getColocatedMembers().entrySet()) {
+        for (Map.Entry<String, Member> entry : getColocatedMembers().entrySet()) {
-          if(colocatedBucket != null) {
+          if (colocatedBucket != null) {
-      if(super.addPrimary(bucket)) {
+      if (super.addPrimary(bucket)) {
-        for(Map.Entry<String, Member> entry: getColocatedMembers().entrySet()) {
+        for (Map.Entry<String, Member> entry : getColocatedMembers().entrySet()) {
-          if(colocatedBucket != null) {
+          if (colocatedBucket != null) {
-      if(super.removePrimary(bucket)) {
+      if (super.removePrimary(bucket)) {
-        for(Map.Entry<String, Member> entry: getColocatedMembers().entrySet()) {
+        for (Map.Entry<String, Member> entry : getColocatedMembers().entrySet()) {
-          if(colocatedBucket != null) {
+          if (colocatedBucket != null) {
-      if(reason.willAccept()) {
+      if (reason.willAccept()) {
-        for(Map.Entry<String, Member> entry: getColocatedMembers().entrySet()) {
+        for (Map.Entry<String, Member> entry : getColocatedMembers().entrySet()) {
-          Member colocatedSource = sourceRollup == null ? null
-              : sourceRollup.getColocatedMembers().get(region);
-          if(colocatedBucket != null) {
+          Member colocatedSource =
+              sourceRollup == null ? null : sourceRollup.getColocatedMembers().get(region);
+          if (colocatedBucket != null) {
-            if(!reason.willAccept()) {
+            if (!reason.willAccept()) {
-    
-    
+
+
-   * Represents the sum of all of colocated buckets with
-   * a given bucket id.
+   * Represents the sum of all of colocated buckets with a given bucket id.
-      if(!this.getColocatedBuckets().containsKey(region)) {
+      if (!this.getColocatedBuckets().containsKey(region)) {
-        
-        //Update the load on the members hosting this bucket
-        //to reflect the fact that the bucket is larger now.
-        for(Member member: getMembersHosting()) {
+
+        // Update the load on the members hosting this bucket
+        // to reflect the fact that the bucket is larger now.
+        for (Member member : getMembersHosting()) {
-          if(this.getPrimary() == member) {
+          if (this.getPrimary() == member) {
-          
+
-      
+
-      if(super.addMember(targetMember)) {
+      if (super.addMember(targetMember)) {
-        for(Map.Entry<String, Bucket> entry: getColocatedBuckets().entrySet()) {
+        for (Map.Entry<String, Bucket> entry : getColocatedBuckets().entrySet()) {
-          if(member != null) {
+          if (member != null) {
-    
+
-      if(super.removeMember(targetMember)) {
+      if (super.removeMember(targetMember)) {
-        for(Map.Entry<String, Bucket> entry: getColocatedBuckets().entrySet()) {
+        for (Map.Entry<String, Bucket> entry : getColocatedBuckets().entrySet()) {
-          if(member != null) {
+          if (member != null) {
-      if(targetMember != null) {
+      if (targetMember != null) {
-        for(Map.Entry<String, Bucket> entry: getColocatedBuckets().entrySet()) {
+        for (Map.Entry<String, Bucket> entry : getColocatedBuckets().entrySet()) {
-          if(member != null) {
+          if (member != null) {
-      }
+        }
-  
+
-    
-    public Member(InternalDistributedMember memberId, boolean isCritical, boolean enforceLocalMaxMemory) {
+
+    public Member(InternalDistributedMember memberId, boolean isCritical,
+        boolean enforceLocalMaxMemory) {
-    public Member(InternalDistributedMember memberId, float weight, long localMaxMemory, boolean isCritical, boolean enforceLocalMaxMemory) {
+    public Member(InternalDistributedMember memberId, float weight, long localMaxMemory,
+        boolean isCritical, boolean enforceLocalMaxMemory) {
-     * @param sourceMember
-     *          the member we will be moving this bucket off of
-     * @param checkZone true if we should not put two copies
-     * of a bucket on two nodes with the same IP address.
+     * @param sourceMember the member we will be moving this bucket off of
+     * @param checkZone true if we should not put two copies of a bucket on two nodes with the same
+     *        IP address.
-      //make sure this member is not already hosting this bucket
-      if(getBuckets().contains(bucket)) {
+      // make sure this member is not already hosting this bucket
+      if (getBuckets().contains(bucket)) {
-      //Check the ip address
-      if(checkZone) {
-        //If the source member is equivalent to the target member, go
-        //ahead and allow the bucket move (it's not making our redundancy worse).
-        //TODO we could have some logic to prefer moving to different ip addresses
-        //Probably that logic should be another stage after redundancy recovery, like
-        //improveRedundancy.
+      // Check the ip address
+      if (checkZone) {
+        // If the source member is equivalent to the target member, go
+        // ahead and allow the bucket move (it's not making our redundancy worse).
+        // TODO we could have some logic to prefer moving to different ip addresses
+        // Probably that logic should be another stage after redundancy recovery, like
+        // improveRedundancy.
-            && addressComparor.areSameZone(getMemberId(),
-                sourceMember.getDistributedMember()); 
+            && addressComparor.areSameZone(getMemberId(), sourceMember.getDistributedMember());
-          for(Member hostingMember : bucket.getMembersHosting()) {
+          for (Member hostingMember : bucket.getMembersHosting()) {
-              if(logger.isDebugEnabled()) {
-                logger.debug("Member {} would prefer not to host {} because it is already on another member with the same redundancy zone", this, bucket);
+              if (logger.isDebugEnabled()) {
+                logger.debug(
+                    "Member {} would prefer not to host {} because it is already on another member with the same redundancy zone",
+                    this, bucket);
-      //check the localMaxMemory
-      if(this.enforceLocalMaxMemory && this.totalBytes + bucket.getBytes() > this.localMaxMemory) {
-        if(logger.isDebugEnabled()) {
-          logger.debug("Member {} won't host bucket {} because it doesn't have enough space", this, bucket);
+      // check the localMaxMemory
+      if (this.enforceLocalMaxMemory && this.totalBytes + bucket.getBytes() > this.localMaxMemory) {
+        if (logger.isDebugEnabled()) {
+          logger.debug("Member {} won't host bucket {} because it doesn't have enough space", this,
+              bucket);
-      
-      //check to see if the heap is critical
-      if(isCritical) {
-        if(logger.isDebugEnabled()) {
-          logger.debug("Member {} won't host bucket {} because it's heap is critical",this, bucket);
+
+      // check to see if the heap is critical
+      if (isCritical) {
+        if (logger.isDebugEnabled()) {
+          logger.debug("Member {} won't host bucket {} because it's heap is critical", this,
+              bucket);
-      
+
-      if(getBuckets().add(bucket)) {
+      if (getBuckets().add(bucket)) {
-      } 
+      }
-    
+
-      if(getBuckets().remove(bucket)) {
+      if (getBuckets().remove(bucket)) {
-      } 
+      }
-    
+
-      if(getPrimaryBuckets().remove(bucket)) {
+      if (getPrimaryBuckets().remove(bucket)) {
-      if(getPrimaryBuckets().add(bucket)) {
+      if (getPrimaryBuckets().add(bucket)) {
-      for(Bucket bucket: getBuckets()) {
-        if(this.equals(bucket.primary)) {
+      for (Bucket bucket : getBuckets()) {
+        if (this.equals(bucket.primary)) {
-    
+
-    
+
-    
+
-      return "Member(id=" + getMemberId()+ ")";
+      return "Member(id=" + getMemberId() + ")";
+
-      Member o = (Member)other;
+      Member o = (Member) other;
-    
+
-    
+
-      if(this.primary == INVALID_MEMBER) {
+      if (this.primary == INVALID_MEMBER) {
-      if(this.primary != null) {
+      if (this.primary != null) {
-      if(primary != INVALID_MEMBER && primary != null) {
+      if (primary != INVALID_MEMBER && primary != null) {
-      if(this.getMembersHosting().add(targetMember)) {
+      if (this.getMembersHosting().add(targetMember)) {
-      
+
-    
+
-      if(this.getMembersHosting().remove(targetMember)) {
-        if(targetMember == this.primary) {
+      if (this.getMembersHosting().remove(targetMember)) {
+        if (targetMember == this.primary) {
-    
+
-    
+
-      return "Bucket(id=" + getId() + ",load=" + load +")";
+      return "Bucket(id=" + getId() + ",load=" + load + ")";
-    
+
-    
+
-    
+
+
-      Bucket o = (Bucket)other;
+      Bucket o = (Bucket) other;
+
-  
+
-   * Represents a move from one node to another. Used
-   * to keep track of moves that we have already attempted
-   * that have failed.
+   * Represents a move from one node to another. Used to keep track of moves that we have already
+   * attempted that have failed.
-    
+
-    
-    
+
+
-      result = prime * result
-          + ((this.bucket == null) ? 0 : this.bucket.hashCode());
-      result = prime * result
-          + ((this.source == null) ? 0 : this.source.hashCode());
-      result = prime * result
-          + ((this.target == null) ? 0 : this.target.hashCode());
+      result = prime * result + ((this.bucket == null) ? 0 : this.bucket.hashCode());
+      result = prime * result + ((this.source == null) ? 0 : this.source.hashCode());
+      result = prime * result + ((this.target == null) ? 0 : this.target.hashCode());
-    
+
-    
-    
-    
+
+
+
-  
+
-    
+
+
-   public boolean areSameZone(InternalDistributedMember member1, InternalDistributedMember member2); 
+    public boolean areSameZone(InternalDistributedMember member1,
+        InternalDistributedMember member2);
-  
+
-    NONE,
-    ALREADY_HOSTING, UNITIALIZED_MEMBER,
-    SAME_ZONE,
-    LOCAL_MAX_MEMORY_FULL,
-    CRITICAL_HEAP;
-    
+    NONE, ALREADY_HOSTING, UNITIALIZED_MEMBER, SAME_ZONE, LOCAL_MAX_MEMORY_FULL, CRITICAL_HEAP;
+
-    
+
-      switch(this) {
-      case NONE:
-        return "No reason, the move should be allowed.";
-      case ALREADY_HOSTING:
-        return "Target member " + target.getMemberId()
-            + " is already hosting bucket " + bucket.getId();
-      case UNITIALIZED_MEMBER:
-        return "Target member " + target.getMemberId()
-            + " is not fully initialized";
-      case SAME_ZONE:
-        return "Target member "
-            + target.getMemberId()
-            + " is in the same redundancy zone as other members hosting bucket "
-            + bucket.getId() + ": " + bucket.getMembersHosting();
-      case LOCAL_MAX_MEMORY_FULL:
-        return "Target member " + target.getMemberId()
-            + " does not have space within it's local max memory for bucket "
-            + bucket.getId() + ". Bucket Size " + bucket.getBytes()
-            + " local max memory: " + target.localMaxMemory + " remaining: "
-            + target.totalBytes;
-      case CRITICAL_HEAP:
-        return "Target member "
-            + target.getMemberId()
-            + " has reached its critical heap percentage, and cannot accept more data"; 
-      default:
-        return this.toString();
+      switch (this) {
+        case NONE:
+          return "No reason, the move should be allowed.";
+        case ALREADY_HOSTING:
+          return "Target member " + target.getMemberId() + " is already hosting bucket "
+              + bucket.getId();
+        case UNITIALIZED_MEMBER:
+          return "Target member " + target.getMemberId() + " is not fully initialized";
+        case SAME_ZONE:
+          return "Target member " + target.getMemberId()
+              + " is in the same redundancy zone as other members hosting bucket " + bucket.getId()
+              + ": " + bucket.getMembersHosting();
+        case LOCAL_MAX_MEMORY_FULL:
+          return "Target member " + target.getMemberId()
+              + " does not have space within it's local max memory for bucket " + bucket.getId()
+              + ". Bucket Size " + bucket.getBytes() + " local max memory: " + target.localMaxMemory
+              + " remaining: " + target.totalBytes;
+        case CRITICAL_HEAP:
+          return "Target member " + target.getMemberId()
+              + " has reached its critical heap percentage, and cannot accept more data";
+        default:
+          return this.toString();
