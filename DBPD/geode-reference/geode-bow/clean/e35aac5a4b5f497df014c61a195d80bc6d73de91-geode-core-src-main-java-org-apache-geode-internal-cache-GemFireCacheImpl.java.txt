Merge branch 'release/1.5.0'

+import static org.apache.geode.distributed.internal.InternalDistributedSystem.ALLOW_MULTIPLE_SYSTEMS;
+import static org.apache.geode.distributed.internal.InternalDistributedSystem.getAnyInstance;
+
+import java.util.Objects;
-import java.util.concurrent.atomic.AtomicReference;
-import org.apache.geode.distributed.internal.DM;
+import org.apache.geode.distributed.internal.ClusterDistributionManager;
-import org.apache.geode.internal.cache.backup.BackupManager;
+import org.apache.geode.internal.Version;
+import org.apache.geode.internal.cache.backup.BackupService;
-  /** the last instance of GemFireCache created */
-  private static volatile GemFireCacheImpl instance = null;
-
-  /**
-   * Just like instance but is valid for a bit longer so that pdx can still find the cache during a
-   * close.
-   */
-  private static volatile GemFireCacheImpl pdxInstance = null;
-
+   * Name of the default pool.
+   */
+  public static final String DEFAULT_POOL_NAME = "DEFAULT";
+
+  /**
-  public static final int MAX_QUERY_EXECUTION_TIME =
+  public static int MAX_QUERY_EXECUTION_TIME =
-  /** To test MAX_QUERY_EXECUTION_TIME option. */
-  public int testMaxQueryExecutionTime = -1;
-
-  private final DM dm;
+  private final DistributionManager dm;
-  private final Map<String, LocalRegion> rootRegions;
+  private final Map<String, InternalRegion> rootRegions;
-  private final ConcurrentMap<String, Region<?, ?>> pathToRegion = new ConcurrentHashMap<>();
+  private final ConcurrentMap<String, InternalRegion> pathToRegion = new ConcurrentHashMap<>();
-  private final AtomicReference<BackupManager> backupManager = new AtomicReference<>();
+  private final BackupService backupService;
-    return instance;
-  }
+    InternalDistributedSystem system = InternalDistributedSystem.getAnyInstance();
+    if (system == null) {
+      return null;
+    }
+    GemFireCacheImpl cache = (GemFireCacheImpl) system.getCache();
+    if (cache == null) {
+      return null;
+    }
-  /**
-   * Used for testing, retain the old instance in the test and re-set the value when test completes
-   */
-  public static GemFireCacheImpl setInstanceForTests(GemFireCacheImpl cache) {
-    GemFireCacheImpl oldInstance = instance;
-    instance = cache;
-    return oldInstance;
+    if (cache.isClosing) {
+      return null;
+    }
+
+    return cache;
+
-    final GemFireCacheImpl result = instance;
+    final GemFireCacheImpl result = getInstance();
-          LocalizedStrings.CacheFactory_THE_CACHE_HAS_BEEN_CLOSED.toLocalizedString(), null);
+          LocalizedStrings.CacheFactory_THE_CACHE_HAS_BEEN_CLOSED.toLocalizedString());
+   *
+   * @deprecated Rather than fishing for a cache with this static method, use a cache that is passed
+   *             in to your method.
-    GemFireCacheImpl result = pdxInstance;
-    if (result == null) {
+
+    InternalDistributedSystem system = getAnyInstance();
+    if (system == null) {
-    return result;
+    GemFireCacheImpl cache = (GemFireCacheImpl) system.getCache();
+    if (cache == null) {
+      throw new CacheClosedException(reason);
+    }
+
+    return cache;
-        GemFireCacheImpl instance = checkExistingCache(existingOk, cacheConfig);
+        GemFireCacheImpl instance = checkExistingCache(existingOk, cacheConfig, system);
-  private static GemFireCacheImpl checkExistingCache(boolean existingOk, CacheConfig cacheConfig) {
-    GemFireCacheImpl instance = getInstance();
+  private static GemFireCacheImpl checkExistingCache(boolean existingOk, CacheConfig cacheConfig,
+      InternalDistributedSystem system) {
+    GemFireCacheImpl instance =
+        ALLOW_MULTIPLE_SYSTEMS ? (GemFireCacheImpl) system.getCache() : getInstance();
-      if (this.dm.getDMType() == DistributionManager.ADMIN_ONLY_DM_TYPE) {
+      if (this.dm.getDMType() == ClusterDistributionManager.ADMIN_ONLY_DM_TYPE) {
-      this.diskMonitor = new DiskStoreMonitor();
+      this.diskMonitor = new DiskStoreMonitor(system.getConfig().getLogFile());
+      backupService = new BackupService(this);
-    if (!(this.dm instanceof DistributionManager)) {
+    if (!(this.dm instanceof ClusterDistributionManager)) {
-    if (this.dm.getDMType() == DistributionManager.LOCATOR_DM_TYPE || this.isClient
+    if (this.dm.getDMType() == ClusterDistributionManager.LOCATOR_DM_TYPE || this.isClient
-  public Pool getDefaultPool() {
+  public synchronized Pool getDefaultPool() {
+    if (this.defaultPool == null) {
+      determineDefaultPool();
+    }
-  private void setDefaultPool(Pool value) {
-    this.defaultPool = value;
-  }
-
-    if (GemFireCacheImpl.instance != null) {
-      Assert.assertTrue(GemFireCacheImpl.instance == null,
-          "Cache instance already in place: " + instance);
-    }
-    GemFireCacheImpl.instance = this;
-    GemFireCacheImpl.pdxInstance = this;
-
-    this.poolFactory = null;
-
-    return this.system.getDistributedMember().getVmKind() != DistributionManager.LOCATOR_DM_TYPE
-        && this.system.getDistributedMember().getVmKind() != DistributionManager.ADMIN_ONLY_DM_TYPE
+    return this.system.getDistributedMember()
+        .getVmKind() != ClusterDistributionManager.LOCATOR_DM_TYPE
+        && this.system.getDistributedMember()
+            .getVmKind() != ClusterDistributionManager.ADMIN_ONLY_DM_TYPE
-      this.restAgent = new RestAgent(this.system.getConfig());
+      this.restAgent = new RestAgent(this.system.getConfig(), this.securityService);
-    if (this.getMyId().getVmKind() == DistributionManager.LOCATOR_DM_TYPE) {
+    if (this.getMyId().getVmKind() == ClusterDistributionManager.LOCATOR_DM_TYPE) {
-        determineDefaultPool();
-      if (this.getMyId().getVmKind() == DistributionManager.LOCATOR_DM_TYPE) {
+      if (this.getMyId().getVmKind() == ClusterDistributionManager.LOCATOR_DM_TYPE) {
+  public CacheClosedException getCacheClosedException(String reason) {
+    return getCacheClosedException(reason, null);
+  }
+
+  /** return a CacheClosedException with the given reason and cause */
+  @Override
-    GemFireCacheImpl cache = GemFireCacheImpl.instance;
+    GemFireCacheImpl cache = getInstance();
-    GemFireCacheImpl.instance = null;
-    GemFireCacheImpl.pdxInstance = null;
-      // Before anything else...make sure that this instance is not
-      // available to anyone "fishing" for a cache...
-      if (GemFireCacheImpl.instance == this) {
-        GemFireCacheImpl.instance = null;
-      }
-
-          if (GemFireCacheImpl.pdxInstance == this) {
-            GemFireCacheImpl.pdxInstance = null;
-          }
-          List<LocalRegion> rootRegionValues;
+          List<InternalRegion> rootRegionValues;
-            LocalRegion prRoot = null;
+            InternalRegion prRoot = null;
-            for (LocalRegion lr : rootRegionValues) {
+            for (InternalRegion lr : rootRegionValues) {
-          DM distributionManager = null;
+          DistributionManager distributionManager = null;
+  @Override
+  private Pool findFirstCompatiblePool(Map<String, Pool> pools) {
+    // act as if the default pool was configured
+    // and see if we can find an existing one that is compatible
+    PoolFactoryImpl pfi = (PoolFactoryImpl) createDefaultPF();
+    for (Pool p : pools.values()) {
+      if (((PoolImpl) p).isCompatible(pfi.getPoolAttributes())) {
+        return p;
+      }
+    }
+    return null;
+  }
+
+  private void addLocalHostAsServer(PoolFactory poolFactory) {
+    PoolFactoryImpl poolFactoryImpl = (PoolFactoryImpl) poolFactory;
+    if (poolFactoryImpl.getPoolAttributes().locators.isEmpty()
+        && poolFactoryImpl.getPoolAttributes().servers.isEmpty()) {
+      try {
+        String localHostName = SocketCreator.getHostName(SocketCreator.getLocalHost());
+        poolFactoryImpl.addServer(localHostName, CacheServer.DEFAULT_PORT);
+      } catch (UnknownHostException ex) {
+        throw new IllegalStateException("Could not determine local host name", ex);
+      }
+    }
+  }
+
-  public void determineDefaultPool() {
+  public synchronized void determineDefaultPool() {
+    PoolFactory defaultPoolFactory = this.poolFactory;
+
-    if (this.poolFactory == null) {
+    if (defaultPoolFactory == null) {
-        this.poolFactory = createDefaultPF();
+        defaultPoolFactory = createDefaultPF();
-        // act as if the default pool was configured
-        // and see if we can find an existing one that is compatible
-        PoolFactoryImpl pfi = (PoolFactoryImpl) createDefaultPF();
-        for (Pool p : pools.values()) {
-          if (((PoolImpl) p).isCompatible(pfi.getPoolAttributes())) {
-            pool = p;
-            break;
-          }
-        }
+        pool = findFirstCompatiblePool(pools);
-      PoolFactoryImpl pfi = (PoolFactoryImpl) this.poolFactory;
-      if (pfi.getPoolAttributes().locators.isEmpty() && pfi.getPoolAttributes().servers.isEmpty()) {
-        try {
-          String localHostName = SocketCreator.getHostName(SocketCreator.getLocalHost());
-          pfi.addServer(localHostName, CacheServer.DEFAULT_PORT);
-        } catch (UnknownHostException ex) {
-          throw new IllegalStateException("Could not determine local host name", ex);
-        }
-      }
+      addLocalHostAsServer(defaultPoolFactory);
+
-        if (((PoolImpl) p).isCompatible(pfi.getPoolAttributes())) {
+        if (((PoolImpl) p)
+            .isCompatible(((PoolFactoryImpl) defaultPoolFactory).getPoolAttributes())) {
-      String poolName = "DEFAULT";
+      String poolName = DEFAULT_POOL_NAME;
-        poolName = "DEFAULT" + count;
+        poolName = DEFAULT_POOL_NAME + count;
-      pool = this.poolFactory.create(poolName);
+      pool = defaultPoolFactory.create(poolName);
-   * Used to see if a existing cache's pool is compatible with us.
+   * Determine whether the specified pool factory matches the pool factory used by this cache.
-   * @return the default pool that is right for us
+   * @param poolFactory Prospective pool factory.
+   * @throws IllegalStateException When the specified pool factory does not match.
-  public Pool determineDefaultPool(PoolFactory poolFactory) {
-    Pool pool;
-    // create the pool if it does not already exist
-    if (poolFactory == null) {
-      Map<String, Pool> pools = PoolManager.getAll();
-      if (pools.isEmpty()) {
-        throw new IllegalStateException("Since a cache already existed a pool should also exist.");
-      } else if (pools.size() == 1) {
-        // otherwise use a singleton.
-        pool = pools.values().iterator().next();
-        if (getDefaultPool() != pool) {
-          throw new IllegalStateException(
-              "Existing cache's default pool was not the same as the only existing pool");
-        }
-      } else {
-        // just use the current default pool if one exists
-        pool = getDefaultPool();
-        if (pool == null) {
-          // act as if the default pool was configured
-          // and see if we can find an existing one that is compatible
-          PoolFactoryImpl pfi = (PoolFactoryImpl) createDefaultPF();
-          for (Pool p : pools.values()) {
-            if (((PoolImpl) p).isCompatible(pfi.getPoolAttributes())) {
-              pool = p;
-              break;
-            }
-          }
-          if (pool == null) {
-            // if pool is still null then we will not have a default pool for this ClientCache
-            return null;
-          }
-        }
-      }
-    } else {
-      PoolFactoryImpl poolFactoryImpl = (PoolFactoryImpl) poolFactory;
-      if (poolFactoryImpl.getPoolAttributes().locators.isEmpty()
-          && poolFactoryImpl.getPoolAttributes().servers.isEmpty()) {
-        try {
-          String localHostName = SocketCreator.getHostName(SocketCreator.getLocalHost());
-          poolFactoryImpl.addServer(localHostName, CacheServer.DEFAULT_PORT);
-        } catch (UnknownHostException ex) {
-          throw new IllegalStateException("Could not determine local host name", ex);
-        }
-      }
-      PoolImpl defaultPool = (PoolImpl) getDefaultPool();
-      if (defaultPool != null && defaultPool.isCompatible(poolFactoryImpl.getPoolAttributes())) {
-        pool = defaultPool;
-      } else {
-        throw new IllegalStateException("Existing cache's default pool was not compatible");
-      }
+  public void validatePoolFactory(PoolFactory poolFactory) {
+    // If the specified pool factory is null, by definition there is no pool factory to validate.
+    if (poolFactory != null && !Objects.equals(this.poolFactory, poolFactory)) {
+      throw new IllegalStateException("Existing cache's default pool was not compatible");
-    return pool;
-    if (getMyId().getVmKind() == DistributionManager.LOCATOR_DM_TYPE) {
+    if (getMyId().getVmKind() == ClusterDistributionManager.LOCATOR_DM_TYPE) {
-    LocalRegion region;
+    InternalRegion region;
-        Future future = null;
+        Future<InternalRegion> future = null;
+              // Abstract region depends on the default pool existing so lazily initialize it
+              // if necessary.
+              if (Objects.equals(attrs.getPoolName(), DEFAULT_POOL_NAME)) {
+                determineDefaultPool();
+              }
-          LocalRegion localRegion = (LocalRegion) future.get(); // wait on Future
-          throw new RegionExistsException(localRegion);
+          throw new RegionExistsException(future.get());
-      LocalRegion localRegion = (LocalRegion) ex.getRegion();
-      localRegion.waitOnInitialization(); // don't give out ref until initialized
+      InternalRegion internalRegion = (InternalRegion) ex.getRegion();
+      internalRegion.waitOnInitialization(); // don't give out ref until initialized
-  public <K, V> RegionAttributes<K, V> invokeRegionBefore(LocalRegion parent, String name,
+  public <K, V> RegionAttributes<K, V> invokeRegionBefore(InternalRegion parent, String name,
-  public void invokeRegionAfter(LocalRegion region) {
+  public void invokeRegionAfter(InternalRegion region) {
-  public void invokeBeforeDestroyed(LocalRegion region) {
+  public void invokeBeforeDestroyed(InternalRegion region) {
-  public void invokeCleanupFailedInitialization(LocalRegion region) {
+  public void invokeCleanupFailedInitialization(InternalRegion region) {
-  public Set<LocalRegion> getAllRegions() {
-    Set<LocalRegion> result = new HashSet<>();
+  public Set<InternalRegion> getAllRegions() {
+    Set<InternalRegion> result = new HashSet<>();
-              result.add((LocalRegion) entry.getValue());
+              result.add((InternalRegion) entry.getValue());
-        } else if (region instanceof LocalRegion) {
-          LocalRegion localRegion = (LocalRegion) region;
-          result.add(localRegion);
-          result.addAll(localRegion.basicSubregions(true));
+        } else if (region instanceof InternalRegion) {
+          InternalRegion internalRegion = (InternalRegion) region;
+          result.add(internalRegion);
+          result.addAll(internalRegion.basicSubregions(true));
-  public Set<LocalRegion> getApplicationRegions() {
-    Set<LocalRegion> result = new HashSet<>();
+  public Set<InternalRegion> getApplicationRegions() {
+    Set<InternalRegion> result = new HashSet<>();
-        LocalRegion localRegion = (LocalRegion) region;
-        if (localRegion.isSecret() || localRegion.isUsedForMetaRegion()
-            || localRegion instanceof HARegion || localRegion.isUsedForPartitionedRegionAdmin()
-            || localRegion.isInternalRegion()/* localRegion.isUsedForPartitionedRegionBucket() */) {
+        InternalRegion internalRegion = (InternalRegion) region;
+        if (internalRegion.isSecret() || internalRegion.isUsedForMetaRegion()
+            || internalRegion instanceof HARegion
+            || internalRegion.isUsedForPartitionedRegionAdmin() || internalRegion
+                .isInternalRegion()/* internalRegion.isUsedForPartitionedRegionBucket() */) {
-        result.add(localRegion);
-        result.addAll(localRegion.basicSubregions(true));
+        result.add(internalRegion);
+        result.addAll(internalRegion.basicSubregions(true));
-      for (LocalRegion region : this.rootRegions.values()) {
+      for (InternalRegion region : this.rootRegions.values()) {
-        for (LocalRegion subRegion : (Set<LocalRegion>) region.basicSubregions(true)) {
+        for (InternalRegion subRegion : (Set<InternalRegion>) region.basicSubregions(true)) {
-  public void setRegionByPath(String path, LocalRegion r) {
+  public void setRegionByPath(String path, InternalRegion r) {
-  public LocalRegion getRegionByPath(String path) {
+  public InternalRegion getRegionByPath(String path) {
-    LocalRegion result = getReinitializingRegion(path);
+    InternalRegion result = getReinitializingRegion(path);
-    return (LocalRegion) this.pathToRegion.get(path);
+    return this.pathToRegion.get(path);
-  public LocalRegion getRegionByPathForProcessing(String path) {
-    LocalRegion result = getRegionByPath(path);
+  public InternalRegion getRegionByPathForProcessing(String path) {
+    InternalRegion result = getRegionByPath(path);
-        LocalRegion rootRegion;
+        InternalRegion rootRegion;
-        result = (LocalRegion) rootRegion.getSubregion(pathParts[1], true);
+        result = (InternalRegion) rootRegion.getSubregion(pathParts[1], true);
-    LocalRegion result = getRegionByPath(path);
+    InternalRegion result = getRegionByPath(path);
-    LocalRegion rootRegion;
+    InternalRegion rootRegion;
-      return isGlobalRegionInitializing((LocalRegion) getRegion(fullPath));
+      return isGlobalRegionInitializing((InternalRegion) getRegion(fullPath));
-  private boolean isGlobalRegionInitializing(LocalRegion region) {
-    boolean result = region != null && region.scope.isGlobal() && !region.isInitialized();
+  private boolean isGlobalRegionInitializing(InternalRegion region) {
+    boolean result = region != null && region.getScope().isGlobal() && !region.isInitialized();
-      for (LocalRegion region : this.rootRegions.values()) {
+      for (InternalRegion region : this.rootRegions.values()) {
-        LocalRegion region = (LocalRegion) iterator.next();
+        InternalRegion region = (InternalRegion) iterator.next();
-        LocalRegion localRegion = (LocalRegion) region;
-        localRegion.cleanupForClient(ccn, client);
+        InternalRegion internalRegion = (InternalRegion) region;
+        internalRegion.cleanupForClient(ccn, client);
-  public LocalRegion getReinitializingRegion(String fullPath) {
+  public InternalRegion getReinitializingRegion(String fullPath) {
-      LocalRegion region = (LocalRegion) future.get();
+      InternalRegion region = (InternalRegion) future.get();
-  public boolean removeRoot(LocalRegion rootRgn) {
+  public boolean removeRoot(InternalRegion rootRgn) {
-      LocalRegion found = this.rootRegions.get(regionName);
+      InternalRegion found = this.rootRegions.get(regionName);
-        LocalRegion previous = this.rootRegions.remove(regionName);
+        InternalRegion previous = this.rootRegions.remove(regionName);
-  /**
-   * @see LocalRegion
-   */
+  public boolean removeCacheServer(CacheServer cacheServer) {
+    boolean removed = this.allCacheServers.remove(cacheServer);
+    sendRemoveCacheServerProfileMessage();
+    return removed;
+  }
+
-      Set<LocalRegion> applicationRegions = getApplicationRegions();
-      for (LocalRegion region : applicationRegions) {
+      Set<InternalRegion> applicationRegions = getApplicationRegions();
+      for (InternalRegion region : applicationRegions) {
+    if (!(sender.getRemoteDSId() < 0)) {
+      this.system.handleResourceEvent(ResourceEvent.GATEWAYSENDER_REMOVE, sender);
+    }
+  public void removeGatewayReceiver(GatewayReceiver receiver) {
+    if (isClient()) {
+      throw new UnsupportedOperationException("operation is not supported on a client cache");
+    }
+    this.stopper.checkCancelInProgress(null);
+    synchronized (this.allGatewayReceiversLock) {
+      Set<GatewayReceiver> newReceivers = new HashSet<>(this.allGatewayReceivers.size() + 1);
+      if (!this.allGatewayReceivers.isEmpty()) {
+        newReceivers.addAll(this.allGatewayReceivers);
+      }
+      newReceivers.remove(receiver);
+      this.allGatewayReceivers = Collections.unmodifiableSet(newReceivers);
+    }
+  }
+
-    for (Entry<String, Region<?, ?>> entry : this.pathToRegion.entrySet()) {
+    for (Entry<String, InternalRegion> entry : this.pathToRegion.entrySet()) {
-      Region<?, ?> region = entry.getValue();
+      InternalRegion region = entry.getValue();
-    LocalRegion r = (LocalRegion) getRegion(regionName, true);
+    InternalRegion r = (InternalRegion) getRegion(regionName, true);
+    if (isClient()) {
+      // If a durable client has been configured...
+      if (Objects.nonNull(system) && Objects.nonNull(system.getConfig())
+          && !Objects.equals(DistributionConfig.DEFAULT_DURABLE_CLIENT_ID,
+              Objects.toString(system.getConfig().getDurableClientId(),
+                  DistributionConfig.DEFAULT_DURABLE_CLIENT_ID))) {
+        // Ensure that there is a pool to use for readyForEvents().
+        if (Objects.isNull(defaultPool)) {
+          determineDefaultPool();
+        }
+      }
+    }
-  public BackupManager startBackup(InternalDistributedMember sender) throws IOException {
-    BackupManager manager = new BackupManager(sender, this);
-    if (!this.backupManager.compareAndSet(null, manager)) {
-      throw new IOException("Backup already in progress");
-    }
-    manager.validateRequestingAdmin();
-    return manager;
-  }
-
-  public void clearBackupManager() {
-    this.backupManager.set(null);
-  }
-
-  public BackupManager getBackupManager() {
-    return this.backupManager.get();
+  public BackupService getBackupService() {
+    return backupService;
-    if (!(MAX_QUERY_EXECUTION_TIME > 0 || this.testMaxQueryExecutionTime > 0 || monitorRequired)) {
+    if (!(MAX_QUERY_EXECUTION_TIME > 0 || monitorRequired)) {
-    boolean needQueryMonitor =
-        MAX_QUERY_EXECUTION_TIME > 0 || this.testMaxQueryExecutionTime > 0 || monitorRequired;
+    boolean needQueryMonitor = MAX_QUERY_EXECUTION_TIME > 0 || monitorRequired;
-          int maxTime = MAX_QUERY_EXECUTION_TIME > this.testMaxQueryExecutionTime
-              ? MAX_QUERY_EXECUTION_TIME : this.testMaxQueryExecutionTime;
+          int maxTime = MAX_QUERY_EXECUTION_TIME;
-          this.queryMonitor = new QueryMonitor(maxTime);
+          this.queryMonitor = new QueryMonitor(this, maxTime);
+
+  private void sendRemoveCacheServerProfileMessage() {
+    Set otherMembers = this.dm.getOtherDistributionManagerIds();
+    RemoveCacheServerProfileMessage message = new RemoveCacheServerProfileMessage();
+    message.operateOnLocalCache(this);
+
+    // Remove this while loop when we release GEODE 2.0
+    // This block prevents sending a message to old members that do not know about
+    // the RemoveCacheServerProfileMessage
+    Iterator memberIterator = otherMembers.iterator();
+    while (memberIterator.hasNext()) {
+      InternalDistributedMember member = (InternalDistributedMember) memberIterator.next();
+      if (Version.GEODE_150.compareTo(member.getVersionObject()) > 0) {
+        memberIterator.remove();
+      }
+    }
+
+    if (!otherMembers.isEmpty()) {
+      if (logger.isDebugEnabled()) {
+        logger.debug("Sending add cache server profile message to other members.");
+      }
+      ReplyProcessor21 replyProcessor = new ReplyProcessor21(this.dm, otherMembers);
+      message.setRecipients(otherMembers);
+      message.processorId = replyProcessor.getProcessorId();
+      this.dm.putOutgoing(message);
+
+      // Wait for replies.
+      try {
+        replyProcessor.waitForReplies();
+      } catch (InterruptedException ignore) {
+        Thread.currentThread().interrupt();
+      }
+    }
+  }
+
-  public DM getDistributionManager() {
+  public DistributionManager getDistributionManager() {
-    return PdxInstanceFactoryImpl.newCreator(className, true);
+    return PdxInstanceFactoryImpl.newCreator(className, true, this);
-    return PdxInstanceFactoryImpl.newCreator(className, expectDomainClass);
+    return PdxInstanceFactoryImpl.newCreator(className, expectDomainClass, this);
+  @Override
-      InternalDistributedMember sender, LocalRegion region,
+      InternalDistributedMember sender, InternalRegion region,
+
+  @Override
+  public Object convertPdxInstanceIfNeeded(Object obj) {
+    Object result = obj;
+    if (!this.getPdxReadSerialized() && obj instanceof PdxInstance) {
+      result = ((PdxInstance) obj).getObject();
+    }
+    return result;
+  }
