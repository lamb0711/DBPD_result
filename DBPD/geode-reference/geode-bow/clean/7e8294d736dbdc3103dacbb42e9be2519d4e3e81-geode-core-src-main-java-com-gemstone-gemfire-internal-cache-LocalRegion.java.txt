Merge branch 'develop' into feature/GEODE-17-2

# Conflicts:
#	geode-core/src/test/resources/com/gemstone/gemfire/codeAnalysis/sanctionedSerializables.txt

-import com.gemstone.gemfire.cache.hdfs.internal.HDFSBucketRegionQueue;
-import com.gemstone.gemfire.cache.hdfs.internal.HDFSIntegrationUtil;
-import com.gemstone.gemfire.cache.hdfs.internal.HoplogListenerForRegion;
-import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSRegionDirector;
-import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSRegionDirector.HdfsRegionManager;
-  
-  protected HdfsRegionManager hdfsManager;
-  protected HoplogListenerForRegion hoplogListener;
-
-    this.hdfsManager = initHDFSManager();
-  private HdfsRegionManager initHDFSManager() {
-    HdfsRegionManager hdfsMgr = null;
-    if (this.getHDFSStoreName() != null) {
-      this.hoplogListener = new HoplogListenerForRegion();
-      HDFSRegionDirector.getInstance().setCache(cache);
-      hdfsMgr = HDFSRegionDirector.getInstance().manageRegion(this, 
-          this.getHDFSStoreName(), hoplogListener);
-    }
-    return hdfsMgr;
-  }
-
-	if ((internalRegionArgs.isReadWriteHDFSRegion()) && this.diskRegion != null) {
-      this.diskRegion.setEntriesMapIncompatible(true);
-    }
-            // create the async queue for HDFS if required. 
-            HDFSIntegrationUtil.createAndAddAsyncQueue(regionPath,
-                regionAttributes, this.cache);
-            regionAttributes = cache.setEvictionAttributesForLargeRegion(
-                regionAttributes);
-                if (!pr.isShadowPRForHDFS()) {
-                    newRegion = new BucketRegionQueue(subregionName, regionAttributes,
-                      this, this.cache, internalRegionArgs);
-                }
-                else {
-                   newRegion = new HDFSBucketRegionQueue(subregionName, regionAttributes,
-                      this, this.cache, internalRegionArgs);
-                }
-                
+                newRegion = new BucketRegionQueue(subregionName, regionAttributes,
+                  this, this.cache, internalRegionArgs);
-    validatedCreate(event, startPut);
-    // TODO OFFHEAP: validatedCreate calls release
+    try {
+      validatedCreate(event, startPut);
+    } finally {
+      event.release();
+    }
-  public final void validatedCreate(@Released EntryEventImpl event, long startPut)
+  public final void validatedCreate(EntryEventImpl event, long startPut)
-    try {
-      assert event.isFetchFromHDFS() : "validatedPut() should have been called";
-    } finally {
-      event.release();
-    }
-    return validatedDestroy(key, event);
-    // TODO OFFHEAP: validatedDestroy calls release
+    try {
+      return validatedDestroy(key, event);
+    } finally {
+      event.release();
+    }
-  public Object validatedDestroy(Object key, @Released EntryEventImpl event)
+  public Object validatedDestroy(Object key, EntryEventImpl event)
-    try {
-    } finally {
-      event.release();
-    }
-  public final Object getDeserializedValue(RegionEntry re, final KeyInfo keyInfo, final boolean updateStats, boolean disableCopyOnRead, 
-  boolean preferCD, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS, boolean retainResult) {
+  public final Object getDeserializedValue(RegionEntry re,
+                                           final KeyInfo keyInfo,
+                                           final boolean updateStats,
+                                           boolean disableCopyOnRead,
+                                           boolean preferCD,
+                                           EntryEventImpl clientEvent,
+                                           boolean returnTombstones,
+                                           boolean retainResult) {
-        if (allowReadFromHDFS) {
-          re = this.entries.getEntry(keyInfo.getKey());
-        } else {
-          re = this.entries.getOperationalEntryInVM(keyInfo.getKey());
-        }
+        re = this.entries.getEntry(keyInfo.getKey());
-    Object result = get(key, aCallbackArgument, generateCallbacks, false, false, null, clientEvent, false, true/*allowReadFromHDFS*/);
+    Object result = get(key, aCallbackArgument, generateCallbacks, false, false, null, clientEvent, false);
-  public Object get(Object key, Object aCallbackArgument,
-	      boolean generateCallbacks, boolean disableCopyOnRead, boolean preferCD,
-	      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) throws TimeoutException, CacheLoaderException {
+  public Object get(Object key,
+                    Object aCallbackArgument,
+                    boolean generateCallbacks,
+                    boolean disableCopyOnRead,
+                    boolean preferCD,
+                    ClientProxyMembershipID requestingClient,
+                    EntryEventImpl clientEvent,
+                    boolean returnTombstones) throws TimeoutException, CacheLoaderException {
-		      generateCallbacks, disableCopyOnRead, preferCD,requestingClient, clientEvent, returnTombstones, false, allowReadFromHDFS, false);
+		      generateCallbacks, disableCopyOnRead, preferCD,requestingClient, clientEvent, returnTombstones, false, false);
-    // TODO OFFHEAP: the last parameter "retainResult" should be true for getRetained. Need to look into what it is being set to false.
-    return get(key, aCallbackArgument, generateCallbacks, disableCopyOnRead, true, requestingClient, clientEvent, returnTombstones, opScopeIsLocal, true, false);
+    return get(key, aCallbackArgument, generateCallbacks, disableCopyOnRead, true, requestingClient, clientEvent, returnTombstones, opScopeIsLocal,
+      false /* see GEODE-1291*/);
-      boolean generateCallbacks, boolean disableCopyOnRead, boolean preferCD,
-      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones, 
-	  boolean opScopeIsLocal, boolean allowReadFromHDFS, boolean retainResult) throws TimeoutException, CacheLoaderException
+                    boolean generateCallbacks, boolean disableCopyOnRead, boolean preferCD,
+                    ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones,
+                    boolean opScopeIsLocal, boolean retainResult) throws TimeoutException, CacheLoaderException
-      Object value = getDataView().getDeserializedValue(keyInfo, this, true, disableCopyOnRead, preferCD, clientEvent, returnTombstones, allowReadFromHDFS, retainResult);
+      Object value = getDataView().getDeserializedValue(keyInfo, this, true, disableCopyOnRead, preferCD, clientEvent, returnTombstones,
+        retainResult);
-            && ((getScope().isDistributed() && !isHDFSRegion())
+            && ((getScope().isDistributed())
-          // TODO OFFHEAP OPTIMIZE: findObject can be enhanced to use the retainResult flag
-              preferCD, requestingClient, clientEvent, returnTombstones, false/*allowReadFromHDFS*/);
+              preferCD, requestingClient, clientEvent, returnTombstones);
-    if (re == null && !isTX() && !isHDFSRegion()) {
+    if (re == null && !isTX()) {
-   * @return true if this region has been configured for HDFS persistence
-   */
-  public boolean isHDFSRegion() {
-    return false;
-  }
-
-  /**
-   * @return true if this region is configured to read and write data from HDFS
-   */
-  public boolean isHDFSReadWriteRegion() {
-    return false;
-  }
-
-  /**
-   * @return true if this region is configured to only write to HDFS
-   */
-  protected boolean isHDFSWriteOnly() {
-    return false;
-  }
-
-  /**
-   * FOR TESTING ONLY
-   */
-  public HoplogListenerForRegion getHoplogListener() {
-    return hoplogListener;
-  }
-  
-  /**
-   * FOR TESTING ONLY
-   */
-  public HdfsRegionManager getHdfsRegionManager() {
-    return hdfsManager;
-  }
-  
-  /**
-   *
-   * @param keyInfo
+   *  @param keyInfo
-   *                the value retrieved from the region for this object.
+*                the value retrieved from the region for this object.
-  Object nonTxnFindObject(KeyInfo keyInfo, boolean p_isCreate,
-      boolean generateCallbacks, Object p_localValue, boolean disableCopyOnRead, boolean preferCD,
-      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) 
+  Object nonTxnFindObject(KeyInfo keyInfo,
+                          boolean p_isCreate,
+                          boolean generateCallbacks,
+                          Object p_localValue,
+                          boolean disableCopyOnRead,
+                          boolean preferCD,
+                          ClientProxyMembershipID requestingClient,
+                          EntryEventImpl clientEvent,
+                          boolean returnTombstones)
-        localValue = getDeserializedValue(null, keyInfo, isCreate, disableCopyOnRead, preferCD, clientEvent, false, false/*allowReadFromHDFS*/, false);
+        localValue = getDeserializedValue(null, keyInfo, isCreate, disableCopyOnRead, preferCD, clientEvent, false,
+          false);
-            localValue, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, false/*allowReadFromHDFS*/);
+            localValue, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones);
-            localValue, disableCopyOnRead, preferCD, null, null, false, allowReadFromHDFS);
+            localValue, disableCopyOnRead, preferCD, null, null, false);
-     //Since Sqlfire directly calls validatedPut, the freeing is done in
-    // validatedPut
-     return validatedPut(event, startPut);
-     // TODO OFFHEAP: validatedPut calls release
-    
+    try {
+      return validatedPut(event, startPut);
+    } finally {
+      event.release();
+    }
-  public final Object validatedPut(@Released EntryEventImpl event, long startPut)
+  public final Object validatedPut(EntryEventImpl event, long startPut)
-    try {
-    } finally {
-      event.release();
-    }
-    ev.setFetchFromHDFS(false);
-  protected boolean includeHDFSResults() {
-    return isUsedForPartitionedRegionBucket() 
-        && isHDFSReadWriteRegion() 
-        && getPartitionedRegion().includeHDFSResults();
-  }
-  
-
-      if (isHDFSReadWriteRegion() && this.initialized) {
-        // this size is not used by HDFS region iterators
-        // fixes bug 49239
-        return 0;
-      }
-	if (includeHDFSResults()) {
-      return result;
-    }
-   * @see DistributedRegion#findObjectInSystem(KeyInfo, boolean, TXStateInterface, boolean, Object, boolean, boolean, ClientProxyMembershipID, EntryEventImpl, boolean, boolean )
+   * @see LocalRegion#findObjectInSystem(KeyInfo, boolean, TXStateInterface, boolean, Object, boolean, boolean, ClientProxyMembershipID, EntryEventImpl, boolean)
-  protected Object findObjectInSystem(KeyInfo keyInfo, boolean isCreate,
-      TXStateInterface tx, boolean generateCallbacks, Object localValue, boolean disableCopyOnRead, boolean preferCD, ClientProxyMembershipID requestingClient,
-      EntryEventImpl clientEvent, boolean returnTombstones,  boolean allowReadFromHDFS)
+  protected Object findObjectInSystem(KeyInfo keyInfo,
+                                      boolean isCreate,
+                                      TXStateInterface tx,
+                                      boolean generateCallbacks,
+                                      Object localValue,
+                                      boolean disableCopyOnRead,
+                                      boolean preferCD,
+                                      ClientProxyMembershipID requestingClient,
+                                      EntryEventImpl clientEvent,
+                                      boolean returnTombstones)
-        // TODO OFFHEAP: verify that the above assertion is true
-  if (this.hdfsStoreName != null) {
-    notifyGatewaySender(eventType, event);
-    }
-    event.setFetchFromHDFS(false);
-  
-  @Retained
-  protected EntryEventImpl generateCustomEvictDestroyEvent(final Object key) {
-    @Retained EntryEventImpl event =  EntryEventImpl.create(
-        this, Operation.CUSTOM_EVICT_DESTROY, key, null/* newValue */,
-        null, false, getMyId());
-    
-    // Fix for bug#36963
-    if (generateEventID()) {
-      event.setNewEventId(cache.getDistributedSystem());
-    }
-    event.setFetchFromHDFS(false);
-    return event;
-  }
-  
-    // mark as destroyed
-    // TODO OFFHEAP MERGE: to fix 49905 asif commented out isDestroyed being set.
-    // But in xd it was set after closeEntries was called.
-    // Here it is set before and it fixed 49555.
+    // mark as destroyed fixes 49555.
-    clearHDFSData();
-    
-  /**Clear HDFS data, if present */
-  protected void clearHDFSData() {
-    //do nothing, clear is implemented for subclasses like BucketRegion.
-  }
-
-    dpao.getEvent().setFetchFromHDFS(false);
-	event.setFetchFromHDFS(putallOp.getEvent().isFetchFromHDFS());
-      @Released EntryEventImpl event = (EntryEventImpl)it.next();
-      try {
+      @Unretained EntryEventImpl event = (EntryEventImpl)it.next();
-      } finally {
-        event.release();
-      }
-      @Released EntryEventImpl event = (EntryEventImpl)it.next();
-      try {
+      @Unretained EntryEventImpl event = (EntryEventImpl)it.next();
-      } finally {
-        event.release();
-      }
-  /// End of Variables and methods for test Hook for HDFS ///////
-  public void forceHDFSCompaction(boolean isMajor, Integer maxWaitTime) {
-    throw new UnsupportedOperationException(
-        LocalizedStrings.HOPLOG_DOES_NOT_USE_HDFSSTORE
-            .toLocalizedString(getName()));
-  }
-
-  public void flushHDFSQueue(int maxWaitTime) {
-    throw new UnsupportedOperationException(
-        LocalizedStrings.HOPLOG_DOES_NOT_USE_HDFSSTORE
-            .toLocalizedString(getName()));
-  }
-  
-  public long lastMajorHDFSCompaction() {
-    throw new UnsupportedOperationException();
-  }
