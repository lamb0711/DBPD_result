GEODE-10: Refactor HdfsStore api to match spec

* Currently HdfsStore's configuration object is nested and a user needs to
  create multiple sub objects to manage the store instance. This is less usable
  and gets confusing at times. User also gets exposed to a lot of internal
  details. So replacing nested configuration with a flat structure will be
  better.
* Rename members

-import com.gemstone.gemfire.cache.hdfs.HDFSStore.HDFSCompactionConfig;
- * To use this factory configure it with the <code>set</code> methods and then
- * call {@link #create} to produce a HDFS store instance.
+ * Usage
+ * <ol>
+ * <li> configure factory using <code>set</code> methods
+ * <li> call {@link #create} to produce a HDFSStore instance.
+ * </ol>
-   * @param name
-   *          name of HDFSStore provided at while creating the instance
+   * @see HDFSStore#getName()
-   * @param url
-   *          Namenode URL associated with this store
+   * @see HDFSStore#getNameNodeURL()
-   * @param dir
-   *          Home directory where regions using this store will be persisted
+   * @see HDFSStore#getHomeDir()
-   * @param file
-   *          hdfs client configuration referred by this store
+   * @see HDFSStore#getHDFSClientConfigFile()
-  public HDFSStoreFactory setHDFSClientConfigFile(String file);
+  public HDFSStoreFactory setHDFSClientConfigFile(String filePath);
-   * @param config
-   *          Instance of compaction configuration associated with this store
-   */
-  public HDFSStoreFactory setHDFSCompactionConfig(HDFSCompactionConfig config);
-  
-  /**
-   * @param percentage
-   *          Size of the block cache as a percentage of the heap in the range
-   *          0 ... 100 
+   * @see HDFSStore#getHDFSClientConfigFile()
-  
+
-   * Sets the HDFS event queue attributes
-   * This causes the store to use the {@link HDFSEventQueueAttributes}.
-   * @param hdfsEventQueueAttrs the attributes of the HDFS Event queue
-   * @return a reference to this RegionFactory object
-   * 
+   * @see HDFSStore#getMaxWriteOnlyFileSize()
-  public HDFSStoreFactory setHDFSEventQueueAttributes(HDFSEventQueueAttributes hdfsEventQueueAttrs);
-  
+  public HDFSStoreFactory setMaxWriteOnlyFileSize(int maxFileSize);
+
-   * For write only tables, data is written to a single file until the file 
-   * reaches a size specified by this API or the time 
-   * for file rollover specified by {@link #setFileRolloverInterval(int)} has passed.  
-   * Default is 256 MB. 
-   * 
-   * @param maxFileSize max file size in MB
+   * @see HDFSStore#getWriteOnlyFileRolloverInterval()
-  public HDFSStoreFactory setMaxFileSize(int maxFileSize);
-  
+  public HDFSStoreFactory setWriteOnlyFileRolloverInterval(int interval);
+
-   * For write only tables, data is written to a single file until the file 
-   * reaches a certain size specified by {@link #setMaxFileSize(int)} or the time 
-   * for file rollover has passed. Default is 3600 seconds. 
-   * 
-   * @param rolloverIntervalInSecs time in seconds after which a file will be rolled over into a new file
-   */
-  public HDFSStoreFactory setFileRolloverInterval(int rolloverIntervalInSecs);
-  
-  /**
-   * @param auto
-   *          true if auto compaction is enabled
+   * @see HDFSStore#getMinorCompaction()
-   * @param strategy
-   *          name of the compaction strategy or null for letting system choose
-   *          and apply default compaction strategy
-   * @return instance of {@link HDFSCompactionConfigFactory}
+   * @see HDFSStore#getMinorCompactionThreads()
-  public HDFSCompactionConfigFactory createCompactionConfigFactory(String strategy);
-
-  public static interface HDFSCompactionConfigFactory {
-
-    /**
-     * @param size
-     *          size threshold (in MB). A file larger than this size will not be
-     *          considered for compaction
-     */
-    public HDFSCompactionConfigFactory setMaxInputFileSizeMB(int size);
-
-    /**
-     * @param count
-     *          minimum count threshold. Compaction cycle will commence if the
-     *          number of files to be compacted is more than this number
-     */
-    public HDFSCompactionConfigFactory setMinInputFileCount(int count);
-
-    /**
-     * @param count
-     *          maximum count threshold.  Compaction cycle will not include more
-     *          files than the maximum
-     */
-    public HDFSCompactionConfigFactory setMaxInputFileCount(int count);
-
-    /**
-     * @param count
-     *          maximum number of threads executing minor compaction. Count must
-     *          be greater than 0
-     */
-    public HDFSCompactionConfigFactory setMaxThreads(int count);
-
-    /**
-     * @param auto
-     *          true if auto major compaction is enabled
-     */
-    public HDFSCompactionConfigFactory setAutoMajorCompaction(boolean auto);
-
-    /**
-     * @param interval
-     *          interval configuration that guides major compaction frequency
-     */
-    public HDFSCompactionConfigFactory setMajorCompactionIntervalMins(int interval);
-
-    /**
-     * @param count
-     *          maximum number of threads executing major compaction. Count must
-     *          be greater than 0
-     */
-    public HDFSCompactionConfigFactory setMajorCompactionMaxThreads(int count);
-    
-    /**
-     * @param interval
-     *          interval configuration that guides deletion of old files
-     */
-    public HDFSCompactionConfigFactory setOldFilesCleanupIntervalMins(int interval);
-    
-    /**
-     * Create a {@link HDFSCompactionConfig}. The returned instance will have
-     * the same configuration as that this factory.
-     * 
-     * @return the newly created {@link HDFSCompactionConfig}
-     * @throws GemFireConfigException
-     *           if the cache xml is invalid
-     */
-    public HDFSCompactionConfig create() throws GemFireConfigException;
-    
-    /**
-     * @return A {@link HDFSCompactionConfig} view of this factory
-     * @throws GemFireConfigException
-     */
-    public HDFSCompactionConfig getConfigView();
-  }
+  public HDFSStoreFactory setMinorCompactionThreads(int count);
-   * Create a new HDFS store. The returned HDFS store's configuration will be
-   * the same as this factory's configuration.
+   * @see HDFSStore#getMajorCompaction()
+   */
+  public HDFSStoreFactory setMajorCompaction(boolean auto);
+
+  /**
+   * @see HDFSStore#getMajorCompactionInterval()
+   */
+  public HDFSStoreFactory setMajorCompactionInterval(int interval);
+
+  /**
+   * @see HDFSStore#getMajorCompactionThreads()
+   */
+  public HDFSStoreFactory setMajorCompactionThreads(int count);
+
+  /**
+   * @see HDFSStore#getMaxInputFileSizeMB()
+   */
+  public HDFSStoreFactory setMaxInputFileSizeMB(int size);
+
+  /**
+   * @see HDFSStore#getMinInputFileCount()
+   */
+  public HDFSStoreFactory setMinInputFileCount(int count);
+
+  /**
+   * @see HDFSStore#getMaxInputFileCount()
+   */
+  public HDFSStoreFactory setMaxInputFileCount(int count);
+
+  /**
+   * @see HDFSStore#getPurgeInterval()
+   */
+  public HDFSStoreFactory setPurgeInterval(int interval);
+
+  /**
+   * @see HDFSStore#getDiskStoreName()
+   */
+  public HDFSStoreFactory setDiskStoreName(String name);
+
+  /**
+   * @see HDFSStore#getMaxMemory()
+   */
+  public HDFSStoreFactory setMaxMemory(int memory);
+
+  /**
+   * @see HDFSStore#getBatchInterval()
+   */
+  public HDFSStoreFactory setBatchInterval(int interval);
+
+  /**
+   * @see HDFSStore#getBatchSize()
+   */
+  public HDFSStoreFactory setBatchSize(int size);
+
+  /**
+   * @see HDFSStore#getBufferPersistent()
+   */
+  public HDFSStoreFactory setBufferPersistent(boolean isPersistent);
+
+  /**
+   * @see HDFSStore#getSynchronousDiskWrite()
+   */
+  public HDFSStoreFactory setSynchronousDiskWrite(boolean isSynchronous);
+
+  /**
+   * @see HDFSStore#getDispatcherThreads()
+   */
+  public HDFSStoreFactory setDispatcherThreads(int dispatcherThreads);
+
+  /**
+   * Validates all attribute values and assigns defaults where applicable.
+   * Creates a new instance of {@link HDFSStore} based on the current attribute
+   * values configured in this factory.
-   *           if the cache xml is invalid
+   *           if the configuration is invalid
-   *           if another instance of {@link HDFSStore} with the same exists
+   *           if a {@link HDFSStore} with the same name exists
-  public HDFSStore create(String name) throws GemFireConfigException,
-      StoreExistsException;
-
-  // TODO this is the only non-factory instance getter in this class
-  HDFSEventQueueAttributes getHDFSEventQueueAttributes();
+  public HDFSStore create(String name) throws GemFireConfigException, StoreExistsException;
