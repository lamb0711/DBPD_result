Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
-import java.io.BufferedReader;
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.OutputStream;
-import java.io.OutputStreamWriter;
-import java.io.PrintStream;
-import java.io.Reader;
-import java.io.StringBufferInputStream;
-import java.io.StringWriter;
-import java.io.Writer;
-import java.net.InetSocketAddress;
-import java.net.URL;
-import java.net.UnknownHostException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Properties;
-import java.util.ServiceLoader;
-import java.util.Set;
-import java.util.TreeMap;
-import java.util.concurrent.ArrayBlockingQueue;
-import java.util.concurrent.CancellationException;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.CopyOnWriteArrayList;
-import java.util.concurrent.CopyOnWriteArraySet;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Executor;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.RejectedExecutionException;
-import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicReference;
-
-import javax.naming.Context;
-
-import org.apache.logging.log4j.Logger;
-
-import org.apache.geode.distributed.internal.SharedConfiguration;
+import org.apache.geode.distributed.internal.ClusterConfigurationService;
+import org.apache.logging.log4j.Logger;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.io.PrintStream;
+import java.io.Reader;
+import java.io.StringBufferInputStream;
+import java.io.StringWriter;
+import java.io.Writer;
+import java.net.InetSocketAddress;
+import java.net.URL;
+import java.net.UnknownHostException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Properties;
+import java.util.ServiceLoader;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.concurrent.ArrayBlockingQueue;
+import java.util.concurrent.CancellationException;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.CopyOnWriteArraySet;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executor;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicReference;
+import javax.naming.Context;
-public class GemFireCacheImpl implements InternalCache, ClientCache, HasCachePerfStats, DistributionAdvisee, CacheTime {
+public class GemFireCacheImpl
+    implements InternalCache, ClientCache, HasCachePerfStats, DistributionAdvisee, CacheTime {
-  
+
-  public static final int DEFAULT_LOCK_TIMEOUT = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultLockTimeout", 60).intValue();
+  public static final int DEFAULT_LOCK_TIMEOUT = Integer
+      .getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultLockTimeout", 60).intValue();
-  public static final int DEFAULT_LOCK_LEASE = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultLockLease", 120).intValue();
+  public static final int DEFAULT_LOCK_LEASE = Integer
+      .getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultLockLease", 120).intValue();
-   * Just like instance but is valid for a bit longer so that pdx can still find the cache during a close.
+   * Just like instance but is valid for a bit longer so that pdx can still find the cache during a
+   * close.
-  public static final int DEFAULT_SEARCH_TIMEOUT = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultSearchTimeout", 300).intValue();
+  public static final int DEFAULT_SEARCH_TIMEOUT = Integer
+      .getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.defaultSearchTimeout", 300).intValue();
-  private static final Set<CacheLifecycleListener> cacheLifecycleListeners = new HashSet<CacheLifecycleListener>();
+  private static final Set<CacheLifecycleListener> cacheLifecycleListeners =
+      new HashSet<CacheLifecycleListener>();
-  private static final boolean ASYNC_EVENT_LISTENERS = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "Cache.ASYNC_EVENT_LISTENERS");
+  private static final boolean ASYNC_EVENT_LISTENERS =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "Cache.ASYNC_EVENT_LISTENERS");
-   * If true then when a delta is applied the size of the entry value will be recalculated. If false (the default) then
-   * the size of the entry value is unchanged by a delta application. Not a final so that tests can change this value.
+   * If true then when a delta is applied the size of the entry value will be recalculated. If false
+   * (the default) then the size of the entry value is unchanged by a delta application. Not a final
+   * so that tests can change this value.
-  public static boolean DELTAS_RECALCULATE_SIZE = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "DELTAS_RECALCULATE_SIZE");
+  public static boolean DELTAS_RECALCULATE_SIZE =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "DELTAS_RECALCULATE_SIZE");
-  public static final int EVENT_QUEUE_LIMIT = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.EVENT_QUEUE_LIMIT", 4096).intValue();
-  public static final int EVENT_THREAD_LIMIT = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.EVENT_THREAD_LIMIT", 16).intValue();
+  public static final int EVENT_QUEUE_LIMIT = Integer
+      .getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.EVENT_QUEUE_LIMIT", 4096).intValue();
+  public static final int EVENT_THREAD_LIMIT = Integer
+      .getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.EVENT_THREAD_LIMIT", 16).intValue();
-   * System property to limit the max query-execution time. By default its turned off (-1), the time is set in MiliSecs.
+   * System property to limit the max query-execution time. By default its turned off (-1), the time
+   * is set in MiliSecs.
-  public static final int MAX_QUERY_EXECUTION_TIME = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.MAX_QUERY_EXECUTION_TIME", -1).intValue();
+  public static final int MAX_QUERY_EXECUTION_TIME =
+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "Cache.MAX_QUERY_EXECUTION_TIME", -1)
+          .intValue();
-  
+
-   * This property defines internal function that will get executed on each node to fetch active REST service endpoints (servers).
+   * This property defines internal function that will get executed on each node to fetch active
+   * REST service endpoints (servers).
-  public static final String FIND_REST_ENABLED_SERVERS_FUNCTION_ID = FindRestEnabledServersFunction.class.getName();
+  public static final String FIND_REST_ENABLED_SERVERS_FUNCTION_ID =
+      FindRestEnabledServersFunction.class.getName();
-   * True if the user is allowed lock when memory resources appear to be overcommitted. 
+   * True if the user is allowed lock when memory resources appear to be overcommitted.
-  public static final boolean ALLOW_MEMORY_LOCK_WHEN_OVERCOMMITTED = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "Cache.ALLOW_MEMORY_OVERCOMMIT");
+  public static final boolean ALLOW_MEMORY_LOCK_WHEN_OVERCOMMITTED =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "Cache.ALLOW_MEMORY_OVERCOMMIT");
-  //time in ms
+  // time in ms
-   * the list of all cache servers. CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval
-   * operations. It is assumed that the traversal operations on cache servers list vastly outnumber the mutative
-   * operations such as add, remove.
+   * the list of all cache servers. CopyOnWriteArrayList is used to allow concurrent add, remove and
+   * retrieval operations. It is assumed that the traversal operations on cache servers list vastly
+   * outnumber the mutative operations such as add, remove.
-   * the set of all gateway senders. It may be fetched safely (for enumeration), but updates must by synchronized via
-   * {@link #allGatewaySendersLock}
+   * the set of all gateway senders. It may be fetched safely (for enumeration), but updates must by
+   * synchronized via {@link #allGatewaySendersLock}
-  
-  /**
-   * The list of all async event queues added to the cache. 
-   * CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval operations.
-   */
-  private volatile Set<AsyncEventQueue> allVisibleAsyncEventQueues = new CopyOnWriteArraySet<AsyncEventQueue>();
-   * The list of all async event queues added to the cache. 
-   * CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval operations.
+   * The list of all async event queues added to the cache. CopyOnWriteArrayList is used to allow
+   * concurrent add, remove and retrieval operations.
-  private volatile Set<AsyncEventQueue> allAsyncEventQueues = new CopyOnWriteArraySet<AsyncEventQueue>();
-  
+  private volatile Set<AsyncEventQueue> allVisibleAsyncEventQueues =
+      new CopyOnWriteArraySet<AsyncEventQueue>();
+
+  /**
+   * The list of all async event queues added to the cache. CopyOnWriteArrayList is used to allow
+   * concurrent add, remove and retrieval operations.
+   */
+  private volatile Set<AsyncEventQueue> allAsyncEventQueues =
+      new CopyOnWriteArraySet<AsyncEventQueue>();
+
-   * the list of all gateway Receivers. It may be fetched safely (for enumeration), but updates must by synchronized via
-   * {@link #allGatewayReceiversLock}
+   * the list of all gateway Receivers. It may be fetched safely (for enumeration), but updates must
+   * by synchronized via {@link #allGatewayReceiversLock}
-   * Fix for 42051 This is a map of regions that are in the process of being destroyed. We could potentially leave the
-   * regions in the pathToRegion map, but that would entail too many changes at this point in the release. We need to
-   * know which regions are being destroyed so that a profile exchange can get the persistent id of the destroying
-   * region and know not to persist that ID if it receives it as part of the persistent view.
+   * Fix for 42051 This is a map of regions that are in the process of being destroyed. We could
+   * potentially leave the regions in the pathToRegion map, but that would entail too many changes
+   * at this point in the release. We need to know which regions are being destroyed so that a
+   * profile exchange can get the persistent id of the destroying region and know not to persist
+   * that ID if it receives it as part of the persistent view.
-  private final ConcurrentMap<String, DistributedRegion> regionsInDestroy = new ConcurrentHashMap<String, DistributedRegion>();
+  private final ConcurrentMap<String, DistributedRegion> regionsInDestroy =
+      new ConcurrentHashMap<String, DistributedRegion>();
-  
+
+   * 
-  
+
-  
+
-  
+
-   * if this cache was forced to close due to a forced-disconnect, we retain a ForcedDisconnectException that can be
-   * used as the cause
+   * if this cache was forced to close due to a forced-disconnect, we retain a
+   * ForcedDisconnectException that can be used as the cause
-   * if this cache was forced to close due to a forced-disconnect or system failure, this keeps track of the reason
+   * if this cache was forced to close due to a forced-disconnect or system failure, this keeps
+   * track of the reason
-   * DistributedLockService for PartitionedRegions. Remains null until the first PartitionedRegion is created. Destroyed
-   * by GemFireCache when closing the cache. Protected by synchronization on this GemFireCache.
+   * DistributedLockService for PartitionedRegions. Remains null until the first PartitionedRegion
+   * is created. Destroyed by GemFireCache when closing the cache. Protected by synchronization on
+   * this GemFireCache.
-  
+
-   * DistributedLockService for GatewaySenders. Remains null until the
-   * first GatewaySender is created. Destroyed by GemFireCache when closing
-   * the cache.
+   * DistributedLockService for GatewaySenders. Remains null until the first GatewaySender is
+   * created. Destroyed by GemFireCache when closing the cache.
+   * 
-  
+
-  
+
-  
+
-  private volatile boolean isShutDownAll = false;
+  private final AtomicBoolean isShutDownAll = new AtomicBoolean();
+  private final CountDownLatch shutDownAllFinished = new CountDownLatch(1);
-  
+
-  
+
-  private final Map<Declarable, Properties> declarablePropertiesMap = new ConcurrentHashMap<Declarable, Properties>();
+  private final Map<Declarable, Properties> declarablePropertiesMap =
+      new ConcurrentHashMap<Declarable, Properties>();
-  protected static boolean xmlParameterizationEnabled = !Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "xml.parameterization.disabled");
+  protected static boolean xmlParameterizationEnabled =
+      !Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "xml.parameterization.disabled");
-  
+
-  
+
+   * 
-  
+
-  
+
-  
-  private final Map<Class<? extends CacheService>, CacheService> services = new HashMap<Class<? extends CacheService>, CacheService>();
-  
+
+  private final Map<Class<? extends CacheService>, CacheService> services =
+      new HashMap<Class<? extends CacheService>, CacheService>();
+
-  private final static Boolean DISABLE_AUTO_EVICTION = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "disableAutoEviction");
+  private final static Boolean DISABLE_AUTO_EVICTION =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "disableAutoEviction");
-   * Invokes mlockall().  Locks  all pages mapped into the address space of the 
-   * calling process.  This includes the pages of the code, data and stack segment, 
-   * as well as shared libraries, user space kernel data, shared memory, and 
-   * memory-mapped files.  All mapped pages are guaranteed to be resident in RAM 
-   * when the call returns successfully; the pages are guaranteed to stay in RAM 
+   * Invokes mlockall(). Locks all pages mapped into the address space of the calling process. This
+   * includes the pages of the code, data and stack segment, as well as shared libraries, user space
+   * kernel data, shared memory, and memory-mapped files. All mapped pages are guaranteed to be
+   * resident in RAM when the call returns successfully; the pages are guaranteed to stay in RAM
-   * @param flags
-   *    MCL_CURRENT 1 - Lock all pages which are currently mapped into the 
-   *    address space of the process.
-   *    
-   *    MCL_FUTURE  2 - Lock all pages which will become mapped into the address 
-   *    space of the process in the future.  These could be for instance new 
-   *    pages required by a growing heap and stack as well as new memory mapped 
-   *    files or shared memory regions.
-   *    
-   * @return 
-   *    0 if success, non-zero if error and errno set
-   *    
+   * @param flags MCL_CURRENT 1 - Lock all pages which are currently mapped into the address space
+   *        of the process.
+   * 
+   *        MCL_FUTURE 2 - Lock all pages which will become mapped into the address space of the
+   *        process in the future. These could be for instance new pages required by a growing heap
+   *        and stack as well as new memory mapped files or shared memory regions.
+   * 
+   * @return 0 if success, non-zero if error and errno set
+   * 
-    if (errno == 1 || errno == 12) {  // EPERM || ENOMEM
-      msg = "Unable to lock memory due to insufficient free space or privileges.  " 
-          + "Please check the RLIMIT_MEMLOCK soft resource limit (ulimit -l) and " 
+    if (errno == 1 || errno == 12) { // EPERM || ENOMEM
+      msg = "Unable to lock memory due to insufficient free space or privileges.  "
+          + "Please check the RLIMIT_MEMLOCK soft resource limit (ulimit -l) and "
-  
+
-   * This is for debugging cache-open issues (esp. {@link org.apache.geode.cache.CacheExistsException})
+   * This is for debugging cache-open issues (esp.
+   * {@link org.apache.geode.cache.CacheExistsException})
-    sb.append("; isShutDownAll = " + this.isShutDownAll);
+    sb.append("; isShutDownAll = " + isCacheAtShutdownAll());
-  
-  /* Used for testing, retain the old instance in the test and re-set the value when test completes*/
+
+  /*
+   * Used for testing, retain the old instance in the test and re-set the value when test completes
+   */
-	  instance = cache;
-	  return oldInstance;
+    instance = cache;
+    return oldInstance;
-   * Returns an existing instance. If a cache does not exist
-   * throws a cache closed exception.
+   * Returns an existing instance. If a cache does not exist throws a cache closed exception.
-   * @throws CacheClosedException
-   *           if an existing cache can not be found.
+   * @throws CacheClosedException if an existing cache can not be found.
-      throw result.getCacheClosedException(LocalizedStrings
-        .CacheFactory_THE_CACHE_HAS_BEEN_CLOSED.toLocalizedString(), null);
+      throw result.getCacheClosedException(
+          LocalizedStrings.CacheFactory_THE_CACHE_HAS_BEEN_CLOSED.toLocalizedString(), null);
-    throw new CacheClosedException(LocalizedStrings
-        .CacheFactory_A_CACHE_HAS_NOT_YET_BEEN_CREATED.toLocalizedString());
+    throw new CacheClosedException(
+        LocalizedStrings.CacheFactory_A_CACHE_HAS_NOT_YET_BEEN_CREATED.toLocalizedString());
-   * @param reason
-   *          the reason an existing cache is being requested.
+   * @param reason the reason an existing cache is being requested.
-   * @throws CacheClosedException
-   *           if an existing cache can not be found.
+   * @throws CacheClosedException if an existing cache can not be found.
-  public static GemFireCacheImpl createClient(DistributedSystem system, PoolFactory pf, CacheConfig cacheConfig) {
+  public static GemFireCacheImpl createClient(DistributedSystem system, PoolFactory pf,
+      CacheConfig cacheConfig) {
-  public static GemFireCacheImpl createWithAsyncEventListeners(DistributedSystem system, CacheConfig cacheConfig, TypeRegistry typeRegistry) {
+  public static GemFireCacheImpl createWithAsyncEventListeners(DistributedSystem system,
+      CacheConfig cacheConfig, TypeRegistry typeRegistry) {
-  
- public static Cache create(DistributedSystem system, boolean existingOk, CacheConfig cacheConfig) {
+
+  public static Cache create(DistributedSystem system, boolean existingOk,
+      CacheConfig cacheConfig) {
-  private static GemFireCacheImpl basicCreate(DistributedSystem system, boolean existingOk, CacheConfig cacheConfig, PoolFactory pf, boolean isClient, boolean asyncEventListeners, TypeRegistry typeRegistry)
-  throws CacheExistsException, TimeoutException, CacheWriterException,
-  GatewayException,
-  RegionExistsException 
-  {
+
+
+  private static GemFireCacheImpl basicCreate(DistributedSystem system, boolean existingOk,
+      CacheConfig cacheConfig, PoolFactory pf, boolean isClient, boolean asyncEventListeners,
+      TypeRegistry typeRegistry) throws CacheExistsException, TimeoutException,
+      CacheWriterException, GatewayException, RegionExistsException {
-          instance = new GemFireCacheImpl(isClient, pf, system, cacheConfig, asyncEventListeners, typeRegistry);
+          instance = new GemFireCacheImpl(isClient, pf, system, cacheConfig, asyncEventListeners,
+              typeRegistry);
-        throw new CacheExistsException(instance, LocalizedStrings.CacheFactory_0_AN_OPEN_CACHE_ALREADY_EXISTS.toLocalizedString(instance), instance.creationStack);
+        throw new CacheExistsException(instance,
+            LocalizedStrings.CacheFactory_0_AN_OPEN_CACHE_ALREADY_EXISTS
+                .toLocalizedString(instance),
+            instance.creationStack);
-   * Creates a new instance of GemFireCache and populates it according to the <code>cache.xml</code>, if appropriate.
+   * Creates a new instance of GemFireCache and populates it according to the
+   * <code>cache.xml</code>, if appropriate.
+   * 
-  private GemFireCacheImpl(boolean isClient, PoolFactory pf, DistributedSystem system, CacheConfig cacheConfig, boolean asyncEventListeners, TypeRegistry typeRegistry) {
+  private GemFireCacheImpl(boolean isClient, PoolFactory pf, DistributedSystem system,
+      CacheConfig cacheConfig, boolean asyncEventListeners, TypeRegistry typeRegistry) {
-      
+
-        // Should do this:     if (!getSystem().isLoner()) {
+        // Should do this: if (!getSystem().isLoner()) {
-          this.system.getInternalLogWriter().info(LocalizedStrings.GemFireCacheImpl_RUNNING_IN_LOCAL_MODE);
+          this.system.getInternalLogWriter()
+              .info(LocalizedStrings.GemFireCacheImpl_RUNNING_IN_LOCAL_MODE);
-          throw new IllegalStateException(LocalizedStrings.GemFireCache_CANNOT_CREATE_A_CACHE_IN_AN_ADMINONLY_VM
-              .toLocalizedString());
+          throw new IllegalStateException(
+              LocalizedStrings.GemFireCache_CANNOT_CREATE_A_CACHE_IN_AN_ADMINONLY_VM
+                  .toLocalizedString());
-      
+
-      initReliableMessageQueueFactory();
+      this.rmqFactory = new ReliableMessageQueueFactoryImpl();
-        final ThreadGroup group = LoggingThreadGroup.createThreadGroup("Message Event Threads",logger);
+        final ThreadGroup group =
+            LoggingThreadGroup.createThreadGroup("Message Event Threads", logger);
-        this.eventThreadPool = new PooledExecutorWithDMStats(q, EVENT_THREAD_LIMIT, this.cachePerfStats.getEventPoolHelper(), tf, 1000);
+        this.eventThreadPool = new PooledExecutorWithDMStats(q, EVENT_THREAD_LIMIT,
+            this.cachePerfStats.getEventPoolHelper(), tf, 1000);
-      
+
-      
+
-      if(null != getOffHeapStore()) {
+      if (null != getOffHeapStore()) {
-      
+
-        this.creationStack = new Exception(LocalizedStrings.GemFireCache_CREATED_GEMFIRECACHE_0.toLocalizedString(toString()));
+        this.creationStack = new Exception(
+            LocalizedStrings.GemFireCache_CREATED_GEMFIRECACHE_0.toLocalizedString(toString()));
-          resolver = new CacheXmlPropertyResolver(false, PropertyResolver.NO_SYSTEM_PROPERTIES_OVERRIDE, userProps);
+          resolver = new CacheXmlPropertyResolver(false,
+              PropertyResolver.NO_SYSTEM_PROPERTIES_OVERRIDE, userProps);
-          resolver = new CacheXmlPropertyResolver(false, PropertyResolver.NO_SYSTEM_PROPERTIES_OVERRIDE, null);
+          resolver = new CacheXmlPropertyResolver(false,
+              PropertyResolver.NO_SYSTEM_PROPERTIES_OVERRIDE, null);
-     
+
-      
+
-  
+
-   * Used by Hydra tests to get handle of Rest Agent  
+   * Used by Hydra tests to get handle of Rest Agent
+   * 
-  
+
-   * Request the shared configuration from the locator(s) which have the Cluster config service running
+   * Request the shared configuration from the locator(s) which have the Cluster config service
+   * running
-    //Request the shared configuration from the locator(s)
-    if( ((DistributionManager)dm).getDMType() == DistributionManager.LOCATOR_DM_TYPE
-      || isClient
-      || Locator.getLocator() !=null )
+    if (((DistributionManager) dm).getDMType() == DistributionManager.LOCATOR_DM_TYPE || isClient
+        || Locator.getLocator() != null)
-    Map<InternalDistributedMember, Collection<String>> scl = this.getDistributionManager().getAllHostedLocatorsWithSharedConfiguration();
+    // can't simply return null if server is not using shared configuration, since we need to find
+    // out
+    // if the locator is running in secure mode or not, if yes, then we need to throw an exception
+    // if server is not using cluster config
-    //If there are no locators with Shared configuration, that means the system has been started without shared configuration
-    //then do not make requests to the locators
-    if(scl.isEmpty()) {
-      logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_NO_LOCATORS_FOUND_WITH_SHARED_CONFIGURATION));
+    Map<InternalDistributedMember, Collection<String>> scl =
+        this.getDistributionManager().getAllHostedLocatorsWithSharedConfiguration();
+
+    // If there are no locators with Shared configuration, that means the system has been started
+    // without shared configuration
+    // then do not make requests to the locators
+    if (scl.isEmpty()) {
+      logger.info(LocalizedMessage
+          .create(LocalizedStrings.GemFireCache_NO_LOCATORS_FOUND_WITH_SHARED_CONFIGURATION));
-    String groupsString = config.getGroups();
+
-      response = ClusterConfigurationLoader.requestConfigurationFromLocators(system.getConfig(), locatorConnectionStrings);
+      response = ClusterConfigurationLoader.requestConfigurationFromLocators(system.getConfig(),
+          locatorConnectionStrings);
-      //log the configuration received from the locator
-      logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_RECEIVED_SHARED_CONFIGURATION_FROM_LOCATORS));
+      // log the configuration received from the locator
+      logger.info(LocalizedMessage
+          .create(LocalizedStrings.GemFireCache_RECEIVED_SHARED_CONFIGURATION_FROM_LOCATORS));
-      Configuration clusterConfig = response.getRequestedConfiguration().get(SharedConfiguration.CLUSTER_CONFIG);
-      Properties clusterSecProperties = (clusterConfig==null) ? new Properties():clusterConfig.getGemfireProperties();
+      Configuration clusterConfig =
+          response.getRequestedConfiguration().get(ClusterConfigurationService.CLUSTER_CONFIG);
+      Properties clusterSecProperties =
+          (clusterConfig == null) ? new Properties() : clusterConfig.getGemfireProperties();
-      if(!config.getUseSharedConfiguration()){
+      if (!config.getUseSharedConfiguration()) {
-          throw new GemFireConfigException(LocalizedStrings.GEMFIRE_CACHE_SECURITY_MISCONFIGURATION_2.toLocalizedString());
+          throw new GemFireConfigException(
+              LocalizedStrings.GEMFIRE_CACHE_SECURITY_MISCONFIGURATION_2.toLocalizedString());
-          logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_NOT_USING_SHARED_CONFIGURATION));
+          logger.info(LocalizedMessage
+              .create(LocalizedStrings.GemFireCache_NOT_USING_SHARED_CONFIGURATION));
-      //check for possible mis-configuration
-      if (isMisConfigured(clusterSecProperties, serverSecProperties, ConfigurationProperties.SECURITY_MANAGER)
-       || isMisConfigured(clusterSecProperties, serverSecProperties, ConfigurationProperties.SECURITY_POST_PROCESSOR)) {
-        throw new GemFireConfigException(LocalizedStrings.GEMFIRE_CACHE_SECURITY_MISCONFIGURATION.toLocalizedString());
+      // check for possible mis-configuration
+      if (isMisConfigured(clusterSecProperties, serverSecProperties,
+          ConfigurationProperties.SECURITY_MANAGER)
+          || isMisConfigured(clusterSecProperties, serverSecProperties,
+              ConfigurationProperties.SECURITY_POST_PROCESSOR)) {
+        throw new GemFireConfigException(
+            LocalizedStrings.GEMFIRE_CACHE_SECURITY_MISCONFIGURATION.toLocalizedString());
-      throw new GemFireConfigException(LocalizedStrings.GemFireCache_SHARED_CONFIGURATION_NOT_AVAILABLE.toLocalizedString(), e);
+      throw new GemFireConfigException(
+          LocalizedStrings.GemFireCache_SHARED_CONFIGURATION_NOT_AVAILABLE.toLocalizedString(), e);
-  public void deployJarsRecevedFromClusterConfiguration(ConfigurationResponse response){
-    try{
+  public void deployJarsRecevedFromClusterConfiguration(ConfigurationResponse response) {
+    try {
-      throw new GemFireConfigException(LocalizedStrings.GemFireCache_EXCEPTION_OCCURED_WHILE_DEPLOYING_JARS_FROM_SHARED_CONDFIGURATION.toLocalizedString(), e);
+      throw new GemFireConfigException(
+          LocalizedStrings.GemFireCache_EXCEPTION_OCCURED_WHILE_DEPLOYING_JARS_FROM_SHARED_CONDFIGURATION
+              .toLocalizedString(),
+          e);
-      throw new GemFireConfigException(LocalizedStrings.GemFireCache_EXCEPTION_OCCURED_WHILE_DEPLOYING_JARS_FROM_SHARED_CONDFIGURATION.toLocalizedString(), e);
+      throw new GemFireConfigException(
+          LocalizedStrings.GemFireCache_EXCEPTION_OCCURED_WHILE_DEPLOYING_JARS_FROM_SHARED_CONDFIGURATION
+              .toLocalizedString(),
+          e);
-  public static boolean isMisConfigured(Properties clusterProps, Properties serverProps, String key){
+  public static boolean isMisConfigured(Properties clusterProps, Properties serverProps,
+      String key) {
-    if(StringUtils.isBlank(serverPropValue))
+    if (StringUtils.isBlank(serverPropValue))
-    if(StringUtils.isBlank(clusterPropValue))
+    if (StringUtils.isBlank(clusterPropValue))
-    
-    Map<InternalDistributedMember, Collection<String>> scl = this.getDistributionManager().getAllHostedLocatorsWithSharedConfiguration();
-    //If there are no locators with Shared configuration, that means the system has been started without shared configuration 
-    //then do not make requests to the locators
+    Map<InternalDistributedMember, Collection<String>> scl =
+        this.getDistributionManager().getAllHostedLocatorsWithSharedConfiguration();
+
+    // If there are no locators with Shared configuration, that means the system has been started
+    // without shared configuration
+    // then do not make requests to the locators
-      Set<Entry<InternalDistributedMember, Collection<String>>> locs =  scl.entrySet();
-      
+      Set<Entry<InternalDistributedMember, Collection<String>>> locs = scl.entrySet();
+
-        
+
-  
-  
-  
- 
+
+
-   * Method to check for GemFire client. In addition to checking for ClientCacheFactory, this method checks for any
-   * defined pools.
+   * Method to check for GemFire client. In addition to checking for ClientCacheFactory, this method
+   * checks for any defined pools.
-   * Perform initialization, solve the early escaped reference problem by putting publishing references to this instance
-   * in this method (vs. the constructor).
+   * Perform initialization, solve the early escaped reference problem by putting publishing
+   * references to this instance in this method (vs. the constructor).
-      Assert.assertTrue(GemFireCacheImpl.instance == null, "Cache instance already in place: " + instance);
+      Assert.assertTrue(GemFireCacheImpl.instance == null,
+          "Cache instance already in place: " + instance);
-    
-    MinimumSystemRequirements.checkAndLog();
-    
-    for (Iterator<CacheLifecycleListener> iter = cacheLifecycleListeners.iterator(); iter.hasNext();) {
+
+    for (Iterator<CacheLifecycleListener> iter = cacheLifecycleListeners.iterator(); iter
+        .hasNext();) {
-    
+
-    //request and check cluster configuration
+    // request and check cluster configuration
-    ClusterConfigurationLoader.applyClusterPropertiesConfiguration(this, configurationResponse, system.getConfig());
+    ClusterConfigurationLoader.applyClusterPropertiesConfiguration(this, configurationResponse,
+        system.getConfig());
+
+    // first initialize the security service using the security properties
-       
+    // secondly if cacheConfig has a securityManager, use that instead
+    if (cacheConfig.getSecurityManager() != null) {
+      securityService.setSecurityManager(cacheConfig.getSecurityManager());
+    }
+    // if cacheConfig has a postProcessor, use that instead
+    if (cacheConfig.getPostProcessor() != null) {
+      securityService.setPostProcessor(cacheConfig.getPostProcessor());
+    }
+
+
-    
-    //Register function that we need to execute to fetch available REST service endpoints in DS
+
+    // Register function that we need to execute to fetch available REST service endpoints in DS
-    
+
-      //Deploy all the jars from the deploy working dir.
+      // Deploy all the jars from the deploy working dir.
-      ClusterConfigurationLoader.applyClusterXmlConfiguration(this, configurationResponse, system.getConfig());
+      ClusterConfigurationLoader.applyClusterXmlConfiguration(this, configurationResponse,
+          system.getConfig());
-    
+
-    
+
-    
+
-    
+
-    
+
-   * Initialize any services that provided as extensions to the cache using the
-   * service loader mechanism.
+   * Initialize any services that provided as extensions to the cache using the service loader
+   * mechanism.
-    for(CacheService service : loader) {
+    for (CacheService service : loader) {
-  private boolean isNotJmxManager(){
+  private boolean isNotJmxManager() {
-  
-  private boolean isServerNode(){
+
+  private boolean isServerNode() {
-         && this.system.getDistributedMember().getVmKind() != DistributionManager.ADMIN_ONLY_DM_TYPE
-         && !isClient());
+        && this.system.getDistributedMember().getVmKind() != DistributionManager.ADMIN_ONLY_DM_TYPE
+        && !isClient());
-  
+
-    if (this.system.getConfig().getStartDevRestApi()
-        && isNotJmxManager()
-        && isServerNode()) {
+    if (this.system.getConfig().getStartDevRestApi() && isNotJmxManager() && isServerNode()) {
-  
+
-        logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_MEMCACHED_SERVER_ON_PORT_0_FOR_1_PROTOCOL,
-                new Object[] { port, protocol }));
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_MEMCACHED_SERVER_ON_PORT_0_FOR_1_PROTOCOL,
+            new Object[] {port, protocol}));
-        logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_MEMCACHED_SERVER_ON_BIND_ADDRESS_0_PORT_1_FOR_2_PROTOCOL,
-                new Object[] { bindAddress, port, protocol }));
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_MEMCACHED_SERVER_ON_BIND_ADDRESS_0_PORT_1_FOR_2_PROTOCOL,
+            new Object[] {bindAddress, port, protocol}));
-      this.memcachedServer = new GemFireMemcachedServer(bindAddress, port, Protocol.valueOf(protocol.toUpperCase()));
+      this.memcachedServer =
+          new GemFireMemcachedServer(bindAddress, port, Protocol.valueOf(protocol.toUpperCase()));
-  
+
-        getLoggerI18n().info(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_PORT_0,
-            new Object[] { port });
+        getLoggerI18n().info(
+            LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_PORT_0,
+            new Object[] {port});
-        getLoggerI18n().info(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_BIND_ADDRESS_0_PORT_1,
-            new Object[] { bindAddress, port });
+        getLoggerI18n().info(
+            LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_BIND_ADDRESS_0_PORT_1,
+            new Object[] {bindAddress, port});
-            LocalizedStrings.GemFireCache_COULD_NOT_CONVERT_XML_FILE_0_TO_AN_URL.toLocalizedString(xmlFile), ex);
+            LocalizedStrings.GemFireCache_COULD_NOT_CONVERT_XML_FILE_0_TO_AN_URL
+                .toLocalizedString(xmlFile),
+            ex);
-          throw new CacheXmlException(LocalizedStrings.GemFireCache_DECLARATIVE_CACHE_XML_FILERESOURCE_0_DOES_NOT_EXIST
-              .toLocalizedString(xmlFile));
-        } else /* if (!xmlFile.isFile()) */{
-          throw new CacheXmlException(LocalizedStrings.GemFireCache_DECLARATIVE_XML_FILE_0_IS_NOT_A_FILE.toLocalizedString(xmlFile));
+          throw new CacheXmlException(
+              LocalizedStrings.GemFireCache_DECLARATIVE_CACHE_XML_FILERESOURCE_0_DOES_NOT_EXIST
+                  .toLocalizedString(xmlFile));
+        } else /* if (!xmlFile.isFile()) */ {
+          throw new CacheXmlException(
+              LocalizedStrings.GemFireCache_DECLARATIVE_XML_FILE_0_IS_NOT_A_FILE
+                  .toLocalizedString(xmlFile));
-   * Initializes the contents of this <code>Cache</code> according to the declarative caching XML file specified by the
-   * given <code>DistributedSystem</code>. Note that this operation cannot be performed in the constructor because
-   * creating regions in the cache, etc. uses the cache itself (which isn't initialized until the constructor returns).
+   * Initializes the contents of this <code>Cache</code> according to the declarative caching XML
+   * file specified by the given <code>DistributedSystem</code>. Note that this operation cannot be
+   * performed in the constructor because creating regions in the cache, etc. uses the cache itself
+   * (which isn't initialized until the constructor returns).
-   * @throws CacheXmlException
-   *           If something goes wrong while parsing the declarative caching XML file.
-   * @throws TimeoutException
-   *           If a {@link org.apache.geode.cache.Region#put(Object, Object)}times out while initializing the cache.
-   * @throws CacheWriterException
-   *           If a <code>CacheWriterException</code> is thrown while initializing the cache.
-   * @throws RegionExistsException
-   *           If the declarative caching XML file desribes a region that already exists (including the root region).
-   * @throws GatewayException
-   *           If a <code>GatewayException</code> is thrown while initializing the cache.
-   *           
+   * @throws CacheXmlException If something goes wrong while parsing the declarative caching XML
+   *         file.
+   * @throws TimeoutException If a {@link org.apache.geode.cache.Region#put(Object, Object)}times
+   *         out while initializing the cache.
+   * @throws CacheWriterException If a <code>CacheWriterException</code> is thrown while
+   *         initializing the cache.
+   * @throws RegionExistsException If the declarative caching XML file desribes a region that
+   *         already exists (including the root region).
+   * @throws GatewayException If a <code>GatewayException</code> is thrown while initializing the
+   *         cache.
+   * 
-  private void initializeDeclarativeCache() throws TimeoutException, CacheWriterException, GatewayException, RegionExistsException {
+  private void initializeDeclarativeCache()
+      throws TimeoutException, CacheWriterException, GatewayException, RegionExistsException {
-      throw new CacheXmlException(LocalizedStrings.GemFireCache_WHILE_OPENING_CACHE_XML_0_THE_FOLLOWING_ERROR_OCCURRED_1
-          .toLocalizedString(new Object[] { url.toString(), ex }));
+      throw new CacheXmlException(
+          LocalizedStrings.GemFireCache_WHILE_OPENING_CACHE_XML_0_THE_FOLLOWING_ERROR_OCCURRED_1
+              .toLocalizedString(new Object[] {url.toString(), ex}));
-      CacheXmlException newEx = new CacheXmlException(LocalizedStrings.GemFireCache_WHILE_READING_CACHE_XML_0_1
-          .toLocalizedString(new Object[] { url, ex.getMessage() }));
+      CacheXmlException newEx =
+          new CacheXmlException(LocalizedStrings.GemFireCache_WHILE_READING_CACHE_XML_0_1
+              .toLocalizedString(new Object[] {url, ex.getMessage()}));
-      logger.info(LocalizedMessage.create(
-          LocalizedStrings.GemFireCache_INITIALIZING_CACHE_USING__0__1, new Object[]{url.toString(), sb.toString()}));
+      logger.info(
+          LocalizedMessage.create(LocalizedStrings.GemFireCache_INITIALIZING_CACHE_USING__0__1,
+              new Object[] {url.toString(), sb.toString()}));
-      logger.info(LocalizedMessage.create(
-          LocalizedStrings.GemFireCache_INITIALIZING_CACHE_USING__0__1, new Object[] {"generated description from old cache", cacheXmlDescription}));
+      logger.info(
+          LocalizedMessage.create(LocalizedStrings.GemFireCache_INITIALIZING_CACHE_USING__0__1,
+              new Object[] {"generated description from old cache", cacheXmlDescription}));
-      //The member with locator is initialized with a NullTypePdxRegistration
+      // The member with locator is initialized with a NullTypePdxRegistration
-   * Call to make this vm's dynamic region factory ready. Public so it can be called from CacheCreation during xml
-   * processing
+   * Call to make this vm's dynamic region factory ready. Public so it can be called from
+   * CacheCreation during xml processing
-      throw new GemFireCacheException(LocalizedStrings.GemFireCache_DYNAMIC_REGION_INITIALIZATION_FAILED.toLocalizedString(), ce);
+      throw new GemFireCacheException(
+          LocalizedStrings.GemFireCache_DYNAMIC_REGION_INITIALIZATION_FAILED.toLocalizedString(),
+          ce);
-      String reason = GemFireCacheImpl.this.getDistributedSystem().getCancelCriterion().cancelInProgress();
+      String reason =
+          GemFireCacheImpl.this.getDistributedSystem().getCancelCriterion().cancelInProgress();
-      RuntimeException result = getDistributedSystem().getCancelCriterion().generateCancelledException(e);
+      RuntimeException result =
+          getDistributedSystem().getCancelCriterion().generateCancelledException(e);
-   * Close the distributed system, cache servers, and gateways. Clears the rootRegions and partitionedRegions map.
-   * Marks the cache as closed.
+   * Close the distributed system, cache servers, and gateways. Clears the rootRegions and
+   * partitionedRegions map. Marks the cache as closed.
-    
+
-    return isShutDownAll;
+    return isShutDownAll.get();
-   * Number of threads used to close PRs in shutdownAll. By default is the number of PRs in the cache
+   * Number of threads used to close PRs in shutdownAll. By default is the number of PRs in the
+   * cache
-  private static final int shutdownAllPoolSize = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "SHUTDOWN_ALL_POOL_SIZE", -1);
+  private static final int shutdownAllPoolSize =
+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "SHUTDOWN_ALL_POOL_SIZE", -1);
-  public synchronized void shutDownAll() {
-    boolean testIGE = Boolean.getBoolean("TestInternalGemFireError");
-
-    if (testIGE) {
-      InternalGemFireError assErr = new InternalGemFireError(LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString());
-      throw assErr;
-    }
-    if (isCacheAtShutdownAll()) {
-      // it's already doing shutdown by another thread
-      return;
-    }
+  public void shutDownAll() {
-    this.isShutDownAll = true;
+    if (!this.isShutDownAll.compareAndSet(false, true)) {
+      // it's already doing shutdown by another thread
+      try {
+        this.shutDownAllFinished.await();
+      } catch (InterruptedException e) {
+        logger.debug(
+            "Shutdown all interrupted while waiting for another thread to do the shutDownAll");
+        Thread.currentThread().interrupt();
+      }
+      return;
+    }
+    synchronized (GemFireCacheImpl.class) {
+      try {
+        boolean testIGE = Boolean.getBoolean("TestInternalGemFireError");
-    // bug 44031 requires multithread shutdownall should be grouped
-    // by root region. However, shutDownAllDuringRecovery.conf test revealed that
-    // we have to close colocated child regions first.
-    // Now check all the PR, if anyone has colocate-with attribute, sort all the
-    // PRs by colocation relationship and close them sequentially, otherwise still
-    // group them by root region.
-    TreeMap<String, Map<String, PartitionedRegion>> prTrees = getPRTrees();
-    if (prTrees.size() > 1 && shutdownAllPoolSize != 1) {
-      ExecutorService es = getShutdownAllExecutorService(prTrees.size());
-      for (final Map<String, PartitionedRegion> prSubMap : prTrees.values()) {
-        es.execute(new Runnable() {
-          public void run() {
-            ConnectionTable.threadWantsSharedResources();
+        if (testIGE) {
+          InternalGemFireError assErr = new InternalGemFireError(
+              LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString());
+          throw assErr;
+        }
+
+        // bug 44031 requires multithread shutdownall should be grouped
+        // by root region. However, shutDownAllDuringRecovery.conf test revealed that
+        // we have to close colocated child regions first.
+        // Now check all the PR, if anyone has colocate-with attribute, sort all the
+        // PRs by colocation relationship and close them sequentially, otherwise still
+        // group them by root region.
+        TreeMap<String, Map<String, PartitionedRegion>> prTrees = getPRTrees();
+        if (prTrees.size() > 1 && shutdownAllPoolSize != 1) {
+          ExecutorService es = getShutdownAllExecutorService(prTrees.size());
+          for (final Map<String, PartitionedRegion> prSubMap : prTrees.values()) {
+            es.execute(new Runnable() {
+              public void run() {
+                ConnectionTable.threadWantsSharedResources();
+                shutdownSubTreeGracefully(prSubMap);
+              }
+            });
+          } // for each root
+          es.shutdown();
+          try {
+            es.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS);
+          } catch (InterruptedException e) {
+            logger
+                .debug("Shutdown all interrupted while waiting for PRs to be shutdown gracefully.");
+          }
+
+        } else {
+          for (final Map<String, PartitionedRegion> prSubMap : prTrees.values()) {
-        });
-      } // for each root
-      es.shutdown();
-      try {
-        es.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS);
-      } catch (InterruptedException e) {
-        logger.debug("Shutdown all interrupted while waiting for PRs to be shutdown gracefully.");
-      }
+        }
-    } else {
-      for (final Map<String, PartitionedRegion> prSubMap : prTrees.values()) {
-        shutdownSubTreeGracefully(prSubMap);
+        close("Shut down all members", null, false, true);
+      } finally {
+        this.shutDownAllFinished.countDown();
-
-    close("Shut down all members", null, false, true);
-    ExecutorService es = Executors.newFixedThreadPool(shutdownAllPoolSize == -1 ? size : shutdownAllPoolSize, thrFactory);
+    ExecutorService es = Executors
+        .newFixedThreadPool(shutdownAllPoolSize == -1 ? size : shutdownAllPoolSize, thrFactory);
-      synchronized(pr.getRedundancyProvider()) {
-      if (pr.isDataStore() && pr.getDataStore() != null && pr.getDataPolicy() == DataPolicy.PERSISTENT_PARTITION) {
-        int numBuckets = pr.getTotalNumberOfBuckets();
-        Map<InternalDistributedMember, PersistentMemberID> bucketMaps[] = new Map[numBuckets];
-        PartitionedRegionDataStore prds = pr.getDataStore();
+      synchronized (pr.getRedundancyProvider()) {
+        if (pr.isDataStore() && pr.getDataStore() != null
+            && pr.getDataPolicy() == DataPolicy.PERSISTENT_PARTITION) {
+          int numBuckets = pr.getTotalNumberOfBuckets();
+          Map<InternalDistributedMember, PersistentMemberID> bucketMaps[] = new Map[numBuckets];
+          PartitionedRegionDataStore prds = pr.getDataStore();
-        // lock all the primary buckets
-        Set<Entry<Integer, BucketRegion>> bucketEntries = prds.getAllLocalBuckets();
-        for (Map.Entry e : bucketEntries) {
-          BucketRegion br = (BucketRegion) e.getValue();
-          if (br == null || br.isDestroyed) {
-            // bucket region could be destroyed in race condition
-            continue;
-          }
-          br.getBucketAdvisor().tryLockIfPrimary();
+          // lock all the primary buckets
+          Set<Entry<Integer, BucketRegion>> bucketEntries = prds.getAllLocalBuckets();
+          for (Map.Entry e : bucketEntries) {
+            BucketRegion br = (BucketRegion) e.getValue();
+            if (br == null || br.isDestroyed) {
+              // bucket region could be destroyed in race condition
+              continue;
+            }
+            br.getBucketAdvisor().tryLockIfPrimary();
-          // get map <InternalDistriutedMemeber, persistentID> for this bucket's
-          // remote members
-          bucketMaps[br.getId()] = br.getBucketAdvisor().adviseInitializedPersistentMembers();
-          if (logger.isDebugEnabled()) {
-            logger.debug("shutDownAll: PR {}: initialized persistent members for {}:{}", pr.getName(), br.getId(), bucketMaps[br.getId()]);
-          }
-        }
-        if (logger.isDebugEnabled()) {
-          logger.debug("shutDownAll: All buckets for PR {} are locked.", pr.getName());
-        }
-
-        // send lock profile update to other members
-        pr.setShutDownAllStatus(PartitionedRegion.PRIMARY_BUCKETS_LOCKED);
-        new UpdateAttributesProcessor(pr).distribute(false);
-        pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.PRIMARY_BUCKETS_LOCKED);
-        if (logger.isDebugEnabled()) {
-          logger.debug("shutDownAll: PR {}: all bucketlock profiles received.", pr.getName());
-        }
-
-        // if async write, do flush
-        if (!pr.getAttributes().isDiskSynchronous()) {
-          // several PRs might share the same diskstore, we will only flush once
-          // even flush is called several times.
-          pr.getDiskStore().forceFlush();
-          // send flush profile update to other members
-          pr.setShutDownAllStatus(PartitionedRegion.DISK_STORE_FLUSHED);
-          new UpdateAttributesProcessor(pr).distribute(false);
-          pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.DISK_STORE_FLUSHED);
-          if (logger.isDebugEnabled()) {
-            logger.debug("shutDownAll: PR {}: all flush profiles received.", pr.getName());
-          }
-        } // async write
-
-        // persist other members to OFFLINE_EQUAL for each bucket region
-        // iterate through all the bucketMaps and exclude the items whose
-        // idm is no longer online
-        Set<InternalDistributedMember> membersToPersistOfflineEqual = pr.getRegionAdvisor().adviseDataStore();
-        for (Map.Entry e : bucketEntries) {
-          BucketRegion br = (BucketRegion) e.getValue();
-          if (br == null || br.isDestroyed) {
-            // bucket region could be destroyed in race condition
-            continue;
-          }
-          Map<InternalDistributedMember, PersistentMemberID> persistMap = getSubMapForLiveMembers(pr, membersToPersistOfflineEqual,
-              bucketMaps[br.getId()]);
-          if (persistMap != null) {
-            br.getPersistenceAdvisor().persistMembersOfflineAndEqual(persistMap);
+            // get map <InternalDistriutedMemeber, persistentID> for this bucket's
+            // remote members
+            bucketMaps[br.getId()] = br.getBucketAdvisor().adviseInitializedPersistentMembers();
-              logger.debug("shutDownAll: PR {}: pesisting bucket {}:{}", pr.getName(), br.getId(), persistMap);
+              logger.debug("shutDownAll: PR {}: initialized persistent members for {}:{}",
+                  pr.getName(), br.getId(), bucketMaps[br.getId()]);
-        }
+          if (logger.isDebugEnabled()) {
+            logger.debug("shutDownAll: All buckets for PR {} are locked.", pr.getName());
+          }
-        // send persited profile update to other members, let all members to persist
-        // before close the region
-        pr.setShutDownAllStatus(PartitionedRegion.OFFLINE_EQUAL_PERSISTED);
-        new UpdateAttributesProcessor(pr).distribute(false);
-        pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.OFFLINE_EQUAL_PERSISTED);
-        if (logger.isDebugEnabled()) {
-          logger.debug("shutDownAll: PR {}: all offline_equal profiles received.", pr.getName());
-        }
-      } // datastore
+          // send lock profile update to other members
+          pr.setShutDownAllStatus(PartitionedRegion.PRIMARY_BUCKETS_LOCKED);
+          new UpdateAttributesProcessor(pr).distribute(false);
+          pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.PRIMARY_BUCKETS_LOCKED);
+          if (logger.isDebugEnabled()) {
+            logger.debug("shutDownAll: PR {}: all bucketlock profiles received.", pr.getName());
+          }
-      // after done all steps for buckets, close pr
-      // close accessor directly
-      RegionEventImpl event = new RegionEventImpl(pr, Operation.REGION_CLOSE, null, false, getMyId(), true);
-      try {
-        // not to acquire lock
-        pr.basicDestroyRegion(event, false, false, true);
-      } catch (CacheWriterException e) {
-        // not possible with local operation, CacheWriter not called
-        throw new Error(LocalizedStrings.LocalRegion_CACHEWRITEREXCEPTION_SHOULD_NOT_BE_THROWN_IN_LOCALDESTROYREGION
-            .toLocalizedString(), e);
-      } catch (TimeoutException e) {
-        // not possible with local operation, no distributed locks possible
-        throw new Error(LocalizedStrings.LocalRegion_TIMEOUTEXCEPTION_SHOULD_NOT_BE_THROWN_IN_LOCALDESTROYREGION
-            .toLocalizedString(), e);
-      }
-      // pr.close();
+          // if async write, do flush
+          if (!pr.getAttributes().isDiskSynchronous()) {
+            // several PRs might share the same diskstore, we will only flush once
+            // even flush is called several times.
+            pr.getDiskStore().forceFlush();
+            // send flush profile update to other members
+            pr.setShutDownAllStatus(PartitionedRegion.DISK_STORE_FLUSHED);
+            new UpdateAttributesProcessor(pr).distribute(false);
+            pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.DISK_STORE_FLUSHED);
+            if (logger.isDebugEnabled()) {
+              logger.debug("shutDownAll: PR {}: all flush profiles received.", pr.getName());
+            }
+          } // async write
+
+          // persist other members to OFFLINE_EQUAL for each bucket region
+          // iterate through all the bucketMaps and exclude the items whose
+          // idm is no longer online
+          Set<InternalDistributedMember> membersToPersistOfflineEqual =
+              pr.getRegionAdvisor().adviseDataStore();
+          for (Map.Entry e : bucketEntries) {
+            BucketRegion br = (BucketRegion) e.getValue();
+            if (br == null || br.isDestroyed) {
+              // bucket region could be destroyed in race condition
+              continue;
+            }
+            Map<InternalDistributedMember, PersistentMemberID> persistMap =
+                getSubMapForLiveMembers(pr, membersToPersistOfflineEqual, bucketMaps[br.getId()]);
+            if (persistMap != null) {
+              br.getPersistenceAdvisor().persistMembersOfflineAndEqual(persistMap);
+              if (logger.isDebugEnabled()) {
+                logger.debug("shutDownAll: PR {}: pesisting bucket {}:{}", pr.getName(), br.getId(),
+                    persistMap);
+              }
+            }
+          }
+
+          // send persited profile update to other members, let all members to persist
+          // before close the region
+          pr.setShutDownAllStatus(PartitionedRegion.OFFLINE_EQUAL_PERSISTED);
+          new UpdateAttributesProcessor(pr).distribute(false);
+          pr.getRegionAdvisor().waitForProfileStatus(PartitionedRegion.OFFLINE_EQUAL_PERSISTED);
+          if (logger.isDebugEnabled()) {
+            logger.debug("shutDownAll: PR {}: all offline_equal profiles received.", pr.getName());
+          }
+        } // datastore
+
+        // after done all steps for buckets, close pr
+        // close accessor directly
+        RegionEventImpl event =
+            new RegionEventImpl(pr, Operation.REGION_CLOSE, null, false, getMyId(), true);
+        try {
+          // not to acquire lock
+          pr.basicDestroyRegion(event, false, false, true);
+        } catch (CacheWriterException e) {
+          // not possible with local operation, CacheWriter not called
+          throw new Error(
+              LocalizedStrings.LocalRegion_CACHEWRITEREXCEPTION_SHOULD_NOT_BE_THROWN_IN_LOCALDESTROYREGION
+                  .toLocalizedString(),
+              e);
+        } catch (TimeoutException e) {
+          // not possible with local operation, no distributed locks possible
+          throw new Error(
+              LocalizedStrings.LocalRegion_TIMEOUTEXCEPTION_SHOULD_NOT_BE_THROWN_IN_LOCALDESTROYREGION
+                  .toLocalizedString(),
+              e);
+        }
+        // pr.close();
-      logger.debug("Encounter CacheClosedException when shutDownAll is closing PR: {}:{}", pr.getFullPath(), cce.getMessage());
+      logger.debug("Encounter CacheClosedException when shutDownAll is closing PR: {}:{}",
+          pr.getFullPath(), cce.getMessage());
-      logger.debug("Encounter CancelException when shutDownAll is closing PR: {}:{}", pr.getFullPath(), ce.getMessage());
+      logger.debug("Encounter CancelException when shutDownAll is closing PR: {}:{}",
+          pr.getFullPath(), ce.getMessage());
-      logger.debug("Encounter CacheDestroyedException when shutDownAll is closing PR: {}:{}", pr.getFullPath(), rde.getMessage());
+      logger.debug("Encounter CacheDestroyedException when shutDownAll is closing PR: {}:{}",
+          pr.getFullPath(), rde.getMessage());
-  private Map<InternalDistributedMember, PersistentMemberID> getSubMapForLiveMembers(PartitionedRegion pr,
-      Set<InternalDistributedMember> membersToPersistOfflineEqual, Map<InternalDistributedMember, PersistentMemberID> bucketMap) {
+  private Map<InternalDistributedMember, PersistentMemberID> getSubMapForLiveMembers(
+      PartitionedRegion pr, Set<InternalDistributedMember> membersToPersistOfflineEqual,
+      Map<InternalDistributedMember, PersistentMemberID> bucketMap) {
+  public void close(String reason, boolean keepalive, boolean keepDS) {
+    close(reason, null, keepalive, keepDS);
+  }
+
-   * Gets or lazily creates the PartitionedRegion distributed lock service. This call will synchronize on this
-   * GemFireCache.
+   * Gets or lazily creates the PartitionedRegion distributed lock service. This call will
+   * synchronize on this GemFireCache.
-          this.prLockService = DLockService.create(PartitionedRegionHelper.PARTITION_LOCK_SERVICE_NAME, getDistributedSystem(),
-              true /* distributed */, true /* destroyOnDisconnect */, true /* automateFreeResources */);
+          this.prLockService =
+              DLockService.create(PartitionedRegionHelper.PARTITION_LOCK_SERVICE_NAME,
+                  getDistributedSystem(), true /* distributed */, true /* destroyOnDisconnect */,
+                  true /* automateFreeResources */);
-          this.prLockService = DistributedLockService.getServiceNamed(PartitionedRegionHelper.PARTITION_LOCK_SERVICE_NAME);
+          this.prLockService = DistributedLockService
+              .getServiceNamed(PartitionedRegionHelper.PARTITION_LOCK_SERVICE_NAME);
+   * 
-            this.gatewayLockService = DLockService.create(
-                AbstractGatewaySender.LOCK_SERVICE_NAME, 
-                getDistributedSystem(), 
-                true /*distributed*/, 
-                true /*destroyOnDisconnect*/, 
-                true /*automateFreeResources*/);
-          }
-          catch (IllegalArgumentException e) {
-            this.gatewayLockService = DistributedLockService.getServiceNamed(
-                AbstractGatewaySender.LOCK_SERVICE_NAME);
+            this.gatewayLockService = DLockService.create(AbstractGatewaySender.LOCK_SERVICE_NAME,
+                getDistributedSystem(), true /* distributed */, true /* destroyOnDisconnect */,
+                true /* automateFreeResources */);
+          } catch (IllegalArgumentException e) {
+            this.gatewayLockService =
+                DistributedLockService.getServiceNamed(AbstractGatewaySender.LOCK_SERVICE_NAME);
-   * Destroys the PartitionedRegion distributed lock service when closing the cache. Caller must be synchronized on this
-   * GemFireCache.
+   * Destroys the PartitionedRegion distributed lock service when closing the cache. Caller must be
+   * synchronized on this GemFireCache.
-   * Destroys the GatewaySender distributed lock service when closing
-   * the cache. Caller must be synchronized on this GemFireCache.
+   * Destroys the GatewaySender distributed lock service when closing the cache. Caller must be
+   * synchronized on this GemFireCache.
-    if (DistributedLockService
-        .getServiceNamed(AbstractGatewaySender.LOCK_SERVICE_NAME) != null) {
+    if (DistributedLockService.getServiceNamed(AbstractGatewaySender.LOCK_SERVICE_NAME) != null) {
-      }
-      catch (IllegalArgumentException e) {
+      } catch (IllegalArgumentException e) {
-    }    
+    }
-  
+
-  private final boolean DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE");
+  private final boolean DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE = Boolean
+      .getBoolean(DistributionConfig.GEMFIRE_PREFIX + "DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE");
-   * @param reason
-   *          the reason the cache is being closed
-   * @param systemFailureCause
-   *          whether this member was ejected from the distributed system
-   * @param keepalive
-   *          whoever added this should javadoc it
+   * @param reason the reason the cache is being closed
+   * @param systemFailureCause whether this member was ejected from the distributed system
+   * @param keepalive whoever added this should javadoc it
-  public void close(String reason, Throwable systemFailureCause, boolean keepalive, boolean keepDS) {
+  public void close(String reason, Throwable systemFailureCause, boolean keepalive,
+      boolean keepDS) {
-       * First close the ManagementService as it uses a lot of infra which will be closed by cache.close()
+       * First close the ManagementService as it uses a lot of infra which will be closed by
+       * cache.close()
-        } 
+        }
-        ParallelGatewaySenderQueue.cleanUpStatics(null);
-         * IMPORTANT: any operation during shut down that can time out (create a CancelException) must be inside of this
-         * try block. If all else fails, we *must* ensure that the cache gets closed!
+         * IMPORTANT: any operation during shut down that can time out (create a CancelException)
+         * must be inside of this try block. If all else fails, we *must* ensure that the cache gets
+         * closed!
-        try {                              
+        try {
-          
+
-            
+
-                if(lr.getName().contains(ParallelGatewaySenderQueue.QSTRING)){
-                  continue; //this region will be closed internally by parent region
+                if (lr.getName().contains(ParallelGatewaySenderQueue.QSTRING)) {
+                  continue; // this region will be closed internally by parent region
-                    logger.warn(LocalizedMessage.create(LocalizedStrings.GemFireCache_0_ERROR_CLOSING_REGION_1,
-                        new Object[] { this, lr.getFullPath() }), e);
+                    logger.warn(LocalizedMessage.create(
+                        LocalizedStrings.GemFireCache_0_ERROR_CLOSING_REGION_1,
+                        new Object[] {this, lr.getFullPath()}), e);
-              logger.warn(LocalizedMessage.create(LocalizedStrings.GemFireCache_0_ERROR_IN_LAST_STAGE_OF_PARTITIONEDREGION_CACHE_CLOSE,
+              logger.warn(LocalizedMessage.create(
+                  LocalizedStrings.GemFireCache_0_ERROR_IN_LAST_STAGE_OF_PARTITIONEDREGION_CACHE_CLOSE,
-          
+
-            logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_1));
+            logger.info(LocalizedMessage.create(
+                LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_1));
-          logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_2));
+          logger.info(LocalizedMessage.create(
+              LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_2));
-        stopDiskStoreTaskPool();        
+        stopDiskStoreTaskPool();
-      
+
-      
+
-      }      
+      }
-      
+
-  
+
-    boolean systemReconnected = this.system.waitUntilReconnected(time,  units);
+    boolean systemReconnected = this.system.waitUntilReconnected(time, units);
-  
+
-  
+
+    if (c == null) {
+      return null;
+    }
-      logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCacheImpl_MEMCACHED_SERVER_ON_PORT_0_IS_SHUTTING_DOWN,
-          new Object[] { this.system.getConfig().getMemcachedPort() }));
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.GemFireCacheImpl_MEMCACHED_SERVER_ON_PORT_0_IS_SHUTTING_DOWN,
+          new Object[] {this.system.getConfig().getMemcachedPort()}));
-  
+
-  
+
-    if ( this.restAgent != null) {
-      logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCacheImpl_REST_SERVER_ON_PORT_0_IS_SHUTTING_DOWN,
-          new Object[] { this.system.getConfig().getHttpServicePort() }));
+    if (this.restAgent != null) {
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.GemFireCacheImpl_REST_SERVER_ON_PORT_0_IS_SHUTTING_DOWN,
+          new Object[] {this.system.getConfig().getHttpServicePort()}));
-    final ThreadGroup compactThreadGroup = LoggingThreadGroup.createThreadGroup("Oplog Compactor Thread Group", logger);
-    /*final ThreadFactory compactThreadFactory = new ThreadFactory() {
-      public Thread newThread(Runnable command) {
-        Thread thread = new Thread(compactThreadGroup, command, "Idle OplogCompactor");
-        thread.setDaemon(true);
-        return thread;
-      }
-    };*/
+    final ThreadGroup compactThreadGroup =
+        LoggingThreadGroup.createThreadGroup("Oplog Compactor Thread Group", logger);
+    /*
+     * final ThreadFactory compactThreadFactory = new ThreadFactory() { public Thread
+     * newThread(Runnable command) { Thread thread = new Thread(compactThreadGroup, command,
+     * "Idle OplogCompactor"); thread.setDaemon(true); return thread; } };
+     */
-    final ThreadFactory compactThreadFactory = GemfireCacheHelper.CreateThreadFactory(compactThreadGroup, "Idle OplogCompactor");
+    final ThreadFactory compactThreadFactory =
+        GemfireCacheHelper.CreateThreadFactory(compactThreadGroup, "Idle OplogCompactor");
-                                             new LinkedBlockingQueue(),
-                                             compactThreadFactory);
+        new LinkedBlockingQueue(), compactThreadFactory);
-  private final ConcurrentMap<String, DiskStoreImpl> diskStores = new ConcurrentHashMap<String, DiskStoreImpl>();
-  private final ConcurrentMap<String, DiskStoreImpl> regionOwnedDiskStores = new ConcurrentHashMap<String, DiskStoreImpl>();
-  
+  private final ConcurrentMap<String, DiskStoreImpl> diskStores =
+      new ConcurrentHashMap<String, DiskStoreImpl>();
+  private final ConcurrentMap<String, DiskStoreImpl> regionOwnedDiskStores =
+      new ConcurrentHashMap<String, DiskStoreImpl>();
+
-    if(!dsi.getOwnedByRegion())
-    system.handleResourceEvent(ResourceEvent.DISKSTORE_REMOVE, dsi);
+    if (!dsi.getOwnedByRegion())
+      system.handleResourceEvent(ResourceEvent.DISKSTORE_REMOVE, dsi);
-        logger.fatal(LocalizedMessage.create(LocalizedStrings.Disk_Store_Exception_During_Cache_Close), e);
+        logger.fatal(
+            LocalizedMessage.create(LocalizedStrings.Disk_Store_Exception_During_Cache_Close), e);
- /* private static class DiskStoreFuture extends FutureTask {
-    private DiskStoreTask task;
-
-    public DiskStoreFuture(DiskStoreTask r) {
-      super(r, null);
-      this.task = r;
-    }
-
-    @Override
-    public boolean cancel(boolean mayInterruptIfRunning) {
-      boolean result = super.cancel(mayInterruptIfRunning);
-      if (result) {
-        task.taskCancelled();
-      }
-      return result;
-    }
-
-  }*/
+  /*
+   * private static class DiskStoreFuture extends FutureTask { private DiskStoreTask task;
+   * 
+   * public DiskStoreFuture(DiskStoreTask r) { super(r, null); this.task = r; }
+   * 
+   * @Override public boolean cancel(boolean mayInterruptIfRunning) { boolean result =
+   * super.cancel(mayInterruptIfRunning); if (result) { task.taskCancelled(); } return result; }
+   * 
+   * }
+   */
-      //this.diskStoreTaskPool = null;
+      // this.diskStoreTaskPool = null;
-    
+
-          advisor = ((AbstractGatewaySender)sender).getSenderAdvisor();
+          advisor = ((AbstractGatewaySender) sender).getSenderAdvisor();
-        }
-        catch (CancelException e) {
+        } catch (CancelException e) {
-    
+
-      logger.debug("{}: finished stopping {} gateway sender(s), total is {}", this, cnt, allGatewaySenders.size());
+      logger.debug("{}: finished stopping {} gateway sender(s), total is {}", this, cnt,
+          allGatewaySenders.size());
-  
+
-        }
-        catch (CancelException e) {
+        } catch (CancelException e) {
-      logger.debug("{}: finished stopping {} gateway receiver(s), total is {}", this, cnt, allGatewayReceivers.size());
+      logger.debug("{}: finished stopping {} gateway receiver(s), total is {}", this, cnt,
+          allGatewayReceivers.size());
-    
+
-      // now that all the cache servers have stopped empty the static pool of commBuffers it might have used.
+      // now that all the cache servers have stopped empty the static pool of commBuffers it might
+      // have used.
-    
+
-  
+
-  
+
-  
+
-  
+
-   * System.currentTimeMillis(). Specially all version stamps/tags must be
-   * populated with this timestamp.
+   * System.currentTimeMillis(). Specially all version stamps/tags must be populated with this
+   * timestamp.
-  public Region createVMRegion(String name, RegionAttributes attrs) throws RegionExistsException, TimeoutException {
+  public Region createVMRegion(String name, RegionAttributes attrs)
+      throws RegionExistsException, TimeoutException {
-          throw new IllegalStateException("Existing cache's default pool was not the same as the only existing pool");
+          throw new IllegalStateException(
+              "Existing cache's default pool was not the same as the only existing pool");
-  public Region createRegion(String name, RegionAttributes attrs) throws RegionExistsException, TimeoutException {
+  public Region createRegion(String name, RegionAttributes attrs)
+      throws RegionExistsException, TimeoutException {
-  public Region basicCreateRegion(String name, RegionAttributes attrs) throws RegionExistsException, TimeoutException {
+  public Region basicCreateRegion(String name, RegionAttributes attrs)
+      throws RegionExistsException, TimeoutException {
-      InternalRegionArguments ira = new InternalRegionArguments().setDestroyLockFlag(true).setRecreateFlag(false)
-          .setSnapshotInputStream(null).setImageTarget(null);
+      InternalRegionArguments ira = new InternalRegionArguments().setDestroyLockFlag(true)
+          .setRecreateFlag(false).setSnapshotInputStream(null).setImageTarget(null);
-      InternalGemFireError assErr = new InternalGemFireError(LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString());
+      InternalGemFireError assErr = new InternalGemFireError(
+          LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString());
-  public <K, V> Region<K, V> createVMRegion(String name, RegionAttributes<K, V> p_attrs, InternalRegionArguments internalRegionArgs)
+  public <K, V> Region<K, V> createVMRegion(String name, RegionAttributes<K, V> p_attrs,
+      InternalRegionArguments internalRegionArgs)
-      if (!internalRegionArgs.isUsedForMetaRegion() && internalRegionArgs.getInternalMetaRegion() == null) {
+      if (!internalRegionArgs.isUsedForMetaRegion()
+          && internalRegionArgs.getInternalMetaRegion() == null) {
-      throw new IllegalArgumentException(LocalizedStrings.GemFireCache_ATTRIBUTES_MUST_NOT_BE_NULL.toLocalizedString());
+      throw new IllegalArgumentException(
+          LocalizedStrings.GemFireCache_ATTRIBUTES_MUST_NOT_BE_NULL.toLocalizedString());
-    
+
-              /*for (String senderId : attrs.getGatewaySenderIds()) {
-                if (getGatewaySender(senderId) != null
-                    && getGatewaySender(senderId).isParallel()) {
-                  throw new IllegalStateException(
-                      LocalizedStrings.AttributesFactory_PARALLELGATEWAYSENDER_0_IS_INCOMPATIBLE_WITH_DISTRIBUTED_REPLICATION
-                          .toLocalizedString(senderId));
-                }
-              }*/
+              /*
+               * for (String senderId : attrs.getGatewaySenderIds()) { if
+               * (getGatewaySender(senderId) != null && getGatewaySender(senderId).isParallel()) {
+               * throw new IllegalStateException( LocalizedStrings.
+               * AttributesFactory_PARALLELGATEWAYSENDER_0_IS_INCOMPATIBLE_WITH_DISTRIBUTED_REPLICATION
+               * .toLocalizedString(senderId)); } }
+               */
-          throw new Error(LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString(), e);
+          throw new Error(LocalizedStrings.GemFireCache_UNEXPECTED_EXCEPTION.toLocalizedString(),
+              e);
-      
+
-            LocalizedStrings.GemFireCache_INITIALIZATION_FAILED_FOR_REGION_0, rgn.getFullPath()), validationException);
+            LocalizedStrings.GemFireCache_INITIALIZATION_FAILED_FOR_REGION_0, rgn.getFullPath()),
+            validationException);
-            
+
-                LocalizedStrings.GemFireCache_INIT_CLEANUP_FAILED_FOR_REGION_0, rgn.getFullPath()), t);
+                LocalizedStrings.GemFireCache_INIT_CLEANUP_FAILED_FOR_REGION_0, rgn.getFullPath()),
+                t);
-      
-      
+
+
-  public RegionAttributes invokeRegionBefore(LocalRegion parent,
-      String name, RegionAttributes attrs, InternalRegionArguments internalRegionArgs) {
-    for(RegionListener listener : regionListeners) {
+  public RegionAttributes invokeRegionBefore(LocalRegion parent, String name,
+      RegionAttributes attrs, InternalRegionArguments internalRegionArgs) {
+    for (RegionListener listener : regionListeners) {
-  
+
-    for(RegionListener listener : regionListeners) {
+    for (RegionListener listener : regionListeners) {
-        if (rgn.isSecret() || rgn.isUsedForMetaRegion() || rgn instanceof HARegion || rgn.isUsedForPartitionedRegionAdmin()
+        if (rgn.isSecret() || rgn.isUsedForMetaRegion() || rgn instanceof HARegion
+            || rgn.isUsedForPartitionedRegionAdmin()
-   * @throws IllegalArgumentException
-   *           if path is not valid
+   * @throws IllegalArgumentException if path is not valid
-      throw new IllegalArgumentException(LocalizedStrings.GemFireCache_PATH_CANNOT_BE_NULL.toLocalizedString());
+      throw new IllegalArgumentException(
+          LocalizedStrings.GemFireCache_PATH_CANNOT_BE_NULL.toLocalizedString());
-      throw new IllegalArgumentException(LocalizedStrings.GemFireCache_PATH_CANNOT_BE_EMPTY.toLocalizedString());
+      throw new IllegalArgumentException(
+          LocalizedStrings.GemFireCache_PATH_CANNOT_BE_EMPTY.toLocalizedString());
-      throw new IllegalArgumentException(LocalizedStrings.GemFireCache_PATH_CANNOT_BE_0.toLocalizedString(Region.SEPARATOR));
+      throw new IllegalArgumentException(
+          LocalizedStrings.GemFireCache_PATH_CANNOT_BE_0.toLocalizedString(Region.SEPARATOR));
-          logger.debug("GemFireCache.getRegion, calling getSubregion on root({}): {}", pathParts[0], pathParts[1]);
+          logger.debug("GemFireCache.getRegion, calling getSubregion on root({}): {}", pathParts[0],
+              pathParts[1]);
-   * @param returnDestroyedRegion
-   *          if true, okay to return a destroyed region
+   * @param returnDestroyedRegion if true, okay to return a destroyed region
-      logger.debug("GemFireCache.getRegion, calling getSubregion on root({}): {}", pathParts[0], pathParts[1]);
+      logger.debug("GemFireCache.getRegion, calling getSubregion on root({}): {}", pathParts[0],
+          pathParts[1]);
-   * @param returnDestroyedRegion
-   *          if true, okay to return a destroyed partitioned region
+   * @param returnDestroyedRegion if true, okay to return a destroyed partitioned region
- 
+
-      logger.fine("GemFireCache.getPartitionedRegion, calling getSubregion on root(" + pathParts[0] + "): " + pathParts[1]);
+      logger.fine("GemFireCache.getPartitionedRegion, calling getSubregion on root(" + pathParts[0]
+          + "): " + pathParts[1]);
-        if (r.isSecret() || r.isUsedForMetaRegion() || r instanceof HARegion || !includePRAdminRegions
-            && (r.isUsedForPartitionedRegionAdmin() || r.isUsedForPartitionedRegionBucket())) {
+        if (r.isSecret() || r.isUsedForMetaRegion() || r instanceof HARegion
+            || !includePRAdminRegions
+                && (r.isUsedForPartitionedRegionAdmin() || r.isUsedForPartitionedRegionBucket())) {
-          LocalizedStrings.GemFireCache_THE_MESSAGESYNCINTERVAL_PROPERTY_FOR_CACHE_CANNOT_BE_NEGATIVE.toLocalizedString());
+          LocalizedStrings.GemFireCache_THE_MESSAGESYNCINTERVAL_PROPERTY_FOR_CACHE_CANNOT_BE_NEGATIVE
+              .toLocalizedString());
-   * Get a reference to a Region that is reinitializing, or null if that Region is not reinitializing or this thread is
-   * interrupted. If a reinitializing region is found, then this method blocks until reinitialization is complete and
-   * then returns the region.
+   * Get a reference to a Region that is reinitializing, or null if that Region is not
+   * reinitializing or this thread is interrupted. If a reinitializing region is found, then this
+   * method blocks until reinitialization is complete and then returns the region.
-   * Register the specified region name as reinitializing, creating and adding a Future for it to the map.
+   * Register the specified region name as reinitializing, creating and adding a Future for it to
+   * the map.
-   * @throws IllegalStateException
-   *           if there is already a region by that name registered.
+   * @throws IllegalStateException if there is already a region by that name registered.
-      throw new IllegalStateException(LocalizedStrings.GemFireCache_FOUND_AN_EXISTING_REINITALIZING_REGION_NAMED_0
-          .toLocalizedString(fullPath));
+      throw new IllegalStateException(
+          LocalizedStrings.GemFireCache_FOUND_AN_EXISTING_REINITALIZING_REGION_NAMED_0
+              .toLocalizedString(fullPath));
-   * @throws IllegalStateException
-   *           if there is no region by that name registered as reinitializing.
+   * @throws IllegalStateException if there is no region by that name registered as reinitializing.
-      throw new IllegalStateException(LocalizedStrings.GemFireCache_COULD_NOT_FIND_A_REINITIALIZING_REGION_NAMED_0
-          .toLocalizedString(regionName));
+      throw new IllegalStateException(
+          LocalizedStrings.GemFireCache_COULD_NOT_FIND_A_REINITIALIZING_REGION_NAMED_0
+              .toLocalizedString(regionName));
-   * @throws IllegalStateException
-   *           if cannot find reinitializing region registered by that name.
+   * @throws IllegalStateException if cannot find reinitializing region registered by that name.
-   * @param rootRgn
-   *          the region to be removed
+   * @param rootRgn the region to be removed
-   * @return array of two Strings, the root name and the relative path from root If there is no relative path from root,
-   *         then String[1] will be an empty string
+   * @return array of two Strings, the root name and the relative path from root If there is no
+   *         relative path from root, then String[1] will be an empty string
-  
-  public void addRegionListener(RegionListener l ) {
+
+  public void addRegionListener(RegionListener l) {
-  
-  public void removeRegionListener(RegionListener l ) {
+
+  public void removeRegionListener(RegionListener l) {
-  
+
-   * Creates the single instance of the Transation Manager for this cache. Returns the existing one upon request.
+   * Creates the single instance of the Transation Manager for this cache. Returns the existing one
+   * upon request.
-  
+
-        throw new IllegalStateException(LocalizedStrings.GemFireCache_A_GATEWAYSENDER_WITH_ID_0_IS_ALREADY_DEFINED_IN_THIS_CACHE
-            .toLocalizedString(sender.getId()));
+        throw new IllegalStateException(
+            LocalizedStrings.GemFireCache_A_GATEWAYSENDER_WITH_ID_0_IS_ALREADY_DEFINED_IN_THIS_CACHE
+                .toLocalizedString(sender.getId()));
-     if(!sender.isParallel()) {
-       Region dynamicMetaRegion = getRegion(DynamicRegionFactory.dynamicRegionListName);
-       if(dynamicMetaRegion == null) {
-         if(logger.isDebugEnabled()) {
-           logger.debug(" The dynamic region is null. ");
-         }
+    if (!sender.isParallel()) {
+      Region dynamicMetaRegion = getRegion(DynamicRegionFactory.dynamicRegionListName);
+      if (dynamicMetaRegion == null) {
+        if (logger.isDebugEnabled()) {
+          logger.debug(" The dynamic region is null. ");
+        }
-  
+
-    
+
-    if(!asyncQueue.isMetaQueue()) {
+    if (!asyncQueue.isMetaQueue()) {
-    system
-        .handleResourceEvent(ResourceEvent.ASYNCEVENTQUEUE_CREATE, asyncQueue);
+    system.handleResourceEvent(ResourceEvent.ASYNCEVENTQUEUE_CREATE, asyncQueue);
-  
+
-   * @return  List    List of GatewaySender objects
+   * @return List List of GatewaySender objects
-      if (!((AbstractGatewaySender)sender).isForInternalUse()) {
+      if (!((AbstractGatewaySender) sender).isForInternalUse()) {
-   * @return  List    List of GatewaySender objects
+   * @return List List of GatewaySender objects
-  
+
-      throw new UnsupportedOperationException(
-          "operation is not supported on a client cache");
+      throw new UnsupportedOperationException("operation is not supported on a client cache");
-      removeGatewaySender(((AsyncEventQueueImpl)asyncQueue).getSender());
+      removeGatewaySender(((AsyncEventQueueImpl) asyncQueue).getSender());
-  
+
-  
+
-  public List getCacheServers() {
+  public List<CacheServer> getCacheServers() {
-    Iterator allCacheServersIterator = allCacheServers.iterator();
-    while (allCacheServersIterator.hasNext()) {
-      CacheServerImpl cacheServer = (CacheServerImpl) allCacheServersIterator.next();
-      // If CacheServer is a GatewayReceiver, don't return as part of CacheServers
-      if (!cacheServer.isGatewayReceiver()) {
-        if (cacheServersWithoutReceiver == null) {
-          cacheServersWithoutReceiver = new ArrayList();
+      Iterator allCacheServersIterator = allCacheServers.iterator();
+      while (allCacheServersIterator.hasNext()) {
+        CacheServerImpl cacheServer = (CacheServerImpl) allCacheServersIterator.next();
+        // If CacheServer is a GatewayReceiver, don't return as part of CacheServers
+        if (!cacheServer.isGatewayReceiver()) {
+          if (cacheServersWithoutReceiver == null) {
+            cacheServersWithoutReceiver = new ArrayList();
+          }
+          cacheServersWithoutReceiver.add(cacheServer);
-        cacheServersWithoutReceiver.add(cacheServer);
-    }
-   * add a partitioned region to the set of tracked partitioned regions. This is used to notify the regions when this
-   * cache requires, or does not require notification of all region/entry events.
+   * add a partitioned region to the set of tracked partitioned regions. This is used to notify the
+   * regions when this cache requires, or does not require notification of all region/entry events.
-    synchronized (GemFireCacheImpl.class) {
-      synchronized (this.partitionedRegions) {
-        if (r.isDestroyed()) {
-          if (logger.isDebugEnabled()) {
-            logger.debug("GemFireCache#addPartitionedRegion did not add destroyed {}", r);
-          }
-          return;
+    synchronized (this.partitionedRegions) {
+      if (r.isDestroyed()) {
+        if (logger.isDebugEnabled()) {
+          logger.debug("GemFireCache#addPartitionedRegion did not add destroyed {}", r);
-        if (this.partitionedRegions.add(r)) {
-          getCachePerfStats().incPartitionedRegions(1);
-        }
+        return;
+      }
+      if (this.partitionedRegions.add(r)) {
+        getCachePerfStats().incPartitionedRegions(1);
-        TreeMap<String, PartitionedRegion> prSubMap = (TreeMap<String, PartitionedRegion>) prTrees.get(rootName);
+        TreeMap<String, PartitionedRegion> prSubMap =
+            (TreeMap<String, PartitionedRegion>) prTrees.get(rootName);
-    for (Map.Entry<String, Region> entry : ((Map<String,Region>)pathToRegion).entrySet()) {
+    for (Map.Entry<String, Region> entry : ((Map<String, Region>) pathToRegion).entrySet()) {
-      
-      //Don't wait for non partitioned regions
-      if(!(region instanceof PartitionedRegion)) {
+
+      // Don't wait for non partitioned regions
+      if (!(region instanceof PartitionedRegion)) {
-      //to finish initialization
+      // to finish initialization
-  private LinkedHashMap<String, PartitionedRegion> orderByColocation(TreeMap<String, PartitionedRegion> prMap) {
+  private LinkedHashMap<String, PartitionedRegion> orderByColocation(
+      TreeMap<String, PartitionedRegion> prMap) {
-  private void addColocatedChildRecursively(LinkedHashMap<String, PartitionedRegion> prMap, PartitionedRegion pr) {
+  private void addColocatedChildRecursively(LinkedHashMap<String, PartitionedRegion> prMap,
+      PartitionedRegion pr) {
-   * check to see if any cache components require notification from a partitioned region. Notification adds to the
-   * messaging a PR must do on each put/destroy/invalidate operation and should be kept to a minimum
+   * check to see if any cache components require notification from a partitioned region.
+   * Notification adds to the messaging a PR must do on each put/destroy/invalidate operation and
+   * should be kept to a minimum
-   * @param r
-   *          the partitioned region
+   * @param r the partitioned region
-    synchronized (GemFireCacheImpl.class) {
-      boolean hasSerialSenders = hasSerialSenders(r);
-      boolean result = hasSerialSenders;
-      if (!result) {
-        Iterator allCacheServersIterator = allCacheServers.iterator();
-        while (allCacheServersIterator.hasNext()) {
-          CacheServerImpl server = (CacheServerImpl) allCacheServersIterator.next();
-          if (!server.getNotifyBySubscription()) {
-            result = true;
-            break;
-          }
+    boolean hasSerialSenders = hasSerialSenders(r);
+    boolean result = hasSerialSenders;
+    if (!result) {
+      Iterator allCacheServersIterator = allCacheServers.iterator();
+      while (allCacheServersIterator.hasNext()) {
+        CacheServerImpl server = (CacheServerImpl) allCacheServersIterator.next();
+        if (!server.getNotifyBySubscription()) {
+          result = true;
+          break;
-
-      return result;
+
+    return result;
-        throw new IllegalStateException("Client cache does not have a default pool. Use getQueryService(String poolName) instead.");
+        throw new IllegalStateException(
+            "Client cache does not have a default pool. Use getQueryService(String poolName) instead.");
-   * Returns the cache currently being xml initialized by the thread that calls this method. The result will be null if
-   * the thread is not initializing a cache.
+   * Returns the cache currently being xml initialized by the thread that calls this method. The
+   * result will be null if the thread is not initializing a cache.
-  public void loadCacheXml(InputStream stream) throws TimeoutException, CacheWriterException, GatewayException,
-      RegionExistsException {
+  public void loadCacheXml(InputStream stream)
+      throws TimeoutException, CacheWriterException, GatewayException, RegionExistsException {
-        /** Now replace all replaceable system properties here using <code>PropertyResolver</code> */
+        /**
+         * Now replace all replaceable system properties here using <code>PropertyResolver</code>
+         */
-         * Turn the string back into the default encoding so that the XML parser can work correctly in the presence of
-         * an "encoding" attribute in the XML prolog.
+         * Turn the string back into the default encoding so that the XML parser can work correctly
+         * in the presence of an "encoding" attribute in the XML prolog.
-      throw new CacheXmlException("Input Stream could not be read for system property substitutions.");
+      throw new CacheXmlException(
+          "Input Stream could not be read for system property substitutions.");
-  private ReliableMessageQueueFactory rmqFactory;
+  private final ReliableMessageQueueFactory rmqFactory;
-   * Initializes the reliable message queue. Needs to be called at cache creation
-   *
-   * @throws IllegalStateException
-   *           if the factory is in use
-   */
-  private void initReliableMessageQueueFactory() {
-    synchronized (GemFireCacheImpl.class) {
-      if (this.rmqFactory != null) {
-        this.rmqFactory.close(false);
-      }
-      this.rmqFactory = new ReliableMessageQueueFactoryImpl();
-    }
-  }
-
-  /**
-  public BackupManager startBackup(InternalDistributedMember sender) 
-  throws IOException {
+  public BackupManager startBackup(InternalDistributedMember sender) throws IOException {
-   * @param id
-   *          ID of GatewaySender or AsyncEventQueue
-   * @param isAsyncListener
-   *          true if this is for an AsyncEventQueue and false if for a
-   *          GatewaySender
-   * @param maxWaitTime
-   *          maximum time to wait in seconds; zero or -ve means infinite wait
+   * @param id ID of GatewaySender or AsyncEventQueue
+   * @param isAsyncListener true if this is for an AsyncEventQueue and false if for a GatewaySender
+   * @param maxWaitTime maximum time to wait in seconds; zero or -ve means infinite wait
-   * @return zero if maxWaitTime was not breached, -1 if queue could not be
-   *         found or is closed, and elapsed time if timeout was breached
+   * @return zero if maxWaitTime was not breached, -1 if queue could not be found or is closed, and
+   *         elapsed time if timeout was breached
-  public int waitForSenderQueueFlush(String id, boolean isAsyncListener,
-      int maxWaitTime) {
+  public int waitForSenderQueueFlush(String id, boolean isAsyncListener, int maxWaitTime) {
-      AsyncEventQueueImpl asyncQueue = (AsyncEventQueueImpl)
-          getAsyncEventQueue(id);
+      AsyncEventQueueImpl asyncQueue = (AsyncEventQueueImpl) getAsyncEventQueue(id);
-    }
-    else {
-      gatewaySender = (AbstractGatewaySender)getGatewaySender(id);
+    } else {
+      gatewaySender = (AbstractGatewaySender) getGatewaySender(id);
-        return (int)(elapsedTime / 1000L);
+        return (int) (elapsedTime / 1000L);
-  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value="ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD")
+  @edu.umd.cs.findbugs.annotations.SuppressWarnings(
+      value = "ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD")
-  
+
-  
+
+   * 
-    //Check to see if monitor is required if ResourceManager critical heap percentage is set
-    //@see org.apache.geode.cache.control.ResourceManager#setCriticalHeapPercentage(int)
-    //or whether we override it with the system variable;
-    boolean monitorRequired = !QUERY_MONITOR_DISABLED_FOR_LOW_MEM && QUERY_MONITOR_REQUIRED_FOR_RESOURCE_MANAGER;
+    // Check to see if monitor is required if ResourceManager critical heap percentage is set
+    // @see org.apache.geode.cache.control.ResourceManager#setCriticalHeapPercentage(int)
+    // or whether we override it with the system variable;
+    boolean monitorRequired =
+        !QUERY_MONITOR_DISABLED_FOR_LOW_MEM && QUERY_MONITOR_REQUIRED_FOR_RESOURCE_MANAGER;
-    if (!(this.MAX_QUERY_EXECUTION_TIME > 0 || this.TEST_MAX_QUERY_EXECUTION_TIME > 0 || monitorRequired)) {
+    if (!(this.MAX_QUERY_EXECUTION_TIME > 0 || this.TEST_MAX_QUERY_EXECUTION_TIME > 0
+        || monitorRequired)) {
-    // Return the QueryMonitor service if MAX_QUERY_EXECUTION_TIME is set or it is required by the ResourceManager and not overriden by system property.
-    if ((this.MAX_QUERY_EXECUTION_TIME > 0 || this.TEST_MAX_QUERY_EXECUTION_TIME > 0 || monitorRequired) && this.queryMonitor == null) {
+    // Return the QueryMonitor service if MAX_QUERY_EXECUTION_TIME is set or it is required by the
+    // ResourceManager and not overriden by system property.
+    if ((this.MAX_QUERY_EXECUTION_TIME > 0 || this.TEST_MAX_QUERY_EXECUTION_TIME > 0
+        || monitorRequired) && this.queryMonitor == null) {
-          int maxTime = MAX_QUERY_EXECUTION_TIME > TEST_MAX_QUERY_EXECUTION_TIME ? MAX_QUERY_EXECUTION_TIME
-              : TEST_MAX_QUERY_EXECUTION_TIME;
-          
+          int maxTime = MAX_QUERY_EXECUTION_TIME > TEST_MAX_QUERY_EXECUTION_TIME
+              ? MAX_QUERY_EXECUTION_TIME : TEST_MAX_QUERY_EXECUTION_TIME;
+
-            //this means that the resource manager is being used and we need to monitor query memory usage
-            //If no max execution time has been set, then we will default to five hours
+            // this means that the resource manager is being used and we need to monitor query
+            // memory usage
+            // If no max execution time has been set, then we will default to five hours
-         
+
-          final LoggingThreadGroup group = LoggingThreadGroup.createThreadGroup("QueryMonitor Thread Group", logger);
+          final LoggingThreadGroup group =
+              LoggingThreadGroup.createThreadGroup("QueryMonitor Thread Group", logger);
-   * Simple class to allow waiters for register interest. Has at most one thread that ever calls wait.
+   * Simple class to allow waiters for register interest. Has at most one thread that ever calls
+   * wait.
-    SimpleWaiter() {
-    }
+    SimpleWaiter() {}
-      throw new IllegalStateException("The pool " + pool.getName() + " did not have multiuser-authentication set to true");
+      throw new IllegalStateException(
+          "The pool " + pool.getName() + " did not have multiuser-authentication set to true");
-      case PARTITION: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_REDUNDANT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_PERSISTENT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_REDUNDANT_PERSISTENT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_REDUNDANT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_PERSISTENT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_REDUNDANT_PERSISTENT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_REDUNDANT_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.REPLICATE);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE_PERSISTENT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.REPLICATE);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE_PERSISTENT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.REPLICATE);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setScope(Scope.LOCAL);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_PERSISTENT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        af.setScope(Scope.LOCAL);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setScope(Scope.LOCAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setScope(Scope.LOCAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_PERSISTENT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        af.setScope(Scope.LOCAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_PROXY: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setLocalMaxMemory(0);
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PARTITION_PROXY_REDUNDANT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PARTITION);
-        PartitionAttributesFactory paf = new PartitionAttributesFactory();
-        paf.setLocalMaxMemory(0);
-        paf.setRedundantCopies(1);
-        af.setPartitionAttributes(paf.create());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case REPLICATE_PROXY: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.EMPTY);
-        af.setScope(Scope.DISTRIBUTED_ACK);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      default:
-        throw new IllegalStateException("unhandled enum " + pra);
+        case PARTITION: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_REDUNDANT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_PERSISTENT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_REDUNDANT_PERSISTENT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_REDUNDANT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_PERSISTENT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_REDUNDANT_PERSISTENT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_REDUNDANT_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.REPLICATE);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE_PERSISTENT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.REPLICATE);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE_PERSISTENT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.REPLICATE);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setScope(Scope.LOCAL);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_PERSISTENT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          af.setScope(Scope.LOCAL);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setScope(Scope.LOCAL);
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setScope(Scope.LOCAL);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_PERSISTENT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          af.setScope(Scope.LOCAL);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_PROXY: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setLocalMaxMemory(0);
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PARTITION_PROXY_REDUNDANT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PARTITION);
+          PartitionAttributesFactory paf = new PartitionAttributesFactory();
+          paf.setLocalMaxMemory(0);
+          paf.setRedundantCopies(1);
+          af.setPartitionAttributes(paf.create());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case REPLICATE_PROXY: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.EMPTY);
+          af.setScope(Scope.DISTRIBUTED_ACK);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        default:
+          throw new IllegalStateException("unhandled enum " + pra);
-      case LOCAL: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_PERSISTENT: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case LOCAL_PERSISTENT_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        c.setRegionAttributes(pra.toString(), af.create());
-        break;
-      }
-      case PROXY: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.EMPTY);
-        UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
-        ra.requiresPoolName = true;
-        c.setRegionAttributes(pra.toString(), ra);
-        break;
-      }
-      case CACHING_PROXY: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
-        ra.requiresPoolName = true;
-        c.setRegionAttributes(pra.toString(), ra);
-        break;
-      }
-      case CACHING_PROXY_HEAP_LRU: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
-        UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
-        ra.requiresPoolName = true;
-        c.setRegionAttributes(pra.toString(), ra);
-        break;
-      }
-      case CACHING_PROXY_OVERFLOW: {
-        AttributesFactory af = new AttributesFactory();
-        af.setDataPolicy(DataPolicy.NORMAL);
-        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-        UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
-        ra.requiresPoolName = true;
-        c.setRegionAttributes(pra.toString(), ra);
-        break;
-      }
-      default:
-        throw new IllegalStateException("unhandled enum " + pra);
+        case LOCAL: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_PERSISTENT: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case LOCAL_PERSISTENT_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          c.setRegionAttributes(pra.toString(), af.create());
+          break;
+        }
+        case PROXY: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.EMPTY);
+          UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
+          ra.requiresPoolName = true;
+          c.setRegionAttributes(pra.toString(), ra);
+          break;
+        }
+        case CACHING_PROXY: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
+          ra.requiresPoolName = true;
+          c.setRegionAttributes(pra.toString(), ra);
+          break;
+        }
+        case CACHING_PROXY_HEAP_LRU: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes());
+          UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
+          ra.requiresPoolName = true;
+          c.setRegionAttributes(pra.toString(), ra);
+          break;
+        }
+        case CACHING_PROXY_OVERFLOW: {
+          AttributesFactory af = new AttributesFactory();
+          af.setDataPolicy(DataPolicy.NORMAL);
+          af.setEvictionAttributes(
+              EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
+          UserSpecifiedRegionAttributes ra = (UserSpecifiedRegionAttributes) af.create();
+          ra.requiresPoolName = true;
+          c.setRegionAttributes(pra.toString(), ra);
+          break;
+        }
+        default:
+          throw new IllegalStateException("unhandled enum " + pra);
-   * Returns true if any of the GemFire services prefers PdxInstance. And application has not requested getObject() on
-   * the PdxInstance.
+   * Returns true if any of the GemFire services prefers PdxInstance. And application has not
+   * requested getObject() on the PdxInstance.
-    if ((getPdxReadSerialized() || DefaultQuery.getPdxReadSerialized()) && PdxInstanceImpl.getPdxReadSerialized()) {
+    if ((getPdxReadSerialized() || DefaultQuery.getPdxReadSerialized())
+        && PdxInstanceImpl.getPdxReadSerialized()) {
-  
-  public GatewaySenderFactory createGatewaySenderFactory(){
+
+  public GatewaySenderFactory createGatewaySenderFactory() {
-  
+
-      AutoSerializableManager asm = (AutoSerializableManager) ((ReflectionBasedAutoSerializer) v).getManager();
+      AutoSerializableManager asm =
+          (AutoSerializableManager) ((ReflectionBasedAutoSerializer) v).getManager();
-   * Add to the map of declarable properties.  Any properties that exactly match existing
-   * properties for a class in the list will be discarded (no duplicate Properties allowed).
+   * Add to the map of declarable properties. Any properties that exactly match existing properties
+   * for a class in the list will be discarded (no duplicate Properties allowed).
-          if (clazz.getName().equals(oldEntry.getKey().getClass().getName()) && (newEntry.getValue().equals(oldEntry.getValue()) ||
-              ((newEntry.getKey() instanceof Identifiable) && (((Identifiable) oldEntry.getKey()).getId().equals(((Identifiable) newEntry.getKey()).getId()))))) {
+          if (clazz.getName().equals(oldEntry.getKey().getClass().getName()) && (newEntry.getValue()
+              .equals(oldEntry.getValue())
+              || ((newEntry.getKey() instanceof Identifiable) && (((Identifiable) oldEntry.getKey())
+                  .getId().equals(((Identifiable) newEntry.getKey()).getId()))))) {
-    
+
-  
+
-  
+
-  
+
-  
+
-  
+
-  
+
