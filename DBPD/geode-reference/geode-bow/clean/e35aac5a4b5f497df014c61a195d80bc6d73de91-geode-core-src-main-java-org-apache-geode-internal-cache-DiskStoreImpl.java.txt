Merge branch 'release/1.5.0'

+import java.util.concurrent.locks.ReentrantLock;
-import org.apache.geode.internal.cache.backup.BackupLock;
-import org.apache.geode.internal.cache.backup.BackupManager;
+import org.apache.geode.internal.cache.backup.BackupService;
+import org.apache.geode.internal.cache.backup.DiskStoreBackup;
+import org.apache.geode.internal.cache.eviction.AbstractEvictionController;
-import org.apache.geode.internal.cache.eviction.EvictionStatistics;
-  PersistentOplogSet persistentOplogs = new PersistentOplogSet(this);
+  private PersistentOplogSet persistentOplogs = new PersistentOplogSet(this);
-      return persistentOplogs;
+      return getPersistentOplogs();
-    return persistentOplogs;
+    return getPersistentOplogs();
-    return persistentOplogs;
+    return getPersistentOplogs();
-    long start = async ? this.stats.startFlush() : this.stats.startWrite();
+    long start = async ? getStats().startFlush() : getStats().startWrite();
-        this.stats.endFlush(start);
+        getStats().endFlush(start);
-        dr.getStats().endWrite(start, this.stats.endWrite(start));
+        dr.getStats().endWrite(start, getStats().endWrite(start));
-          return convertBytesAndBitsIntoObject(bb);
+          return convertBytesAndBitsIntoObject(bb, getCache());
-  static Object convertBytesAndBitsIntoObject(BytesAndBits bb) {
+  static Object convertBytesAndBitsIntoObject(BytesAndBits bb, InternalCache cache) {
-      value = DiskEntry.Helper.readSerializedValue(bytes, bb.getVersion(), null, true);
+      value = DiskEntry.Helper.readSerializedValue(bytes, bb.getVersion(), null, true, cache);
-  static Object convertBytesAndBitsToSerializedForm(BytesAndBits bb) {
+  static Object convertBytesAndBitsToSerializedForm(BytesAndBits bb, InternalCache cache) {
-      value = DiskEntry.Helper.readSerializedValue(bytes, bb.getVersion(), null, false);
+      value = DiskEntry.Helper.readSerializedValue(bytes, bb.getVersion(), null, false, cache);
-        return convertBytesAndBitsIntoObject(bb);
+        return convertBytesAndBitsIntoObject(bb, getCache());
-        long start = this.stats.startRemove();
+        long start = getStats().startRemove();
-        dr.getStats().endRemove(start, this.stats.endRemove(start));
+        dr.getStats().endRemove(start, getStats().endRemove(start));
-    persistentOplogs.forceRoll(null);
+    getPersistentOplogs().forceRoll(null);
-    return convertBytesAndBitsToSerializedForm(getBytesAndBits(dr, id, true));
+    return convertBytesAndBitsToSerializedForm(getBytesAndBits(dr, id, true), dr.getCache());
-        this.asyncQueue.forcePut(item);
+        getAsyncQueue().forcePut(item);
-        if (!this.asyncQueue.offer(item)) {
+        if (!getAsyncQueue().offer(item)) {
-      this.stats.incQueueSize(1);
+      getStats().incQueueSize(1);
-        synchronized (this.asyncMonitor) {
-          this.asyncMonitor.notifyAll();
+        synchronized (getAsyncMonitor()) {
+          getAsyncMonitor().notifyAll();
-    if (this.asyncQueue.remove(item)) {
-      this.stats.incQueueSize(-1);
+    if (getAsyncQueue().remove(item)) {
+      getStats().incQueueSize(-1);
-    return this.stats.startWrite();
+    return getStats().startWrite();
-    dr.getStats().endWrite(start, this.stats.endWrite(start));
+    dr.getStats().endWrite(start, getStats().endWrite(start));
-  private int fillDrainList() {
-    synchronized (this.drainSync) {
-      this.drainList = new ArrayList(asyncQueue.size());
-      return asyncQueue.drainTo(this.drainList);
+  int fillDrainList() {
+    synchronized (getDrainSync()) {
+      ForceableLinkedBlockingQueue<Object> queue = getAsyncQueue();
+      this.drainList = new ArrayList(queue.size());
+      return queue.drainTo(this.drainList);
-  private ArrayList getDrainList() {
+  ArrayList getDrainList() {
-    synchronized (this.drainSync) {
+    synchronized (getDrainSync()) {
-        new FlusherThread(), thName);
+        new FlusherThread(this), thName);
-    synchronized (asyncMonitor) {
+    synchronized (getAsyncMonitor()) {
-      this.asyncMonitor.notifyAll();
+      getAsyncMonitor().notifyAll();
-    return this.stopFlusher || this.flusherThreadTerminated || this.flusherThread == null
+    return isStopFlusher() || this.flusherThreadTerminated || this.flusherThread == null
-    synchronized (this.asyncMonitor) {
-      this.forceFlushCount.incrementAndGet(); // moved inside sync to fix bug
-                                              // 41654
-      this.asyncMonitor.notifyAll();
+    Object monitor = getAsyncMonitor();
+    synchronized (monitor) {
+      getForceFlushCount().incrementAndGet(); // moved inside sync to fix bug
+      // 41654
+      monitor.notifyAll();
-  private boolean checkAndClearForceFlush() {
-    if (stopFlusher) {
+  boolean checkAndClearForceFlush() {
+    if (isStopFlusher()) {
-      int v = this.forceFlushCount.get();
+      int v = getForceFlushCount().get();
-        done = this.forceFlushCount.compareAndSet(v, 0);
+        done = getForceFlushCount().compareAndSet(v, 0);
+  Object getAsyncMonitor() {
+    return asyncMonitor;
+  }
+
+  AtomicInteger getForceFlushCount() {
+    return forceFlushCount;
+  }
+
+  Object getDrainSync() {
+    return drainSync;
+  }
+
+  ForceableLinkedBlockingQueue<Object> getAsyncQueue() {
+    return asyncQueue;
+  }
+
+  PersistentOplogSet getPersistentOplogs() {
+    return persistentOplogs;
+  }
+
+  boolean isStopFlusher() {
+    return stopFlusher;
+  }
+
-    return this.asyncQueue.size() >= this.maxAsyncItems;
+    return getAsyncQueue().size() >= this.maxAsyncItems;
-  private class FlusherThread implements Runnable {
+  protected static class FlusherThread implements Runnable {
+    private DiskStoreImpl diskStore;
+
+    public FlusherThread(DiskStoreImpl diskStore) {
+      this.diskStore = diskStore;
+    }
+
-      if (maxAsyncItems > 0) {
-        final long time = getTimeInterval();
-        synchronized (asyncMonitor) {
+      if (diskStore.maxAsyncItems > 0) {
+        final long time = diskStore.getTimeInterval();
+        synchronized (diskStore.getAsyncMonitor()) {
-            boolean done = checkAndClearForceFlush() || checkAsyncItemLimit();
+            boolean done = diskStore.checkAndClearForceFlush() || diskStore.checkAsyncItemLimit();
-              TimeUnit.NANOSECONDS.timedWait(asyncMonitor, nanosRemaining);
-              done = checkAndClearForceFlush() || checkAsyncItemLimit();
+              TimeUnit.NANOSECONDS.timedWait(diskStore.getAsyncMonitor(), nanosRemaining);
+              done = diskStore.checkAndClearForceFlush() || diskStore.checkAsyncItemLimit();
-            boolean done = checkAndClearForceFlush() || checkAsyncItemLimit();
+            boolean done = diskStore.checkAndClearForceFlush() || diskStore.checkAsyncItemLimit();
-              asyncMonitor.wait();
-              done = checkAndClearForceFlush() || checkAsyncItemLimit();
+              diskStore.getAsyncMonitor().wait();
+              done = diskStore.checkAndClearForceFlush() || diskStore.checkAsyncItemLimit();
-        long time = getTimeInterval();
+        long time = diskStore.getTimeInterval();
-          synchronized (asyncMonitor) {
-            boolean done = checkAndClearForceFlush();
+          synchronized (diskStore.getAsyncMonitor()) {
+            boolean done = diskStore.checkAndClearForceFlush();
-              TimeUnit.NANOSECONDS.timedWait(asyncMonitor, nanosRemaining);
-              done = checkAndClearForceFlush();
+              TimeUnit.NANOSECONDS.timedWait(diskStore.getAsyncMonitor(), nanosRemaining);
+              done = diskStore.checkAndClearForceFlush();
-          synchronized (asyncMonitor) {
-            boolean done = checkAndClearForceFlush();
+          synchronized (diskStore.getAsyncMonitor()) {
+            boolean done = diskStore.checkAndClearForceFlush();
-              asyncMonitor.wait();
-              done = checkAndClearForceFlush();
+              diskStore.getAsyncMonitor().wait();
+              done = diskStore.checkAndClearForceFlush();
-      return !stopFlusher;
+      return !diskStore.isStopFlusher();
-      persistentOplogs.flushChild();
+      diskStore.getPersistentOplogs().flushChild();
+      doAsyncFlush();
+    }
+
+    void doAsyncFlush() {
-          int drainCount = fillDrainList();
+          int drainCount = diskStore.fillDrainList();
-            stats.incQueueSize(-drainCount);
-            Iterator it = getDrainList().iterator();
+            Iterator it = diskStore.getDrainList().iterator();
+            diskStore.getStats().incQueueSize(-drainCount);
-        getCache().getCancelCriterion().checkCancelInProgress(ie);
+        diskStore.getCache().getCancelCriterion().checkCancelInProgress(ie);
-        if (!okToIgnore || !stopFlusher) {
+        if (!okToIgnore || !diskStore.isStopFlusher()) {
-            LocalizedStrings.DiskStoreImpl_FATAL_ERROR_ON_FLUSH.toLocalizedString(), t,
-            DiskStoreImpl.this);
+            LocalizedStrings.DiskStoreImpl_FATAL_ERROR_ON_FLUSH.toLocalizedString(), t, diskStore);
-          logger.debug("Async writer thread stopped. Pending opcount={}", asyncQueue.size());
+          logger.debug("Async writer thread stopped. Pending opcount={}",
+              diskStore.getAsyncQueue().size());
-        flusherThreadTerminated = true;
-        stopFlusher = true; // set this before calling handleDiskAccessException
+        diskStore.flusherThreadTerminated = true;
+        diskStore.stopFlusher = true; // set this before calling handleDiskAccessException
-          handleDiskAccessException(fatalDae);
+          diskStore.handleDiskAccessException(fatalDae);
-          persistentOplogs.findFiles(partialFileName);
+          getPersistentOplogs().findFiles(partialFileName);
-      persistentOplogs.createOplogs(needsOplogs, persistentBackupFiles);
+      getPersistentOplogs().createOplogs(needsOplogs, persistentBackupFiles);
-                .startsWith(BackupManager.DATA_STORES_TEMPORARY_DIRECTORY))
+                .startsWith(BackupService.DATA_STORES_TEMPORARY_DIRECTORY))
-    this.stats.close();
+    getStats().close();
-    if (!persistentOplogs.alreadyRecoveredOnce.get()) {
+    if (!getPersistentOplogs().alreadyRecoveredOnce.get()) {
-    persistentOplogs.recoverRegionsThatAreReady();
+    getPersistentOplogs().recoverRegionsThatAreReady();
-      for (final Object o : this.asyncQueue) {
+      for (final Object o : getAsyncQueue()) {
-        RuntimeException exception = persistentOplogs.close();
+        RuntimeException exception = getPersistentOplogs().close();
-    persistentOplogs.prepareForClose();
+    getPersistentOplogs().prepareForClose();
-    PersistentOplogSet oplogSet = persistentOplogs;
+    PersistentOplogSet oplogSet = getPersistentOplogs();
-    persistentOplogs.destroyAllOplogs();
+    getPersistentOplogs().destroyAllOplogs();
-    persistentOplogs.getCompactableOplogs(l, max);
+    getPersistentOplogs().getCompactableOplogs(l, max);
-    return persistentOplogs.getAllOplogs();
+    return getPersistentOplogs().getAllOplogs();
-          writer = GFSnapshot.create(f, regionName);
+          writer = GFSnapshot.create(f, regionName, cache);
-    persistentOplogs.recoverRegionsThatAreReady();
-    persistentOplogs.offlineCompact();
+    getPersistentOplogs().recoverRegionsThatAreReady();
+    getPersistentOplogs().offlineCompact();
-  private final HashMap<String, EvictionStatistics> prlruStatMap =
-      new HashMap<String, EvictionStatistics>();
+  private final HashMap<String, EvictionController> prEvictionControllerMap =
+      new HashMap<String, EvictionController>();
-  private final BackupLock backupLock = new BackupLock();
+  private final ReentrantLock backupLock = new ReentrantLock();
-  public BackupLock getBackupLock() {
+  public ReentrantLock getBackupLock() {
-  EvictionStatistics getOrCreatePRLRUStats(PlaceHolderDiskRegion dr) {
+  EvictionController getOrCreatePRLRUStats(PlaceHolderDiskRegion dr) {
-    EvictionStatistics result = null;
-    synchronized (this.prlruStatMap) {
-      result = this.prlruStatMap.get(prName);
+    EvictionController result = null;
+    synchronized (this.prEvictionControllerMap) {
+      result = this.prEvictionControllerMap.get(prName);
-        EvictionAttributesImpl ea = dr.getEvictionAttributes();
-        EvictionController ec = ea.createEvictionController(null, dr.getOffHeap());
-        StatisticsFactory sf = cache.getDistributedSystem();
-        result = ec.initStats(dr, sf);
-        this.prlruStatMap.put(prName, result);
+        result = AbstractEvictionController.create(dr.getEvictionAttributes(), dr.getOffHeap(),
+            dr.getStatisticsFactory(), prName);
+        this.prEvictionControllerMap.put(prName, result);
-   * If we have recovered a bucket earlier for the given pr then we will have an EvictionStatistics
+   * If we have recovered a bucket earlier for the given pr then we will have an EvictionController
-  EvictionStatistics getPRLRUStats(PartitionedRegion pr) {
+  EvictionController getExistingPREvictionContoller(PartitionedRegion pr) {
-    EvictionStatistics result = null;
-    synchronized (this.prlruStatMap) {
-      result = this.prlruStatMap.get(prName);
+    EvictionController result = null;
+    synchronized (this.prEvictionControllerMap) {
+      result = this.prEvictionControllerMap.get(prName);
-   * disk stores on all members are locked, we still move on to startBackup.
+   * disk stores on all members are locked, we still move on to prepareBackup.
-    getBackupLock().lockForBackup();
+    getBackupLock().lock();
-    getBackupLock().unlockForBackup();
+    ReentrantLock backupLock = getBackupLock();
+    if (backupLock.isHeldByCurrentThread()) {
+      backupLock.unlock();
+    }
-    BackupManager backupManager = cache.getBackupManager();
-    return backupManager == null ? null : backupManager.getBackupForDiskStore(this);
+    BackupService backupService = cache.getBackupService();
+    return backupService.getBackupForDiskStore(this);
-    return persistentOplogs.getChild() != null;
+    return getPersistentOplogs().getChild() != null;
+
+  public StatisticsFactory getStatisticsFactory() {
+    return this.cache.getDistributedSystem();
+  }
+
