Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * Abstract implementation of {@link RegionMap}that has all the common
- * behavior.
+ * Abstract implementation of {@link RegionMap}that has all the common behavior.
-  
+
-   * This test hook is used to force the conditions for defect 48182.
-   * This hook is used by Bug48182JUnitTest.
+   * This test hook is used to force the conditions for defect 48182. This hook is used by
+   * Bug48182JUnitTest.
-  static Runnable testHookRunnableFor48182 =  null;
-  
+  static Runnable testHookRunnableFor48182 = null;
+
-  
-  protected AbstractRegionMap(InternalRegionArguments internalRegionArgs) {
-  }
-  protected void initialize(Object owner,
-                            Attributes attr,
-                            InternalRegionArguments internalRegionArgs,
-                            boolean isLRU) {
+  protected AbstractRegionMap(InternalRegionArguments internalRegionArgs) {}
+
+  protected void initialize(Object owner, Attributes attr,
+      InternalRegionArguments internalRegionArgs, boolean isLRU) {
-    _setMap(createConcurrentMap(attr.initialCapacity, attr.loadFactor,
-        attr.concurrencyLevel, false,
+    _setMap(createConcurrentMap(attr.initialCapacity, attr.loadFactor, attr.concurrencyLevel, false,
-      LocalRegion region = (LocalRegion)owner;
+      LocalRegion region = (LocalRegion) owner;
-    }
-    else if (owner instanceof PlaceHolderDiskRegion) {
+    } else if (owner instanceof PlaceHolderDiskRegion) {
-      withVersioning = ((PlaceHolderDiskRegion)owner).getFlags().contains(
-          DiskRegionFlag.IS_WITH_VERSIONING);
+      withVersioning =
+          ((PlaceHolderDiskRegion) owner).getFlags().contains(DiskRegionFlag.IS_WITH_VERSIONING);
-    }
-    else {
-      throw new IllegalStateException(
-          "expected LocalRegion or PlaceHolderDiskRegion");
+    } else {
+      throw new IllegalStateException("expected LocalRegion or PlaceHolderDiskRegion");
-    setEntryFactory(new RegionEntryFactoryBuilder().getRegionEntryFactoryOrNull(attr.statisticsEnabled,isLRU,isDisk,withVersioning,offHeap));
+    setEntryFactory(new RegionEntryFactoryBuilder().getRegionEntryFactoryOrNull(
+        attr.statisticsEnabled, isLRU, isDisk, withVersioning, offHeap));
-  protected CustomEntryConcurrentHashMap<Object, Object> createConcurrentMap(
-      int initialCapacity, float loadFactor, int concurrencyLevel,
-      boolean isIdentityMap,
+  protected CustomEntryConcurrentHashMap<Object, Object> createConcurrentMap(int initialCapacity,
+      float loadFactor, int concurrencyLevel, boolean isIdentityMap,
-    }
-    else {
-      return new CustomEntryConcurrentHashMap<Object, Object>(initialCapacity,
-          loadFactor, concurrencyLevel, isIdentityMap);
+    } else {
+      return new CustomEntryConcurrentHashMap<Object, Object>(initialCapacity, loadFactor,
+          concurrencyLevel, isIdentityMap);
-  
+
-    return (LocalRegion)this.owner;
+    return (LocalRegion) this.owner;
-  
+
-  public int size()
-  {
+  public int size() {
-  public boolean isEmpty()
-  {
+  public boolean isEmpty() {
-  public Set keySet()
-  {
+  public Set keySet() {
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
-    return (Collection)_getMap().values();
+    return (Collection) _getMap().values();
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
-    return (Collection)_getMap().values();
+    return (Collection) _getMap().values();
-    RegionEntry re = (RegionEntry)_getMap().get(key);
+    RegionEntry re = (RegionEntry) _getMap().get(key);
-    return (RegionEntry)_getMap().get(key);
+    return (RegionEntry) _getMap().get(key);
-    RegionEntry oldRe = (RegionEntry)_getMap().putIfAbsent(key, re);
-    if (oldRe == null && (re instanceof OffHeapRegionEntry) 
-        && _isOwnerALocalRegion() && _getOwner().isThisRegionBeingClosedOrDestroyed()) {
+    RegionEntry oldRe = (RegionEntry) _getMap().putIfAbsent(key, re);
+    if (oldRe == null && (re instanceof OffHeapRegionEntry) && _isOwnerALocalRegion()
+        && _getOwner().isThisRegionBeingClosedOrDestroyed()) {
-      if (v != Token.REMOVED_PHASE1 && v != Token.REMOVED_PHASE2
-          && v instanceof StoredObject && ((StoredObject)v).hasRefCount()) {
+      if (v != Token.REMOVED_PHASE1 && v != Token.REMOVED_PHASE2 && v instanceof StoredObject
+          && ((StoredObject) v).hasRefCount()) {
-          ((OffHeapRegionEntry)re).release();
+          ((OffHeapRegionEntry) re).release();
-    RegionEntry re = (RegionEntry)_getMap().get(key);
+    RegionEntry re = (RegionEntry) _getMap().get(key);
- 
+
-    if (re.isTombstone() && _getMap().get(key) == re){
-      logger.fatal(LocalizedMessage.create(LocalizedStrings.AbstractRegionMap_ATTEMPT_TO_REMOVE_TOMBSTONE), new Exception("stack trace"));
+    if (re.isTombstone() && _getMap().get(key) == re) {
+      logger.fatal(
+          LocalizedMessage.create(LocalizedStrings.AbstractRegionMap_ATTEMPT_TO_REMOVE_TOMBSTONE),
+          new Exception("stack trace"));
-    if (re.isTombstone()&& _getMap().get(key) == re) {
-      logger.fatal(LocalizedMessage.create(LocalizedStrings.AbstractRegionMap_ATTEMPT_TO_REMOVE_TOMBSTONE), new Exception("stack trace"));
+    if (re.isTombstone() && _getMap().get(key) == re) {
+      logger.fatal(
+          LocalizedMessage.create(LocalizedStrings.AbstractRegionMap_ATTEMPT_TO_REMOVE_TOMBSTONE),
+          new Exception("stack trace"));
-  
+
-  
+
-    for (SuspectEntryList l: this.suspectEntries.values()) {
-      for (EntryEventImpl e: l) {
-        e.release();
-      }
-    }
-    */
+     * for (SuspectEntryList l: this.suspectEntries.values()) { for (EntryEventImpl e: l) {
+     * e.release(); } }
+     */
-  
+
-   * Clear the region and, if an RVV is given, return a collection of the
-   * version sources in all remaining tags
+   * Clear the region and, if an RVV is given, return a collection of the version sources in all
+   * remaining tags
-  public Set<VersionSource> clear(RegionVersionVector rvv)
-  {
+  public Set<VersionSource> clear(RegionVersionVector rvv) {
-    
-    if(!_isOwnerALocalRegion()) {
-      //Fix for #41333. Just clear the the map
-      //if we failed during initialization.
+
+    if (!_isOwnerALocalRegion()) {
+      // Fix for #41333. Just clear the the map
+      // if we failed during initialization.
-    Object lockObj = lr.getConcurrencyChecksEnabled()? lr.getSizeGuard() : new Object();
+    Object lockObj = lr.getConcurrencyChecksEnabled() ? lr.getSizeGuard() : new Object();
-          synchronized(re) {
+          synchronized (re) {
-            
+
-                logger.trace("region clear op is removing {} {}", re.getKey(), re.getVersionStamp());
+                logger.trace("region clear op is removing {} {}", re.getKey(),
+                    re.getVersionStamp());
-                //If this is an overflow only region, we need to free the entry on
-                //disk at this point.
+                // If this is an overflow only region, we need to free the entry on
+                // disk at this point.
-                  //do nothing, it's already cleared.
+                  // do nothing, it's already cleared.
-  
-  public void lruUpdateCallback()
-  {
-    // By default do nothing; LRU maps needs to override this method
-  }
-  public void lruUpdateCallback(boolean b)
-  {
-    // By default do nothing; LRU maps needs to override this method
-  }
-  public void lruUpdateCallback(int i)
-  {
+
+  public void lruUpdateCallback() {
-  public boolean disableLruUpdateCallback()
-  {
+  public void lruUpdateCallback(boolean b) {
+    // By default do nothing; LRU maps needs to override this method
+  }
+
+  public void lruUpdateCallback(int i) {
+    // By default do nothing; LRU maps needs to override this method
+  }
+
+  public boolean disableLruUpdateCallback() {
-  public void enableLruUpdateCallback()
-  {
+  public void enableLruUpdateCallback() {
-  public void resetThreadLocals()
-  {
+  public void resetThreadLocals() {
-  protected void lruEntryCreate(RegionEntry e)
-  {
+  protected void lruEntryCreate(RegionEntry e) {
-  protected void lruEntryDestroy(RegionEntry e)
-  {
+  protected void lruEntryDestroy(RegionEntry e) {
-  protected void lruEntryUpdate(RegionEntry e)
-  {
+  protected void lruEntryUpdate(RegionEntry e) {
-  public void decTxRefCount(RegionEntry e)
-  {
+  public void decTxRefCount(RegionEntry e) {
-  
+
-  
+
-   * Process an incoming version tag for concurrent operation detection.
-   * This must be done before modifying the region entry.
+   * Process an incoming version tag for concurrent operation detection. This must be done before
+   * modifying the region entry.
+   * 
-   * @throws ConcurrentCacheModificationException if the event is in conflict
-   *    with a previously applied change
+   * @throws ConcurrentCacheModificationException if the event is in conflict with a previously
+   *         applied change
-      
+
-  
-  private void processVersionTagForGII(RegionEntry re, LocalRegion owner, VersionTag entryVersion, boolean isTombstone, InternalDistributedMember sender, boolean checkConflicts) {
-    
-    re.getVersionStamp().processVersionTag(_getOwner(), entryVersion, isTombstone, false, owner.getMyId(), sender, checkConflicts);
+
+  private void processVersionTagForGII(RegionEntry re, LocalRegion owner, VersionTag entryVersion,
+      boolean isTombstone, InternalDistributedMember sender, boolean checkConflicts) {
+
+    re.getVersionStamp().processVersionTag(_getOwner(), entryVersion, isTombstone, false,
+        owner.getMyId(), sender, checkConflicts);
-    //We need to sort the tombstones before scheduling them,
-    //so that they will be in the correct order.
+    // We need to sort the tombstones before scheduling them,
+    // so that they will be in the correct order.
-      CustomEntryConcurrentHashMap<Object, Object> other = ((AbstractRegionMap)rm)._getMap();
-      Iterator<Map.Entry<Object, Object>> it = other
-          .entrySetWithReusableEntries().iterator();
+      CustomEntryConcurrentHashMap<Object, Object> other = ((AbstractRegionMap) rm)._getMap();
+      Iterator<Map.Entry<Object, Object>> it = other.entrySetWithReusableEntries().iterator();
-        it.remove(); // This removes the RegionEntry from "rm" but it does not decrement its refcount to an offheap value.
-        RegionEntry oldRe = (RegionEntry)me.getValue();
+        it.remove(); // This removes the RegionEntry from "rm" but it does not decrement its
+                     // refcount to an offheap value.
+        RegionEntry oldRe = (RegionEntry) me.getValue();
-        
-        @Retained @Released Object value = oldRe._getValueRetain((RegionEntryContext) ((AbstractRegionMap) rm)._getOwnerObject(), true);
+
+        @Retained
+        @Released
+        Object value = oldRe
+            ._getValueRetain((RegionEntryContext) ((AbstractRegionMap) rm)._getOwnerObject(), true);
-          RegionEntry newRe = getEntryFactory().createEntry((RegionEntryContext) _getOwnerObject(), key, value);
+          RegionEntry newRe =
+              getEntryFactory().createEntry((RegionEntryContext) _getOwnerObject(), key, value);
-          //   The disk stats have already been set to track oldRe.
-          //   So when we call createEntry we probably want to give it REMOVED_PHASE1
-          //   and then set the value in copyRecoveredEntry it a way that does not
-          //   change the disk stats. This also depends on DiskEntry.Helper.initialize not changing the stats for REMOVED_PHASE1
+          // The disk stats have already been set to track oldRe.
+          // So when we call createEntry we probably want to give it REMOVED_PHASE1
+          // and then set the value in copyRecoveredEntry it a way that does not
+          // change the disk stats. This also depends on DiskEntry.Helper.initialize not changing
+          // the stats for REMOVED_PHASE1
-      for (Iterator<RegionEntry> iter = regionEntries().iterator(); iter.hasNext(); ) {
+      for (Iterator<RegionEntry> iter = regionEntries().iterator(); iter.hasNext();) {
-          if (re.getVersionStamp() == null) { // bug #50992 - recovery from versioned to non-versioned
+          if (re.getVersionStamp() == null) { // bug #50992 - recovery from versioned to
+                                              // non-versioned
-          _getOwner().updateSizeOnCreate(re.getKey(), _getOwner().calculateRegionEntryValueSize(re));
+          _getOwner().updateSizeOnCreate(re.getKey(),
+              _getOwner().calculateRegionEntryValueSize(re));
-    
-    //Schedule all of the tombstones, now that we have sorted them
+
+    // Schedule all of the tombstones, now that we have sorted them
-    while((entry = tombstones.take()) != null) {
+    while ((entry = tombstones.take()) != null) {
-    
+
-  
+
-    if(newRe.getVersionStamp() != null) {
+    if (newRe.getVersionStamp() != null) {
-    
+
-      ((AbstractOplogDiskRegionEntry)newRe).setDiskId(oldRe);
+      ((AbstractOplogDiskRegionEntry) newRe).setDiskId(oldRe);
-  @Retained     // Region entry may contain an off-heap value
+  @Retained // Region entry may contain an off-heap value
-    @Retained RegionEntry newRe = getEntryFactory().createEntry((RegionEntryContext) _getOwnerObject(), key, value);
+    @Retained
+    RegionEntry newRe =
+        getEntryFactory().createEntry((RegionEntryContext) _getOwnerObject(), key, value);
-      if (value.getVersionTag()!=null && newRe.getVersionStamp()!=null) {
+      if (value.getVersionTag() != null && newRe.getVersionStamp() != null) {
-          } 
+          }
-           * Entry already exists which should be impossible.
-           * Free the current entry (if off-heap) and
-           * throw an exception.
+           * Entry already exists which should be impossible. Free the current entry (if off-heap)
+           * and throw an exception.
-            throw new IllegalStateException("Could not recover entry for key " + key + ".  The entry already exists!");
+            throw new IllegalStateException(
+                "Could not recover entry for key " + key + ".  The entry already exists!");
-        incEntryCount(1); // we are creating an entry that was recovered from disk including tombstone
+        incEntryCount(1); // we are creating an entry that was recovered from disk including
+                          // tombstone
-    
+
-    
+
-  
+
-      if (value.getVersionTag()!=null && re.getVersionStamp()!=null) {
+      if (value.getVersionTag() != null && re.getVersionStamp() != null) {
-          re.setValue(_getOwner(), value); // OFFHEAP no need to call AbstractRegionMap.prepareValueForCache because setValue is overridden for disk and that code takes apart value (RecoveredEntry) and prepares its nested value for the cache
+          re.setValue(_getOwner(), value); // OFFHEAP no need to call
+                                           // AbstractRegionMap.prepareValueForCache because
+                                           // setValue is overridden for disk and that code takes
+                                           // apart value (RecoveredEntry) and prepares its nested
+                                           // value for the cache
-            _getOwner().updateSizeOnPut(key, oldSize, _getOwner().calculateRegionEntryValueSize(re));
+            _getOwner().updateSizeOnPut(key, oldSize,
+                _getOwner().calculateRegionEntryValueSize(re));
-          DiskEntry.Helper.updateRecoveredEntry((PlaceHolderDiskRegion)_getOwnerObject(),
-              (DiskEntry)re, value, (RegionEntryContext) _getOwnerObject());
+          DiskEntry.Helper.updateRecoveredEntry((PlaceHolderDiskRegion) _getOwnerObject(),
+              (DiskEntry) re, value, (RegionEntryContext) _getOwnerObject());
-        throw new IllegalStateException("RegionClearedException should never happen in this context", rce);
+        throw new IllegalStateException(
+            "RegionClearedException should never happen in this context", rce);
-    
+
-    
+
-  public final boolean initialImagePut(final Object key,
-                                       final long lastModified,
-                                       Object newValue,
-                                       final boolean wasRecovered,
-                                       boolean deferLRUCallback,
-                                       VersionTag entryVersion, InternalDistributedMember sender, boolean isSynchronizing)
-  {
+  public final boolean initialImagePut(final Object key, final long lastModified, Object newValue,
+      final boolean wasRecovered, boolean deferLRUCallback, VersionTag entryVersion,
+      InternalDistributedMember sender, boolean isSynchronizing) {
-    
+
-      Object actualVal = ((CachedDeserializable)newValue)
-        .getDeserializedValue(null, null);
+      Object actualVal = ((CachedDeserializable) newValue).getDeserializedValue(null, null);
-        HAEventWrapper haEventWrapper = (HAEventWrapper)actualVal;
+        HAEventWrapper haEventWrapper = (HAEventWrapper) actualVal;
-        HAContainerWrapper haContainer = (HAContainerWrapper)CacheClientNotifier
-            .getInstance().getHaContainer();
+        HAContainerWrapper haContainer =
+            (HAContainerWrapper) CacheClientNotifier.getInstance().getHaContainer();
-//      synchronized (haContainer) {
-      do {
-        ClientUpdateMessageImpl oldMsg = (ClientUpdateMessageImpl) haContainer
-            .putIfAbsent(haEventWrapper,
-                haEventWrapper.getClientUpdateMessage());
-        if (oldMsg != null) {
-          original = (HAEventWrapper) haContainer.getKey(haEventWrapper);
-          if (original == null) {
-            continue;
-          }
-          synchronized (original) {
-            if ((HAEventWrapper) haContainer.getKey(original) != null) {
-              original.incAndGetReferenceCount();
-              HARegionQueue.addClientCQsAndInterestList(oldMsg,
-                  haEventWrapper, haContainer, owner.getName());
-              haEventWrapper.setClientUpdateMessage(null);
-              newValue = CachedDeserializableFactory.create(original,
-                  ((CachedDeserializable) newValue).getSizeInBytes());
-            } else {
-              original = null;
+        // synchronized (haContainer) {
+        do {
+          ClientUpdateMessageImpl oldMsg = (ClientUpdateMessageImpl) haContainer
+              .putIfAbsent(haEventWrapper, haEventWrapper.getClientUpdateMessage());
+          if (oldMsg != null) {
+            original = (HAEventWrapper) haContainer.getKey(haEventWrapper);
+            if (original == null) {
+              continue;
+            synchronized (original) {
+              if ((HAEventWrapper) haContainer.getKey(original) != null) {
+                original.incAndGetReferenceCount();
+                HARegionQueue.addClientCQsAndInterestList(oldMsg, haEventWrapper, haContainer,
+                    owner.getName());
+                haEventWrapper.setClientUpdateMessage(null);
+                newValue = CachedDeserializableFactory.create(original,
+                    ((CachedDeserializable) newValue).getSizeInBytes());
+              } else {
+                original = null;
+              }
+            }
+          } else { // putIfAbsent successful
+            synchronized (haEventWrapper) {
+              haEventWrapper.incAndGetReferenceCount();
+              haEventWrapper.setHAContainer(haContainer);
+              haEventWrapper.setClientUpdateMessage(null);
+              haEventWrapper.setIsRefFromHAContainer(true);
+            }
+            break;
-        } else { // putIfAbsent successful
-          synchronized (haEventWrapper) {
-            haEventWrapper.incAndGetReferenceCount();
-            haEventWrapper.setHAContainer(haContainer);
-            haEventWrapper.setClientUpdateMessage(null);
-            haEventWrapper.setIsRefFromHAContainer(true);
-          }
-          break;
-        }
-        // try until we either get a reference to HAEventWrapper from
-        // HAContainer or successfully put one into it.
-      } while (original == null);
-      /*
-        entry = (Map.Entry)haContainer.getEntry(haEventWrapper);
-        if (entry != null) {
-          original = (HAEventWrapper)entry.getKey();
-          original.incAndGetReferenceCount();
-        }
-        else {
-          haEventWrapper.incAndGetReferenceCount();
-          haEventWrapper.setHAContainer(haContainer);
-          haContainer.put(haEventWrapper, haEventWrapper
-              .getClientUpdateMessage());
-          haEventWrapper.setClientUpdateMessage(null);
-          haEventWrapper.setIsRefFromHAContainer(true);
-        }
-      }
-      if (entry != null) {
-        HARegionQueue.addClientCQsAndInterestList(entry, haEventWrapper,
-            haContainer, owner.getName());
-        haEventWrapper.setClientUpdateMessage(null);
-        newValue = CachedDeserializableFactory.create(original,
-            ((CachedDeserializable)newValue).getSizeInBytes());
-      }
-*/
+          // try until we either get a reference to HAEventWrapper from
+          // HAContainer or successfully put one into it.
+        } while (original == null);
+        /*
+         * entry = (Map.Entry)haContainer.getEntry(haEventWrapper); if (entry != null) { original =
+         * (HAEventWrapper)entry.getKey(); original.incAndGetReferenceCount(); } else {
+         * haEventWrapper.incAndGetReferenceCount(); haEventWrapper.setHAContainer(haContainer);
+         * haContainer.put(haEventWrapper, haEventWrapper .getClientUpdateMessage());
+         * haEventWrapper.setClientUpdateMessage(null);
+         * haEventWrapper.setIsRefFromHAContainer(true); } } if (entry != null) {
+         * HARegionQueue.addClientCQsAndInterestList(entry, haEventWrapper, haContainer,
+         * owner.getName()); haEventWrapper.setClientUpdateMessage(null); newValue =
+         * CachedDeserializableFactory.create(original,
+         * ((CachedDeserializable)newValue).getSizeInBytes()); }
+         */
-    
+
-      RegionEntry newRe = getEntryFactory().createEntry(owner, key,
-          Token.REMOVED_PHASE1);
+      RegionEntry newRe = getEntryFactory().createEntry(owner, key, Token.REMOVED_PHASE1);
-      
-      @Retained @Released Object oldValue = null;
-      
+
+      @Retained
+      @Released
+      Object oldValue = null;
+
-      RegionEntry oldRe = null;
-      synchronized (newRe) {
-        try {
-          oldRe = putEntryIfAbsent(key, newRe);
-          while (!done && oldRe != null) {
-            synchronized (oldRe) {
-              if (oldRe.isRemovedPhase2()) {
-                owner.getCachePerfStats().incRetries();
-                _getMap().remove(key, oldRe);
-                oldRe = putEntryIfAbsent(key, newRe);
-              }
-              else {
-                boolean acceptedVersionTag = false;
-                if (entryVersion != null && owner.concurrencyChecksEnabled) {
-                  Assert.assertTrue(entryVersion.getMemberID() != null, "GII entry versions must have identifiers");
-                  try {
-                    boolean isTombstone = (newValue == Token.TOMBSTONE);
-                    // don't reschedule the tombstone if it hasn't changed
-                    boolean isSameTombstone = oldRe.isTombstone() && isTombstone
-                              && oldRe.getVersionStamp().asVersionTag()
-                                .equals(entryVersion);
-                    if (isSameTombstone) {
-                      return true;
-                    }
-                    processVersionTagForGII(oldRe, owner, entryVersion, isTombstone, sender, !wasRecovered || isSynchronizing);
-                    acceptedVersionTag = true;
-                  } catch (ConcurrentCacheModificationException e) {
-                    return false;
-                  }
-                }
-                final boolean oldIsTombstone = oldRe.isTombstone();
-                final int oldSize = owner.calculateRegionEntryValueSize(oldRe);
-                try {
-                  result = oldRe.initialImagePut(owner, lastModified, newValue, wasRecovered, acceptedVersionTag);
-                  if (result) {
-                    if (oldIsTombstone) {
-                      owner.unscheduleTombstone(oldRe);
-                      if (newValue != Token.TOMBSTONE){
-                        lruEntryCreate(oldRe);
-                      } else {
-                        lruEntryUpdate(oldRe);
-                      }
-                    }
-                    if (newValue == Token.TOMBSTONE) {
-                      owner.updateSizeOnRemove(key, oldSize);
-                      if (owner.getServerProxy() == null &&
-                          owner.getVersionVector().isTombstoneTooOld(entryVersion.getMemberID(), entryVersion.getRegionVersion())) {
-                        // the received tombstone has already been reaped, so don't retain it
-                        removeTombstone(oldRe, entryVersion, false, false);
-                        return false;
-                      } else {
-                        owner.scheduleTombstone(oldRe, entryVersion);
-                        lruEntryDestroy(oldRe);
-                      }
-                    } else {
-                      int newSize = owner.calculateRegionEntryValueSize(oldRe);
-                      if(!oldIsTombstone) {
-                        owner.updateSizeOnPut(key, oldSize, newSize);
-                      } else {
-                        owner.updateSizeOnCreate(key, newSize);
-                      }
-                      EntryLogger.logInitialImagePut(_getOwnerObject(), key, newValue);
-                    }
-                  }
-                  if (owner.getIndexManager() != null) {
-                    // Due to having no reverse map, we need to be able to generate the oldkey before doing an update
-                    // Without the BEFORE_UPDATE_OP, we would see duplicate entries in the index as the update could not locate the old key
-                    if (!oldRe.isRemoved()) {
-                      owner.getIndexManager().updateIndexes(oldRe, IndexManager.REMOVE_ENTRY, IndexProtocol.BEFORE_UPDATE_OP);
-                    }
-                    owner.getIndexManager().updateIndexes(oldRe, oldRe.isRemoved() ? IndexManager.ADD_ENTRY : IndexManager.UPDATE_ENTRY, 
-                        oldRe.isRemoved() ? IndexProtocol.OTHER_OP : IndexProtocol.AFTER_UPDATE_OP);
-                  }
-                  done = true;
-                } finally {
-                  if (event != null) {
-                    event.release();
-                    event = null;
-                  }
-                }
-              }
-            }
-          }
-          if (!done) {
-            boolean versionTagAccepted = false;
-            if (entryVersion != null && owner.concurrencyChecksEnabled) {
-              Assert.assertTrue(entryVersion.getMemberID() != null, "GII entry versions must have identifiers");
-              try {
-                boolean isTombstone = (newValue == Token.TOMBSTONE);
-                processVersionTagForGII(newRe, owner, entryVersion, isTombstone, sender, !wasRecovered || isSynchronizing);
-                versionTagAccepted = true;
-              } catch (ConcurrentCacheModificationException e) {
-                return false;
-              }
-            }
-            result = newRe.initialImageInit(owner, lastModified, newValue,
-                true, wasRecovered, versionTagAccepted);
-            try {
-              if (result) {
-                if (newValue == Token.TOMBSTONE) {
-                  owner.scheduleTombstone(newRe, entryVersion);
+        RegionEntry oldRe = null;
+        synchronized (newRe) {
+          try {
+            oldRe = putEntryIfAbsent(key, newRe);
+            while (!done && oldRe != null) {
+              synchronized (oldRe) {
+                if (oldRe.isRemovedPhase2()) {
+                  owner.getCachePerfStats().incRetries();
+                  _getMap().remove(key, oldRe);
+                  oldRe = putEntryIfAbsent(key, newRe);
-                  owner.updateSizeOnCreate(key, owner.calculateRegionEntryValueSize(newRe));
-                  EntryLogger.logInitialImagePut(_getOwnerObject(), key, newValue);
-                  lruEntryCreate(newRe);
-                }
-                incEntryCount(1);
-              }
-              
-              //Update local indexes
-                if (owner.getIndexManager() != null) {
-                  // Due to having no reverse map, we need to be able to generate the oldkey before doing an update
-                  // Without the BEFORE_UPDATE_OP, we would see duplicate entries in the index as the update could not locate the old key
-                  if (oldRe != null && !oldRe.isRemoved()) {
-                    owner.getIndexManager().updateIndexes(oldRe, IndexManager.REMOVE_ENTRY, IndexProtocol.BEFORE_UPDATE_OP);
+                  boolean acceptedVersionTag = false;
+                  if (entryVersion != null && owner.concurrencyChecksEnabled) {
+                    Assert.assertTrue(entryVersion.getMemberID() != null,
+                        "GII entry versions must have identifiers");
+                    try {
+                      boolean isTombstone = (newValue == Token.TOMBSTONE);
+                      // don't reschedule the tombstone if it hasn't changed
+                      boolean isSameTombstone = oldRe.isTombstone() && isTombstone
+                          && oldRe.getVersionStamp().asVersionTag().equals(entryVersion);
+                      if (isSameTombstone) {
+                        return true;
+                      }
+                      processVersionTagForGII(oldRe, owner, entryVersion, isTombstone, sender,
+                          !wasRecovered || isSynchronizing);
+                      acceptedVersionTag = true;
+                    } catch (ConcurrentCacheModificationException e) {
+                      return false;
+                    }
-                  owner.getIndexManager().updateIndexes(newRe, newRe.isRemoved() ? IndexManager.REMOVE_ENTRY : IndexManager.UPDATE_ENTRY,
+                  final boolean oldIsTombstone = oldRe.isTombstone();
+                  final int oldSize = owner.calculateRegionEntryValueSize(oldRe);
+                  try {
+                    result = oldRe.initialImagePut(owner, lastModified, newValue, wasRecovered,
+                        acceptedVersionTag);
+                    if (result) {
+                      if (oldIsTombstone) {
+                        owner.unscheduleTombstone(oldRe);
+                        if (newValue != Token.TOMBSTONE) {
+                          lruEntryCreate(oldRe);
+                        } else {
+                          lruEntryUpdate(oldRe);
+                        }
+                      }
+                      if (newValue == Token.TOMBSTONE) {
+                        owner.updateSizeOnRemove(key, oldSize);
+                        if (owner.getServerProxy() == null
+                            && owner.getVersionVector().isTombstoneTooOld(
+                                entryVersion.getMemberID(), entryVersion.getRegionVersion())) {
+                          // the received tombstone has already been reaped, so don't retain it
+                          removeTombstone(oldRe, entryVersion, false, false);
+                          return false;
+                        } else {
+                          owner.scheduleTombstone(oldRe, entryVersion);
+                          lruEntryDestroy(oldRe);
+                        }
+                      } else {
+                        int newSize = owner.calculateRegionEntryValueSize(oldRe);
+                        if (!oldIsTombstone) {
+                          owner.updateSizeOnPut(key, oldSize, newSize);
+                        } else {
+                          owner.updateSizeOnCreate(key, newSize);
+                        }
+                        EntryLogger.logInitialImagePut(_getOwnerObject(), key, newValue);
+                      }
+                    }
+                    if (owner.getIndexManager() != null) {
+                      // Due to having no reverse map, we need to be able to generate the oldkey
+                      // before doing an update
+                      // Without the BEFORE_UPDATE_OP, we would see duplicate entries in the index
+                      // as the update could not locate the old key
+                      if (!oldRe.isRemoved()) {
+                        owner.getIndexManager().updateIndexes(oldRe, IndexManager.REMOVE_ENTRY,
+                            IndexProtocol.BEFORE_UPDATE_OP);
+                      }
+                      owner.getIndexManager().updateIndexes(oldRe,
+                          oldRe.isRemoved() ? IndexManager.ADD_ENTRY : IndexManager.UPDATE_ENTRY,
+                          oldRe.isRemoved() ? IndexProtocol.OTHER_OP
+                              : IndexProtocol.AFTER_UPDATE_OP);
+                    }
+                    done = true;
+                  } finally {
+                    if (event != null) {
+                      event.release();
+                      event = null;
+                    }
+                  }
+                }
+              }
+            }
+            if (!done) {
+              boolean versionTagAccepted = false;
+              if (entryVersion != null && owner.concurrencyChecksEnabled) {
+                Assert.assertTrue(entryVersion.getMemberID() != null,
+                    "GII entry versions must have identifiers");
+                try {
+                  boolean isTombstone = (newValue == Token.TOMBSTONE);
+                  processVersionTagForGII(newRe, owner, entryVersion, isTombstone, sender,
+                      !wasRecovered || isSynchronizing);
+                  versionTagAccepted = true;
+                } catch (ConcurrentCacheModificationException e) {
+                  return false;
+                }
+              }
+              result = newRe.initialImageInit(owner, lastModified, newValue, true, wasRecovered,
+                  versionTagAccepted);
+              try {
+                if (result) {
+                  if (newValue == Token.TOMBSTONE) {
+                    owner.scheduleTombstone(newRe, entryVersion);
+                  } else {
+                    owner.updateSizeOnCreate(key, owner.calculateRegionEntryValueSize(newRe));
+                    EntryLogger.logInitialImagePut(_getOwnerObject(), key, newValue);
+                    lruEntryCreate(newRe);
+                  }
+                  incEntryCount(1);
+                }
+
+                // Update local indexes
+                if (owner.getIndexManager() != null) {
+                  // Due to having no reverse map, we need to be able to generate the oldkey before
+                  // doing an update
+                  // Without the BEFORE_UPDATE_OP, we would see duplicate entries in the index as
+                  // the update could not locate the old key
+                  if (oldRe != null && !oldRe.isRemoved()) {
+                    owner.getIndexManager().updateIndexes(oldRe, IndexManager.REMOVE_ENTRY,
+                        IndexProtocol.BEFORE_UPDATE_OP);
+                  }
+                  owner.getIndexManager().updateIndexes(newRe,
+                      newRe.isRemoved() ? IndexManager.REMOVE_ENTRY : IndexManager.UPDATE_ENTRY,
+                }
+                done = true;
+              } finally {
+                if (event != null) {
+                  event.release();
+                  event = null;
+                }
-              done = true;
-            } finally {
-              if (event != null) {
-                event.release();
-                event = null;
+            }
+          } finally {
+            if (done && result) {
+              initialImagePutEntry(newRe);
+            }
+            if (!done) {
+              removeEntry(key, newRe, false);
+              if (owner.getIndexManager() != null) {
+                owner.getIndexManager().updateIndexes(newRe, IndexManager.REMOVE_ENTRY,
+                    IndexProtocol.OTHER_OP);
-        }
-        finally {
-          if (done && result) {
-            initialImagePutEntry(newRe);
-          }
-          if (!done) {
-            removeEntry(key, newRe, false);
-            if (owner.getIndexManager() != null) {
-              owner.getIndexManager().updateIndexes(newRe, IndexManager.REMOVE_ENTRY, IndexProtocol.OTHER_OP);
-            }
-          }
-       } 
-      } // synchronized
+        } // synchronized
-        if (event != null) event.release();
+        if (event != null)
+          event.release();
-    } catch(RegionClearedException rce) {
-      //Asif: do not issue any sort of callbacks
+    } catch (RegionClearedException rce) {
+      // Asif: do not issue any sort of callbacks
-      cleared= true;
-    }catch(QueryException qe) {
+      cleared = true;
+    } catch (QueryException qe) {
-      cleared= true;
-    }
-    finally {
+      cleared = true;
+    } finally {
-      }
-      else if (!cleared) {
+      } else if (!cleared) {
-  protected void initialImagePutEntry(RegionEntry newRe) {
-  }
+  protected void initialImagePutEntry(RegionEntry newRe) {}
-  boolean confirmEvictionDestroy(RegionEntry re)
-  {
+  boolean confirmEvictionDestroy(RegionEntry re) {
-    Assert.assertTrue(false,
-        "Not an LRU region, can not confirm LRU eviction operation");
+    Assert.assertTrue(false, "Not an LRU region, can not confirm LRU eviction operation");
-  public final boolean destroy(EntryEventImpl event,
-                               boolean inTokenMode,
-                               boolean duringRI,
-                               boolean cacheWrite,
-                               boolean isEviction,
-                               Object expectedOldValue,
-                               boolean removeRecoveredEntry)
-  throws CacheWriterException, EntryNotFoundException, TimeoutException {
-    
+  public final boolean destroy(EntryEventImpl event, boolean inTokenMode, boolean duringRI,
+      boolean cacheWrite, boolean isEviction, Object expectedOldValue, boolean removeRecoveredEntry)
+      throws CacheWriterException, EntryNotFoundException, TimeoutException {
+
-      Assert.assertTrue(false, "The owner for RegionMap " + this    // "fix" for bug 32440
+      Assert.assertTrue(false, "The owner for RegionMap " + this // "fix" for bug 32440
-    
+
-    
+
-        // The outer try/finally ensures that the lock will be released without fail.  
+        // The outer try/finally ensures that the lock will be released without fail.
-        RegionEntry re = getOrCreateRegionEntry(owner, event, Token.REMOVED_PHASE1, null, true, true); 
+        RegionEntry re =
+            getOrCreateRegionEntry(owner, event, Token.REMOVED_PHASE1, null, true, true);
-         * Execute the test hook runnable inline (not threaded) if it is not null. 
+         * Execute the test hook runnable inline (not threaded) if it is not null.
-        if(null != testHookRunnableFor48182) {
+        if (null != testHookRunnableFor48182) {
-        }    
+        }
-          if (logger.isTraceEnabled(LogMarker.LRU_TOMBSTONE_COUNT) && !(owner instanceof HARegion)) {
+          if (logger.isTraceEnabled(LogMarker.LRU_TOMBSTONE_COUNT)
+              && !(owner instanceof HARegion)) {
-                inTokenMode, duringRI, event.isFromRILocalDestroy(), owner.dataPolicy.withReplication(), event.isFromServer(),
-                owner.concurrencyChecksEnabled, event.isOriginRemote(), isEviction, event.getOperation(), re);
+                inTokenMode, duringRI, event.isFromRILocalDestroy(),
+                owner.dataPolicy.withReplication(), event.isFromServer(),
+                owner.concurrencyChecksEnabled, event.isOriginRemote(), isEviction,
+                event.getOperation(), re);
-          // permutations to (re != null) greatly complicates it.  So, we check
+          // permutations to (re != null) greatly complicates it. So, we check
-          IndexManager oqlIndexManager = owner.getIndexManager() ; 
+          IndexManager oqlIndexManager = owner.getIndexManager();
-                    || event.isBridgeEvent())); /* event from client must create a tombstone so client has a version # */ 
-            if (inTokenMode
-                || retainForConcurrency) { 
+                    || event.isBridgeEvent())); /*
+                                                 * event from client must create a tombstone so
+                                                 * client has a version #
+                                                 */
+            if (inTokenMode || retainForConcurrency) {
-              RegionEntry newRe = getEntryFactory().createEntry(owner,
-                  event.getKey(),
-                  Token.REMOVED_PHASE1);
+              RegionEntry newRe =
+                  getEntryFactory().createEntry(owner, event.getKey(), Token.REMOVED_PHASE1);
-                          //if concurrency checks are enabled, destroy will
-                          //set the version tag
-                          boolean destroyed = destroyEntry(oldRe, event, inTokenMode, cacheWrite, expectedOldValue, false, removeRecoveredEntry);
+                          // if concurrency checks are enabled, destroy will
+                          // set the version tag
+                          boolean destroyed = destroyEntry(oldRe, event, inTokenMode, cacheWrite,
+                              expectedOldValue, false, removeRecoveredEntry);
-                        }
-                        catch (RegionClearedException rce) {
+                        } catch (RegionClearedException rce) {
-                        //if concurrency checks are enabled, destroy will
-                        //set the version tag
+                        // if concurrency checks are enabled, destroy will
+                        // set the version tag
-                          return opCompleted; 
+                          return opCompleted;
-                        opCompleted = destroyEntry(newRe, event, inTokenMode, cacheWrite, expectedOldValue, true, removeRecoveredEntry);
+                        opCompleted = destroyEntry(newRe, event, inTokenMode, cacheWrite,
+                            expectedOldValue, true, removeRecoveredEntry);
-                          // a tombstone.  There is no oldValue, so we don't need to
+                          // a tombstone. There is no oldValue, so we don't need to
-                          //                    owner.recordEvent(event);
-                          event.setIsRedestroyedEntry(true);  // native clients need to know if the entry didn't exist
+                          // owner.recordEvent(event);
+                          event.setIsRedestroyedEntry(true); // native clients need to know if the
+                                                             // entry didn't exist
-                      }
-                      catch (RegionClearedException rce) {
+                      } catch (RegionClearedException rce) {
-                        owner.basicDestroyPart2(newRe, event, inTokenMode, true /* conflict with clear*/, duringRI, true);
+                        owner.basicDestroyPart2(newRe, event, inTokenMode,
+                            true /* conflict with clear */, duringRI, true);
-                      if (!opCompleted && !haveTombstone  /* to fix bug 51583 do this for all operations */ ) {
+                      if (!opCompleted
+                          && !haveTombstone /* to fix bug 51583 do this for all operations */ ) {
-              if (!isEviction || owner.concurrencyChecksEnabled) {                                 
+              if (!isEviction || owner.concurrencyChecksEnabled) {
-                RegionEntry newRe = haveTombstone? tombstone : getEntryFactory().createEntry(owner, event.getKey(),
-                    Token.REMOVED_PHASE1);
-                synchronized(newRe) {
+                RegionEntry newRe = haveTombstone ? tombstone
+                    : getEntryFactory().createEntry(owner, event.getKey(), Token.REMOVED_PHASE1);
+                synchronized (newRe) {
-                    //retryEntry = tombstone; // leave this in place for debugging
+                    // retryEntry = tombstone; // leave this in place for debugging
-                  re = (RegionEntry)_getMap().putIfAbsent(event.getKey(), newRe);
+                  re = (RegionEntry) _getMap().putIfAbsent(event.getKey(), newRe);
-                    //retryEntry = tombstone; // leave this in place for debugging
+                    // retryEntry = tombstone; // leave this in place for debugging
-                  }
-                  else if (!isEviction) {
+                  } else if (!isEviction) {
-                    EntryNotFoundException ex =  null;
+                    EntryNotFoundException ex = null;
-                          ex = e; 
+                          ex = e;
-                        if (!event.isOriginRemote() && !event.getOperation().isLocal() &&
-                            (event.isFromBridgeAndVersioned() ||  // if this is a replayed client event that already has a version
-                                event.isFromWANAndVersioned())) { // or if this is a WAN event that has been applied in another system
-                          // we must distribute these since they will update the version information in peers
+                        if (!event.isOriginRemote() && !event.getOperation().isLocal()
+                            && (event.isFromBridgeAndVersioned() || // if this is a replayed client
+                                                                    // event that already has a
+                                                                    // version
+                                event.isFromWANAndVersioned())) { // or if this is a WAN event that
+                                                                  // has been applied in another
+                                                                  // system
+                          // we must distribute these since they will update the version information
+                          // in peers
-                            logger.debug("ARM.destroy is allowing wan/client destroy of {} to continue", event.getKey());
+                            logger.debug(
+                                "ARM.destroy is allowing wan/client destroy of {} to continue",
+                                event.getKey());
-                      if (throwex) {                    
+                      if (throwex) {
-                          // Fix for 48182, check cache state and/or region state before sending entry not found.
+                          // Fix for 48182, check cache state and/or region state before sending
+                          // entry not found.
-                        if (!event.isOriginRemote() && event.getVersionTag() != null && owner.concurrencyChecksEnabled) {
+                        if (!event.isOriginRemote() && event.getVersionTag() != null
+                            && owner.concurrencyChecksEnabled) {
-                          //                    lruEntryCreate(newRe);
+                          // lruEntryCreate(newRe);
-                        } else if (event.getVersionTag() != null ) { // haveTombstone - update the tombstone version info
+                        } else if (event.getVersionTag() != null) { // haveTombstone - update the
+                                                                    // tombstone version info
-                          // This is not conflict, we need to persist the tombstone again with new version tag 
+                          // This is not conflict, we need to persist the tombstone again with new
+                          // version tag
-                          owner.basicDestroyPart2(tombstone, event, inTokenMode, true /* conflict with clear*/, duringRI, true);
+                          owner.basicDestroyPart2(tombstone, event, inTokenMode,
+                              true /* conflict with clear */, duringRI, true);
-                // version stamp.  Otherwise we would retain an old version stamp and may allow
+                // version stamp. Otherwise we would retain an old version stamp and may allow
-                // Bug 45170: If removeRecoveredEntry, we treat tombstone as regular entry to be deleted
-                boolean createTombstoneForConflictChecks = (owner.concurrencyChecksEnabled
-                    && (event.isOriginRemote() || event.getContext() != null || removeRecoveredEntry));
+                // Bug 45170: If removeRecoveredEntry, we treat tombstone as regular entry to be
+                // deleted
+                boolean createTombstoneForConflictChecks =
+                    (owner.concurrencyChecksEnabled && (event.isOriginRemote()
+                        || event.getContext() != null || removeRecoveredEntry));
-                    // If this expiration started locally then only do it if the RE is not being used by a tx.
+                    // If this expiration started locally then only do it if the RE is not being
+                    // used by a tx.
-                    opCompleted = destroyEntry(re, event, inTokenMode, cacheWrite, expectedOldValue, false, removeRecoveredEntry);
+                    opCompleted = destroyEntry(re, event, inTokenMode, cacheWrite, expectedOldValue,
+                        false, removeRecoveredEntry);
-                        if ( re.getVersionStamp() == null) {
+                        if (re.getVersionStamp() == null) {
-                      owner.basicDestroyPart2(re, event, inTokenMode, false /* conflict with clear*/, duringRI, true);
-                      //                  if (!re.isTombstone() || isEviction) {
+                      owner.basicDestroyPart2(re, event, inTokenMode,
+                          false /* conflict with clear */, duringRI, true);
+                      // if (!re.isTombstone() || isEviction) {
-                      //                  } else {
-                      //                    lruEntryUpdate(re);
-                      //                    lruUpdateCallback = true;
-                      //                  }
+                      // } else {
+                      // lruEntryUpdate(re);
+                      // lruUpdateCallback = true;
+                      // }
-                  }
-                  catch (RegionClearedException rce) {
+                  } catch (RegionClearedException rce) {
-                    owner.basicDestroyPart2(re, event, inTokenMode, true /*conflict with clear*/, duringRI, true);
+                    owner.basicDestroyPart2(re, event, inTokenMode, true /* conflict with clear */,
+                        duringRI, true);
-                  }
-                  finally {
+                  } finally {
-            }  catch (ConcurrentCacheModificationException ccme) {
+            } catch (ConcurrentCacheModificationException ccme) {
-          if(opCompleted) {
+          if (opCompleted) {
-        }
-        finally {
+        } finally {
-            if (event.isConcurrencyConflict() &&
-                (event.getVersionTag() != null && event.getVersionTag().isGatewayTag())) {
+            if (event.isConcurrencyConflict()
+                && (event.getVersionTag() != null && event.getVersionTag().isGatewayTag())) {
+                // we only want to cancel if concurrency-check is not enabled
+                // re(regionentry) will be null when concurrency-check is enable and removeTombstone
+                // method
+                // will call cancelExpiryTask on regionEntry
-              } else if (tombstone != null) {
-                owner.cancelExpiryTask(tombstone);
-  public final void txApplyDestroy(Object key, TransactionId txId,
-      TXRmtEvent txEvent, boolean inTokenMode, boolean inRI, Operation op, 
-      EventID eventId, Object aCallbackArgument,List<EntryEventImpl> pendingCallbacks,FilterRoutingInfo filterRoutingInfo,ClientProxyMembershipID bridgeContext,
-      boolean isOriginRemote, TXEntryState txEntryState, VersionTag versionTag, long tailKey)
-  {
+  public final void txApplyDestroy(Object key, TransactionId txId, TXRmtEvent txEvent,
+      boolean inTokenMode, boolean inRI, Operation op, EventID eventId, Object aCallbackArgument,
+      List<EntryEventImpl> pendingCallbacks, FilterRoutingInfo filterRoutingInfo,
+      ClientProxyMembershipID bridgeContext, boolean isOriginRemote, TXEntryState txEntryState,
+      VersionTag versionTag, long tailKey) {
-    
+
-    final boolean hasRemoteOrigin = !((TXId)txId).getMemberId().equals(owner.getMyId());
+    final boolean hasRemoteOrigin = !((TXId) txId).getMemberId().equals(owner.getMyId());
-    lockForTXCacheModification(owner, versionTag);
-    IndexManager oqlIndexManager = owner.getIndexManager() ; 
+    IndexManager oqlIndexManager = owner.getIndexManager();
-              @Released EntryEventImpl cbEvent = createCBEvent(owner, op,
-                  key, null, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
+              @Released
+              EntryEventImpl cbEvent =
+                  createCBEvent(owner, op, key, null, txId, txEvent, eventId, aCallbackArgument,
+                      filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-              
+
-              cbEvent.setOldValue(oldValue);
-              if (isDebugEnabled) {
-                logger.debug("txApplyDestroy cbEvent={}", cbEvent);
-              }
-              
-              txRemoveOldIndexEntry(Operation.DESTROY, re);
-              if (txEvent != null) {
-                txEvent.addDestroy(owner, re, re.getKey(),aCallbackArgument);
-              }
-              boolean clearOccured = false;
-              try {
-                processAndGenerateTXVersionTag(owner, cbEvent, re, txEntryState);
-                if (inTokenMode) {
-                  if (oldValue == Token.TOMBSTONE) {
-                    owner.unscheduleTombstone(re);
-                  }
-                  re.setValue(owner, Token.DESTROYED);
+                cbEvent.setOldValue(oldValue);
+                if (isDebugEnabled) {
+                  logger.debug("txApplyDestroy cbEvent={}", cbEvent);
-                else {
-                  if (!re.isTombstone()) {
-                    {
-                      if (shouldPerformConcurrencyChecks(owner, cbEvent) && cbEvent.getVersionTag() != null) {
-                        re.makeTombstone(owner, cbEvent.getVersionTag());
-                      } else {
-                        re.removePhase1(owner, false); // fix for bug 43063
-                        re.removePhase2();
-                        removeEntry(key, re, false);
-                      }
+
+                txRemoveOldIndexEntry(Operation.DESTROY, re);
+                if (txEvent != null) {
+                  txEvent.addDestroy(owner, re, re.getKey(), aCallbackArgument);
+                }
+                boolean clearOccured = false;
+                try {
+                  processAndGenerateTXVersionTag(owner, cbEvent, re, txEntryState);
+                  if (inTokenMode) {
+                    if (oldValue == Token.TOMBSTONE) {
+                      owner.unscheduleTombstone(re);
+                    re.setValue(owner, Token.DESTROYED);
-                    owner.rescheduleTombstone(re, re.getVersionStamp().asVersionTag());
+                    if (!re.isTombstone()) {
+                      {
+                        if (shouldPerformConcurrencyChecks(owner, cbEvent)
+                            && cbEvent.getVersionTag() != null) {
+                          re.makeTombstone(owner, cbEvent.getVersionTag());
+                        } else {
+                          re.removePhase1(owner, false); // fix for bug 43063
+                          re.removePhase2();
+                          removeEntry(key, re, false);
+                        }
+                      }
+                    } else {
+                      owner.rescheduleTombstone(re, re.getVersionStamp().asVersionTag());
+                    }
+                  }
+                  EntryLogger.logTXDestroy(_getOwnerObject(), key);
+                  owner.updateSizeOnRemove(key, oldSize);
+                } catch (RegionClearedException rce) {
+                  clearOccured = true;
+                }
+                owner.txApplyDestroyPart2(re, re.getKey(), inTokenMode,
+                    clearOccured /* Clear Conflciting with the operation */);
+                if (invokeCallbacks) {
+                  switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
+                  if (pendingCallbacks == null) {
+                    owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY, cbEvent,
+                        true/* callDispatchListenerEvent */);
+                  } else {
+                    pendingCallbacks.add(cbEvent);
+                    cbEventInPending = true;
-                EntryLogger.logTXDestroy(_getOwnerObject(), key);
-                owner.updateSizeOnRemove(key, oldSize);
-              }
-              catch (RegionClearedException rce) {
-                clearOccured = true;
-              }
-              owner.txApplyDestroyPart2(re, re.getKey(), inTokenMode,
-                  clearOccured /* Clear Conflciting with the operation */);
-              if (invokeCallbacks) {
-                switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
-                if(pendingCallbacks==null) {
-                  owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY,
-                      cbEvent, true/*callDispatchListenerEvent*/);
-                } else {
-                  pendingCallbacks.add(cbEvent);
-                  cbEventInPending = true;
+                if (!clearOccured) {
+                  lruEntryDestroy(re);
-              }
-              if (!clearOccured) {
-                lruEntryDestroy(re);
-              }
-              if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent!= null) {
-                txEntryState.setVersionTag(cbEvent.getVersionTag());
-              }
+                if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent != null) {
+                  txEntryState.setVersionTag(cbEvent.getVersionTag());
+                }
-                if (!cbEventInPending) cbEvent.release();
+                if (!cbEventInPending)
+                  cbEvent.release();
-        // TODO: if inTokenMode then Token.DESTROYED is ok but what about !inTokenMode because owner.concurrencyChecksEnabled? In that case we do not want a DESTROYED token.
-        RegionEntry newRe = getEntryFactory().createEntry(owner, key,
-            Token.DESTROYED);
-        if ( oqlIndexManager != null) {
+        // TODO: if inTokenMode then Token.DESTROYED is ok but what about !inTokenMode because
+        // owner.concurrencyChecksEnabled? In that case we do not want a DESTROYED token.
+        RegionEntry newRe = getEntryFactory().createEntry(owner, key, Token.DESTROYED);
+        if (oqlIndexManager != null) {
-                }
-                else {
+                } else {
-                    cbEvent = createCBEvent(owner, op,
-                        key, null, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
+                    cbEvent = createCBEvent(owner, op, key, null, txId, txEvent, eventId,
+                        aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState,
+                        versionTag, tailKey);
-                    cbEvent.setRegionEntry(oldRe);
-                    cbEvent.setOldValue(Token.NOT_AVAILABLE);
-                    if (isDebugEnabled) {
-                      logger.debug("txApplyDestroy token mode cbEvent={}", cbEvent);
-                    }
-                    if (owner.isUsedForPartitionedRegionBucket()) {
-                      txHandleWANEvent(owner, cbEvent, txEntryState);
-                    }
-                    processAndGenerateTXVersionTag(owner, cbEvent, oldRe, txEntryState);
-                    if (invokeCallbacks) {
-                      switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
-                      if(pendingCallbacks==null) {
-                        owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY,
-                            cbEvent, dispatchListenerEvent);
-                      } else {
-                        pendingCallbacks.add(cbEvent);
-                        cbEventInPending = true;
+                      cbEvent.setRegionEntry(oldRe);
+                      cbEvent.setOldValue(Token.NOT_AVAILABLE);
+                      if (isDebugEnabled) {
+                        logger.debug("txApplyDestroy token mode cbEvent={}", cbEvent);
-                    }
-                    int oldSize = 0;
-                    boolean wasTombstone = oldRe.isTombstone();
-                    {
-                      if (!wasTombstone) {
-                        oldSize = owner.calculateRegionEntryValueSize(oldRe);
+                      if (owner.isUsedForPartitionedRegionBucket()) {
+                        txHandleWANEvent(owner, cbEvent, txEntryState);
-                    }
-                    oldRe.setValue(owner, Token.DESTROYED);
-                    EntryLogger.logTXDestroy(_getOwnerObject(), key);
-                    if (wasTombstone) {
-                      owner.unscheduleTombstone(oldRe);
-                    }
-                    owner.updateSizeOnRemove(oldRe.getKey(), oldSize);
-                    owner.txApplyDestroyPart2(oldRe, oldRe.getKey(), inTokenMode,
-                        false /* Clear Conflicting with the operation */);
-                    lruEntryDestroy(oldRe);
+                      processAndGenerateTXVersionTag(owner, cbEvent, oldRe, txEntryState);
+                      if (invokeCallbacks) {
+                        switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
+                        if (pendingCallbacks == null) {
+                          owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY, cbEvent,
+                              dispatchListenerEvent);
+                        } else {
+                          pendingCallbacks.add(cbEvent);
+                          cbEventInPending = true;
+                        }
+                      }
+                      int oldSize = 0;
+                      boolean wasTombstone = oldRe.isTombstone();
+                      {
+                        if (!wasTombstone) {
+                          oldSize = owner.calculateRegionEntryValueSize(oldRe);
+                        }
+                      }
+                      oldRe.setValue(owner, Token.DESTROYED);
+                      EntryLogger.logTXDestroy(_getOwnerObject(), key);
+                      if (wasTombstone) {
+                        owner.unscheduleTombstone(oldRe);
+                      }
+                      owner.updateSizeOnRemove(oldRe.getKey(), oldSize);
+                      owner.txApplyDestroyPart2(oldRe, oldRe.getKey(), inTokenMode,
+                          false /* Clear Conflicting with the operation */);
+                      lruEntryDestroy(oldRe);
-                      if (!cbEventInPending) cbEvent.release();
+                      if (!cbEventInPending)
+                        cbEvent.release();
-                  }
-                  catch (RegionClearedException rce) {
+                  } catch (RegionClearedException rce) {
-                  if (shouldPerformConcurrencyChecks(owner, cbEvent) && cbEvent.getVersionTag() != null) {
+                  if (shouldPerformConcurrencyChecks(owner, cbEvent)
+                      && cbEvent.getVersionTag() != null) {
-              cbEvent = createCBEvent(owner, op,
-                  key, null, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
+              cbEvent =
+                  createCBEvent(owner, op, key, null, txId, txEvent, eventId, aCallbackArgument,
+                      filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-              cbEvent.setRegionEntry(newRe);
-              cbEvent.setOldValue(Token.NOT_AVAILABLE);
-              if (isDebugEnabled) {
-                logger.debug("txApplyDestroy token mode cbEvent={}", cbEvent);
-              }
-              if (owner.isUsedForPartitionedRegionBucket()) {
-                txHandleWANEvent(owner, cbEvent, txEntryState);
-              }
-              processAndGenerateTXVersionTag(owner, cbEvent, newRe, txEntryState);
-              if (invokeCallbacks) {
-                switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
-                if(pendingCallbacks==null) {
-                  owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY,
-                      cbEvent, dispatchListenerEvent);
-                } else {
-                  pendingCallbacks.add(cbEvent);
-                  cbEventInPending = true;
+                cbEvent.setRegionEntry(newRe);
+                cbEvent.setOldValue(Token.NOT_AVAILABLE);
+                if (isDebugEnabled) {
+                  logger.debug("txApplyDestroy token mode cbEvent={}", cbEvent);
-              }
-              EntryLogger.logTXDestroy(_getOwnerObject(), key);
-              owner.updateSizeOnCreate(newRe.getKey(), 0);
-              if (shouldPerformConcurrencyChecks(owner, cbEvent) && cbEvent.getVersionTag() != null) {
-                newRe.makeTombstone(owner, cbEvent.getVersionTag());
-              } else if (!inTokenMode) {
-                // only remove for NORMAL regions if they do not generate versions see 51781
-                newRe.removePhase1(owner, false); // fix for bug 43063
-                newRe.removePhase2();
-                removeEntry(key, newRe, false);
-              }
-              owner
-                  .txApplyDestroyPart2(newRe, newRe.getKey(), inTokenMode,
-                      false /*clearConflict*/);
-              // Note no need for LRU work since the entry is destroyed
-              // and will be removed when gii completes
+                if (owner.isUsedForPartitionedRegionBucket()) {
+                  txHandleWANEvent(owner, cbEvent, txEntryState);
+                }
+                processAndGenerateTXVersionTag(owner, cbEvent, newRe, txEntryState);
+                if (invokeCallbacks) {
+                  switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
+                  if (pendingCallbacks == null) {
+                    owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY, cbEvent,
+                        dispatchListenerEvent);
+                  } else {
+                    pendingCallbacks.add(cbEvent);
+                    cbEventInPending = true;
+                  }
+                }
+                EntryLogger.logTXDestroy(_getOwnerObject(), key);
+                owner.updateSizeOnCreate(newRe.getKey(), 0);
+                if (shouldPerformConcurrencyChecks(owner, cbEvent)
+                    && cbEvent.getVersionTag() != null) {
+                  newRe.makeTombstone(owner, cbEvent.getVersionTag());
+                } else if (!inTokenMode) {
+                  // only remove for NORMAL regions if they do not generate versions see 51781
+                  newRe.removePhase1(owner, false); // fix for bug 43063
+                  newRe.removePhase2();
+                  removeEntry(key, newRe, false);
+                }
+                owner.txApplyDestroyPart2(newRe, newRe.getKey(), inTokenMode,
+                    false /* clearConflict */);
+                // Note no need for LRU work since the entry is destroyed
+                // and will be removed when gii completes
-                if (!cbEventInPending) cbEvent.release();
+                if (!cbEventInPending)
+                  cbEvent.release();
-          // TODO 
+          // TODO
-        // In cases where bucket region is re-created, it may so happen that 
-        // the destroy is already applied on the Initial image provider, thus 
-        // causing region entry to be absent. 
+        // In cases where bucket region is re-created, it may so happen that
+        // the destroy is already applied on the Initial image provider, thus
+        // causing region entry to be absent.
-        @Released EntryEventImpl cbEvent = createCBEvent(owner, op,
-            key, null, txId, txEvent, eventId, aCallbackArgument, 
-            filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
+        @Released
+        EntryEventImpl cbEvent = createCBEvent(owner, op, key, null, txId, txEvent, eventId,
+            aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-        if (owner.isUsedForPartitionedRegionBucket()) {
-          txHandleWANEvent(owner, cbEvent, txEntryState);
-        }
-        switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
-        if (pendingCallbacks == null) {
-          owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY,cbEvent,false);
-        } else {
-          pendingCallbacks.add(cbEvent);
-          cbEventInPending = true;
-        }
+          if (owner.isUsedForPartitionedRegionBucket()) {
+            txHandleWANEvent(owner, cbEvent, txEntryState);
+          }
+          switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
+          if (pendingCallbacks == null) {
+            owner.invokeTXCallbacks(EnumListenerEvent.AFTER_DESTROY, cbEvent, false);
+          } else {
+            pendingCallbacks.add(cbEvent);
+            cbEventInPending = true;
+          }
-          if (!cbEventInPending) cbEvent.release();
+          if (!cbEventInPending)
+            cbEvent.release();
-    } catch( DiskAccessException dae) {
+    } catch (DiskAccessException dae) {
-    finally {
-      releaseTXCacheModificationLock(owner, versionTag);
-    }
-   * If true then invalidates that throw EntryNotFoundException
-   * or that are already invalid will first call afterInvalidate on CacheListeners. 
-   * The old value on the event passed to afterInvalidate will be null.
-   * If the region is not initialized then callbacks will not be done.
-   * This property only applies to non-transactional invalidates.
-   * Transactional invalidates ignore this property.
-   * Note that empty "proxy" regions on a client will not be sent invalidates
-   * from the server unless they also set the proxy InterestPolicy to ALL.
-   * If the invalidate is not sent then this property will not cause a listener 
-   * on that client to be notified of the invalidate.
-   * A non-empty "caching-proxy" will receive invalidates from the server.
+   * If true then invalidates that throw EntryNotFoundException or that are already invalid will
+   * first call afterInvalidate on CacheListeners. The old value on the event passed to
+   * afterInvalidate will be null. If the region is not initialized then callbacks will not be done.
+   * This property only applies to non-transactional invalidates. Transactional invalidates ignore
+   * this property. Note that empty "proxy" regions on a client will not be sent invalidates from
+   * the server unless they also set the proxy InterestPolicy to ALL. If the invalidate is not sent
+   * then this property will not cause a listener on that client to be notified of the invalidate. A
+   * non-empty "caching-proxy" will receive invalidates from the server.
-  public static boolean FORCE_INVALIDATE_EVENT = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "FORCE_INVALIDATE_EVENT");
+  public static boolean FORCE_INVALIDATE_EVENT =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "FORCE_INVALIDATE_EVENT");
-   * If the FORCE_INVALIDATE_EVENT flag is true
-   * then invoke callbacks on the given event.
+   * If the FORCE_INVALIDATE_EVENT flag is true then invoke callbacks on the given event.
-  
-  public final boolean invalidate(EntryEventImpl event,
-      boolean invokeCallbacks, boolean forceNewEntry, boolean forceCallbacks)
-          throws EntryNotFoundException
-  {
+
+  public final boolean invalidate(EntryEventImpl event, boolean invokeCallbacks,
+      boolean forceNewEntry, boolean forceCallbacks) throws EntryNotFoundException {
-      Assert.assertTrue(false, "The owner for RegionMap " + this
-          + " is null for event " + event);
+      Assert.assertTrue(false, "The owner for RegionMap " + this + " is null for event " + event);
-      IndexManager oqlIndexManager = owner.getIndexManager() ; 
+      IndexManager oqlIndexManager = owner.getIndexManager();
-            RegionEntry newRe = getEntryFactory().createEntry(owner, event.getKey(),
-                Token.REMOVED_PHASE1);
+            RegionEntry newRe =
+                getEntryFactory().createEntry(owner, event.getKey(), Token.REMOVED_PHASE1);
-                    // from the map.  Otherwise, we can use it here and the thread
+                    // from the map. Otherwise, we can use it here and the thread
-                          logger.debug("mapInvalidate: Found DESTROYED token, not invalidated; key={}", event.getKey());
+                          logger.debug(
+                              "mapInvalidate: Found DESTROYED token, not invalidated; key={}",
+                              event.getKey());
-                          logger.debug("mapInvalidate: Entry already invalid: '{}'", event.getKey());
+                          logger.debug("mapInvalidate: Entry already invalid: '{}'",
+                              event.getKey());
-                          oldRe.setValue(owner, oldRe.getValueInVM(owner)); // OFFHEAP noop setting an already invalid to invalid; No need to call prepareValueForCache since it is an invalid token.
+                          oldRe.setValue(owner, oldRe.getValueInVM(owner)); // OFFHEAP noop setting
+                                                                            // an already invalid to
+                                                                            // invalid; No need to
+                                                                            // call
+                                                                            // prepareValueForCache
+                                                                            // since it is an
+                                                                            // invalid token.
-                        //added for cq which needs old value. rdubey
+                        // added for cq which needs old value. rdubey
-                        if (!oldRe.isRemoved() && 
-                            (fp != null && fp.getCqCount() > 0)) {
+                        if (!oldRe.isRemoved() && (fp != null && fp.getCqCount() > 0)) {
-                          Object oldValue = oldRe.getValueInVM(owner); // OFFHEAP EntryEventImpl oldValue
+                          Object oldValue = oldRe.getValueInVM(owner); // OFFHEAP EntryEventImpl
+                                                                       // oldValue
-                          if (oldValue == Token.NOT_AVAILABLE){
+                          if (oldValue == Token.NOT_AVAILABLE) {
-                              owner.updateSizeOnPut(event.getKey(), oldSize, event.getNewValueBucketSize());
+                              owner.updateSizeOnPut(event.getKey(), oldSize,
+                                  event.getNewValueBucketSize());
-                              owner.updateSizeOnCreate(event.getKey(), event.getNewValueBucketSize());
+                              owner.updateSizeOnCreate(event.getKey(),
+                                  event.getNewValueBucketSize());
-                            owner.updateSizeOnPut(event.getKey(), oldSize, event.getNewValueBucketSize());
+                            owner.updateSizeOnPut(event.getKey(), oldSize,
+                                event.getNewValueBucketSize());
-                        }
-                        catch (RegionClearedException e) {
+                        } catch (RegionClearedException e) {
-                        }                   
+                        }
-                    }
-                    else {
+                    } else {
-                  }
-                  catch (RegionClearedException e) {
+                  } catch (RegionClearedException e) {
-                  owner.basicInvalidatePart2(newRe, event, clearOccured /*conflict with clear*/, invokeCallbacks);
+                  owner.basicInvalidatePart2(newRe, event, clearOccured /* conflict with clear */,
+                      invokeCallbacks);
-                  }            
+                  }
-                  } 
+                  }
-                  RegionEntry newRe = haveTombstone? tombstone : getEntryFactory().createEntry(owner, event.getKey(),
-                      Token.INVALID);
+                  RegionEntry newRe = haveTombstone ? tombstone
+                      : getEntryFactory().createEntry(owner, event.getKey(), Token.INVALID);
-                      //retryEntry = tombstone; // leave this in place for debugging
+                      // retryEntry = tombstone; // leave this in place for debugging
-                  Object sync = haveTombstone? tombstone : new Object();
-                  synchronized(sync) {
-                    if (haveTombstone && !tombstone.isTombstone()) { 
+                  Object sync = haveTombstone ? tombstone : new Object();
+                  synchronized (sync) {
+                    if (haveTombstone && !tombstone.isTombstone()) {
-                      //retryEntry = tombstone; // leave this in place for debugging
+                      // retryEntry = tombstone; // leave this in place for debugging
-                    // bug #43287 - send event to server even if it's not in the client (LRU may have evicted it)
+                    // bug #43287 - send event to server even if it's not in the client (LRU may
+                    // have evicted it)
-                              logger.debug("tombstone is no longer a tombstone. {}:event={}", tombstone, event);
+                              logger.debug("tombstone is no longer a tombstone. {}:event={}",
+                                  tombstone, event);
-                        // update the tombstone's version to prevent an older CCU/putAll from overwriting it
+                        // update the tombstone's version to prevent an older CCU/putAll from
+                        // overwriting it
-                // if the GII got processed earlier for this entry, then do 
+                // if the GII got processed earlier for this entry, then do
-                    // If this expiration started locally then only do it if the RE is not being used by a tx.
+                    // If this expiration started locally then only do it if the RE is not being
+                    // used by a tx.
-                        owner.getVersionVector().recordVersion((InternalDistributedMember) event.getDistributedMember(), event.getVersionTag());
+                        owner.getVersionVector().recordVersion(
+                            (InternalDistributedMember) event.getDistributedMember(),
+                            event.getVersionTag());
-                    }
-                    else { // previous value not invalid
+                    } else { // previous value not invalid
-                          logger.debug("returning early because server did not generate a version stamp for this event:{}", event);
+                          logger.debug(
+                              "returning early because server did not generate a version stamp for this event:{}",
+                              event);
-                      if(owner.getFilterProfile().getCqCount() > 0){
-                        //use to be getValue and can cause dead lock rdubey.
+                      if (owner.getFilterProfile().getCqCount() > 0) {
+                        // use to be getValue and can cause dead lock rdubey.
-                      }
-                      catch (RegionClearedException rce) {
+                      } catch (RegionClearedException rce) {
-                      owner.basicInvalidatePart2(re, event,
-                          clearOccured /* conflict with clear */, invokeCallbacks);
+                      owner.basicInvalidatePart2(re, event, clearOccured /* conflict with clear */,
+                          invokeCallbacks);
-                      }             
+                      }
-        } catch( DiskAccessException dae) {
+        } catch (DiskAccessException dae) {
-            } catch( DiskAccessException dae) {
+            } catch (DiskAccessException dae) {
-          }
-          else if (!didInvalidate){
+          } else if (!didInvalidate) {
-  protected void invalidateNewEntry(EntryEventImpl event,
-      final LocalRegion owner, RegionEntry newRe) throws RegionClearedException {
+  protected void invalidateNewEntry(EntryEventImpl event, final LocalRegion owner,
+      RegionEntry newRe) throws RegionClearedException {
-  protected void invalidateEntry(EntryEventImpl event, RegionEntry re,
-      int oldSize) throws RegionClearedException {
+  protected void invalidateEntry(EntryEventImpl event, RegionEntry re, int oldSize)
+      throws RegionClearedException {
-  
-  /* (non-Javadoc)
-   * @see org.apache.geode.internal.cache.RegionMap#updateEntryVersion(org.apache.geode.internal.cache.EntryEventImpl)
+
+  /*
+   * (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.RegionMap#updateEntryVersion(org.apache.geode.internal.cache.
+   * EntryEventImpl)
-      Assert.assertTrue(false, "The owner for RegionMap " + this
-          + " is null for event " + event);
+      Assert.assertTrue(false, "The owner for RegionMap " + this + " is null for event " + event);
-    
+
-            if (re.isTombstone()
-                || (!re.isRemoved() && !re.isDestroyed())) {
+            if (re.isTombstone() || (!re.isRemoved() && !re.isDestroyed())) {
-    }  catch( DiskAccessException dae) {
+    } catch (DiskAccessException dae) {
-      TransactionId txId, TXRmtEvent txEvent, boolean localOp, 
-      EventID eventId, Object aCallbackArgument,List<EntryEventImpl> pendingCallbacks,FilterRoutingInfo filterRoutingInfo,ClientProxyMembershipID bridgeContext, TXEntryState txEntryState, VersionTag versionTag, long tailKey)
-  {
-//    boolean didInvalidate = false;
+      TransactionId txId, TXRmtEvent txEvent, boolean localOp, EventID eventId,
+      Object aCallbackArgument, List<EntryEventImpl> pendingCallbacks,
+      FilterRoutingInfo filterRoutingInfo, ClientProxyMembershipID bridgeContext,
+      TXEntryState txEntryState, VersionTag versionTag, long tailKey) {
+    // boolean didInvalidate = false;
-    
-    @Released EntryEventImpl cbEvent = null;
+
+    @Released
+    EntryEventImpl cbEvent = null;
-    final boolean hasRemoteOrigin = !((TXId)txId).getMemberId().equals(owner.getMyId());
+    final boolean hasRemoteOrigin = !((TXId) txId).getMemberId().equals(owner.getMyId());
-    IndexManager oqlIndexManager = owner.getIndexManager() ; 
+    IndexManager oqlIndexManager = owner.getIndexManager();
-    lockForTXCacheModification(owner, versionTag);
-        RegionEntry newRe = getEntryFactory().createEntry(owner, key,
-            Token.REMOVED_PHASE1);
-          synchronized (newRe) {
-            try {
-              RegionEntry oldRe = putEntryIfAbsent(key, newRe);
-              while (!opCompleted && oldRe != null) {
-                synchronized (oldRe) {
-                  if (oldRe.isRemovedPhase2()) {
-                    owner.getCachePerfStats().incRetries();
-                    _getMap().remove(key, oldRe);
-                    oldRe = putEntryIfAbsent(key, newRe);
-                  }
-                  else {
-                    opCompleted = true;
-                    final boolean oldWasTombstone = oldRe.isTombstone();
-                    final int oldSize = owner.calculateRegionEntryValueSize(oldRe);
-                    Object oldValue = oldRe.getValueInVM(owner); // OFFHEAP eei
-                    // Create an entry event only if the calling context is
-                    // a receipt of a TXCommitMessage AND there are callbacks
-                    // installed
-                    // for this region
-                    boolean invokeCallbacks = shouldCreateCBEvent(owner, owner.isInitialized());
-                    boolean cbEventInPending = false;
-                    cbEvent = createCBEvent(owner, 
-                        localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE,
-                        key, newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-                    try {
+        RegionEntry newRe = getEntryFactory().createEntry(owner, key, Token.REMOVED_PHASE1);
+        synchronized (newRe) {
+          try {
+            RegionEntry oldRe = putEntryIfAbsent(key, newRe);
+            while (!opCompleted && oldRe != null) {
+              synchronized (oldRe) {
+                if (oldRe.isRemovedPhase2()) {
+                  owner.getCachePerfStats().incRetries();
+                  _getMap().remove(key, oldRe);
+                  oldRe = putEntryIfAbsent(key, newRe);
+                } else {
+                  opCompleted = true;
+                  final boolean oldWasTombstone = oldRe.isTombstone();
+                  final int oldSize = owner.calculateRegionEntryValueSize(oldRe);
+                  Object oldValue = oldRe.getValueInVM(owner); // OFFHEAP eei
+                  // Create an entry event only if the calling context is
+                  // a receipt of a TXCommitMessage AND there are callbacks
+                  // installed
+                  // for this region
+                  boolean invokeCallbacks = shouldCreateCBEvent(owner, owner.isInitialized());
+                  boolean cbEventInPending = false;
+                  cbEvent = createCBEvent(owner,
+                      localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE, key, newValue,
+                      txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext,
+                      txEntryState, versionTag, tailKey);
+                  try {
-                      txEvent.addInvalidate(owner, oldRe, oldRe.getKey(),
-                          newValue,aCallbackArgument);
+                      txEvent.addInvalidate(owner, oldRe, oldRe.getKey(), newValue,
+                          aCallbackArgument);
-                    }
-                    catch (RegionClearedException rce) {
+                    } catch (RegionClearedException rce) {
-                    owner.txApplyInvalidatePart2(oldRe, oldRe.getKey(),
-                        didDestroy, true, clearOccured);
-  //                  didInvalidate = true;
+                    owner.txApplyInvalidatePart2(oldRe, oldRe.getKey(), didDestroy, true,
+                        clearOccured);
+                    // didInvalidate = true;
-                      if(pendingCallbacks==null) {
-                        owner.invokeTXCallbacks(
-                            EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
-                            true/*callDispatchListenerEvent*/);
+                      if (pendingCallbacks == null) {
+                        owner.invokeTXCallbacks(EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
+                            true/* callDispatchListenerEvent */);
-                    } finally {
-                      if (!cbEventInPending) cbEvent.release();
-                    }
+                  } finally {
+                    if (!cbEventInPending)
+                      cbEvent.release();
-              if (!opCompleted) {
-                boolean invokeCallbacks = shouldCreateCBEvent( owner, owner.isInitialized());
-                boolean cbEventInPending = false;
-                cbEvent = createCBEvent(owner, 
-                    localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE,
-                        key, newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-                try {
+            }
+            if (!opCompleted) {
+              boolean invokeCallbacks = shouldCreateCBEvent(owner, owner.isInitialized());
+              boolean cbEventInPending = false;
+              cbEvent =
+                  createCBEvent(owner, localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE,
+                      key, newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo,
+                      bridgeContext, txEntryState, versionTag, tailKey);
+              try {
-                  owner.updateSizeOnCreate(newRe.getKey(), 0);//we are putting in a new invalidated entry
-                }
-                catch (RegionClearedException rce) {
+                  owner.updateSizeOnCreate(newRe.getKey(), 0);// we are putting in a new invalidated
+                                                              // entry
+                } catch (RegionClearedException rce) {
-                owner.txApplyInvalidatePart2(newRe, newRe.getKey(), didDestroy,
-                    true, clearOccured);
-                
+                owner.txApplyInvalidatePart2(newRe, newRe.getKey(), didDestroy, true, clearOccured);
+
-                  if(pendingCallbacks==null) {
-                    owner.invokeTXCallbacks(
-                        EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
-                        true/*callDispatchListenerEvent*/);
+                  if (pendingCallbacks == null) {
+                    owner.invokeTXCallbacks(EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
+                        true/* callDispatchListenerEvent */);
-                } finally {
-                  if (!cbEventInPending) cbEvent.release();
-                }
+              } finally {
+                if (!cbEventInPending)
+                  cbEvent.release();
-            finally {
-              if (!opCompleted) {
-                removeEntry(key, newRe, false);
-              }
+          } finally {
+            if (!opCompleted) {
+              removeEntry(key, newRe, false);
-      }
-      else { /* !forceNewEntry */
+        }
+      } else { /* !forceNewEntry */
-            synchronized (re) {
-              {
-                final int oldSize = owner.calculateRegionEntryValueSize(re);
-                boolean wasTombstone = re.isTombstone();
-                Object oldValue = re.getValueInVM(owner); // OFFHEAP eei
-                // Create an entry event only if the calling context is
-                // a receipt of a TXCommitMessage AND there are callbacks
-                // installed
-                // for this region
-                boolean invokeCallbacks = shouldCreateCBEvent(owner, owner.isInitialized());
-                boolean cbEventInPending = false;
-                cbEvent = createCBEvent(owner, 
-                    localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE, 
-                        key, newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-                try {
+          synchronized (re) {
+            {
+              final int oldSize = owner.calculateRegionEntryValueSize(re);
+              boolean wasTombstone = re.isTombstone();
+              Object oldValue = re.getValueInVM(owner); // OFFHEAP eei
+              // Create an entry event only if the calling context is
+              // a receipt of a TXCommitMessage AND there are callbacks
+              // installed
+              // for this region
+              boolean invokeCallbacks = shouldCreateCBEvent(owner, owner.isInitialized());
+              boolean cbEventInPending = false;
+              cbEvent =
+                  createCBEvent(owner, localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE,
+                      key, newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo,
+                      bridgeContext, txEntryState, versionTag, tailKey);
+              try {
-                  txEvent.addInvalidate(owner, re, re.getKey(), newValue,aCallbackArgument);
+                  txEvent.addInvalidate(owner, re, re.getKey(), newValue, aCallbackArgument);
-                }
-                catch (RegionClearedException rce) {
+                } catch (RegionClearedException rce) {
-                owner.txApplyInvalidatePart2(re, re.getKey(), didDestroy, true,
-                    clearOccured);
-  //              didInvalidate = true;
+                owner.txApplyInvalidatePart2(re, re.getKey(), didDestroy, true, clearOccured);
+                // didInvalidate = true;
-                  if(pendingCallbacks==null) {
-                    owner.invokeTXCallbacks(
-                        EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
-                        true/*callDispatchListenerEvent*/);
+                  if (pendingCallbacks == null) {
+                    owner.invokeTXCallbacks(EnumListenerEvent.AFTER_INVALIDATE, cbEvent,
+                        true/* callDispatchListenerEvent */);
-                } finally {
-                  if (!cbEventInPending) cbEvent.release();
-                }
+              } finally {
+                if (!cbEventInPending)
+                  cbEvent.release();
-        } else  { //re == null
+          }
+        } else { // re == null
-          // In cases where bucket region is re-created, it may so happen 
-          // that the invalidate is already applied on the Initial image 
-          // provider, thus causing region entry to be absent. 
+          // In cases where bucket region is re-created, it may so happen
+          // that the invalidate is already applied on the Initial image
+          // provider, thus causing region entry to be absent.
-          cbEvent = createCBEvent(owner, 
-              localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE, 
-                  key, newValue, txId, txEvent, eventId, aCallbackArgument, 
-                  filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
+          cbEvent =
+              createCBEvent(owner, localOp ? Operation.LOCAL_INVALIDATE : Operation.INVALIDATE, key,
+                  newValue, txId, txEvent, eventId, aCallbackArgument, filterRoutingInfo,
+                  bridgeContext, txEntryState, versionTag, tailKey);
-          switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
-          if (pendingCallbacks == null) {
-            owner.invokeTXCallbacks(EnumListenerEvent.AFTER_INVALIDATE,
-                cbEvent, false);
-          } else {
-            pendingCallbacks.add(cbEvent);
-            cbEventInPending = true;
-          }
+            switchEventOwnerAndOriginRemote(cbEvent, hasRemoteOrigin);
+            if (pendingCallbacks == null) {
+              owner.invokeTXCallbacks(EnumListenerEvent.AFTER_INVALIDATE, cbEvent, false);
+            } else {
+              pendingCallbacks.add(cbEvent);
+              cbEventInPending = true;
+            }
-            if (!cbEventInPending) cbEvent.release();
+            if (!cbEventInPending)
+              cbEvent.release();
-    }catch( DiskAccessException dae) {
+    } catch (DiskAccessException dae) {
-    }
-    finally {
-      releaseTXCacheModificationLock(owner, versionTag);
+    } finally {
-   * This code needs to be evaluated. It was added quickly to help PR persistence
-   * not to consume as much memory.
+   * This code needs to be evaluated. It was added quickly to help PR persistence not to consume as
+   * much memory.
-          if(owner instanceof BucketRegion)
-          {
-            ((BucketRegion)owner).incNumEntriesInVM(-1L);
-            ((BucketRegion)owner).incNumOverflowOnDisk(1L);
+          if (owner instanceof BucketRegion) {
+            ((BucketRegion) owner).incNumEntriesInVM(-1L);
+            ((BucketRegion) owner).incNumOverflowOnDisk(1L);
-  private RegionEntry getOrCreateRegionEntry(Object ownerRegion,
-      EntryEventImpl event, Object value,
-      MapCallbackAdapter<Object, Object, Object, Object> valueCreator,
-      boolean onlyExisting, boolean returnTombstone) {
+  private RegionEntry getOrCreateRegionEntry(Object ownerRegion, EntryEventImpl event, Object value,
+      MapCallbackAdapter<Object, Object, Object, Object> valueCreator, boolean onlyExisting,
+      boolean returnTombstone) {
-  public RegionEntry basicPut(EntryEventImpl event,
-                                    final long lastModified,
-                                    final boolean ifNew,
-                                    final boolean ifOld,
-                                    Object expectedOldValue, // only non-null if ifOld
-                                    boolean requireOldValue,
-                                    final boolean overwriteDestroyed)
-  throws CacheWriterException,
-        TimeoutException {
+  public RegionEntry basicPut(EntryEventImpl event, final long lastModified, final boolean ifNew,
+      final boolean ifOld, Object expectedOldValue, // only non-null if ifOld
+      boolean requireOldValue, final boolean overwriteDestroyed)
+      throws CacheWriterException, TimeoutException {
-      Assert.assertTrue(false, "The owner for RegionMap " + this
-          + " is null for event " + event);
+      Assert.assertTrue(false, "The owner for RegionMap " + this + " is null for event " + event);
-          event, expectedOldValue, requireOldValue, ifNew, ifOld, owner.isInitialized(), overwriteDestroyed);
+          event, expectedOldValue, requireOldValue, ifNew, ifOld, owner.isInitialized(),
+          overwriteDestroyed);
-    
+
-    final boolean cacheWrite = !event.isOriginRemote() && !event.isNetSearch() && event.isGenerateCallbacks()
-        && (cacheWriter != null
-            || owner.hasServerProxy()
-            || owner.scope.isDistributed());
+    final boolean cacheWrite =
+        !event.isOriginRemote() && !event.isNetSearch() && event.isGenerateCallbacks()
+            && (cacheWriter != null || owner.hasServerProxy() || owner.scope.isDistributed());
-     * For performance reason, we try to minimize object creation and do as much
-     * work as we can outside of synchronization, especially getting
-     * distribution advice.
+     * For performance reason, we try to minimize object creation and do as much work as we can
+     * outside of synchronization, especially getting distribution advice.
-        netWriteRecipients = ((DistributedRegion)owner)
-            .getCacheDistributionAdvisor().adviseNetWrite();
-      }
-      else {
+        netWriteRecipients =
+            ((DistributedRegion) owner).getCacheDistributionAdvisor().adviseNetWrite();
+      } else {
-    }
-    else {
+    } else {
-    boolean retrieveOldValueForDelta = event.getDeltaBytes() != null
-        && event.getRawNewValue() == null;
+    boolean retrieveOldValueForDelta =
+        event.getDeltaBytes() != null && event.getRawNewValue() == null;
-        oqlIndexManager = owner.getIndexManager() ; 
+        oqlIndexManager = owner.getIndexManager();
-        boolean replaceOnClient = event.getOperation() == Operation.REPLACE
-            && owner.getServerProxy() != null; 
+        boolean replaceOnClient =
+            event.getOperation() == Operation.REPLACE && owner.getServerProxy() != null;
-        re = getOrCreateRegionEntry(owner, event, 
+        re = getOrCreateRegionEntry(owner, event,
-              re = getOrCreateRegionEntry(owner, event, Token.REMOVED_PHASE1, null, onlyExisting, false);
+              re = getOrCreateRegionEntry(owner, event, Token.REMOVED_PHASE1, null, onlyExisting,
+                  false);
-              @Released Object oldValueForDelta = null;
+              @Released
+              Object oldValueForDelta = null;
-                  oldValueForDelta = re.getValue(owner); // OFFHEAP: if we are synced on oldRe no issue since we can use ARE's ref
+                  oldValueForDelta = re.getValue(owner); // OFFHEAP: if we are synced on oldRe no
+                                                         // issue since we can use ARE's ref
-                invokeCacheWriter(re, event, cacheWrite, cacheWriter,
-                    netWriteRecipients, requireOldValue, expectedOldValue, replaceOnClient);
+                invokeCacheWriter(re, event, cacheWrite, cacheWriter, netWriteRecipients,
+                    requireOldValue, expectedOldValue, replaceOnClient);
-                    if ((cacheWrite && event.getOperation().isUpdate()) // if there is a cacheWriter, type of event has already been set
-                        || !re.isRemoved()
-                        || replaceOnClient) {
+                    if ((cacheWrite && event.getOperation().isUpdate()) // if there is a
+                                                                        // cacheWriter, type of
+                                                                        // event has already been
+                                                                        // set
+                        || !re.isRemoved() || replaceOnClient) {
-                  lastModifiedTime = owner.basicPutPart2(event, re,
-                      !uninitialized, lastModifiedTime, clearOccured);
+                  lastModifiedTime = owner.basicPutPart2(event, re, !uninitialized,
+                      lastModifiedTime, clearOccured);
-                }
-                else if (re != null && owner.isUsedForPartitionedRegionBucket()) {
-                  BucketRegion br = (BucketRegion)owner;
+                } else if (re != null && owner.isUsedForPartitionedRegionBucket()) {
+                  BucketRegion br = (BucketRegion) owner;
-        }// end while
+        } // end while
-        //Asif:Feel that it is safe to destroy the region here as there appears
-        // to be no chance of deadlock during region destruction      
+        // Asif:Feel that it is safe to destroy the region here as there appears
+        // to be no chance of deadlock during region destruction
-            owner.basicPutPart3(event, result, !uninitialized,
-                lastModifiedTime, invokeListeners, ifNew, ifOld, expectedOldValue, requireOldValue);
+            owner.basicPutPart3(event, result, !uninitialized, lastModifiedTime, invokeListeners,
+                ifNew, ifOld, expectedOldValue, requireOldValue);
-              } catch( DiskAccessException dae) {
-                //Asif:Feel that it is safe to destroy the region here as there appears
-                // to be no chance of deadlock during region destruction      
+              } catch (DiskAccessException dae) {
+                // Asif:Feel that it is safe to destroy the region here as there appears
+                // to be no chance of deadlock during region destruction
-          } //  finally
+          } // finally
-      } 
+      }
-   * If the value in the VM is still REMOVED_PHASE1 Token, then the operation
-   * was not completed (due to cacheWriter exception, concurrentMap operation) etc.
+   * If the value in the VM is still REMOVED_PHASE1 Token, then the operation was not completed (due
+   * to cacheWriter exception, concurrentMap operation) etc.
-  private boolean satisfiesExpectedOldValue(EntryEventImpl event,
-      RegionEntry re, Object expectedOldValue, boolean replaceOnClient) {
+  private boolean satisfiesExpectedOldValue(EntryEventImpl event, RegionEntry re,
+      Object expectedOldValue, boolean replaceOnClient) {
-      @Unretained Object v = event.getRawOldValue();
+      @Unretained
+      Object v = event.getRawOldValue();
-  private void setOldValueInEvent(EntryEventImpl event, RegionEntry re, boolean cacheWrite, boolean requireOldValue) {
-    boolean needToSetOldValue = cacheWrite || requireOldValue || event.getOperation().guaranteesOldValue();
+  private void setOldValueInEvent(EntryEventImpl event, RegionEntry re, boolean cacheWrite,
+      boolean requireOldValue) {
+    boolean needToSetOldValue =
+        cacheWrite || requireOldValue || event.getOperation().guaranteesOldValue();
-        @Released Object oldValueInVMOrDisk = re.getValueOffHeapOrDiskWithoutFaultIn(event.getLocalRegion());
+        @Released
+        Object oldValueInVMOrDisk = re.getValueOffHeapOrDiskWithoutFaultIn(event.getLocalRegion());
-        
-        @Retained @Released Object oldValueInVM = re._getValueRetain(event.getLocalRegion(), true); // OFFHEAP: re synced so can use its ref.
-        
+
+        @Retained
+        @Released
+        Object oldValueInVM = re._getValueRetain(event.getLocalRegion(), true); // OFFHEAP: re
+                                                                                // synced so can use
+                                                                                // its ref.
+
-      @Unretained Object ov = re._getValue(); // OFFHEAP _getValue is ok since re is synced and we only use it if its a GatewaySenderEventImpl.
-      // Since GatewaySenderEventImpl is never stored in an off-heap region nor a compressed region we don't need to worry about ov being compressed.
+      @Unretained
+      Object ov = re._getValue(); // OFFHEAP _getValue is ok since re is synced and we only use it
+                                  // if its a GatewaySenderEventImpl.
+      // Since GatewaySenderEventImpl is never stored in an off-heap region nor a compressed region
+      // we don't need to worry about ov being compressed.
-  protected void createEntry(EntryEventImpl event, final LocalRegion owner,
-      RegionEntry re) throws RegionClearedException {
+  protected void createEntry(EntryEventImpl event, final LocalRegion owner, RegionEntry re)
+      throws RegionClearedException {
-  protected void updateEntry(EntryEventImpl event, boolean requireOldValue,
-      Object oldValueForDelta, RegionEntry re) throws RegionClearedException {
+  protected void updateEntry(EntryEventImpl event, boolean requireOldValue, Object oldValueForDelta,
+      RegionEntry re) throws RegionClearedException {
-    event.putExistingEntry(event.getLocalRegion(), re, requireOldValue,
-        oldValueForDelta);
+    event.putExistingEntry(event.getLocalRegion(), re, requireOldValue, oldValueForDelta);
-  private void updateSize(EntryEventImpl event, int oldSize, boolean isUpdate, boolean wasTombstone) {
+  private void updateSize(EntryEventImpl event, int oldSize, boolean isUpdate,
+      boolean wasTombstone) {
-  private void invokeCacheWriter(RegionEntry re, EntryEventImpl event,
-      boolean cacheWrite, CacheWriter cacheWriter, Set netWriteRecipients,
-      boolean requireOldValue, Object expectedOldValue, boolean replaceOnClient) {
+  private void invokeCacheWriter(RegionEntry re, EntryEventImpl event, boolean cacheWrite,
+      CacheWriter cacheWriter, Set netWriteRecipients, boolean requireOldValue,
+      Object expectedOldValue, boolean replaceOnClient) {
-      _getOwner().cacheWriteBeforePut(event, netWriteRecipients, cacheWriter,
-          requireOldValue, expectedOldValue);
+      _getOwner().cacheWriteBeforePut(event, netWriteRecipients, cacheWriter, requireOldValue,
+          expectedOldValue);
-  private boolean continueOverwriteDestroyed(RegionEntry re,
-      EntryEventImpl event, boolean overwriteDestroyed, boolean ifNew) {
+  private boolean continueOverwriteDestroyed(RegionEntry re, EntryEventImpl event,
+      boolean overwriteDestroyed, boolean ifNew) {
-      if (!_getOwner().isInitialized() && (oldValueInVM == Token.DESTROYED || oldValueInVM == Token.TOMBSTONE)) {
+      if (!_getOwner().isInitialized()
+          && (oldValueInVM == Token.DESTROYED || oldValueInVM == Token.TOMBSTONE)) {
-  private boolean continueUpdate(RegionEntry re, EntryEventImpl event,
-      boolean ifOld, boolean replaceOnClient) {
+  private boolean continueUpdate(RegionEntry re, EntryEventImpl event, boolean ifOld,
+      boolean replaceOnClient) {
-  protected boolean destroyEntry(RegionEntry re, EntryEventImpl event,
-      boolean inTokenMode, boolean cacheWrite, @Released Object expectedOldValue,
-      boolean forceDestroy, boolean removeRecoveredEntry)
-      throws CacheWriterException, TimeoutException, EntryNotFoundException,
-      RegionClearedException {
+  protected boolean destroyEntry(RegionEntry re, EntryEventImpl event, boolean inTokenMode,
+      boolean cacheWrite, @Released Object expectedOldValue, boolean forceDestroy,
+      boolean removeRecoveredEntry) throws CacheWriterException, TimeoutException,
+      EntryNotFoundException, RegionClearedException {
-    boolean retVal = re.destroy(event.getLocalRegion(), event, inTokenMode,
-        cacheWrite, expectedOldValue, forceDestroy, removeRecoveredEntry);
+    boolean retVal = re.destroy(event.getLocalRegion(), event, inTokenMode, cacheWrite,
+        expectedOldValue, forceDestroy, removeRecoveredEntry);
-  public void txApplyPut(Operation p_putOp, Object key, Object nv,
-      boolean didDestroy, TransactionId txId, TXRmtEvent txEvent, 
-      EventID eventId, Object aCallbackArgument,List<EntryEventImpl> pendingCallbacks,FilterRoutingInfo filterRoutingInfo,ClientProxyMembershipID bridgeContext, TXEntryState txEntryState, VersionTag versionTag, long tailKey)
-  {
+  public void txApplyPut(Operation p_putOp, Object key, Object nv, boolean didDestroy,
+      TransactionId txId, TXRmtEvent txEvent, EventID eventId, Object aCallbackArgument,
+      List<EntryEventImpl> pendingCallbacks, FilterRoutingInfo filterRoutingInfo,
+      ClientProxyMembershipID bridgeContext, TXEntryState txEntryState, VersionTag versionTag,
+      long tailKey) {
-      Assert.assertTrue(false, "The owner for RegionMap " + this
-          + " is null");
+      Assert.assertTrue(false, "The owner for RegionMap " + this + " is null");
-    
+
-    
+
-    final boolean hasRemoteOrigin = !((TXId)txId).getMemberId().equals(owner.getMyId());
+    final boolean hasRemoteOrigin = !((TXId) txId).getMemberId().equals(owner.getMyId());
-    @Released EntryEventImpl cbEvent = null;
+    @Released
+    EntryEventImpl cbEvent = null;
-    cbEvent = createCBEvent(owner, putOp, key, newValue, txId, 
-        txEvent, eventId, aCallbackArgument,filterRoutingInfo,bridgeContext, txEntryState, versionTag, tailKey);
+    cbEvent = createCBEvent(owner, putOp, key, newValue, txId, txEvent, eventId, aCallbackArgument,
+        filterRoutingInfo, bridgeContext, txEntryState, versionTag, tailKey);
-    if (logger.isDebugEnabled()) {
-      logger.debug("txApplyPut cbEvent={}", cbEvent);
-    }
-    
-    
-    if (owner.isUsedForPartitionedRegionBucket()) {
-      newValue = EntryEventImpl.getCachedDeserializable(nv, cbEvent);
-      txHandleWANEvent(owner, cbEvent, txEntryState);
-    }
-    
-    boolean opCompleted = false;
-    // Fix for Bug #44431. We do NOT want to update the region and wait
-    // later for index INIT as region.clear() can cause inconsistency if
-    // happened in parallel as it also does index INIT.
-    IndexManager oqlIndexManager = owner.getIndexManager() ; 
-    if (oqlIndexManager != null) {
-      oqlIndexManager.waitForIndexInit();
-    }
-    lockForTXCacheModification(owner, versionTag);
-    try {
-      if (hasRemoteOrigin && !isTXHost && !isClientTXOriginator) {
-        // If we are not a mirror then only apply the update to existing
-        // entries
-        // 
-        // If we are a mirror then then only apply the update to
-        // existing entries when the operation is an update and we
-        // are initialized.
-        // Otherwise use the standard create/update logic
-        if (!owner.isAllEvents() || (!putOp.isCreate() && isRegionReady)) {
-          // At this point we should only apply the update if the entry exists
-          RegionEntry re = getEntry(key); // Fix for bug 32347.
-          if (re != null) {
+      if (logger.isDebugEnabled()) {
+        logger.debug("txApplyPut cbEvent={}", cbEvent);
+      }
+
+
+      if (owner.isUsedForPartitionedRegionBucket()) {
+        newValue = EntryEventImpl.getCachedDeserializable(nv, cbEvent);
+        txHandleWANEvent(owner, cbEvent, txEntryState);
+      }
+
+      boolean opCompleted = false;
+      // Fix for Bug #44431. We do NOT want to update the region and wait
+      // later for index INIT as region.clear() can cause inconsistency if
+      // happened in parallel as it also does index INIT.
+      IndexManager oqlIndexManager = owner.getIndexManager();
+      if (oqlIndexManager != null) {
+        oqlIndexManager.waitForIndexInit();
+      }
+      try {
+        if (hasRemoteOrigin && !isTXHost && !isClientTXOriginator) {
+          // If we are not a mirror then only apply the update to existing
+          // entries
+          //
+          // If we are a mirror then then only apply the update to
+          // existing entries when the operation is an update and we
+          // are initialized.
+          // Otherwise use the standard create/update logic
+          if (!owner.isAllEvents() || (!putOp.isCreate() && isRegionReady)) {
+            // At this point we should only apply the update if the entry exists
+            RegionEntry re = getEntry(key); // Fix for bug 32347.
+            if (re != null) {
-                      txEvent.addPut(putOp, owner, re, re.getKey(), newValue,aCallbackArgument);
+                      txEvent.addPut(putOp, owner, re, re.getKey(), newValue, aCallbackArgument);
-                        re.setValue(owner, re.prepareValueForCache(owner, newValue, cbEvent, !putOp.isCreate()));
+                        re.setValue(owner,
+                            re.prepareValueForCache(owner, newValue, cbEvent, !putOp.isCreate()));
-                       // Rahul : fix for 41694. Negative bucket size can also be 
-                        // an issue with normal GFE Delta and will have to be fixed 
-                        // in a similar manner and may be this fix the the one for 
+                        // Rahul : fix for 41694. Negative bucket size can also be
+                        // an issue with normal GFE Delta and will have to be fixed
+                        // in a similar manner and may be this fix the the one for
-                          owner.updateSizeOnPut(key, oldSize, owner.calculateRegionEntryValueSize(re));
+                          owner.updateSizeOnPut(key, oldSize,
+                              owner.calculateRegionEntryValueSize(re));
-                    }
-                    catch (RegionClearedException rce) {
+                    } catch (RegionClearedException rce) {
-                    } 
+                    }
-                      re.updateStatsForPut(lastMod);
-                      owner.txApplyPutPart2(re, re.getKey(), newValue, lastMod,
-                          false, didDestroy, clearOccured);
+                      re.updateStatsForPut(lastMod, lastMod);
+                      owner.txApplyPutPart2(re, re.getKey(), newValue, lastMod, false, didDestroy,
+                          clearOccured);
-                    if(pendingCallbacks==null) {
-                      owner.invokeTXCallbacks(EnumListenerEvent.AFTER_UPDATE,
-                          cbEvent, hasRemoteOrigin);
+                    if (pendingCallbacks == null) {
+                      owner.invokeTXCallbacks(EnumListenerEvent.AFTER_UPDATE, cbEvent,
+                          hasRemoteOrigin);
-            if (didDestroy && !opCompleted) {
-              owner
-                  .txApplyInvalidatePart2(re, re.getKey(), true, false, false /* clear*/);
+              if (didDestroy && !opCompleted) {
+                owner.txApplyInvalidatePart2(re, re.getKey(), true, false, false /* clear */);
+              }
+            if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent != null) {
+              txEntryState.setVersionTag(cbEvent.getVersionTag());
+            }
+            return;
-          if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent != null) {
-            txEntryState.setVersionTag(cbEvent.getVersionTag());
-          }
-          return;
-      }
-      RegionEntry newRe = getEntryFactory().createEntry(owner, key,
-          Token.REMOVED_PHASE1);
+        RegionEntry newRe = getEntryFactory().createEntry(owner, key, Token.REMOVED_PHASE1);
-                }
-                else {
+                } else {
-                      txEvent.addPut(putOp, owner, oldRe, oldRe.getKey(), newValue,aCallbackArgument);
+                      txEvent.addPut(putOp, owner, oldRe, oldRe.getKey(), newValue,
+                          aCallbackArgument);
-                        oldRe.setValue(owner, oldRe.prepareValueForCache(owner, newValue, cbEvent, !putOp.isCreate()));
+                        oldRe.setValue(owner, oldRe.prepareValueForCache(owner, newValue, cbEvent,
+                            !putOp.isCreate()));
-                        // Rahul : fix for 41694. Negative bucket size can also be 
-                        // an issue with normal GFE Delta and will have to be fixed 
-                        // in a similar manner and may be this fix the the one for 
+                        // Rahul : fix for 41694. Negative bucket size can also be
+                        // an issue with normal GFE Delta and will have to be fixed
+                        // in a similar manner and may be this fix the the one for
-                          owner.updateSizeOnPut(key, oldSize, owner.calculateRegionEntryValueSize(oldRe));
+                          owner.updateSizeOnPut(key, oldSize,
+                              owner.calculateRegionEntryValueSize(oldRe));
-                    }
-                    catch (RegionClearedException rce) {
+                    } catch (RegionClearedException rce) {
-                      long lastMod = System.currentTimeMillis();
+                      long lastMod = owner.cacheTimeMillis();
-                      oldRe.updateStatsForPut(lastMod);
-                      owner.txApplyPutPart2(oldRe, oldRe.getKey(), newValue,
-                          lastMod, false, didDestroy, clearOccured);
+                      oldRe.updateStatsForPut(lastMod, lastMod);
+                      owner.txApplyPutPart2(oldRe, oldRe.getKey(), newValue, lastMod, false,
+                          didDestroy, clearOccured);
-                    if(pendingCallbacks==null) {
-                      owner.invokeTXCallbacks(cbEvent.op.isCreate() ? EnumListenerEvent.AFTER_CREATE : EnumListenerEvent.AFTER_UPDATE,
-                          cbEvent, true/*callDispatchListenerEvent*/);
+                    if (pendingCallbacks == null) {
+                      owner.invokeTXCallbacks(
+                          cbEvent.op.isCreate() ? EnumListenerEvent.AFTER_CREATE
+                              : EnumListenerEvent.AFTER_UPDATE,
+                          cbEvent, true/* callDispatchListenerEvent */);
-                  txEvent.addPut(putOp, owner, newRe, newRe.getKey(), newValue,aCallbackArgument);
+                  txEvent.addPut(putOp, owner, newRe, newRe.getKey(), newValue, aCallbackArgument);
-                  
+
-                    newRe.setValue(owner, newRe.prepareValueForCache(owner, newValue, cbEvent, !putOp.isCreate()));
+                    newRe.setValue(owner,
+                        newRe.prepareValueForCache(owner, newValue, cbEvent, !putOp.isCreate()));
-                  owner.updateSizeOnCreate(newRe.getKey(), owner.calculateRegionEntryValueSize(newRe));
-                }
-                catch (RegionClearedException rce) {
+                  owner.updateSizeOnCreate(newRe.getKey(),
+                      owner.calculateRegionEntryValueSize(newRe));
+                } catch (RegionClearedException rce) {
-                  long lastMod = System.currentTimeMillis();
+                  long lastMod = owner.cacheTimeMillis();
-                  newRe.updateStatsForPut(lastMod);
-                  owner.txApplyPutPart2(newRe, newRe.getKey(), newValue, lastMod,
-                      true, didDestroy, clearOccured);
+                  newRe.updateStatsForPut(lastMod, lastMod);
+                  owner.txApplyPutPart2(newRe, newRe.getKey(), newValue, lastMod, true, didDestroy,
+                      clearOccured);
-                if(pendingCallbacks==null) {
+                if (pendingCallbacks == null) {
-                      true/*callDispatchListenerEvent*/);
+                      true/* callDispatchListenerEvent */);
-          }
-          finally {
+          } finally {
-      if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent != null) {
-        txEntryState.setVersionTag(cbEvent.getVersionTag());
+        if (owner.concurrencyChecksEnabled && txEntryState != null && cbEvent != null) {
+          txEntryState.setVersionTag(cbEvent.getVersionTag());
+        }
+      } catch (DiskAccessException dae) {
+        owner.handleDiskAccessException(dae);
+        throw dae;
+      } finally {
+        if (oqlIndexManager != null) {
+          oqlIndexManager.countDownIndexUpdaters();
+        }
-    }catch( DiskAccessException dae) {
-      owner.handleDiskAccessException(dae);
-      throw dae;
-    }
-    finally {
-      releaseTXCacheModificationLock(owner, versionTag);
-      if (oqlIndexManager != null) {
-        oqlIndexManager.countDownIndexUpdaters();
-      }
-    }
-      if (!cbEventInPending) cbEvent.release();
+      if (!cbEventInPending)
+        cbEvent.release();
-  private void txHandleWANEvent(final LocalRegion owner, EntryEventImpl cbEvent, TXEntryState txEntryState) {
-    ((BucketRegion)owner).handleWANEvent(cbEvent);
+  private void txHandleWANEvent(final LocalRegion owner, EntryEventImpl cbEvent,
+      TXEntryState txEntryState) {
+    ((BucketRegion) owner).handleWANEvent(cbEvent);
-  private void processAndGenerateTXVersionTag(final LocalRegion owner,
-      EntryEventImpl cbEvent, RegionEntry re, TXEntryState txEntryState) {
+  private void processAndGenerateTXVersionTag(final LocalRegion owner, EntryEventImpl cbEvent,
+      RegionEntry re, TXEntryState txEntryState) {
-        cbEvent.setNextRegionVersion(txEntryState.getDistTxEntryStates().getRegionVersion());  
+        cbEvent.setNextRegionVersion(txEntryState.getDistTxEntryStates().getRegionVersion());
-      
-      //cbEvent.setNextRegionVersion(txEntryState.getNextRegionVersion());
+
+      // cbEvent.setNextRegionVersion(txEntryState.getNextRegionVersion());
-   * Switch the event's region from BucketRegion to owning PR and set originRemote to the given value
+   * Switch the event's region from BucketRegion to owning PR and set originRemote to the given
+   * value
-  static EntryEventImpl switchEventOwnerAndOriginRemote(EntryEventImpl event, boolean originRemote) {
+  static EntryEventImpl switchEventOwnerAndOriginRemote(EntryEventImpl event,
+      boolean originRemote) {
-   * Removing the existing indexed value requires the current value in the cache, 
-   * that is the one prior to applying the operation.
+   * Removing the existing indexed value requires the current value in the cache, that is the one
+   * prior to applying the operation.
+   * 
-    if ((op.isUpdate() && !entry.isInvalid()) ||
-        op.isInvalidate() || op.isDestroy()) {
+    if ((op.isUpdate() && !entry.isInvalid()) || op.isInvalidate() || op.isDestroy()) {
-          idxManager.updateIndexes(entry,
-                                  IndexManager.REMOVE_ENTRY,
-                                  op.isUpdate() ?
-                                  IndexProtocol.BEFORE_UPDATE_OP :
-                                  IndexProtocol.OTHER_OP);
+          idxManager.updateIndexes(entry, IndexManager.REMOVE_ENTRY,
+              op.isUpdate() ? IndexProtocol.BEFORE_UPDATE_OP : IndexProtocol.OTHER_OP);
-  
+
-    logger.debug("dump of concurrent map of size {} for region {}", this._getMap().size(), this._getOwner());
-    for (Iterator it = this._getMap().values().iterator(); it.hasNext(); ) {
-      logger.trace("dumpMap:"+it.next().toString());
+    logger.debug("dump of concurrent map of size {} for region {}", this._getMap().size(),
+        this._getOwner());
+    for (Iterator it = this._getMap().values().iterator(); it.hasNext();) {
+      logger.trace("dumpMap:" + it.next().toString());
-  
-  static boolean shouldCreateCBEvent( final LocalRegion owner, 
-      final boolean isInitialized)
-  {
+
+  static boolean shouldCreateCBEvent(final LocalRegion owner, final boolean isInitialized) {
-    
-    if(isPartitioned){
-     /* if(!((BucketRegion)lr).getBucketAdvisor().isPrimary()) {
-        if(!BucketRegion.FORCE_LOCAL_LISTENERS_INVOCATION) {
-          return false;
-        }
-      }*/
+
+    if (isPartitioned) {
+      /*
+       * if(!((BucketRegion)lr).getBucketAdvisor().isPrimary()) {
+       * if(!BucketRegion.FORCE_LOCAL_LISTENERS_INVOCATION) { return false; } }
+       */
-    return (isPartitioned || isInitialized)
-          && (lr.shouldDispatchListenerEvent()
-            || lr.shouldNotifyBridgeClients()
-            || lr.getConcurrencyChecksEnabled());
+    return (isPartitioned || isInitialized) && (lr.shouldDispatchListenerEvent()
+        || lr.shouldNotifyBridgeClients() || lr.getConcurrencyChecksEnabled());
-  public static final EntryEventImpl createCBEvent(final LocalRegion re,
-      Operation op, Object key, Object newValue, TransactionId txId, 
-      TXRmtEvent txEvent,EventID eventId, Object aCallbackArgument,FilterRoutingInfo filterRoutingInfo,ClientProxyMembershipID bridgeContext, TXEntryState txEntryState, VersionTag versionTag, long tailKey)
-  {
-    DistributedMember originator = null ;
-    //txId should not be null even on localOrigin
+  public static final EntryEventImpl createCBEvent(final LocalRegion re, Operation op, Object key,
+      Object newValue, TransactionId txId, TXRmtEvent txEvent, EventID eventId,
+      Object aCallbackArgument, FilterRoutingInfo filterRoutingInfo,
+      ClientProxyMembershipID bridgeContext, TXEntryState txEntryState, VersionTag versionTag,
+      long tailKey) {
+    DistributedMember originator = null;
+    // txId should not be null even on localOrigin
-    originator = ((TXId)txId).getMemberId();
-    
+    originator = ((TXId) txId).getMemberId();
+
-    
-    @Retained EntryEventImpl retVal = EntryEventImpl.create(
-        re, op, key, newValue,
-        aCallbackArgument,
+
+    @Retained
+    EntryEventImpl retVal = EntryEventImpl.create(re, op, key, newValue, aCallbackArgument,
- 
-    
-    if(bridgeContext!=null) {
-      retVal.setContext(bridgeContext);
-    }
-    
-    if (eventRegion.generateEventID()) {
-      retVal.setEventId(eventId);
-    }
-    if (versionTag != null) {
-      retVal.setVersionTag(versionTag);
-    }
-    
-    retVal.setTailKey(tailKey);
-    
-    FilterInfo localRouting = null;
-    boolean computeFilterInfo = false;
-    if (filterRoutingInfo == null) {
-      computeFilterInfo = true;
-    } else {
-      localRouting = filterRoutingInfo.getLocalFilterInfo();
-      if (localRouting != null) {
-        // routing was computed in this VM but may need to perform local interest processing
-        computeFilterInfo = !filterRoutingInfo.hasLocalInterestBeenComputed();
-      } else {
-        // routing was computed elsewhere and is in the "remote" routing table
-        localRouting = filterRoutingInfo.getFilterInfo(re.getMyId());
+
+      if (bridgeContext != null) {
+        retVal.setContext(bridgeContext);
-      if (localRouting != null) {
-        if (!computeFilterInfo) {
-          retVal.setLocalFilterInfo(localRouting);
-        }
-      } else {
+
+      if (eventRegion.generateEventID()) {
+        retVal.setEventId(eventId);
+      }
+
+      if (versionTag != null) {
+        retVal.setVersionTag(versionTag);
+      }
+
+      retVal.setTailKey(tailKey);
+
+      FilterInfo localRouting = null;
+      boolean computeFilterInfo = false;
+      if (filterRoutingInfo == null) {
-      }
-    }
-    if (logger.isTraceEnabled()) {
-      logger.trace("createCBEvent filterRouting={} computeFilterInfo={} local routing={}", filterRoutingInfo, computeFilterInfo, localRouting);
-    }
-    
-    if (re.isUsedForPartitionedRegionBucket()) {
-      BucketRegion bucket = (BucketRegion)re;
-      if(BucketRegion.FORCE_LOCAL_LISTENERS_INVOCATION || bucket.getBucketAdvisor().isPrimary()) {
-        retVal.setInvokePRCallbacks(true);
-        retVal.setInvokePRCallbacks(false);
+        localRouting = filterRoutingInfo.getLocalFilterInfo();
+        if (localRouting != null) {
+          // routing was computed in this VM but may need to perform local interest processing
+          computeFilterInfo = !filterRoutingInfo.hasLocalInterestBeenComputed();
+        } else {
+          // routing was computed elsewhere and is in the "remote" routing table
+          localRouting = filterRoutingInfo.getFilterInfo(re.getMyId());
+        }
+        if (localRouting != null) {
+          if (!computeFilterInfo) {
+            retVal.setLocalFilterInfo(localRouting);
+          }
+        } else {
+          computeFilterInfo = true;
+        }
+      }
+      if (logger.isTraceEnabled()) {
+        logger.trace("createCBEvent filterRouting={} computeFilterInfo={} local routing={}",
+            filterRoutingInfo, computeFilterInfo, localRouting);
-      if (computeFilterInfo) {
-        if (bucket.getBucketAdvisor().isPrimary()) {
-          if (logger.isTraceEnabled()) {
-            logger.trace("createCBEvent computing routing for primary bucket");
-          }
-          FilterProfile fp = ((BucketRegion)re).getPartitionedRegion().getFilterProfile();
-          if (fp != null) {
-            FilterRoutingInfo fri = fp.getFilterRoutingInfoPart2(filterRoutingInfo, retVal);
-            if (fri != null) {
-              retVal.setLocalFilterInfo(fri.getLocalFilterInfo());
+      if (re.isUsedForPartitionedRegionBucket()) {
+        BucketRegion bucket = (BucketRegion) re;
+        if (BucketRegion.FORCE_LOCAL_LISTENERS_INVOCATION
+            || bucket.getBucketAdvisor().isPrimary()) {
+          retVal.setInvokePRCallbacks(true);
+        } else {
+          retVal.setInvokePRCallbacks(false);
+        }
+
+        if (computeFilterInfo) {
+          if (bucket.getBucketAdvisor().isPrimary()) {
+            if (logger.isTraceEnabled()) {
+              logger.trace("createCBEvent computing routing for primary bucket");
-          } 
-        } 
+            FilterProfile fp = ((BucketRegion) re).getPartitionedRegion().getFilterProfile();
+            if (fp != null) {
+              FilterRoutingInfo fri = fp.getFilterRoutingInfoPart2(filterRoutingInfo, retVal);
+              if (fri != null) {
+                retVal.setLocalFilterInfo(fri.getLocalFilterInfo());
+              }
+            }
+          }
+        }
+      } else if (computeFilterInfo) { // not a bucket
+        if (logger.isTraceEnabled()) {
+          logger.trace("createCBEvent computing routing for non-bucket");
+        }
+        FilterProfile fp = re.getFilterProfile();
+        if (fp != null) {
+          retVal.setLocalFilterInfo(fp.getLocalFilterRouting(retVal));
+        }
-    } else if (computeFilterInfo) { // not a bucket
-      if (logger.isTraceEnabled()) {
-        logger.trace("createCBEvent computing routing for non-bucket");
-      }
-      FilterProfile fp = re.getFilterProfile();
-      if (fp != null) {
-        retVal.setLocalFilterInfo(fp.getLocalFilterRouting(retVal));
-      }
-    }    
-    retVal.setTransactionId(txId);
-    returnedRetVal = true;
-    return retVal;
+      retVal.setTransactionId(txId);
+      returnedRetVal = true;
+      return retVal;
-  public final void writeSyncIfPresent(Object key, Runnable runner)
-  {
+  public final void writeSyncIfPresent(Object key, Runnable runner) {
-      }
-      finally {
+      } finally {
-        }catch(DiskAccessException dae) {
+        } catch (DiskAccessException dae) {
-  public final void removeIfDestroyed(Object key)
-  {
+  public final void removeIfDestroyed(Object key) {
-//    boolean makeTombstones = owner.concurrencyChecksEnabled;
+    // boolean makeTombstones = owner.concurrencyChecksEnabled;
-      RegionEntry re = getEntry(key);
-      if (re != null) {
-        if (re.isDestroyed()) {
-          synchronized (re) {
-            if (re.isDestroyed()) {
-              // [bruce] destroyed entries aren't in the LRU clock, so they can't be retained here
-//              if (makeTombstones) {
-//                re.makeTombstone(owner, re.getVersionStamp().asVersionTag());
-//              } else {
-              re.removePhase2();
-              removeEntry(key, re, true);
-            }
+    RegionEntry re = getEntry(key);
+    if (re != null) {
+      if (re.isDestroyed()) {
+        synchronized (re) {
+          if (re.isDestroyed()) {
+            // [bruce] destroyed entries aren't in the LRU clock, so they can't be retained here
+            // if (makeTombstones) {
+            // re.makeTombstone(owner, re.getVersionStamp().asVersionTag());
+            // } else {
+            re.removePhase2();
+            removeEntry(key, re, true);
-//      }
+    }
+    // }
-  
+
-    
-    if(armLockTestHook!=null) armLockTestHook.beforeLock(owner, event);
-    
+
+    if (armLockTestHook != null)
+      armLockTestHook.beforeLock(owner, event);
+
-    
-    if(armLockTestHook!=null) armLockTestHook.afterLock(owner, event);
+
+    if (armLockTestHook != null)
+      armLockTestHook.afterLock(owner, event);
-  
+
-    
-    if(armLockTestHook!=null) armLockTestHook.beforeRelease(owner, event);
+
+    if (armLockTestHook != null)
+      armLockTestHook.beforeRelease(owner, event);
-    
-    if(armLockTestHook!=null) armLockTestHook.afterRelease(owner, event);
+
+    if (armLockTestHook != null)
+      armLockTestHook.afterRelease(owner, event);
-  
-  /** get version-generation permission from the region's version vector */
-  private void lockForTXCacheModification(LocalRegion owner, VersionTag tag) {
-    
-    if(armLockTestHook!=null) armLockTestHook.beforeLock(owner, null);
-    
-    if ( !(tag != null && tag.isFromOtherMember()) ) {
-      RegionVersionVector vector = owner.getVersionVector();
-      if (vector != null && !owner.hasServerProxy()) {
-        vector.lockForCacheModification();
-      }
-    }
-    
-    if(armLockTestHook!=null) armLockTestHook.afterLock(owner, null);
+  @Override
+  public void lockRegionForAtomicTX(LocalRegion r) {
+    if (armLockTestHook != null)
+      armLockTestHook.beforeLock(r, null);
+
+    RegionVersionVector vector = r.getVersionVector();
+    if (vector != null) {
+      vector.lockForCacheModification();
+    }
+
+    if (armLockTestHook != null)
+      armLockTestHook.afterLock(r, null);
-  
-  /** release version-generation permission from the region's version vector */
-  private void releaseTXCacheModificationLock(LocalRegion owner, VersionTag tag) {
-    
-    if(armLockTestHook!=null) armLockTestHook.beforeRelease(owner, null);
-    if ( !(tag != null && tag.isFromOtherMember()) ) {
-      RegionVersionVector vector = owner.getVersionVector();
-      if (vector != null && !owner.hasServerProxy()) {
-       vector.releaseCacheModificationLock();
-      }
+  @Override
+  public void unlockRegionForAtomicTX(LocalRegion r) {
+    if (armLockTestHook != null)
+      armLockTestHook.beforeRelease(r, null);
+
+    RegionVersionVector vector = r.getVersionVector();
+    if (vector != null) {
+      vector.releaseCacheModificationLock();
-    
-    if(armLockTestHook!=null) armLockTestHook.afterRelease(owner, null);
+    if (armLockTestHook != null)
+      armLockTestHook.afterRelease(r, null);
-   * for testing race conditions between threads trying to apply ops to the
-   * same entry
+   * for testing race conditions between threads trying to apply ops to the same entry
+   * 
-    return (RegionEntry)putEntryIfAbsent(entry.getKey(), entry);
+    return (RegionEntry) putEntryIfAbsent(entry.getKey(), entry);
-    if ( getEntry(re.getKey()) != re) {
+    if (getEntry(re.getKey()) != re) {
-      logger.error("Unexpected RegionEntry scheduled as tombstone: re.getClass {} destroyedVersion {}", re.getClass(), destroyedVersion);
+      logger.error(
+          "Unexpected RegionEntry scheduled as tombstone: re.getClass {} destroyedVersion {}",
+          re.getClass(), destroyedVersion);
-  public final boolean removeTombstone(RegionEntry re, VersionHolder version, boolean isEviction, boolean isScheduledTombstone)  {
+  public final boolean removeTombstone(RegionEntry re, VersionHolder version, boolean isEviction,
+      boolean isScheduledTombstone) {
-    synchronized(this._getOwner().getSizeGuard()) { // do this sync first; see bug 51985
-        synchronized (re) {
-          int entryVersion = re.getVersionStamp().getEntryVersion();
-          if (!re.isTombstone() || entryVersion > destroyedVersion) {
-            if (logger.isTraceEnabled(LogMarker.TOMBSTONE_COUNT)) {
+    synchronized (this._getOwner().getSizeGuard()) { // do this sync first; see bug 51985
+      synchronized (re) {
+        int entryVersion = re.getVersionStamp().getEntryVersion();
+        if (!re.isTombstone() || entryVersion > destroyedVersion) {
+          if (logger.isTraceEnabled(LogMarker.TOMBSTONE_COUNT)) {
+            logger.trace(LogMarker.TOMBSTONE_COUNT,
+                "tombstone for {} was resurrected with v{}; destroyed version was v{}; count is {}; entryMap size is {}",
+                re.getKey(), re.getVersionStamp().getEntryVersion(), destroyedVersion,
+                this._getOwner().getTombstoneCount(), size());
+          }
+        } else {
+          if (logger.isTraceEnabled(LogMarker.TOMBSTONE_COUNT)) {
+            if (entryVersion == destroyedVersion) {
+              // logging this can put tremendous pressure on the log writer in tests
+              // that "wait for silence"
-                  "tombstone for {} was resurrected with v{}; destroyed version was v{}; count is {}; entryMap size is {}",
-                  re.getKey(), re.getVersionStamp().getEntryVersion(), destroyedVersion, this._getOwner().getTombstoneCount(), size());
+                  "removing tombstone for {} with v{} rv{}; count is {}", re.getKey(),
+                  destroyedVersion, version.getRegionVersion(),
+                  (this._getOwner().getTombstoneCount() - 1));
+            } else {
+              logger.trace(LogMarker.TOMBSTONE_COUNT,
+                  "removing entry (v{}) that is older than an expiring tombstone (v{} rv{}) for {}",
+                  entryVersion, destroyedVersion, version.getRegionVersion(), re.getKey());
-          } else {
-            if (logger.isTraceEnabled(LogMarker.TOMBSTONE_COUNT)) {
-              if (entryVersion == destroyedVersion) {
-                // logging this can put tremendous pressure on the log writer in tests
-                // that "wait for silence"
-                logger.trace(LogMarker.TOMBSTONE_COUNT,
-                    "removing tombstone for {} with v{} rv{}; count is {}",
-                    re.getKey(), destroyedVersion, version.getRegionVersion(), (this._getOwner().getTombstoneCount() - 1));
-              } else {
-                logger.trace(LogMarker.TOMBSTONE_COUNT, "removing entry (v{}) that is older than an expiring tombstone (v{} rv{}) for {}",
-                    entryVersion, destroyedVersion, version.getRegionVersion(), re.getKey());
+          }
+          try {
+            re.setValue(_getOwner(), Token.REMOVED_PHASE2);
+            if (removeTombstone(re)) {
+              _getOwner().cancelExpiryTask(re);
+              result = true;
+              incEntryCount(-1);
+              // Bug 51118: When the method is called by tombstoneGC thread, current 're' is an
+              // expired tombstone. Then we detected an destroyed (due to overwritingOldTombstone()
+              // returns true earlier) tombstone with bigger entry version, it's safe to delete
+              // current tombstone 're' and adjust the tombstone count.
+              // lruEntryDestroy(re); // tombstones are invisible to LRU
+              if (isScheduledTombstone) {
+                _getOwner().incTombstoneCount(-1);
+              }
+              RegionVersionVector vector = _getOwner().getVersionVector();
+              if (vector != null) {
+                vector.recordGCVersion(version.getMemberID(), version.getRegionVersion());
-            try {
-              re.setValue(_getOwner(), Token.REMOVED_PHASE2);
-              if (removeTombstone(re)) {
-                result = true;
-                incEntryCount(-1);
-                // Bug 51118: When the method is called by tombstoneGC thread, current 're' is an
-                // expired tombstone. Then we detected an destroyed (due to overwritingOldTombstone() 
-                // returns true earlier) tombstone with bigger entry version, it's safe to delete
-                // current tombstone 're' and adjust the tombstone count. 
-  //              lruEntryDestroy(re); // tombstones are invisible to LRU
-                if (isScheduledTombstone) {
-                  _getOwner().incTombstoneCount(-1);
-                }
-                RegionVersionVector vector = _getOwner().getVersionVector();
-                if (vector != null) {
-                  vector.recordGCVersion(version.getMemberID(), version.getRegionVersion());
-                }
-              }
-            } catch (RegionClearedException e) {
-              // if the region has been cleared we don't need to remove the tombstone
-            } catch (RegionDestroyedException e) {
-              //if the region has been destroyed, the tombstone is already
-              //gone. Catch an exception to avoid an error from the GC thread.
-            }
+          } catch (RegionClearedException e) {
+            // if the region has been cleared we don't need to remove the tombstone
+          } catch (RegionDestroyedException e) {
+            // if the region has been destroyed, the tombstone is already
+            // gone. Catch an exception to avoid an error from the GC thread.
+    }
-      for (Iterator it=_getMap().values().iterator(); it.hasNext(); ) {
-        RegionEntry re = (RegionEntry)it.next();
+      for (Iterator it = _getMap().values().iterator(); it.hasNext();) {
+        RegionEntry re = (RegionEntry) it.next();
-            numTombstones, deadEntries, new Exception());
+              numTombstones, deadEntries, new Exception());
-  
+
+
+
+
+
+
+
-  
+
-  
+
-  
+
