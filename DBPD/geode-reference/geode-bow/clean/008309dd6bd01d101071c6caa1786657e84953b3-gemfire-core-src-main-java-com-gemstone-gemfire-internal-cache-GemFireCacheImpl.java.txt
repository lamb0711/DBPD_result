Merge branch 'release/1.0.0-incubating.M1'

-/*=========================================================================
- * Copyright (c) 2002-2014 Pivotal Software, Inc. All Rights Reserved.
- * This product is protected by U.S. and international copyright
- * and intellectual property laws. Pivotal products are covered by
- * more patents listed at http://www.pivotal.io/patents.
- *=========================================================================
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+import java.util.ServiceLoader;
+import com.gemstone.gemfire.cache.CacheExistsException;
+import com.gemstone.gemfire.cache.asyncqueue.internal.AsyncEventQueueImpl;
+import com.gemstone.gemfire.cache.hdfs.HDFSStoreFactory;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSIntegrationUtil;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSStoreCreation;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSStoreFactoryImpl;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSStoreImpl;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSFlushQueueFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSForceCompactionFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSLastCompactionTimeFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSRegionDirector;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSStoreDirector;
-import com.gemstone.gemfire.cache.util.BridgeServer;
+import com.gemstone.gemfire.cache.util.ObjectSizer;
+import com.gemstone.gemfire.internal.cache.control.InternalResourceManager.ResourceType;
+import com.gemstone.gemfire.internal.cache.lru.OffHeapEvictor;
+import com.gemstone.gemfire.internal.cache.tier.sockets.ServerConnection;
+import com.gemstone.gemfire.internal.concurrent.ConcurrentHashSet;
+import com.gemstone.gemfire.internal.offheap.MemoryAllocator;
-import com.gemstone.gemfire.internal.util.ArrayUtils;
+import com.gemstone.gemfire.redis.GemFireRedisServer;
+import com.sun.jna.Native;
+import com.sun.jna.Platform;
-public class GemFireCacheImpl implements InternalCache, ClientCache, HasCachePerfStats, DistributionAdvisee, Extensible<Cache> {
-
+public class GemFireCacheImpl implements InternalCache, ClientCache, HasCachePerfStats, DistributionAdvisee {
-  
+
+  /**
+   * True if the user is allowed lock when memory resources appear to be overcommitted. 
+   */
+  public static final boolean ALLOW_MEMORY_LOCK_WHEN_OVERCOMMITTED = Boolean.getBoolean("gemfire.Cache.ALLOW_MEMORY_OVERCOMMIT");
+
-   * the list of all bridge servers. CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval
-   * operations. It is assumed that the traversal operations on bridge servers list vastly outnumber the mutative
+   * the list of all cache servers. CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval
+   * operations. It is assumed that the traversal operations on cache servers list vastly outnumber the mutative
-  private volatile List allBridgeServers = new CopyOnWriteArrayList();
+  private volatile List allCacheServers = new CopyOnWriteArrayList();
+  
+  /**
+   * The list of all async event queues added to the cache. 
+   * CopyOnWriteArrayList is used to allow concurrent add, remove and retrieval operations.
+   */
+  private volatile Set<AsyncEventQueue> allVisibleAsyncEventQueues = new CopyOnWriteArraySet<AsyncEventQueue>();
+  
+  private OffHeapEvictor offHeapEvictor = null;
+  private final Object offHeapEvictorLock = new Object();
+
+  public static Runnable internalBeforeApplyChanges;
+
+  public static Runnable internalBeforeNonTXBasicPut;
+
+   * Redis server is started when {@link DistributionConfig#getRedisPort()} is set
+   */
+  private GemFireRedisServer redisServer;
+  
+  /**
-
+  
+  private final Set<RegionListener> regionListeners = new ConcurrentHashSet<RegionListener>();
+  
+  private final Map<Class<? extends CacheService>, CacheService> services = new HashMap<Class<? extends CacheService>, CacheService>();
+  
+  
+  private final static Boolean DISABLE_AUTO_EVICTION = Boolean.getBoolean("gemfire.disableAutoEviction");
+   * Invokes mlockall().  Locks  all pages mapped into the address space of the 
+   * calling process.  This includes the pages of the code, data and stack segment, 
+   * as well as shared libraries, user space kernel data, shared memory, and 
+   * memory-mapped files.  All mapped pages are guaranteed to be resident in RAM 
+   * when the call returns successfully; the pages are guaranteed to stay in RAM 
+   * until later unlocked.
+   * 
+   * @param flags
+   *    MCL_CURRENT 1 - Lock all pages which are currently mapped into the 
+   *    address space of the process.
+   *    
+   *    MCL_FUTURE  2 - Lock all pages which will become mapped into the address 
+   *    space of the process in the future.  These could be for instance new 
+   *    pages required by a growing heap and stack as well as new memory mapped 
+   *    files or shared memory regions.
+   *    
+   * @return 
+   *    0 if success, non-zero if error and errno set
+   *    
+   */
+  private static native int mlockall(int flags);
+
+  public static void lockMemory() {
+    int result = 0;
+    try {
+      Native.register(Platform.C_LIBRARY_NAME);
+      result = mlockall(1);
+      if (result == 0) {
+        return;
+      }
+    } catch (Throwable t) {
+      throw new IllegalStateException("Error trying to lock memory", t);
+    }
+
+    int errno = Native.getLastError();
+    String msg = "mlockall failed: " + errno;
+    if (errno == 1 || errno == 12) {  // EPERM || ENOMEM
+      msg = "Unable to lock memory due to insufficient free space or privileges.  " 
+          + "Please check the RLIMIT_MEMLOCK soft resource limit (ulimit -l) and " 
+          + "increase the available memory if needed";
+    }
+    throw new IllegalStateException(msg);
+  }
+  
+  /**
-    // sb.append("; bridgeServers = (" + this.bridgeServers + ")");
+    // sb.append("; cacheServers = (" + this.cacheServers + ")");
+  public static Cache create(DistributedSystem system, boolean existingOk, CacheConfig cacheConfig)
+  throws CacheExistsException, TimeoutException, CacheWriterException,
+  GatewayException,
+  RegionExistsException 
+  {
+    GemFireCacheImpl instance = getInstance();
+    if (instance != null && !instance.isClosed()) {
+      if (existingOk) {
+        // Check if cache configuration matches.
+        cacheConfig.validateCacheConfig(instance);
+
+        return instance;
+      } else {
+        // instance.creationStack argument is for debugging...
+        throw new CacheExistsException(instance, LocalizedStrings.CacheFactory_0_AN_OPEN_CACHE_ALREADY_EXISTS.toLocalizedString(instance), instance.creationStack);
+      }
+    }
+    return create(system, cacheConfig);
+  }
+  
+      
-      getResourceManager().addResourceListener(getHeapEvictor());
+
+      getResourceManager().addResourceListener(ResourceType.HEAP_MEMORY, getHeapEvictor());
+      
+      /*
+       * Only bother creating an off-heap evictor if we have off-heap memory enabled.
+       */
+      if(null != getOffHeapStore()) {
+        getResourceManager().addResourceListener(ResourceType.OFFHEAP_MEMORY, getOffHeapEvictor());
+      }
+      
+      FunctionService.registerFunction(new HDFSLastCompactionTimeFunction());
+      FunctionService.registerFunction(new HDFSForceCompactionFunction());
+      FunctionService.registerFunction(new HDFSFlushQueueFunction());
+    initializeServices();
+    
+    startRedisServer();
+    
+
+  /**
+   * Initialize any services that provided as extensions to the cache using the
+   * service loader mechanism.
+   */
+  private void initializeServices() {
+    ServiceLoader<CacheService> loader = ServiceLoader.load(CacheService.class);
+    for(CacheService service : loader) {
+      service.init(this);
+      this.services.put(service.getInterface(), service);
+    }
+  }
+  
+  private void startRedisServer() {
+    int port = system.getConfig().getRedisPort();
+    if (port != 0) {
+      String bindAddress = system.getConfig().getRedisBindAddress();
+      assert bindAddress != null;
+      if (bindAddress.equals(DistributionConfig.DEFAULT_REDIS_BIND_ADDRESS)) {
+        getLoggerI18n().info(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_PORT_0,
+            new Object[] { port });
+      } else {
+        getLoggerI18n().info(LocalizedStrings.GemFireCacheImpl_STARTING_GEMFIRE_REDIS_SERVER_ON_BIND_ADDRESS_0_PORT_1,
+            new Object[] { bindAddress, port });
+      }
+      this.redisServer = new GemFireRedisServer(bindAddress, port);
+      this.redisServer.start();
+    }
+  }
+
-      throw new CacheXmlException(LocalizedStrings.GemFireCache_WHILE_OPENING_CACHE_XML_0_THE_FOLLOWING_ERROR_OCCURRED_1
-          .toLocalizedString(new Object[] { url.toString(), ex }));
+      String exceptionMsg = LocalizedStrings.GemFireCache_WHILE_OPENING_CACHE_XML_0_THE_FOLLOWING_ERROR_OCCURRED_1
+          .toLocalizedString(new Object[] { url.toString(), ex });
+      logger.error(exceptionMsg);
+      throw new CacheXmlException(exceptionMsg);
-      CacheXmlException newEx = new CacheXmlException(LocalizedStrings.GemFireCache_WHILE_READING_CACHE_XML_0_1
-          .toLocalizedString(new Object[] { url, ex.getMessage() }));
+      String exceptionMsg = LocalizedStrings.GemFireCache_WHILE_READING_CACHE_XML_0_1
+          .toLocalizedString(new Object[] { url, ex.getMessage() });
+      logger.error(exceptionMsg);
+      CacheXmlException newEx = new CacheXmlException(exceptionMsg);
-   * Close the distributed system, bridge servers, and gateways. Clears the rootRegions and partitionedRegions map.
+   * Close the distributed system, cache servers, and gateways. Clears the rootRegions and partitionedRegions map.
-    // Clear bridge servers
+    // Clear cache servers
-      System.err.println("DEBUG: Close bridge servers");
+      System.err.println("DEBUG: Close cache servers");
-      Iterator allBridgeServersItr = inst.allBridgeServers.iterator();
-      while (allBridgeServersItr.hasNext()) {
-        BridgeServerImpl bs = (BridgeServerImpl) allBridgeServersItr.next();
+      Iterator allCacheServersItr = inst.allCacheServers.iterator();
+      while (allCacheServersItr.hasNext()) {
+        CacheServerImpl bs = (CacheServerImpl) allCacheServersItr.next();
+    if (LocalRegion.ISSUE_CALLBACKS_TO_CACHE_OBSERVER) {
+      try {
+        CacheObserverHolder.getInstance().beforeShutdownAll();
+      } finally {
+        LocalRegion.ISSUE_CALLBACKS_TO_CACHE_OBSERVER = false;
+      }
+    }
+  public OffHeapEvictor getOffHeapEvictor() {
+    synchronized (this.offHeapEvictorLock) {
+      stopper.checkCancelInProgress(null);
+      if (this.offHeapEvictor == null) {
+        this.offHeapEvictor = new OffHeapEvictor(this);
+      }
+      return this.offHeapEvictor;
+    }    
+  }
+  
-        PoolManagerImpl.setKeepAlive(keepalive);
+          ParallelGatewaySenderQueue.cleanUpStatics(null);
+          
+          stopRedisServer();
-          // bridgeServers or gatewayHubs
+          // cacheServers or gatewayHubs
+          closeHDFSStores();
+          
-            // [bruce] if multicast is available, use it to send the message to
-            // avoid race conditions with cache content operations that might
-            // also be multicast
-            msg.setMulticast(system.getConfig().getMcastPort() != 0);
+          closeHDFSStores();
+  private void stopRedisServer() {
+    if (redisServer != null)
+      this.redisServer.shutdown();
+  }
+  
-      logger.debug("{}: stopping bridge servers...", this);
+      logger.debug("{}: stopping cache servers...", this);
-    Iterator allBridgeServersIterator = this.allBridgeServers.iterator();
-    while (allBridgeServersIterator.hasNext()) {
-      BridgeServerImpl bridge = (BridgeServerImpl) allBridgeServersIterator.next();
+    boolean stoppedCacheServer = false;
+    Iterator allCacheServersIterator = this.allCacheServers.iterator();
+    while (allCacheServersIterator.hasNext()) {
+      CacheServerImpl bridge = (CacheServerImpl) allCacheServersIterator.next();
-      allBridgeServers.remove(bridge);
+      allCacheServers.remove(bridge);
+      stoppedCacheServer = true;
+    }
+    if (stoppedCacheServer) {
+      // now that all the cache servers have stopped empty the static pool of commBuffers it might have used.
+      ServerConnection.emptyCommBufferPool();
+    attrs = invokeRegionBefore(null, name, attrs, internalRegionArgs);
+    final String regionPath = LocalRegion.calcFullPath(name, null);
+
+            HDFSIntegrationUtil.createAndAddAsyncQueue(regionPath, attrs, this);
+            attrs = setEvictionAttributesForLargeRegion(attrs);
+    invokeRegionAfter(rgn);
-  public Region getRegion(String path) {
+  public RegionAttributes invokeRegionBefore(LocalRegion parent,
+      String name, RegionAttributes attrs, InternalRegionArguments internalRegionArgs) {
+    for(RegionListener listener : regionListeners) {
+      attrs = listener.beforeCreate(parent, name, attrs, internalRegionArgs);
+    }
+    return attrs;
+  }
+  
+  public void invokeRegionAfter(LocalRegion region) {
+    for(RegionListener listener : regionListeners) {
+      listener.afterCreate(region);
+    }
+  }
+
+  /**
+   * turn on eviction by default for HDFS regions
+   */
+  @SuppressWarnings("deprecation")
+  public <K, V> RegionAttributes<K, V> setEvictionAttributesForLargeRegion(
+      RegionAttributes<K, V> attrs) {
+    RegionAttributes<K, V> ra = attrs;
+    if (DISABLE_AUTO_EVICTION) {
+      return ra;
+    }
+    if (attrs.getDataPolicy().withHDFS()
+        || attrs.getHDFSStoreName() != null) {
+      // make the region overflow by default
+      EvictionAttributes evictionAttributes = attrs.getEvictionAttributes();
+      boolean hasNoEvictionAttrs = evictionAttributes == null
+          || evictionAttributes.getAlgorithm().isNone();
+      AttributesFactory<K, V> af = new AttributesFactory<K, V>(attrs);
+      String diskStoreName = attrs.getDiskStoreName();
+      // set the local persistent directory to be the same as that for
+      // HDFS store
+      if (attrs.getHDFSStoreName() != null) {
+        HDFSStoreImpl hdfsStore = findHDFSStore(attrs.getHDFSStoreName());
+        if (attrs.getPartitionAttributes().getLocalMaxMemory() != 0 && hdfsStore == null) {
+          // HDFS store expected to be found at this point
+          throw new IllegalStateException(
+              LocalizedStrings.HOPLOG_HDFS_STORE_NOT_FOUND
+                  .toLocalizedString(attrs.getHDFSStoreName()));
+        }
+        // if there is no disk store, use the one configured for hdfs queue
+        if (attrs.getPartitionAttributes().getLocalMaxMemory() != 0 && diskStoreName == null) {
+          diskStoreName = hdfsStore.getDiskStoreName();
+        }
+      }
+      // set LRU heap eviction with overflow to disk for HDFS stores with
+      // local Oplog persistence
+      // set eviction attributes only if not set
+      if (hasNoEvictionAttrs) {
+        if (diskStoreName != null) {
+          af.setDiskStoreName(diskStoreName);
+        }
+        af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(
+            ObjectSizer.DEFAULT, EvictionAction.OVERFLOW_TO_DISK));
+      }
+      ra = af.create();
+    }
+    return ra;
+  }
+
+  public final Region getRegion(String path) {
+  /**
+   * @param returnDestroyedRegion
+   *          if true, okay to return a destroyed partitioned region
+   */
+  public final Region getPartitionedRegion(String path, boolean returnDestroyedRegion) {
+    stopper.checkCancelInProgress(null);
+    {
+      LocalRegion result = getRegionByPath(path);
+      // Do not waitOnInitialization() for PR
+      if (result != null) {
+        if (!(result instanceof PartitionedRegion)) {
+          return null;
+        } else {
+          return result;
+        }
+      }
+    }
+ 
+    String[] pathParts = parsePath(path);
+    LocalRegion root;
+    LogWriterI18n logger = getLoggerI18n();
+    synchronized (this.rootRegions) {
+      root = (LocalRegion) this.rootRegions.get(pathParts[0]);
+      if (root == null) {
+        if (logger.fineEnabled()) {
+          logger.fine("GemFireCache.getRegion, no region found for " + pathParts[0]);
+        }
+        stopper.checkCancelInProgress(null);
+        return null;
+      }
+      if (!returnDestroyedRegion && root.isDestroyed()) {
+        stopper.checkCancelInProgress(null);
+        return null;
+      }
+    }
+    if (logger.fineEnabled()) {
+      logger.fine("GemFireCache.getPartitionedRegion, calling getSubregion on root(" + pathParts[0] + "): " + pathParts[1]);
+    }
+    Region result = root.getSubregion(pathParts[1], returnDestroyedRegion);
+    if (result != null && !(result instanceof PartitionedRegion)) {
+      return null;
+    } else {
+      return result;
+    }
+  }
+
+  
+  public void addRegionListener(RegionListener l ) {
+    this.regionListeners.add(l);
+  }
+  
+  public void removeRegionListener(RegionListener l ) {
+    this.regionListeners.remove(l);
+  }
+  
+  @SuppressWarnings("unchecked")
+  public <T extends CacheService> T getService(Class<T> clazz) {
+    return (T) services.get(clazz);
+  }
-  public BridgeServer addBridgeServer() {
-    return (BridgeServer) addCacheServer();
-  }
-
-    BridgeServerImpl bridge = new BridgeServerImpl(this, isGatewayReceiver);
-    allBridgeServers.add(bridge);
+    CacheServerImpl bridge = new CacheServerImpl(this, isGatewayReceiver);
+    allCacheServers.add(bridge);
-  public void addAsyncEventQueue(AsyncEventQueue asyncQueue) {
+  public void addAsyncEventQueue(AsyncEventQueueImpl asyncQueue) {
+    if(!asyncQueue.isMetaQueue()) {
+      this.allVisibleAsyncEventQueues.add(asyncQueue);
+    }
-    return this.allAsyncEventQueues;
+    return this.allVisibleAsyncEventQueues;
+
+  public void removeAsyncEventQueue(AsyncEventQueue asyncQueue) {
+    if (isClient()) {
+      throw new UnsupportedOperationException(
+          "operation is not supported on a client cache");
+    }
+    // first remove the gateway sender of the queue
+    if (asyncQueue instanceof AsyncEventQueueImpl) {
+      removeGatewaySender(((AsyncEventQueueImpl)asyncQueue).getSender());
+    }
+    // using gateway senders lock since async queue uses a gateway sender
+    synchronized (allGatewaySendersLock) {
+      this.allAsyncEventQueues.remove(asyncQueue);
+      this.allVisibleAsyncEventQueues.remove(asyncQueue);
+    }
+  }
-  public List getBridgeServers() {
-    return getCacheServers();
-  }
-
-    List bridgeServersWithoutReceiver = null;
-    if (!allBridgeServers.isEmpty()) {
-    Iterator allBridgeServersIterator = allBridgeServers.iterator();
-    while (allBridgeServersIterator.hasNext()) {
-      BridgeServerImpl bridgeServer = (BridgeServerImpl) allBridgeServersIterator.next();
-      // If BridgeServer is a GatewayReceiver, don't return as part of CacheServers
-      if (!bridgeServer.isGatewayReceiver()) {
-        if (bridgeServersWithoutReceiver == null) {
-          bridgeServersWithoutReceiver = new ArrayList();
+    List cacheServersWithoutReceiver = null;
+    if (!allCacheServers.isEmpty()) {
+    Iterator allCacheServersIterator = allCacheServers.iterator();
+    while (allCacheServersIterator.hasNext()) {
+      CacheServerImpl cacheServer = (CacheServerImpl) allCacheServersIterator.next();
+      // If CacheServer is a GatewayReceiver, don't return as part of CacheServers
+      if (!cacheServer.isGatewayReceiver()) {
+        if (cacheServersWithoutReceiver == null) {
+          cacheServersWithoutReceiver = new ArrayList();
-        bridgeServersWithoutReceiver.add(bridgeServer);
+        cacheServersWithoutReceiver.add(cacheServer);
-    if (bridgeServersWithoutReceiver == null) {
-      bridgeServersWithoutReceiver = Collections.emptyList();
+    if (cacheServersWithoutReceiver == null) {
+      cacheServersWithoutReceiver = Collections.emptyList();
-    return bridgeServersWithoutReceiver;
+    return cacheServersWithoutReceiver;
-  public List getBridgeServersAndGatewayReceiver() {
-    return allBridgeServers;
+  public List getCacheServersAndGatewayReceiver() {
+    return allCacheServers;
-        Iterator allBridgeServersIterator = allBridgeServers.iterator();
-        while (allBridgeServersIterator.hasNext()) {
-          BridgeServerImpl server = (BridgeServerImpl) allBridgeServersIterator.next();
+        Iterator allCacheServersIterator = allCacheServers.iterator();
+        while (allCacheServersIterator.hasNext()) {
+          CacheServerImpl server = (CacheServerImpl) allCacheServersIterator.next();
-      return (this.allBridgeServers.size() > 0);
+      return (this.allCacheServers.size() > 0);
-  
+
+  /**
+   * Wait for given sender queue to flush for given timeout.
+   * 
+   * @param id
+   *          ID of GatewaySender or AsyncEventQueue
+   * @param isAsyncListener
+   *          true if this is for an AsyncEventQueue and false if for a
+   *          GatewaySender
+   * @param maxWaitTime
+   *          maximum time to wait in seconds; zero or -ve means infinite wait
+   * 
+   * @return zero if maxWaitTime was not breached, -1 if queue could not be
+   *         found or is closed, and elapsed time if timeout was breached
+   */
+  public int waitForSenderQueueFlush(String id, boolean isAsyncListener,
+      int maxWaitTime) {
+    getCancelCriterion().checkCancelInProgress(null);
+    AbstractGatewaySender gatewaySender = null;
+    if (isAsyncListener) {
+      AsyncEventQueueImpl asyncQueue = (AsyncEventQueueImpl)
+          getAsyncEventQueue(id);
+      if (asyncQueue != null) {
+        gatewaySender = (AbstractGatewaySender) asyncQueue.getSender();
+      }
+    }
+    else {
+      gatewaySender = (AbstractGatewaySender)getGatewaySender(id);
+    }
+    RegionQueue rq;
+    final long startTime = System.currentTimeMillis();
+    long elapsedTime;
+    if (maxWaitTime <= 0) {
+      maxWaitTime = Integer.MAX_VALUE;
+    }
+    while (gatewaySender != null && gatewaySender.isRunning()
+        && (rq = gatewaySender.getQueue()) != null) {
+      if (rq.size() == 0) {
+        // return zero since it was not a timeout
+        return 0;
+      }
+      try {
+        Thread.sleep(500);
+        getCancelCriterion().checkCancelInProgress(null);
+      } catch (InterruptedException ie) {
+        Thread.currentThread().interrupt();
+        getCancelCriterion().checkCancelInProgress(ie);
+      }
+      // clear interrupted flag before retry
+      Thread.interrupted();
+      elapsedTime = System.currentTimeMillis() - startTime;
+      if (elapsedTime >= (maxWaitTime * 1000L)) {
+        // return elapsed time
+        return (int)(elapsedTime / 1000L);
+      }
+    }
+    return -1;
+  }
+
-      AutoSerializableManager asm = AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) v);
+      AutoSerializableManager asm = (AutoSerializableManager) ((ReflectionBasedAutoSerializer) v).getManager();
+  public HDFSStoreFactory createHDFSStoreFactory(HDFSStoreCreation creation) {
+    return new HDFSStoreFactoryImpl(this, creation);
+  }
+  public void addHDFSStore(HDFSStoreImpl hsi) {
+    HDFSStoreDirector.getInstance().addHDFSStore(hsi);
+    //TODO:HDFS Add a resource event for hdfs store creation as well 
+    // like the following disk store event
+    //system.handleResourceEvent(ResourceEvent.DISKSTORE_CREATE, dsi);
+  }
+
+  public void removeHDFSStore(HDFSStoreImpl hsi) {
+    //hsi.destroy();
+    HDFSStoreDirector.getInstance().removeHDFSStore(hsi.getName());
+    //TODO:HDFS Add a resource event for hdfs store as well 
+    // like the following disk store event
+    //system.handleResourceEvent(ResourceEvent.DISKSTORE_REMOVE, dsi);
+  }
+
+  public void closeHDFSStores() {
+    HDFSRegionDirector.reset();
+    HDFSStoreDirector.getInstance().closeHDFSStores();
+  }
+
+  
+  public HDFSStoreImpl findHDFSStore(String name) {
+    return HDFSStoreDirector.getInstance().getHDFSStore(name);
+  }
+  
+  public Collection<HDFSStoreImpl> getHDFSStores() {
+    return HDFSStoreDirector.getInstance().getAllHDFSStores();
+  }
+  
+  
-  
+
+  public MemoryAllocator getOffHeapStore() {
+    return this.getSystem().getOffHeapStore();
+  }
+
