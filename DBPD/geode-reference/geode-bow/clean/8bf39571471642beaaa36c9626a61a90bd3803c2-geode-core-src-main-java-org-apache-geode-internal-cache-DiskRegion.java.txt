Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * Represents a (disk-based) persistent store for region data.
- * Used for both persistent recoverable regions and overflow-only regions.
+ * Represents a (disk-based) persistent store for region data. Used for both persistent recoverable
+ * regions and overflow-only regions.
-  //////////////////////  Instance Fields  ///////////////////////
+  ////////////////////// Instance Fields ///////////////////////
-  
+
-  
+
-  
+
-  
+
-   * Creates a new <code>DiskRegion</code> that access disk on behalf of the
-   * given region.
-   */ 
-  protected DiskRegion(DiskStoreImpl ds,
-                       String name,
-                       boolean isBucket,
-                       boolean isPersistBackup,
-                       boolean overflowEnabled,
-                       boolean isSynchronous,
-                       DiskRegionStats stats,
-                       CancelCriterion cancel,
-                       DiskExceptionHandler exceptionHandler,
-                       RegionAttributes ra, EnumSet<DiskRegionFlag> flags,
-                       String partitionName, int startingBucketId, 
-                       String compressorClassName,  boolean offHeap) {
+   * Creates a new <code>DiskRegion</code> that access disk on behalf of the given region.
+   */
+  protected DiskRegion(DiskStoreImpl ds, String name, boolean isBucket, boolean isPersistBackup,
+      boolean overflowEnabled, boolean isSynchronous, DiskRegionStats stats, CancelCriterion cancel,
+      DiskExceptionHandler exceptionHandler, RegionAttributes ra, EnumSet<DiskRegionFlag> flags,
+      String partitionName, int startingBucketId, String compressorClassName, boolean offHeap) {
-    if(this.getPartitionName() != null){
+    if (this.getPartitionName() != null) {
-      // Only use the passed in values of these if we have not already recovered this region from disk.
-      if(this.getStartingBucketId() != startingBucketId || !this.getPartitionName().equals(partitionName)){
+      // Only use the passed in values of these if we have not already recovered this region from
+      // disk.
+      if (this.getStartingBucketId() != startingBucketId
+          || !this.getPartitionName().equals(partitionName)) {
-    
+
-      throw new IllegalStateException("The region \""
-                                      + name
-                                      + "\" has been persisted to disk so it can not be recreated on the same disk store without persistence. Either destroy the persistent region, recreate it as overflow and persistent, or create the overflow only region on a different disk store.");
+      throw new IllegalStateException("The region \"" + name
+          + "\" has been persisted to disk so it can not be recreated on the same disk store without persistence. Either destroy the persistent region, recreate it as overflow and persistent, or create the overflow only region on a different disk store.");
-        throw new IllegalStateException("The region \""
-                                        + name
-                                        + "\" has been persisted to disk as a partition region bucket but is not being recreated as a bucket. This should not be possible.");
+        throw new IllegalStateException("The region \"" + name
+            + "\" has been persisted to disk as a partition region bucket but is not being recreated as a bucket. This should not be possible.");
-        throw new IllegalStateException("The region \""
-                                        + name
-                                        + "\" has not been persisted to disk as a partition region bucket but is now being recreated as a bucket. This should not be possible.");
+        throw new IllegalStateException("The region \"" + name
+            + "\" has not been persisted to disk as a partition region bucket but is now being recreated as a bucket. This should not be possible.");
-    if(isRecreated() && !flags.equals(getFlags())) {
-      throw new IllegalStateException("The region \""
-          + name
-          + "\" has changed it's concurrency enabled setting. Old setting " + getFlags() + ", new setting " + flags);
+    if (isRecreated() && !flags.equals(getFlags())) {
+      throw new IllegalStateException(
+          "The region \"" + name + "\" has changed it's concurrency enabled setting. Old setting "
+              + getFlags() + ", new setting " + flags);
-    
+
-//    EvictionAttributes ea = region.getAttributes().getEvictionAttributes();
-//    this.overflowEnabled = ea != null && ea.getAction().isOverflowToDisk();
+    // EvictionAttributes ea = region.getAttributes().getEvictionAttributes();
+    // this.overflowEnabled = ea != null && ea.getAction().isOverflowToDisk();
-//    if (region instanceof BucketRegion) {
-//      this.stats = internalRegionArgs.getPartitionedRegion()
-//          .getDiskRegionStats();
-//    }
-//    else {
-//      this.stats = new DiskRegionStats(factory, name);
-//    }
+    // if (region instanceof BucketRegion) {
+    // this.stats = internalRegionArgs.getPartitionedRegion()
+    // .getDiskRegionStats();
+    // }
+    // else {
+    // this.stats = new DiskRegionStats(factory, name);
+    // }
-      byte raLruAlgorithm = (byte)(ra.getEvictionAttributes().getAlgorithm().getValue());
-      byte raLruAction = (byte)(ra.getEvictionAttributes().getAction().getValue());
+      byte raLruAlgorithm = (byte) (ra.getEvictionAttributes().getAlgorithm().getValue());
+      byte raLruAction = (byte) (ra.getEvictionAttributes().getAction().getValue());
-//       GemFireCache.getInstance().getLogger()
-//         .info("DEBUG isRecreated=" + isRecreated()
-//               + " raLruLimit=" + raLruLimit
-//               + " getLruLimit()=" + getLruLimit(),
-//               new RuntimeException("STACK"));
+      // GemFireCache.getInstance().getLogger()
+      // .info("DEBUG isRecreated=" + isRecreated()
+      // + " raLruLimit=" + raLruLimit
+      // + " getLruLimit()=" + getLruLimit(),
+      // new RuntimeException("STACK"));
-        if (raLruAlgorithm != getLruAlgorithm()
-            || raLruAction != getLruAction()
-            || raLruLimit != getLruLimit()
-            || ra.getConcurrencyLevel() != getConcurrencyLevel()
+        if (raLruAlgorithm != getLruAlgorithm() || raLruAction != getLruAction()
+            || raLruLimit != getLruLimit() || ra.getConcurrencyLevel() != getConcurrencyLevel()
-            || ra.getStatisticsEnabled() != getStatisticsEnabled()
-            || offHeap != getOffHeap()
-            || !hasSameCompressor(ra)) { 
+            || ra.getStatisticsEnabled() != getStatisticsEnabled() || offHeap != getOffHeap()
+            || !hasSameCompressor(ra)) {
-          
+
-      setConfig(raLruAlgorithm, raLruAction, raLruLimit,
-                ra.getConcurrencyLevel(),
-                ra.getInitialCapacity(),
-                ra.getLoadFactor(),
-                ra.getStatisticsEnabled(),
-                isBucket, flags, partitionName, startingBucketId,
-                compressorClassName, offHeap);
+      setConfig(raLruAlgorithm, raLruAction, raLruLimit, ra.getConcurrencyLevel(),
+          ra.getInitialCapacity(), ra.getLoadFactor(), ra.getStatisticsEnabled(), isBucket, flags,
+          partitionName, startingBucketId, compressorClassName, offHeap);
-    
-    if(!isBucket) {
-      //Bucket should create data storage only when the actual bucket
-      //is created.
+
+    if (!isBucket) {
+      // Bucket should create data storage only when the actual bucket
+      // is created.
-  static DiskRegion create(DiskStoreImpl dsi, String name,
-                           boolean isBucket, boolean isPersistBackup,
-                           boolean overflowEnabled, boolean isSynchronous,
-                           DiskRegionStats stats, CancelCriterion cancel,
-                           DiskExceptionHandler exceptionHandler,
-                           RegionAttributes ra, EnumSet<DiskRegionFlag> flags,
-                           String partitionName, int startingBucketId,
-                           Compressor compressor, boolean offHeap) {
+  static DiskRegion create(DiskStoreImpl dsi, String name, boolean isBucket,
+      boolean isPersistBackup, boolean overflowEnabled, boolean isSynchronous,
+      DiskRegionStats stats, CancelCriterion cancel, DiskExceptionHandler exceptionHandler,
+      RegionAttributes ra, EnumSet<DiskRegionFlag> flags, String partitionName,
+      int startingBucketId, Compressor compressor, boolean offHeap) {
-                                                  overflowEnabled, isSynchronous,
-                                                  stats, cancel, exceptionHandler, ra, flags,
-                                                  partitionName, startingBucketId,
-                                                  compressor, offHeap);
+        overflowEnabled, isSynchronous, stats, cancel, exceptionHandler, ra, flags, partitionName,
+        startingBucketId, compressor, offHeap);
-  
+
-  //////////////////////  Instance Methods  //////////////////////
+  ////////////////////// Instance Methods //////////////////////
-  private boolean hasSameCompressor(final RegionAttributes<?,?> ra) {
+  private boolean hasSameCompressor(final RegionAttributes<?, ?> ra) {
-  
+
-   * Initializes the contents of the region that owns this disk region.
-   * Currently the only time this method does any work is when backup is true
-   * and recovery data was discovered when this disk region was created.
+   * Initializes the contents of the region that owns this disk region. Currently the only time this
+   * method does any work is when backup is true and recovery data was discovered when this disk
+   * region was created.
+
-      //this.scheduleCompaction();
+      // this.scheduleCompaction();
-      } else if(getRegionVersionVector() != null){
+      } else if (getRegionVersionVector() != null) {
-      if(!GIIStatus.didGII(giiStatus)) {
-        //If we did not do a GII, but we are still recovering using
-        //an untrusted RVV, that means that the RVV may not reflect
-        //what is in the region. We need to fix the RVV before
-        //we mark the RVV as trusted and allow the region to recover.
+      if (!GIIStatus.didGII(giiStatus)) {
+        // If we did not do a GII, but we are still recovering using
+        // an untrusted RVV, that means that the RVV may not reflect
+        // what is in the region. We need to fix the RVV before
+        // we mark the RVV as trusted and allow the region to recover.
-      
-      // since rvvTrust will be true, so persist disk region rvv directly. It does not care inmemory rvv
+
+      // since rvvTrust will be true, so persist disk region rvv directly. It does not care inmemory
+      // rvv
-        writeRVVGC((LocalRegion)drs);
+        writeRVVGC((LocalRegion) drs);
-        this.getDiskStore().addDiskRegionToQueue((LocalRegion)drs);
+        this.getDiskStore().addDiskRegionToQueue((LocalRegion) drs);
- // iterate over all region entries in drs
+    // iterate over all region entries in drs
-        public void handleRegionEntry(RegionEntry re) {
-          DiskEntry de = (DiskEntry)re;
-          synchronized (de) {
-            DiskId id = de.getDiskId();
-            if (id != null && re.isTombstone()) {
-              VersionStamp stamp = re.getVersionStamp();
-              if(getRegionVersionVector().isTombstoneTooOld(stamp.getMemberID(), stamp.getRegionVersion())) {
-                drs.destroyRecoveredEntry(de.getKey());
-              }
+      public void handleRegionEntry(RegionEntry re) {
+        DiskEntry de = (DiskEntry) re;
+        synchronized (de) {
+          DiskId id = de.getDiskId();
+          if (id != null && re.isTombstone()) {
+            VersionStamp stamp = re.getVersionStamp();
+            if (getRegionVersionVector().isTombstoneTooOld(stamp.getMemberID(),
+                stamp.getRegionVersion())) {
+              drs.destroyRecoveredEntry(de.getKey());
-      });
-    
+      }
+    });
+
-        public void handleRegionEntry(RegionEntry re) {
-          DiskEntry de = (DiskEntry)re;
-          synchronized (de) {
-            DiskId id = de.getDiskId();
-            if (id != null) {
-              if (EntryBits.isRecoveredFromDisk(id.getUserBits())) {
-                drs.destroyRecoveredEntry(de.getKey());
-              }
+      public void handleRegionEntry(RegionEntry re) {
+        DiskEntry de = (DiskEntry) re;
+        synchronized (de) {
+          DiskId id = de.getDiskId();
+          if (id != null) {
+            if (EntryBits.isRecoveredFromDisk(id.getUserBits())) {
+              drs.destroyRecoveredEntry(de.getKey());
-      });
+      }
+    });
-   * Remark all entries as "Recovered From Disk" in preparation for
-   * a new GII. This will allow us to destroy those entries
-   * if we do not receive them as part of a new GII.
+   * Remark all entries as "Recovered From Disk" in preparation for a new GII. This will allow us to
+   * destroy those entries if we do not receive them as part of a new GII.
-        public void handleRegionEntry(RegionEntry re) {
-          DiskEntry de = (DiskEntry)re;
-          synchronized (de) {
-            DiskId id = de.getDiskId();
-            if (id != null) {
-              id.setRecoveredFromDisk(true);
-            }
+      public void handleRegionEntry(RegionEntry re) {
+        DiskEntry de = (DiskEntry) re;
+        synchronized (de) {
+          DiskId id = de.getDiskId();
+          if (id != null) {
+            id.setRecoveredFromDisk(true);
-      });
+      }
+    });
-  
+
-   * Stores a key/value pair from a region entry on disk. Updates all of the
-   * necessary {@linkplain DiskRegionStats statistics}and invokes
-   * {@link Oplog#create}or {@link Oplog#modify}.
+   * Stores a key/value pair from a region entry on disk. Updates all of the necessary
+   * {@linkplain DiskRegionStats statistics}and invokes {@link Oplog#create}or {@link Oplog#modify}.
-   * @param entry
-   *          The entry which is going to be written to disk
-   * @throws RegionClearedException
-   *                 If a clear operation completed before the put operation
-   *                 completed successfully, resulting in the put operation to
-   *                 abort.
-   * @throws IllegalArgumentException
-   *         If <code>id</code> is less than zero
+   * @param entry The entry which is going to be written to disk
+   * @throws RegionClearedException If a clear operation completed before the put operation
+   *         completed successfully, resulting in the put operation to abort.
+   * @throws IllegalArgumentException If <code>id</code> is less than zero
-      throws  RegionClearedException
-  {
+      throws RegionClearedException {
-    
+
-   * Returns the value of the key/value pair with the given diskId. Updates all
-   * of the necessary {@linkplain DiskRegionStats statistics}
+   * Returns the value of the key/value pair with the given diskId. Updates all of the necessary
+   * {@linkplain DiskRegionStats statistics}
-   * Gets the Object from the OpLog . It can be invoked from OpLog , if by
-   * the time a get operation reaches the OpLog, the entry gets compacted
-   * or if we allow concurrent put & get operations. It will also minimize the
-   * synch lock on DiskId
+   * Gets the Object from the OpLog . It can be invoked from OpLog , if by the time a get operation
+   * reaches the OpLog, the entry gets compacted or if we allow concurrent put & get operations. It
+   * will also minimize the synch lock on DiskId
-   * @param id
-   *          DiskId object for the entry
+   * @param id DiskId object for the entry
-  final BytesAndBits getBytesAndBitsWithoutLock(DiskId id, boolean faultIn,
-                                                boolean bitOnly) {
+  final BytesAndBits getBytesAndBitsWithoutLock(DiskId id, boolean faultIn, boolean bitOnly) {
-   }
-  
+  }
+
-   * Asif: THIS SHOULD ONLY BE USED FOR TESTING PURPOSES AS IT IS NOT THREAD
-   * SAFE
+   * Asif: THIS SHOULD ONLY BE USED FOR TESTING PURPOSES AS IT IS NOT THREAD SAFE
-   * Returns the object stored on disk with the given id. This method is used
-   * for testing purposes only. As such, it bypasses the buffer and goes
-   * directly to the disk. This is not a thread safe function , in the sense, it
-   * is possible that by the time the OpLog is queried , data might move HTree
-   * with the oplog being destroyed
+   * Returns the object stored on disk with the given id. This method is used for testing purposes
+   * only. As such, it bypasses the buffer and goes directly to the disk. This is not a thread safe
+   * function , in the sense, it is possible that by the time the OpLog is queried , data might move
+   * HTree with the oplog being destroyed
-   * @throws IllegalArgumentException
-   *        If <code>id</code> is less than zero, no action is taken.
+   * @throws IllegalArgumentException If <code>id</code> is less than zero, no action is taken.
-   * @throws RegionClearedException
-   *                 If a clear operation completed before the put operation
-   *                 completed successfully, resulting in the put operation to
-   *                 abort.
-   * @throws IllegalArgumentException
-   *           If <code>id</code> is {@linkplain #INVALID_ID invalid}or is
-   *           less than zero, no action is taken.
+   * @throws RegionClearedException If a clear operation completed before the put operation
+   *         completed successfully, resulting in the put operation to abort.
+   * @throws IllegalArgumentException If <code>id</code> is {@linkplain #INVALID_ID invalid}or is
+   *         less than zero, no action is taken.
-  final void remove(LocalRegion region, DiskEntry entry, boolean async, boolean isClear) throws RegionClearedException {
+
+  final void remove(LocalRegion region, DiskEntry entry, boolean async, boolean isClear)
+      throws RegionClearedException {
-  //////////////////////  Access Methods for DiskRegionSegment ///////////////
+  ////////////////////// Access Methods for DiskRegionSegment ///////////////
-  
+
-  
+
+   * 
+
-  
+
-   * The diskStats are at PR level.Hence if the region is a bucket region, the
-   * stats should not be closed, but the figures of entriesInVM and
-   * overflowToDisk contributed by that bucket need to be removed from the stats .
+   * The diskStats are at PR level.Hence if the region is a bucket region, the stats should not be
+   * closed, but the figures of entriesInVM and overflowToDisk contributed by that bucket need to be
+   * removed from the stats .
-//       region.getGemFireCache().getLogger().info("DEBUG statsClose br= " + region.getFullPath()
-//                                                + " inVm=" + owner.getNumEntriesInVM()
-//                                                + " onDisk=" + owner.getNumOverflowOnDisk());
+      // region.getGemFireCache().getLogger().info("DEBUG statsClose br= " + region.getFullPath()
+      // + " inVm=" + owner.getNumEntriesInVM()
+      // + " onDisk=" + owner.getNumOverflowOnDisk());
-//       region.getGemFireCache().getLogger().info("DEBUG statsClose r=" + region.getFullPath());
+      // region.getGemFireCache().getLogger().info("DEBUG statsClose r=" + region.getFullPath());
-      BucketRegion owner=(BucketRegion)region;
-      long curInVM = owner.getNumEntriesInVM()*-1;
-      long curOnDisk = owner.getNumOverflowOnDisk()*-1;
-      long curOnDiskBytes = owner.getNumOverflowBytesOnDisk()*-1;
+      BucketRegion owner = (BucketRegion) region;
+      long curInVM = owner.getNumEntriesInVM() * -1;
+      long curOnDisk = owner.getNumOverflowOnDisk() * -1;
+      long curOnDiskBytes = owner.getNumOverflowBytesOnDisk() * -1;
-      incNumEntriesInVM(getNumEntriesInVM()*-1);
-      incNumOverflowOnDisk(getNumOverflowOnDisk()*-1);
-      incNumOverflowBytesOnDisk(getNumOverflowBytesOnDisk()*-1);
+      incNumEntriesInVM(getNumEntriesInVM() * -1);
+      incNumOverflowOnDisk(getNumOverflowOnDisk() * -1);
+      incNumOverflowBytesOnDisk(getNumOverflowBytesOnDisk() * -1);
-   * Returns true if the state of the specified entry was recovered from disk.
-   * If so it will also set it to no longer be recovered.
+   * Returns true if the state of the specified entry was recovered from disk. If so it will also
+   * set it to no longer be recovered.
+   * 
-    DiskEntry de = (DiskEntry)re;
+    DiskEntry de = (DiskEntry) re;
-    if (!isReadyForRecovery()) return false;
-    if (id == null) return false;
+    if (!isReadyForRecovery())
+      return false;
+    if (id == null)
+      return false;
-  
-  /** For Testing * */
-//   void addToOplogSet(long oplogID, File opFile, DirectoryHolder dirHolder) {
-//     getDiskStore().addToOplogSet(oplogID, opFile, dirHolder);
-//   }
-//   /** For Testing * */
-//   void setIsRecovering(boolean isRecovering) {
-//     this.isRecovering = isRecovering;
-//   }
+  /** For Testing * */
+  // void addToOplogSet(long oplogID, File opFile, DirectoryHolder dirHolder) {
+  // getDiskStore().addToOplogSet(oplogID, opFile, dirHolder);
+  // }
+
+  // /** For Testing * */
+  // void setIsRecovering(boolean isRecovering) {
+  // this.isRecovering = isRecovering;
+  // }
+
-   * Stops the compactor without taking a write lock. Then it invokes appropriate
-   * methods of super & current class to clear the Oplogs & once done restarts
-   * the compactor.
+   * Stops the compactor without taking a write lock. Then it invokes appropriate methods of super &
+   * current class to clear the Oplogs & once done restarts the compactor.
-  
+
-   * stops the compactor outside the write lock. Once stopped then it proceeds to
-   * close the current * old oplogs
+   * stops the compactor outside the write lock. Once stopped then it proceeds to close the current
+   * * old oplogs
-  
+
-   * stops the compactor outside the write lock. Once stopped then it proceeds to
-   * close the current * old oplogs
+   * stops the compactor outside the write lock. Once stopped then it proceeds to close the current
+   * * old oplogs
-//     // now that we get a readLock it should not be possible for the lock to change
-//     assert !result;
+    // // now that we get a readLock it should not be possible for the lock to change
+    // assert !result;
-  
+
-//     releaseReadLock();
+    // releaseReadLock();
-  
+
-//     acquireReadLock();
+    // acquireReadLock();
-    }else{
+    } else {
+
-   * Note that this is no longer implemented by getting a write lock
-   * but instead locks the same lock that acquireReadLock does.
+   * Note that this is no longer implemented by getting a write lock but instead locks the same lock
+   * that acquireReadLock does.
+
-   * Note that this is no longer implemented by getting a read lock
-   * but instead locks the same lock that acquireWriteLock does.
+   * Note that this is no longer implemented by getting a read lock but instead locks the same lock
+   * that acquireWriteLock does.
+
+
+
+
-/*
-  private void basicAcquireLock() {
-    this.lock.lock();
-  }
-  private void basicReleaseLock() {
-    // It is assumed that releasing the lock will not throw any
-    // ShutdownException
-    this.lock.unlock();
-  }
-*/
+  /*
+   * private void basicAcquireLock() { this.lock.lock(); } private void basicReleaseLock() { // It
+   * is assumed that releasing the lock will not throw any // ShutdownException this.lock.unlock();
+   * }
+   */
+
-    if (isRecreated() 
-        && !this.wasAboutToDestroy()
-        && !this.wasAboutToDestroyDataStorage()) {
+    if (isRecreated() && !this.wasAboutToDestroy() && !this.wasAboutToDestroyDataStorage()) {
-      if(this.isBucket() && !this.wasAboutToDestroy()) {
-        //Fix for 48642
-        //If this is a bucket, only destroy the data, if required.
+      if (this.isBucket() && !this.wasAboutToDestroy()) {
+        // Fix for 48642
+        // If this is a bucket, only destroy the data, if required.
-    }  
+    }
+
+
+
-  
+
-  
+
+
+
+
+
+
+
+
+
+
+
+
-   * Only called on overflow-only regions.
-   * Needs to take every entry currently using disk storage and free up that storage
+   * Only called on overflow-only regions. Needs to take every entry currently using disk storage
+   * and free up that storage
-    if(region == null) {
+    if (region == null) {
-        public void handleRegionEntry(RegionEntry re) {
-          DiskEntry de = (DiskEntry)re;
-          DiskId id = de.getDiskId();
-          if (id != null) {
-            synchronized (id) {
-              re.setValueToNull(); // TODO why call _setValue twice in a row?
-              re.removePhase2();
-              id.unmarkForWriting();
-              if (EntryBits.isNeedsValue(id.getUserBits())) {
-                long oplogId = id.getOplogId();
-                long offset = id.getOffsetInOplog();
-                //int length = id.getValueLength();
-                if (oplogId != -1 && offset != -1) {
-                  id.setOplogId(-1);
-                  OverflowOplog oplog = getDiskStore().overflowOplogs.getChild((int)oplogId);
-                  if (oplog != null) {
-                    oplog.freeEntry(de);
-                  }
+      public void handleRegionEntry(RegionEntry re) {
+        DiskEntry de = (DiskEntry) re;
+        DiskId id = de.getDiskId();
+        if (id != null) {
+          synchronized (id) {
+            re.setValueToNull(); // TODO why call _setValue twice in a row?
+            re.removePhase2();
+            id.unmarkForWriting();
+            if (EntryBits.isNeedsValue(id.getUserBits())) {
+              long oplogId = id.getOplogId();
+              long offset = id.getOffsetInOplog();
+              // int length = id.getValueLength();
+              if (oplogId != -1 && offset != -1) {
+                id.setOplogId(-1);
+                OverflowOplog oplog = getDiskStore().overflowOplogs.getChild((int) oplogId);
+                if (oplog != null) {
+                  oplog.freeEntry(de);
-      });
+      }
+    });
-  
+
-    if(wasFullDestroy) {
+    if (wasFullDestroy) {
-    
+
-   * Record that we have done tombstone garbage collection to disk.
-   * On recovery or compaction, we will discard tombstones less than
-   * the GC RVV. 
+   * Record that we have done tombstone garbage collection to disk. On recovery or compaction, we
+   * will discard tombstones less than the GC RVV.
-    if(this.getFlags().contains(DiskRegionFlag.IS_WITH_VERSIONING)) {
+    if (this.getFlags().contains(DiskRegionFlag.IS_WITH_VERSIONING)) {
-  
+
-   * Record current RVV to disk and update into disk region RVV. 
+   * Record current RVV to disk and update into disk region RVV.
-    if(this.getFlags().contains(DiskRegionFlag.IS_WITH_VERSIONING)) {
+    if (this.getFlags().contains(DiskRegionFlag.IS_WITH_VERSIONING)) {
-  
+
-    try { 
+    try {
