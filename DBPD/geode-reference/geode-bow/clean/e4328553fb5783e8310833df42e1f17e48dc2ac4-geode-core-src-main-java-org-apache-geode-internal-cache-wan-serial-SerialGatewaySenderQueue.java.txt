GEODE-7971: Gw sender deliver TX events atomically to Gw receivers (#4928)

* GEODE-7971: Gw sender deliver TX events atomically to Gw receivers

A new flag is added to gateway senders: group-transaction-events.
If set to true, events for the same transaction will not be
spread across different batches, i.e. it is guaranteed that
they will be delivered inside the same batch.

In order to implement this behavior,
the last event for each transaction is marked with a new flag
and the transactionId before it is put in the sender's queue
(new flag added to GatewaySenderEvent). That way, it is possible
for the gateway senders to go through a
batch ready to be sent and verify if the last event for
each transaction is present in the batch.
If not, the gateway sender will traverse the sender queue
to get the missing events for the incomplete transactions
and once they are added to the batch, the batch will be sent.

This feature has the following restrictions:
- The group-transaction-events can only be set on
serial gateway senders with just 1 dispatcher thread
or on parallel gateway senders.
- In order to guarantee that the events of a transaction
are to not spread
across different batches, the regions involved in the
transaction must all have the same senders with the
group-transaction-events flag set to true configured.

* GEODE-7971: small fix in gwSenderFactory + extra info on config error

* GEODE-7971: Add logic for case when batches are redistributed

Also added parameter for retries when not all
events for a transaction can be read from the queue.

* GEODE-7971: Undo changes on cache*.dtd files unneeded

Also changed a couple of timeouts in test cases.

* feature/GEODE-7971: Changes after review

* feature/GEODE-7971: Simplify test JUnit test case

* GEODE-7971: Update create document and refactor test case

* GEODE-7971: Add check in serial gwsender creation with threads>1 and group-trans-events=true.

Also corrected some documentation errors.

* GEODE-7971: Add HA test cases and fix bug in SerialGatewaySenderQueue

* feature/GEODE-7971: Documentation change after review and flaxy test fix

* GEODE-7971: Doc changes after review
+import static org.apache.geode.cache.wan.GatewaySender.GET_TRANSACTION_EVENTS_FROM_QUEUE_RETRIES;
+import java.util.HashSet;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.function.Predicate;
+import org.apache.geode.annotations.VisibleForTesting;
+import org.apache.geode.cache.TransactionId;
+  /**
+   * Last key peeked from the queue excluding the keys peeked
+   * to complete transactions when group-transaction-events is enabled.
+   */
+  private final AtomicLong lastPeekedId = new AtomicLong(-1);
+
+   * Contains the set of peekedIds that were peeked to complete a transaction
+   * inside a batch when groupTransactionEvents is set.
+   */
+  private final Set<Long> extraPeekedIds = ConcurrentHashMap.newKeySet();
+
+  /**
-   * The writeLock of this concurrent lock is used to protect access to the queue.
-   * It is implemented as a fair lock to ensure FIFO ordering of queueing attempts.
-   * Otherwise threads can be unfairly delayed.
+   * The writeLock of this concurrent lock is used to protect access to the queue. It is implemented
+   * as a fair lock to ensure FIFO ordering of queueing attempts. Otherwise threads can be unfairly
+   * delayed.
+  private MetaRegionFactory metaRegionFactory;
+
+    this(abstractSender, regionName, listener, cleanQueues, new MetaRegionFactory());
+  }
+
+  public SerialGatewaySenderQueue(AbstractGatewaySender abstractSender, String regionName,
+      CacheListener listener, boolean cleanQueues, MetaRegionFactory metaRegionFactory) {
-
+    this.metaRegionFactory = metaRegionFactory;
-      if (this.peekedIds.isEmpty()) {
+      if (peekedIds.isEmpty()) {
-      Long key = this.peekedIds.remove();
+      Long key = peekedIds.remove();
+      extraPeekedIds.remove(key);
-    Object object = peekAhead();
+    KeyAndEventPair object = peekAhead();
-    return object;
+    return object.event;
+
+    Set<TransactionId> incompleteTransactionsInBatch = new HashSet<>();
+    long lastKey = -1;
-      AsyncEvent object = peekAhead();
+      KeyAndEventPair pair = peekAhead();
-      if (object != null) {
+      if (pair != null) {
+        AsyncEvent object = pair.event;
+        lastKey = pair.key;
+        if (object instanceof GatewaySenderEventImpl) {
+          GatewaySenderEventImpl event = (GatewaySenderEventImpl) object;
+          if (event.getTransactionId() != null) {
+            if (event.isLastEventInTransaction()) {
+              incompleteTransactionsInBatch.remove(event.getTransactionId());
+            } else {
+              incompleteTransactionsInBatch.add(event.getTransactionId());
+            }
+          }
+        }
+    if (batch.size() > 0) {
+      peekEventsFromIncompleteTransactions(batch, incompleteTransactionsInBatch, lastKey);
+    }
+
+  private void peekEventsFromIncompleteTransactions(List<AsyncEvent> batch,
+      Set<TransactionId> incompleteTransactionIdsInBatch, long lastKey) {
+    if (!mustGroupTransactionEvents()) {
+      return;
+    }
+
+    if (areAllTransactionsCompleteInBatch(incompleteTransactionIdsInBatch)) {
+      return;
+    }
+
+    for (TransactionId transactionId : incompleteTransactionIdsInBatch) {
+      boolean areAllEventsForTransactionInBatch = false;
+      int retries = 0;
+      long lastKeyForTransaction = lastKey;
+      while (!areAllEventsForTransactionInBatch
+          && retries++ < GET_TRANSACTION_EVENTS_FROM_QUEUE_RETRIES) {
+        EventsAndLastKey eventsAndKey =
+            peekEventsWithTransactionId(transactionId, lastKeyForTransaction);
+
+        for (Object object : eventsAndKey.events) {
+          GatewaySenderEventImpl event = (GatewaySenderEventImpl) object;
+          batch.add(event);
+          areAllEventsForTransactionInBatch = event.isLastEventInTransaction();
+
+          if (logger.isDebugEnabled()) {
+            logger.debug(
+                "Peeking extra event: {}, isLastEventInTransaction: {}, batch size: {}",
+                event.getKey(), event.isLastEventInTransaction(), batch.size());
+          }
+        }
+        lastKeyForTransaction = eventsAndKey.lastKey;
+      }
+      if (!areAllEventsForTransactionInBatch) {
+        logger.warn("Not able to retrieve all events for transaction {} after {} tries",
+            transactionId, retries);
+      }
+    }
+  }
+
+  protected boolean mustGroupTransactionEvents() {
+    return sender.mustGroupTransactionEvents();
+  }
+
+  private boolean areAllTransactionsCompleteInBatch(Set incompleteTransactions) {
+    return (incompleteTransactions.size() == 0);
+  }
+
+    extraPeekedIds.clear();
+    lastPeekedId.set(-1);
-    if (this.peekedIds.isEmpty()) {
+    if (lastPeekedId.equals(-1)) {
-      Long lastPeek = this.peekedIds.peekLast();
-      if (lastPeek == null) {
-        return null;
-      }
-      currentKey = lastPeek.longValue() + 1;
+      currentKey = inc(lastPeekedId.get());
-  private AsyncEvent peekAhead() throws CacheException {
+  @VisibleForTesting
+  static class KeyAndEventPair {
+    public final long key;
+    public final AsyncEvent event;
+
+    KeyAndEventPair(Long key, AsyncEvent event) {
+      this.key = key;
+      this.event = event;
+    }
+  }
+
+  @VisibleForTesting
+  public KeyAndEventPair peekAhead() throws CacheException {
-    while (before(currentKey, getTailKey())
-        && (null == (object = getObjectInSerialSenderQueue(currentKey)))) {
+    while (before(currentKey, getTailKey())) {
+      if (!extraPeekedIds.contains(currentKey)) {
+        object = getObjectInSerialSenderQueue(currentKey);
+        if (object != null) {
+          break;
+        }
+      }
+
+      lastPeekedId.set(currentKey);
+      return new KeyAndEventPair(currentKey, object);
-    return object;
+    return null;
+  }
+
+  private EventsAndLastKey peekEventsWithTransactionId(TransactionId transactionId, long lastKey) {
+    Predicate<GatewaySenderEventImpl> hasTransactionIdPredicate =
+        x -> x.getTransactionId().equals(transactionId);
+    Predicate<GatewaySenderEventImpl> isLastEventInTransactionPredicate =
+        x -> x.isLastEventInTransaction();
+
+    return getElementsMatching(hasTransactionIdPredicate, isLastEventInTransactionPredicate,
+        lastKey);
+  }
+
+  static class EventsAndLastKey {
+    public final List<Object> events;
+    public final long lastKey;
+
+    EventsAndLastKey(List<Object> events, long lastKey) {
+      this.events = events;
+      this.lastKey = lastKey;
+    }
+  }
+
+  EventsAndLastKey getElementsMatching(Predicate condition, Predicate stopCondition, long lastKey) {
+    Object object;
+    List elementsMatching = new ArrayList<>();
+
+    long currentKey = lastKey;
+
+    while ((currentKey = inc(currentKey)) != getTailKey()) {
+      if (extraPeekedIds.contains(currentKey)) {
+        continue;
+      }
+      object = optimalGet(currentKey);
+      if (object == null) {
+        continue;
+      }
+
+      if (condition.test(object)) {
+        elementsMatching.add(object);
+        peekedIds.add(currentKey);
+        extraPeekedIds.add(currentKey);
+        lastKey = currentKey;
+
+        if (stopCondition.test(object)) {
+          break;
+        }
+      }
+    }
+
+    return new EventsAndLastKey(elementsMatching, lastKey);
-            new SerialGatewaySenderQueueMetaRegion(this.regionName, ra, null, gemCache, sender,
-                sender.getStatisticsClock());
+            metaRegionFactory.newMetaRegion(gemCache, this.regionName, ra, sender);
+
-  private void addOverflowStatisticsToMBean(Cache cache, AbstractGatewaySender sender) {
+  @VisibleForTesting
+  protected void addOverflowStatisticsToMBean(Cache cache, AbstractGatewaySender sender) {
+  static class MetaRegionFactory {
+    SerialGatewaySenderQueueMetaRegion newMetaRegion(InternalCache cache,
+        final String regionName,
+        final RegionAttributes ra,
+        AbstractGatewaySender sender) {
+      SerialGatewaySenderQueueMetaRegion meta =
+          new SerialGatewaySenderQueueMetaRegion(regionName, ra, null, cache, sender,
+              sender.getStatisticsClock());
+      return meta;
+    }
+  }
+
