Merge branch 'release/1.0.0-incubating.M3'

- * @since 3.2
+ * @since GemFire 3.2
-  
-  /**
-   * In some cases we need to do something just after we unset the value
-   * from a DiskEntry that has been moved (i.e. overflowed) to disk.
-   * @param context
-   */
-  public void afterValueOverflow(RegionEntryContext context);
-     * @since 3.2.1
+     * @since GemFire 3.2.1
-     * @since gemfire57_hotfix
+     * @since GemFire 57_hotfix
-     * @since 5.1
+     * @since GemFire 5.1
-      
-    /**
-     * Returns false if the entry is INVALID (or LOCAL_INVALID). Determines this
-     * without faulting in the value from disk.
-     * 
-     * @since 3.2.1
-     */
-    /* TODO prpersist - Do we need this method? It was added by the sqlf merge
-    static boolean isValid(DiskEntry entry, DiskRegion dr) {
-      synchronized (entry) {
-        if (entry.isRecovered()) {
-          // We have a recovered entry whose value is still on disk.
-          // So take a peek at it without faulting it in.
-          //long id = entry.getDiskId().getKeyId();
-          //entry.getDiskId().setKeyId(-id);
-          byte bits = dr.getBits(entry.getDiskId());
-          //TODO Asif:Check if resetting is needed
-          return !EntryBits.isInvalid(bits) && !EntryBits.isLocalInvalid(bits);
-        }
-      }
-    }*/
-     * @since 3.2.1
+     * @since GemFire 3.2.1
-      final boolean isEagerDeserialize = entry.isEagerDeserialize();
-      if (isEagerDeserialize) {
-        entry.clearEagerDeserialize();
-      }
-            //For SQLFire we prefer eager deserialized
-//            if(v instanceof ByteSource) {
-//              entry.setEagerDeserialize();
-//            }
-          //For SQLFire we prefer eager deserialized
-//            if(v instanceof ByteSource) {
-//              entry.setEagerDeserialize();
-//            }
-            else if (isEagerDeserialize && tmp instanceof byte[][]) {
-              // optimize for byte[][] since it will need to be eagerly deserialized
-              // for SQLFabric
-              entry.value = tmp;
-              entry.setEagerDeserialize();
-              entry.setSerialized(true);
-            }
-      else if (isEagerDeserialize && v instanceof byte[][]) {
-        // optimize for byte[][] since it will need to be eagerly deserialized
-        // for SQLFabric
-        entry.value = v;
-        entry.setEagerDeserialize();
-      }
-      if (CachedDeserializableFactory.preferObject()) {
-        entry.value = preparedValue;
-        entry.setEagerDeserialize();
-      }
-      else {
+      {
-        if (!event.hasDelta()) {
-          // We don't do this for the delta case because getRawNewValue returns delta
-          // and we want to write the entire new value to disk.
+        {
-      // TODO OFFHEAP: No need to retain since we hold the sync on entry but we need a flavor of _getValue that will decompress
-          // The following undo and then do fixes bug 41849
-          // First, undo the stats done for the previous recovered value
-          if (oldKeyId < 0) {
-            dr.incNumOverflowOnDisk(-1L);
-            dr.incNumOverflowBytesOnDisk(-oldValueLength);
-            incrementBucketStats(region, 0/*InVM*/, -1/*OnDisk*/, -oldValueLength);
-          } else {
-            dr.incNumEntriesInVM(-1L);
-            incrementBucketStats(region, -1/*InVM*/, 0/*OnDisk*/, 0);
-          }
-          // Second, do the stats done for the current recovered value
+          
-              try {
-                entry.handleValueOverflow(region);
-                entry.setValueWithContext(region, null); // fixes bug 41119
-              }finally {
-                entry.afterValueOverflow(region);
-              }
-              
+              entry.handleValueOverflow(region);
+              entry.setValueWithContext(region, null); // fixes bug 41119
-            dr.incNumOverflowOnDisk(1L);
-            dr.incNumOverflowBytesOnDisk(did.getValueLength());
-            incrementBucketStats(region, 0/*InVM*/, 1/*OnDisk*/,
-                                 did.getValueLength());
-            dr.incNumEntriesInVM(1L);
-            incrementBucketStats(region, 1/*InVM*/, 0/*OnDisk*/, 0);
+          }
+          
+          if (re.getRecoveredKeyId() < 0) {
+            if(oldKeyId >= 0) {
+              dr.incNumEntriesInVM(-1L);
+              dr.incNumOverflowOnDisk(1L);
+              dr.incNumOverflowBytesOnDisk(did.getValueLength());
+              incrementBucketStats(region, -1/*InVM*/, 1/*OnDisk*/,
+                                   did.getValueLength());
+            }
+          } else {
+            if(oldKeyId < 0) {
+              dr.incNumEntriesInVM(1L);
+              dr.incNumOverflowOnDisk(-1L);
+              dr.incNumOverflowBytesOnDisk(-oldValueLength);
+              incrementBucketStats(region, 1/*InVM*/, -1/*OnDisk*/, -oldValueLength);
+            }
-          // has succeeded. If not , for GemFireXD , it is possible that other thread
-          // may pick this transient value from region entry ( which for 
-          //offheap will eventually be released ) as index key, 
-          //given that this operation is bound to fail in case of
-          //disk access exception.
+          // has succeeded.
-              //In case of compression the value is being set first 
-              // because atleast for now , GemFireXD does not support compression
-              // if and when it does support, this needs to be taken care of else
-              // we risk Bug 48965
+              //In case of compression the value is being set first
-        }
-        if (entry instanceof LRUEntry) {
-          LRUEntry le = (LRUEntry)entry;
-          boolean wasEvicted = le.testEvicted();
-          le.unsetEvicted();
-          if (!Token.isRemovedFromDisk(newValue)) {
-            if (oldValue == null
-                // added null check for bug 41759
-                || wasEvicted && did != null && did.isPendingAsync()) {
-              // Note we do not append this entry because that will be
-              // done by lruEntryUpdate
+          
+          if(newValue == Token.TOMBSTONE) {
+            if (oldValue == null) {
+              dr.incNumOverflowOnDisk(-1L);
+              dr.incNumOverflowBytesOnDisk(-oldValueLength);
+              incrementBucketStats(region, 0/*InVM*/, -1/*OnDisk*/, -oldValueLength);
+            } else {
+              dr.incNumEntriesInVM(-1L);
+              incrementBucketStats(region, -1/*InVM*/, 0/*OnDisk*/, 0);
+            }
+          } else {
+            if (oldValue == null) {
+            } else if(oldValue == Token.TOMBSTONE) {
+              dr.incNumEntriesInVM(1L);
+              incrementBucketStats(region, 1/*InVM*/, 0/*OnDisk*/, 0/*overflowBytesOnDisk*/);
+        if (entry instanceof LRUEntry) {
+          LRUEntry le = (LRUEntry)entry;
+          le.unsetEvicted();          
+        }
+
-            try {
-              entry.handleValueOverflow(context);
-              entry.setValueWithContext(context,null); // fixes bug 41119
-            }finally {
-              entry.afterValueOverflow(context);
-            }
+            entry.handleValueOverflow(context);
+            entry.setValueWithContext(context,null); // fixes bug 41119
-      //Asif: If the entry is instance of LRU then DidkRegion cannot be null.
-      //Since SqlFabric is accessing this method direcly & it passes the owning region,
-      //if the region happens to be persistent PR type, the owning region passed is PR,
-      // but it will have DiskRegion as null. SqlFabric takes care of passing owning region
-      // as BucketRegion in case of Overflow type entry. This is fix for Bug # 41804
-              // since it was evicted fix the stats here
-              dr.incNumEntriesInVM(1L);
-              dr.incNumOverflowOnDisk(-1L);
-              // no need to dec overflowBytesOnDisk because it was not inced in this case.
-              incrementBucketStats(region, 1/*InVM*/, -1/*OnDisk*/, 0);
-     * return the result will only be off-heap if the value is a sqlf ByteSource. Otherwise result will be on-heap.
-    @Retained
-        @Unretained Object preparedValue = setValueOnFaultIn(value, did, entry, dr, region);
-        // For Sqlfire we want to return the offheap representation.
-        // So we need to retain it for the caller to release.
-        /*if (preparedValue instanceof ByteSource) {
-          // This is the only case in which we return a retained off-heap ref.
-          ((ByteSource)preparedValue).retain();
-          return preparedValue;
-        } else */{
-          return value;
-        }
+        setValueOnFaultIn(value, did, entry, dr, region);
+        return value;
-      /*
-      final StaticSystemCallbacks sysCb;
-      if (version != null && (sysCb = GemFireCacheImpl.FactoryStatics
-          .systemCallbacks) != null) {
-        // may need to change serialized shape for SQLFire
-        return sysCb.fromVersion(valueBytes, false, version, in);
-      }
-      else */ {
-        return valueBytes;
-      }
+      return valueBytes;
-      // Notify the SQLFire IndexManager if present
-     /* final IndexUpdater indexUpdater = region.getIndexUpdater();
-      if(indexUpdater != null && dr.isSync()) {
-        indexUpdater.onOverflowToDisk(entry);
-      }*/
-      
-
-          //did.setValueSerializedSize(byteSizeOnDisk);
-          try {
-            entry.handleValueOverflow(region);
-            entry.setValueWithContext(region,null);
-          }finally {
-            entry.afterValueOverflow(region);
-          }
+          entry.handleValueOverflow(region);
+          entry.setValueWithContext(region,null);
-        dr.incNumEntriesInVM(-1L);
-        dr.incNumOverflowOnDisk(1L);
-        dr.incNumOverflowBytesOnDisk(valueLength);
-        incrementBucketStats(region, -1/*InVM*/, 1/*OnDisk*/, valueLength);
+        if(dr.isSync() || movedValueToDisk) {
+          dr.incNumEntriesInVM(-1L);
+          dr.incNumOverflowOnDisk(1L);
+          dr.incNumOverflowBytesOnDisk(valueLength);
+          incrementBucketStats(region, -1/*InVM*/, 1/*OnDisk*/, valueLength);
+        }
-                try {
-                  entry.handleValueOverflow(region);
-                  entry.setValueWithContext(region,null);
-                }finally {
-                  entry.afterValueOverflow(region);
-                }
+                entry.handleValueOverflow(region);
+                entry.setValueWithContext(region,null);
-     * @since prPersistSprint1
+     * @since GemFire prPersistSprint1
-                // note the old size was already accounted for
-                // onDisk was already inced so just do the valueLength here
+                dr.incNumEntriesInVM(-1);
+                dr.incNumOverflowOnDisk(1L);
-                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
+                incrementBucketStats(region, -1/*InVM*/, 1/*OnDisk*/,
-                try {
-                 entry.handleValueOverflow(region);
-                 entry.setValueWithContext(region,null);
-                }finally {
-                  entry.afterValueOverflow(region);
-                }
+                entry.handleValueOverflow(region);
+                entry.setValueWithContext(region,null);
