Merge branch 'release/1.8.0'

-import java.util.concurrent.Executors;
-import org.apache.geode.cache.query.internal.IndexTrackingQueryObserver;
-import org.apache.geode.cache.query.internal.QueryObserver;
-import org.apache.geode.cache.query.internal.QueryObserverHolder;
-import org.apache.geode.internal.cache.PartitionedRegionQueryEvaluator.PRQueryResultCollector;
-import org.apache.geode.internal.i18n.LocalizedStrings;
+import org.apache.geode.internal.logging.LoggingExecutors;
-  private synchronized void incNumBucketsProcessed() {
-    this.numBucketsProcessed++;
-  }
-
-  private synchronized int getNumBucketsProcessed() {
-    return this.numBucketsProcessed;
-  }
-
-    // Set indexInfoMap to this threads observer.
-    // QueryObserver observer = QueryObserverHolder.getInstance();
-    // if(observer != null && observer instanceof IndexTrackingQueryObserver){
-    // ((IndexTrackingQueryObserver)observer).setIndexInfo(resultCollector.getIndexInfoMap());
-    // }
-
-                LocalizedStrings.PRQueryProcessor_TIMED_OUT_WHILE_EXECUTING_QUERY_TIME_EXCEEDED_0
-                    .toLocalizedString(BUCKET_QUERY_TIMEOUT),
+                String.format("Timed out while executing query, time exceeded %s",
+                    BUCKET_QUERY_TIMEOUT),
-                  LocalizedStrings.PRQueryProcessor_GOT_UNEXPECTED_EXCEPTION_WHILE_EXECUTING_QUERY_ON_PARTITIONED_REGION_BUCKET
-                      .toLocalizedString(),
+                  "Got unexpected exception while executing query on partitioned region bucket",
-
-  }
-
-  /**
-   * @throws ForceReattemptException if bucket was moved so caller should try query again
-   */
-  private void doBucketQuery(final Integer bId, final PartitionedRegionDataStore prds,
-      final DefaultQuery query, final Object[] params, final PRQueryResultCollector rq)
-      throws QueryException, ForceReattemptException, InterruptedException {
-    final BucketRegion bukRegion = (BucketRegion) prds.getLocalBucket2RegionMap().get(bId);
-    final PartitionedRegion pr = prds.getPartitionedRegion();
-    try {
-      pr.checkReadiness();
-      if (bukRegion == null) {
-        if (pr.isLocallyDestroyed || pr.isClosed) {
-          throw new RegionDestroyedException("PR destroyed during query", pr.getFullPath());
-        } else {
-          throw new ForceReattemptException(
-              "Bucket id " + pr.bucketStringForLogs(bId) + " not found on VM " + pr.getMyId());
-        }
-      }
-      bukRegion.waitForData();
-      SelectResults results = null;
-
-      // If the query has LIMIT and is not order by, apply the limit while building the result set.
-      int limit = -1;
-      if (query.getSimpleSelect().getOrderByAttrs() == null) {
-        limit = query.getLimit(params);
-      }
-
-      if (!bukRegion.isBucketDestroyed()) {
-        // If the result queue has reached the limit, no need to
-        // execute the query. Handle the bucket destroy condition
-        // and add the end bucket token.
-        int numBucketsProcessed = getNumBucketsProcessed();
-        if (limit < 0 || (rq.size() - numBucketsProcessed) < limit) {
-          results = (SelectResults) query.prExecuteOnBucket(params, pr, bukRegion);
-          this.resultType = results.getCollectionType().getElementType();
-        }
-
-        if (!bukRegion.isBucketDestroyed()) {
-          // someday, when queries can return objects as a stream, the entire results set won't need
-          // to be manifested
-          // here before we can start adding to the results queue
-          if (results != null) {
-            for (Object r : results) {
-              if (r == null) { // Blocking queue does not support adding null.
-                rq.put(DefaultQuery.NULL_RESULT);
-              } else {
-                // Count from each bucket should be > 0 otherwise limit makes the final result
-                // wrong.
-                // Avoid if query is distinct as this Integer could be a region value.
-                if (!query.getSimpleSelect().isDistinct() && query.getSimpleSelect().isCount()
-                    && r instanceof Integer) {
-                  if ((Integer) r != 0) {
-                    rq.put(r);
-                  }
-                } else {
-                  rq.put(r);
-                }
-              }
-
-              // Check if limit is satisfied.
-              if (limit >= 0 && (rq.size() - numBucketsProcessed) >= limit) {
-                break;
-              }
-            }
-          }
-          rq.put(new EndOfBucket(bId));
-          this.incNumBucketsProcessed();
-          return; // success
-        }
-      }
-
-      // if we get here then the bucket must have been moved
-      checkForBucketMoved(bId, bukRegion, pr);
-      Assert.assertTrue(false, "checkForBucketMoved should have thrown ForceReattemptException");
-    } catch (RegionDestroyedException rde) {
-      checkForBucketMoved(bId, bukRegion, pr);
-      throw rde;
-    } catch (QueryException qe) {
-      checkForBucketMoved(bId, bukRegion, pr);
-      throw qe;
-    }
-  }
-
-  /**
-   * @throws ForceReattemptException if it detects that the given bucket moved
-   * @throws RegionDestroyedException if the given pr was destroyed
-   */
-  private static void checkForBucketMoved(Integer bId, BucketRegion br, PartitionedRegion pr)
-      throws ForceReattemptException, RegionDestroyedException {
-    if (br.isBucketDestroyed()) {
-      // see if the pr is destroyed
-      if (pr.isLocallyDestroyed || pr.isClosed) {
-        throw new RegionDestroyedException("PR destroyed during query", pr.getFullPath());
-      }
-      pr.checkReadiness();
-      throw new ForceReattemptException(
-          "Bucket id " + pr.bucketStringForLogs(bId) + " not found on VM " + pr.getMyId());
-    }
-    /*
-     * for (Iterator itr = _bucketsToQuery.iterator(); itr.hasNext(); ) { Integer bId =
-     * (Integer)itr.next(); doBucketQuery(bId, this._prds, this.query, this.parameters,
-     * resultCollector); }
-     */
-
-        queryMonitor.monitorQueryThread(Thread.currentThread(), query);
+        queryMonitor.monitorQueryThread(query);
-        // TODO: In what situation would the results object itself be undefined?
-        // The elements of the results can be undefined , but not the resultset itself
-        queryMonitor.stopMonitoringQueryThread(Thread.currentThread(), query);
+        queryMonitor.stopMonitoringQueryThread(query);
-  private List buildCallableTaskList(Collection<Collection> resultsColl) {
-    List callableTasks = new ArrayList();
-    for (Iterator itr = _bucketsToQuery.iterator(); itr.hasNext();) {
-      Integer bId = (Integer) itr.next();
+  private List<QueryTask> buildCallableTaskList(Collection<Collection> resultsColl) {
+    List<QueryTask> callableTasks = new ArrayList<>();
+    for (Integer bId : _bucketsToQuery) {
-   *
-   *
-        execService = Executors.newFixedThreadPool(numThreads);
+        execService = LoggingExecutors.newFixedThreadPool("PRQueryProcessor", false, numThreads);
-      // TODO Auto-generated method stub
-      boolean retry = false;
-        // Add indexInfo of this thread to result collector
-        QueryObserver observer = QueryObserverHolder.getInstance();
-        if (observer != null && observer instanceof IndexTrackingQueryObserver) {
-          // ((IndexTrackingQueryObserver)observer).setIndexInfo(resultColl.getIndexInfoMap());
-        }
-
-        // executeSequentially(this.resultColl, bucketList);
-        // success
-        // doBucketQuery(bId, this._prDs, this.query, this.parameters, this.resultColl);
-      } catch (ForceReattemptException fre) {
+      } catch (ForceReattemptException | QueryException | CacheRuntimeException fre) {
-      } catch (QueryException e) {
-        bukResult.setException(e);
-      } catch (CacheRuntimeException cre) {
-        bukResult.setException(cre);
