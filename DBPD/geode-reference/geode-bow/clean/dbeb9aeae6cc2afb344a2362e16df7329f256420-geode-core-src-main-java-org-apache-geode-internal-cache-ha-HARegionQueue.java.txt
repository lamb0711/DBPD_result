Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
+import org.apache.geode.cache.server.CacheServer;
- * An implementation of Queue using Gemfire Region as the underlying
- * datastructure. The key will be a counter(long) and value will be the offered
- * Object in the queue. For example, an entry in this region (key = 5; value =
- * obj1) would mean that the Object obj1 is at the 5th position in the queue.
+ * An implementation of Queue using Gemfire Region as the underlying datastructure. The key will be
+ * a counter(long) and value will be the offered Object in the queue. For example, an entry in this
+ * region (key = 5; value = obj1) would mean that the Object obj1 is at the 5th position in the
+ * queue.
- * This class has a field idsAvailable which is guraded by a
- * ReentrantReadWriteLock. The peek threads which do not modify the idsAvailable
- * LinkedhashSet take read lock , thereby increasing the concurrency of peek
- * operations. The threads like take, remove, QRM ,put& expiry take a write lock
- * while operating on the set. <BR>
- * <B>This class is performant for multiple dispatchers that are trying to do
- * non blocking peek </B> <br>
- * For Blocking operations the object should be of type BlockingHARegionQueue.
- * This class has just a ReentrantLock . Condition object of this lock is used
- * to issue signal to the waiting peek & take threads for put operation. As a
- * result , concurrency of peek operations is not possible. This class is
- * optimized for a single peek thread .
+ * This class has a field idsAvailable which is guraded by a ReentrantReadWriteLock. The peek
+ * threads which do not modify the idsAvailable LinkedhashSet take read lock , thereby increasing
+ * the concurrency of peek operations. The threads like take, remove, QRM ,put& expiry take a write
+ * lock while operating on the set. <BR>
+ * <B>This class is performant for multiple dispatchers that are trying to do non blocking peek </B>
+ * <br>
+ * For Blocking operations the object should be of type BlockingHARegionQueue. This class has just a
+ * ReentrantLock . Condition object of this lock is used to issue signal to the waiting peek & take
+ * threads for put operation. As a result , concurrency of peek operations is not possible. This
+ * class is optimized for a single peek thread .
- * 30 May 2008: 
- * 5.7 onwards the underlying GemFire Region will continue to have key as
- * counter(long) but the value will be a wrapper object(HAEventWrapper) which
- * will be a key in a separate data strucure called haContainer (an
- * implementation of Map). The value against this wrapper will be the offered
- * object in the queue. The purpose of this modification is to allow multiple
- * ha-region-queues share their offered values without storing separate copies
- * in memory, upon GII.
+ * 30 May 2008: 5.7 onwards the underlying GemFire Region will continue to have key as counter(long)
+ * but the value will be a wrapper object(HAEventWrapper) which will be a key in a separate data
+ * strucure called haContainer (an implementation of Map). The value against this wrapper will be
+ * the offered object in the queue. The purpose of this modification is to allow multiple
+ * ha-region-queues share their offered values without storing separate copies in memory, upon GII.
-public class HARegionQueue implements RegionQueue
-{
+public class HARegionQueue implements RegionQueue {
-  
+
-   * The key into the <code>Region</code> used when putting entries onto the
-   * queue. The counter uses incrementAndGet so counter will always be started
-   * from 1
-   *  
+   * The key into the <code>Region</code> used when putting entries onto the queue. The counter uses
+   * incrementAndGet so counter will always be started from 1
+   * 
-   * Map whose key is the ThreadIdentifier object value is the
-   * LastDispatchedAndCurrentEvents object. Every add operation will be
-   * identified by the ThreadIdentifier object & the position recorded in the
-   * LastDispatchedAndCurrentEvents object.
+   * Map whose key is the ThreadIdentifier object value is the LastDispatchedAndCurrentEvents
+   * object. Every add operation will be identified by the ThreadIdentifier object & the position
+   * recorded in the LastDispatchedAndCurrentEvents object.
-   * The <code>Map</code> mapping the regionName->key to the queue key. This
-   * index allows fast updating of entries in the queue for conflation.
+   * The <code>Map</code> mapping the regionName->key to the queue key. This index allows fast
+   * updating of entries in the queue for conflation.
-  //TODO:Asif: Should we worry about whether to some how make it writer
+  // TODO:Asif: Should we worry about whether to some how make it writer
-  
-  /** The ClientProxyMembershipID associated with the ha queue*/
+
+  /** The ClientProxyMembershipID associated with the ha queue */
-   * Map of HA queue region-name and value as a MapWrapper object (whose
-   * underlying map contains ThreadIdentifier as key & value as the last
-   * dispatched sequence ID)
+   * Map of HA queue region-name and value as a MapWrapper object (whose underlying map contains
+   * ThreadIdentifier as key & value as the last dispatched sequence ID)
-   * A MapWrapper object whose underlying map contains ThreadIdentifier as key &
-   * value as the last dispatched sequence ID
+   * A MapWrapper object whose underlying map contains ThreadIdentifier as key & value as the last
+   * dispatched sequence ID
-   * A sequence violation can occur , if an HARegionQueue receives events thru
-   * GII & the same event also arrives via Gemfire Put in that local VM. If the
-   * HARegionQueue does not receive any data via GII , then there should not be
-   * any violation. If there is data arriving thru GII, such voiolations can be
-   * expected , but should be analyzed thoroughly.
+   * A sequence violation can occur , if an HARegionQueue receives events thru GII & the same event
+   * also arrives via Gemfire Put in that local VM. If the HARegionQueue does not receive any data
+   * via GII , then there should not be any violation. If there is data arriving thru GII, such
+   * voiolations can be expected , but should be analyzed thoroughly.
-   * <p>author Asif
+   * <p>
+   * author Asif
-  
+
-   * flag indicating whether interest has been registered for this queue.  This
-   * is used to prevent race conditions between secondaries and primary for
-   * interest registration.
+   * flag indicating whether interest has been registered for this queue. This is used to prevent
+   * race conditions between secondaries and primary for interest registration.
-   * a thread local to store the counters corresponding to the events peeked by
-   * a particular thread. When <code>remove()</code> will be called, these
-   * events stored in thread-local will be destroyed.
+   * a thread local to store the counters corresponding to the events peeked by a particular thread.
+   * When <code>remove()</code> will be called, these events stored in thread-local will be
+   * destroyed.
-   * Thread which creates the <code>QueueRemovalMessage</code> and sends it to
-   * other nodes in the system
+   * Thread which creates the <code>QueueRemovalMessage</code> and sends it to other nodes in the
+   * system
-  
+
-  
+
-   * Constant used to indicate the instance of BlockingHARegionQueue. The static
-   * function used for creating the queue instance should be passed this as
-   * parameter for creating BlockingHARegionQueue
+   * Constant used to indicate the instance of BlockingHARegionQueue. The static function used for
+   * creating the queue instance should be passed this as parameter for creating
+   * BlockingHARegionQueue
-   * Constant used to indicate the instance of HARegionQueue. The static
-   * function used for creating the queue instance should be passed this as
-   * parameter for creating HARegionQueue
+   * Constant used to indicate the instance of HARegionQueue. The static function used for creating
+   * the queue instance should be passed this as parameter for creating HARegionQueue
-  
+
-  
+
-  
+
-  public static final String REGION_ENTRY_EXPIRY_TIME = DistributionConfig.GEMFIRE_PREFIX + "MessageTimeToLive";
-  
+  public static final String REGION_ENTRY_EXPIRY_TIME =
+      DistributionConfig.GEMFIRE_PREFIX + "MessageTimeToLive";
+
-   * The default frequency (in seconds) at which a message will be sent by the
-   * primary to all the secondary nodes to remove the events which have already
-   * been dispatched from the queue.
+   * The default frequency (in seconds) at which a message will be sent by the primary to all the
+   * secondary nodes to remove the events which have already been dispatched from the queue.
-   * The frequency (in seconds) at which a message will be sent by the primary
-   * to all the secondary nodes to remove the events which have already been
-   * dispatched from the queue.
+   * The frequency (in seconds) at which a message will be sent by the primary to all the secondary
+   * nodes to remove the events which have already been dispatched from the queue.
-  
+
-   * The underlying map (may hold reference to a Region or a ConcurrentHashMap)
-   * for this HARegionQueue instance (and also shared by all the HARegionQueue
-   * instances associated with the same CacheClientNotifier).
+   * The underlying map (may hold reference to a Region or a ConcurrentHashMap) for this
+   * HARegionQueue instance (and also shared by all the HARegionQueue instances associated with the
+   * same CacheClientNotifier).
-   * Boolean to indicate whether this HARegionQueue is having active dispatcher
-   * or not( primary node or the secondary node). This will be used to prevent
-   * the events from expiry if the node is primary. This was introduced for
-   * fixing the bug#36853
+   * Boolean to indicate whether this HARegionQueue is having active dispatcher or not( primary node
+   * or the secondary node). This will be used to prevent the events from expiry if the node is
+   * primary. This was introduced for fixing the bug#36853
-  
+
-  
+
-  
+
-   *  Boolean to indicate whether client is a slow receiver 
+   * Boolean to indicate whether client is a slow receiver
-  
+
-  
+
-   * For testing purposes, allows resetting expiry time for ThreadIdentifiers.
-   * In seconds.
+   * For testing purposes, allows resetting expiry time for ThreadIdentifiers. In seconds.
-   * Processes the given string and returns a string which is allowed for region
-   * names
+   * Processes the given string and returns a string which is allowed for region names
-  public static String createRegionName(String regionName)
-  {
-    String result = regionName.replace('/', '#'); //[yogi]: region name cannot
+  public static String createRegionName(String regionName) {
+    String result = regionName.replace('/', '#'); // [yogi]: region name cannot
-      final byte clientConflation, boolean isPrimary) throws IOException,
-      ClassNotFoundException, CacheException, InterruptedException {
+      final byte clientConflation, boolean isPrimary)
+      throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-    
+
-  throws IOException, ClassNotFoundException {
+      throws IOException, ClassNotFoundException {
-    this.region = HARegion.getInstance(processedRegionName,
-        cache, this, ra);
-    
-    if (isPrimary) {//fix for 41878      
+    this.region = HARegion.getInstance(processedRegionName, cache, this, ra);
+
+    if (isPrimary) {// fix for 41878
-  
+
-  
-  
+
+
-  public void recordEventState(InternalDistributedMember sender,Map eventState) {
+  public void recordEventState(InternalDistributedMember sender, Map eventState) {
-      sb.append("Recording initial event state for ")
-        .append(this.regionName)
-        .append(" from ")
-        .append(sender);
+      sb.append("Recording initial event state for ").append(this.regionName).append(" from ")
+          .append(sender);
-    for (Iterator it=eventState.entrySet().iterator(); it.hasNext(); ) {
-      Map.Entry entry = (Map.Entry)it.next();
-      DispatchedAndCurrentEvents giiDace = (DispatchedAndCurrentEvents)entry.getValue();
+    for (Iterator it = eventState.entrySet().iterator(); it.hasNext();) {
+      Map.Entry entry = (Map.Entry) it.next();
+      DispatchedAndCurrentEvents giiDace = (DispatchedAndCurrentEvents) entry.getValue();
-          sb.append("\n  ").append(((ThreadIdentifier)entry.getKey()).expensiveToString())
-            .append("; sequenceID=")
-            .append(giiDace.lastSequenceIDPut);
+          sb.append("\n  ").append(((ThreadIdentifier) entry.getKey()).expensiveToString())
+              .append("; sequenceID=").append(giiDace.lastSequenceIDPut);
-/**
-   * Repopulates the HARegion after the GII is over so as to reset the counters
-   * and populate the DACE objects for the thread identifiers . This method
-   * should be invoked as the last method in the constructor . Thus while
-   * creating BlockingQueue this method should be invoked lastly in the derived
-   * class contructor , after the HARegionQueue contructor is complete.
-   * Otherwise, the ReentrantLock will be null.
+  /**
+   * Repopulates the HARegion after the GII is over so as to reset the counters and populate the
+   * DACE objects for the thread identifiers . This method should be invoked as the last method in
+   * the constructor . Thus while creating BlockingQueue this method should be invoked lastly in the
+   * derived class contructor , after the HARegionQueue contructor is complete. Otherwise, the
+   * ReentrantLock will be null.
-  void putGIIDataInRegion() throws CacheException, InterruptedException
-  {
+  void putGIIDataInRegion() throws CacheException, InterruptedException {
-    //data, then the relevant data structures have to
-    //be populated
+    // data, then the relevant data structures have to
+    // be populated
-          entry = (Region.Entry)iterator.next();
+          entry = (Region.Entry) iterator.next();
-            if ( !(entry.getValue() instanceof ClientMarkerMessageImpl) ) {
+            if (!(entry.getValue() instanceof ClientMarkerMessageImpl)) {
-            mapEntry = (Map.Entry)iterator.next();
-            Conflatable val = (Conflatable)mapEntry.getValue();
-            if (val.getEventId() != null) { // bug #44959 null event ID caused NPE
-              counterInRegion = ((Long)mapEntry.getKey()).intValue();
+            mapEntry = (Map.Entry) iterator.next();
+            Conflatable val = (Conflatable) mapEntry.getValue();
+            if (val != null && val.getEventId() != null) {
+              counterInRegion = ((Long) mapEntry.getKey()).intValue();
-              //putInQueue(val);
-  //            logger.info(LocalizedStrings.DEBUG, this + " putting GII entry #" + counterInRegion
-  //                + " into queue: " + val);
+              // putInQueue(val);
+              // logger.info(LocalizedStrings.DEBUG, this + " putting GII entry #" + counterInRegion
+              // + " into queue: " + val);
-              logger.debug("bug 44959 encountered: HARegion.putGIIDataInRegion found null eventId in {}", val);
+              logger.debug(
+                  "bug 44959 encountered: HARegion.putGIIDataInRegion found null eventId in {}",
+                  val);
-    //TODO:Asif: Avoid invocation of this method
+    // TODO:Asif: Avoid invocation of this method
-  
+
-   * Puts the GII'd entry into the ha region, if it was GII'd along with its
-   * ClientUpdateMessageImpl instance.
+   * Puts the GII'd entry into the ha region, if it was GII'd along with its ClientUpdateMessageImpl
+   * instance.
-    if (val instanceof HAEventWrapper
-        && ((HAEventWrapper)val)
-            .getClientUpdateMessage() == null) {
+    if (val instanceof HAEventWrapper && ((HAEventWrapper) val).getClientUpdateMessage() == null) {
-        logger.debug("HARegionQueue.putGIIDataInRegion(): key={} was removed at sender side, so not putting it into the ha queue.", ((HAEventWrapper)val).getKeyToConflate());
+        logger.debug(
+            "HARegionQueue.putGIIDataInRegion(): key={} was removed at sender side, so not putting it into the ha queue.",
+            ((HAEventWrapper) val).getKeyToConflate());
-    }
-    else {
+    } else {
-  /** 
+  /**
+   * 
-    case HandShake.CONFLATION_OFF:
-      return false; // always disable
-    case HandShake.CONFLATION_ON:
-      if (event instanceof HAEventWrapper) {
-        ClientUpdateMessage cum = (ClientUpdateMessage) this.haContainer.get(event);
-        if (cum != null) {
-          retVal = cum.isUpdate();
+      case HandShake.CONFLATION_OFF:
+        return false; // always disable
+      case HandShake.CONFLATION_ON:
+        if (event instanceof HAEventWrapper) {
+          ClientUpdateMessage cum = (ClientUpdateMessage) this.haContainer.get(event);
+          if (cum != null) {
+            retVal = cum.isUpdate();
+          }
+          break;
+        if (event instanceof ClientUpdateMessage) {
+          // Does this ever happen now?
+          retVal = ((ClientUpdateMessage) event).isUpdate();
+          break;
+        }
+        // Oddness
-      }
-      if (event instanceof ClientUpdateMessage) {
-        // Does this ever happen now?
-        retVal = ((ClientUpdateMessage)event).isUpdate();
-        break;
-      }
-      // Oddness
-      break;
-    case HandShake.CONFLATION_DEFAULT:
-      return retVal;
-    default:
-      throw new InternalGemFireError("Invalid clientConflation");
+      case HandShake.CONFLATION_DEFAULT:
+        return retVal;
+      default:
+        throw new InternalGemFireError("Invalid clientConflation");
-  
+
-   * Adds an object at the queue's tail. The implementation supports concurrent
-   * put operations in a performant manner. This is done in following steps:
-   * <br>
-   * 1)Check if the Event being added has a sequence ID less than the Last
-   * Dispatched SequenceId. If yes do not add the Event to the Queue <br>
+   * Adds an object at the queue's tail. The implementation supports concurrent put operations in a
+   * performant manner. This is done in following steps: <br>
+   * 1)Check if the Event being added has a sequence ID less than the Last Dispatched SequenceId. If
+   * yes do not add the Event to the Queue <br>
-   * LastDispatchedAndCurrentEvents object or adding the position to the
-   * existing object for the ThreadIdentifier
+   * LastDispatchedAndCurrentEvents object or adding the position to the existing object for the
+   * ThreadIdentifier
-   * It is possible that DispatchedAnCurrentEvents object just retrieved by the
-   * put thread has expired thus a one level recursion can occur to do a valid
-   * put
+   * It is possible that DispatchedAnCurrentEvents object just retrieved by the put thread has
+   * expired thus a one level recursion can occur to do a valid put
-   * The operation is thread safe & is guarded by taking a lock on
-   * LastDispatchedAndCurrentEvents object & SIZE Lock
+   * The operation is thread safe & is guarded by taking a lock on LastDispatchedAndCurrentEvents
+   * object & SIZE Lock
-   * @param object
-   *          object to put onto the queue
+   * @param object object to put onto the queue
-   * @return boolean 
+   * @return boolean
-          logger.debug("{}: adding message to GII queue of size {}: {}", this.region.getName(), giiQueue.size(), object);
+          logger.debug("{}: adding message to GII queue of size {}: {}", this.region.getName(),
+              giiQueue.size(), object);
-          putEntryConditionallyIntoHAContainer((HAEventWrapper)object);
+          putEntryConditionallyIntoHAContainer((HAEventWrapper) object);
-    
-    //basicPut() invokes dace.putObject() to put onto HARegionQueue
-    //However, dace.putObject could return true even though 
-    //the event is not put onto the HARegionQueue due to eliding events etc. 
-    //So it is not reliable to be used whether offheap ref ownership is passed over to 
-    //the queue (if and when HARegionQueue uses offheap). The probable 
-    //solution could be that to let dace.putObject() to increase offheap REF count
-    //when it puts the event onto the region queue. Also always release (dec)
-    //the offheap REF count from the caller.
+
+    // basicPut() invokes dace.putObject() to put onto HARegionQueue
+    // However, dace.putObject could return true even though
+    // the event is not put onto the HARegionQueue due to eliding events etc.
+    // So it is not reliable to be used whether offheap ref ownership is passed over to
+    // the queue (if and when HARegionQueue uses offheap). The probable
+    // solution could be that to let dace.putObject() to increase offheap REF count
+    // when it puts the event onto the region queue. Also always release (dec)
+    // the offheap REF count from the caller.
-  
+
-    //optmistically decrease the put count
+    // optmistically decrease the put count
-      //this.region.checkReadiness(); // throws CacheClosed or RegionDestroyed
-    }
-    catch (InterruptedException ie) {
+      // this.region.checkReadiness(); // throws CacheClosed or RegionDestroyed
+    } catch (InterruptedException ie) {
-   
-    Conflatable event = (Conflatable)object;
+
+    Conflatable event = (Conflatable) object;
-    DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)this.eventsMap
-        .get(ti);
+    DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents) this.eventsMap.get(ti);
-          if ( !this.puttingGIIDataInQueue ) {
+          if (!this.puttingGIIDataInQueue) {
-      }
-      else {
+      } else {
-          logger.debug("{}: This queue has already seen this event.  The highest sequence number in the queue for {} is {}, but this event's sequence number is {}", this.regionName, ti, dace.lastDispatchedSequenceId, sequenceID);
+          logger.debug(
+              "{}: This queue has already seen this event.  The highest sequence number in the queue for {} is {}, but this event's sequence number is {}",
+              this.regionName, ti, dace.lastDispatchedSequenceId, sequenceID);
-         incrementTakeSidePutPermits();
+        incrementTakeSidePutPermits();
-    }
-    else {
+    } else {
-      DispatchedAndCurrentEvents oldDace = (DispatchedAndCurrentEvents)this.eventsMap
-          .putIfAbsent(ti, dace);
+      DispatchedAndCurrentEvents oldDace =
+          (DispatchedAndCurrentEvents) this.eventsMap.putIfAbsent(ti, dace);
-      }
-      else {
+      } else {
-        //update the stats
-        //if (logger.isDebugEnabled()) {
+        // update the stats
+        // if (logger.isDebugEnabled()) {
-        //}
+        // }
-    //if (logger.isDebugEnabled()) {
-    //this.stats.incEventsEnqued();
-    //}
+    // if (logger.isDebugEnabled()) {
+    // this.stats.incEventsEnqued();
+    // }
-   * while serving a GII request we queue put()s in a list so that the
-   * GII image is not modified.  This keeps the chunking iteration from
-   * sometimes seeing a later event but missing an older event. Bug #41681
+   * while serving a GII request we queue put()s in a list so that the GII image is not modified.
+   * This keeps the chunking iteration from sometimes seeing a later event but missing an older
+   * event. Bug #41681
-//    try {Thread.sleep(5000);} catch (InterruptedException e) { Thread.currentThread().interrupt(); }
+    // try {Thread.sleep(5000);} catch (InterruptedException e) {
+    // Thread.currentThread().interrupt(); }
-  
+
-   * at the end of a GII image request we decrement the in-process count and,
-   * if it falls to zero we empty the list of messages that put() has been
-   * building.  This is done with the lock held to prevent newer events from
-   * being queued before the list is drained.
+   * at the end of a GII image request we decrement the in-process count and, if it falls to zero we
+   * empty the list of messages that put() has been building. This is done with the lock held to
+   * prevent newer events from being queued before the list is drained.
-//            if (actualCount != expectedCount) {
-//              logger.severe(LocalizedStrings.DEBUG,  "expected to drain "
-//                  + expectedCount + " messages but drained " + actualCount
-//                  + " queue.size() is now " + giiQueue.size() + ", in queue" + this, e);
-//            } else {
-//              logger.severe(LocalizedStrings.DEBUG, "drained " + actualCount + " messages.  Queue size is " + giiQueue.size() + " in " + this);
-//            }
+            // if (actualCount != expectedCount) {
+            // logger.severe(LocalizedStrings.DEBUG, "expected to drain "
+            // + expectedCount + " messages but drained " + actualCount
+            // + " queue.size() is now " + giiQueue.size() + ", in queue" + this, e);
+            // } else {
+            // logger.severe(LocalizedStrings.DEBUG, "drained " + actualCount + " messages. Queue
+            // size is " + giiQueue.size() + " in " + this);
+            // }
-              logger.debug("draining #{}: {}", (actualCount+1), value);
+              logger.debug("draining #{}: {}", (actualCount + 1), value);
-              if (((HAEventWrapper)value).getClientUpdateMessage() == null) {
+              if (((HAEventWrapper) value).getClientUpdateMessage() == null) {
-                    logger.debug("ATTENTION: found gii queued event with null event message.  Please see bug #44852: {}", value);
+                    logger.debug(
+                        "ATTENTION: found gii queued event with null event message.  Please see bug #44852: {}",
+                        value);
-              decAndRemoveFromHAContainer((HAEventWrapper)value);
+              decAndRemoveFromHAContainer((HAEventWrapper) value);
-              // complete draining while holding the write-lock so nothing else
-              // can get into the queue
-              //logger.severe(LocalizedStrings.DEBUG, "endGiiQueueing interrupted - ignoring until draining completes");
-              interrupted = true;
+            // complete draining while holding the write-lock so nothing else
+            // can get into the queue
+            // logger.severe(LocalizedStrings.DEBUG, "endGiiQueueing interrupted - ignoring until
+            // draining completes");
+            interrupted = true;
-          this.region.getCache().getCancelCriterion().checkCancelInProgress(new InterruptedException());
+          this.region.getCache().getCancelCriterion()
+              .checkCancelInProgress(new InterruptedException());
-  
+
-   * this method is for transmission of DACE information with initial image state
-   * in HARegions.  It should not be used for other purposes.  The map contains
-   * only those entries that have no items queued.  This is used to prevent
-   * replay of events in the new queue that have already been removed from this queue.
+   * this method is for transmission of DACE information with initial image state in HARegions. It
+   * should not be used for other purposes. The map contains only those entries that have no items
+   * queued. This is used to prevent replay of events in the new queue that have already been
+   * removed from this queue.
-        for (Map.Entry<ThreadIdentifier, DispatchedAndCurrentEvents> entry: events.entrySet()) {
+        for (Map.Entry<ThreadIdentifier, DispatchedAndCurrentEvents> entry : events.entrySet()) {
-      } catch (ConcurrentModificationException e) { // TODO:WTF: bad practice but eventsMap is ConcurrentHashMap
+      } catch (ConcurrentModificationException e) { // TODO:WTF: bad practice but eventsMap is
+                                                    // ConcurrentHashMap
-          logger.debug("HARegion encountered concurrent modification exception while analysing event state - will try again");
+          logger.debug(
+              "HARegion encountered concurrent modification exception while analysing event state - will try again");
-  
+
-  void checkQueueSizeConstraint() throws InterruptedException
-  {
-    if (Thread.interrupted()) throw new InterruptedException();
+  void checkQueueSizeConstraint() throws InterruptedException {
+    if (Thread.interrupted())
+      throw new InterruptedException();
-   *  
+   * 
-  void incrementTakeSidePutPermitsWithoutNotify()
-  {
+  void incrementTakeSidePutPermitsWithoutNotify() {
-   * Creates the static dispatchedMessagesMap (if not present) and starts the
-   * QueuRemovalThread if not running
-   *  
+   * Creates the static dispatchedMessagesMap (if not present) and starts the QueuRemovalThread if
+   * not running
+   * 
-  public static synchronized void startHAServices(GemFireCacheImpl c)
-  {
-    
+  public static synchronized void startHAServices(GemFireCacheImpl c) {
+
-   *  
+   * 
-  public synchronized static void stopHAServices()
-  {
+  public synchronized static void stopHAServices() {
-  
+
-   * @return the frequency (in seconds) at which a message will be sent by the
-   *         primary to all the secondary nodes to remove the events which have
-   *         already been dispatched from the queue.
+   * @return the frequency (in seconds) at which a message will be sent by the primary to all the
+   *         secondary nodes to remove the events which have already been dispatched from the queue.
-  public static int getMessageSyncInterval()
-  {
+  public static int getMessageSyncInterval() {
+
-   * The internal method used for setting the message synch interval time
-   * via the Cache API
+   * The internal method used for setting the message synch interval time via the Cache API
-  public static  void setMessageSyncInterval(int seconds)
-  {
-    messageSyncInterval =seconds;
+  public static void setMessageSyncInterval(int seconds) {
+    messageSyncInterval = seconds;
-   * @param event
-   *          Object to be conflated
-   * @param newPosition
-   *          New Conflatable object's position
-   * @return Long object denoting the position of the previous conflatable
-   *         object
+   * @param event Object to be conflated
+   * @param newPosition New Conflatable object's position
+   * @return Long object denoting the position of the previous conflatable object
-  protected Long addToConflationMap(Conflatable event, Long newPosition)
-  {
+  protected Long addToConflationMap(Conflatable event, Long newPosition) {
-    ConcurrentMap latestIndexesForRegion = (ConcurrentMap)this.indexes.get(r);
+    ConcurrentMap latestIndexesForRegion = (ConcurrentMap) this.indexes.get(r);
-        if ((latestIndexesForRegion = (ConcurrentMap)this.indexes.get(r)) == null) {
+        if ((latestIndexesForRegion = (ConcurrentMap) this.indexes.get(r)) == null) {
-    Long previousPosition = (Long)latestIndexesForRegion.put(key, newPosition);
+    Long previousPosition = (Long) latestIndexesForRegion.put(key, newPosition);
-   * Creates and returns a ConcurrentMap. This method is over-ridden in test
-   * classes to test some functionality
+   * Creates and returns a ConcurrentMap. This method is over-ridden in test classes to test some
+   * functionality
-  ConcurrentMap createConcurrentMap()
-  {
+  ConcurrentMap createConcurrentMap() {
-   * @return CacheListener object having the desired functionility of expiry of
-   *         Thread Identifier & Events for the HAregion. This method is
-   *         appropriately over ridden in the test classes.
+   * @return CacheListener object having the desired functionility of expiry of Thread Identifier &
+   *         Events for the HAregion. This method is appropriately over ridden in the test classes.
-  CacheListener createCacheListenerForHARegion()
-  {
+  CacheListener createCacheListenerForHARegion() {
-      public void afterInvalidate(EntryEvent event)
-      {
+      public void afterInvalidate(EntryEvent event) {
-//          if (!HARegionQueue.this.isPrimary()) {
-            HARegionQueue.this.expireTheEventOrThreadIdentifier(event);
-//          }
-        }
-        catch (CancelException e) {
+          // if (!HARegionQueue.this.isPrimary()) {
+          HARegionQueue.this.expireTheEventOrThreadIdentifier(event);
+          // }
+        } catch (CancelException e) {
-        }
-        catch (CacheException ce) {
+        } catch (CacheException ce) {
-            logger.error(LocalizedMessage.create(LocalizedStrings.HARegionQueue_HAREGIONQUEUECREATECACHELISTNEREXCEPTION_IN_THE_EXPIRY_THREAD), ce);
+            logger.error(
+                LocalizedMessage.create(
+                    LocalizedStrings.HARegionQueue_HAREGIONQUEUECREATECACHELISTNEREXCEPTION_IN_THE_EXPIRY_THREAD),
+                ce);
-   * This function is invoked by the createCacheListenerForHARegion for
-   * theHARegionQueue & also by overridden function
-   * createCacheListenerForHARegion of the HARegionQueueJUnitTest class for the
-   * test testConcurrentEventExpiryAndTake. This function provides the
-   * meaningful functionality for expiry of the Event object as well as
-   * ThreadIdentifier
-   * <p>author Asif
+   * This function is invoked by the createCacheListenerForHARegion for theHARegionQueue & also by
+   * overridden function createCacheListenerForHARegion of the HARegionQueueJUnitTest class for the
+   * test testConcurrentEventExpiryAndTake. This function provides the meaningful functionality for
+   * expiry of the Event object as well as ThreadIdentifier
+   * <p>
+   * author Asif
-   * @param event
-   *          event object representing the data being expired
+   * @param event event object representing the data being expired
-  void expireTheEventOrThreadIdentifier(EntryEvent event) throws CacheException
-  {
+  void expireTheEventOrThreadIdentifier(EntryEvent event) throws CacheException {
-      logger.debug("HARegionQueue::afterInvalidate. Entry Event being invalidated:{}, isPrimaryQueue:{}", event, HARegionQueue.this.isPrimary());
+      logger.debug(
+          "HARegionQueue::afterInvalidate. Entry Event being invalidated:{}, isPrimaryQueue:{}",
+          event, HARegionQueue.this.isPrimary());
-//    if (HARegionQueue.this.isPrimary()) {
-//      logger.info(LocalizedStrings.DEBUG,
-//          "HARegionQueue: Entry Event being invalidated ="
-//              + event+", after current queue became primary.");
-//    }
+    // if (HARegionQueue.this.isPrimary()) {
+    // logger.info(LocalizedStrings.DEBUG,
+    // "HARegionQueue: Entry Event being invalidated ="
+    // + event+", after current queue became primary.");
+    // }
-      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)HARegionQueue.this.eventsMap
-          .get(key);
+      DispatchedAndCurrentEvents dace =
+          (DispatchedAndCurrentEvents) HARegionQueue.this.eventsMap.get(key);
-      Long expirySequenceID = (Long)event.getOldValue();
-      boolean expired = dace.expireOrUpdate(expirySequenceID.longValue(),
-          (ThreadIdentifier)key);
+      Long expirySequenceID = (Long) event.getOldValue();
+      boolean expired = dace.expireOrUpdate(expirySequenceID.longValue(), (ThreadIdentifier) key);
-        logger.debug("HARegionQueue::afterInvalidate:Size of the region after expiring or updating the ThreadIdentifier={}", HARegionQueue.this.region.keys().size());
+        logger.debug(
+            "HARegionQueue::afterInvalidate:Size of the region after expiring or updating the ThreadIdentifier={}",
+            HARegionQueue.this.region.keys().size());
-    }
-    else if (key instanceof Long) {
-      //if (destroyFromAvailableIDsAndRegion((Long)key)) {
+    } else if (key instanceof Long) {
+      // if (destroyFromAvailableIDsAndRegion((Long)key)) {
-      Conflatable cf = (Conflatable)event.getOldValue();
+      Conflatable cf = (Conflatable) event.getOldValue();
-      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)eventsMap
-          .get(new ThreadIdentifier(memID, threadId));
+      DispatchedAndCurrentEvents dace =
+          (DispatchedAndCurrentEvents) eventsMap.get(new ThreadIdentifier(memID, threadId));
-        dace
-            .destroy((Long)key, cf.getKeyToConflate(), cf.getRegionToConflate());
+        dace.destroy((Long) key, cf.getKeyToConflate(), cf.getRegionToConflate());
+      } else {
+        dace.destroy((Long) key);
-      else {
-        dace.destroy((Long)key);
-      }
-      //}
-    }
-    else {
+      // }
+    } else {
-   * This method adds the position of newly added object to the List of
-   * available IDs so that it is avaialble for peek or take. This method is
-   * called from DispatchedAndCurrentEvents object. This method is invoked in a
-   * write lock for non blocking queue & in a reentrant lock in a blocking
-   * queue. In case of blokcing queue , this method also signals the waiting
-   * take & peek threads to awake.
-   * <p>author Asif
+   * This method adds the position of newly added object to the List of available IDs so that it is
+   * avaialble for peek or take. This method is called from DispatchedAndCurrentEvents object. This
+   * method is invoked in a write lock for non blocking queue & in a reentrant lock in a blocking
+   * queue. In case of blokcing queue , this method also signals the waiting take & peek threads to
+   * awake.
+   * <p>
+   * author Asif
-   * @param position
-   *          The Long position of the object which has been added
+   * @param position The Long position of the object which has been added
-  void publish(Long position) throws InterruptedException 
-  {
+  void publish(Long position) throws InterruptedException {
-      //Asif:Notify the wiating peek threads or take threads of blocking queue
-      //A void operation for the non blocking queue operations
+      // Asif:Notify the wiating peek threads or take threads of blocking queue
+      // A void operation for the non blocking queue operations
-    }
-    finally {
+    } finally {
-  protected boolean removeFromOtherLists(Long position)
-  {
+  protected boolean removeFromOtherLists(Long position) {
-  
+
-   * <p>author Asif
-   * @param position
-   *          Long value present in the Available IDs map against which Event
-   *          object is present in HARegion. This function is directly ivnoked
-   *          from the basicInvalidate function where expiry is aborted if this
-   *          function returns false
+   * <p>
+   * author Asif
+   * 
+   * @param position Long value present in the Available IDs map against which Event object is
+   *        present in HARegion. This function is directly ivnoked from the basicInvalidate function
+   *        where expiry is aborted if this function returns false
-   * @throws InterruptedException   * 
+   * @throws InterruptedException *
-  public boolean destroyFromAvailableIDs(Long position) throws InterruptedException 
-  {
+  public boolean destroyFromAvailableIDs(Long position) throws InterruptedException {
-    }
-    finally {
+    } finally {
-   * Destroys the entry at the position from the Region. It checks for the
-   * presence of the position in the AvailableID Set. If the position existed in
-   * the Set, then only it is removed from the Set & the underlying Region
+   * Destroys the entry at the position from the Region. It checks for the presence of the position
+   * in the AvailableID Set. If the position existed in the Set, then only it is removed from the
+   * Set & the underlying Region
-   * @param position
-   *          Long poistion counter for entry in the Region
+   * @param position Long poistion counter for entry in the Region
-  protected boolean destroyFromAvailableIDsAndRegion(Long position) throws InterruptedException     
-  {
+  protected boolean destroyFromAvailableIDsAndRegion(Long position) throws InterruptedException {
-      }
-      catch (EntryNotFoundException enfe) {
-        //if (!this.region.isDestroyed()) {
-        //if (!HARegionQueue.this.destroyInProgress || !this.region.isDestroyed()) {
-        if(!HARegionQueue.this.destroyInProgress){
-          if(!this.region.isDestroyed()){
-            Assert
-            .assertTrue(
-                false,
-                "HARegionQueue::remove: The position "
-                    + position
-                    + "existed in availableIDs set but not in Region object is not expected");
+      } catch (EntryNotFoundException enfe) {
+        // if (!this.region.isDestroyed()) {
+        // if (!HARegionQueue.this.destroyInProgress || !this.region.isDestroyed()) {
+        if (!HARegionQueue.this.destroyInProgress) {
+          if (!this.region.isDestroyed()) {
+            Assert.assertTrue(false, "HARegionQueue::remove: The position " + position
+                + "existed in availableIDs set but not in Region object is not expected");
-  
+
-   * Removes from the local region and decrements stats
-   * GII does not call this because it messes with the cq stats
-   * Expiry can call this for now as durable client expires would
-   * shut down the cq anyways if anything goes wrong
+   * Removes from the local region and decrements stats GII does not call this because it messes
+   * with the cq stats Expiry can call this for now as durable client expires would shut down the cq
+   * anyways if anything goes wrong
+   * 
-  private void destroyFromQueue(Object key) {    
+  private void destroyFromQueue(Object key) {
-    
+
-  public String toString()
-  {
-    return "RegionQueue on " + this.regionName + "(" + (this.isPrimary? "primary" : "backup") + ")";
+  public String toString() {
+    return "RegionQueue on " + this.regionName + "(" + (this.isPrimary ? "primary" : "backup")
+        + ")";
-  public HARegion getRegion()
-  {
+  public HARegion getRegion() {
-   * This method is inoked by the take function . For non blocking queue it
-   * returns null or a valid long position while for blocking queue it waits for
-   * data in the queue or throws Exception if the thread encounters exception
-   * while waiting.
+   * This method is inoked by the take function . For non blocking queue it returns null or a valid
+   * long position while for blocking queue it waits for data in the queue or throws Exception if
+   * the thread encounters exception while waiting.
-  protected Long getAndRemoveNextAvailableID() throws InterruptedException 
-  {
+  protected Long getAndRemoveNextAvailableID() throws InterruptedException {
-          next = (Long)itr.next();
+          next = (Long) itr.next();
-      }
-      else {
+      } else {
-        next = (Long)itr.next();
+        next = (Long) itr.next();
-    }
-    finally {
+    } finally {
-   * Returns the next position counter present in idsAvailable set. This method
-   * is invoked by the peek function. In case of BlockingQueue, this method
-   * waits till a valid ID is available.
+   * Returns the next position counter present in idsAvailable set. This method is invoked by the
+   * peek function. In case of BlockingQueue, this method waits till a valid ID is available.
-   * <p>author Asif
+   * <p>
+   * author Asif
+   * 
-   * @throws InterruptedException 
+   * @throws InterruptedException
-   *  
+   * 
-  private Long getNextAvailableID() throws InterruptedException
-  {
+  private Long getNextAvailableID() throws InterruptedException {
-        //Asif:Wait in case it is a blocking thread
+        // Asif:Wait in case it is a blocking thread
-          next = (Long)this.idsAvailable.iterator().next();
+          next = (Long) this.idsAvailable.iterator().next();
+      } else {
+        next = (Long) this.idsAvailable.iterator().next();
-      else {
-        next = (Long)this.idsAvailable.iterator().next();
-      }
-    }
-    finally {
+    } finally {
-   * For non blocking queue , this method either returns null or an Object. For
-   * blocking queue it will always return with an Object or wait for queue to be
-   * populated.
+   * For non blocking queue , this method either returns null or an Object. For blocking queue it
+   * will always return with an Object or wait for queue to be populated.
+   * 
-   * @throws CacheException
-   *           The exception can be thrown by BlockingQueue if it encounters
-   *           InterruptedException while waiting for data
+   * @throws CacheException The exception can be thrown by BlockingQueue if it encounters
+   *         InterruptedException while waiting for data
-  public Object take() throws CacheException, InterruptedException 
-  {
+  public Object take() throws CacheException, InterruptedException {
-      object = (Conflatable)this.region.get(next);
+      object = (Conflatable) this.region.get(next);
-      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)this.eventsMap
-          .get(threadid);
+      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents) this.eventsMap.get(threadid);
-      dace.removeEventAndSetSequenceID(new RemovedEventInfo(next, object
-          .getRegionToConflate(), keyToConflate), sequenceId);
-      
-      //Periodic ack from the client will add to the addDispatchMessage Map.
-      //This method gets called from cacheClientNotifier upon receiving the ack from client. 
-      //addDispatchedMessage(threadid, sequenceId);
+      dace.removeEventAndSetSequenceID(
+          new RemovedEventInfo(next, object.getRegionToConflate(), keyToConflate), sequenceId);
+
+      // Periodic ack from the client will add to the addDispatchMessage Map.
+      // This method gets called from cacheClientNotifier upon receiving the ack from client.
+      // addDispatchedMessage(threadid, sequenceId);
-      //if (logger.isDebugEnabled()) {
+      // if (logger.isDebugEnabled()) {
-      //}
+      // }
-  public List take(int batchSize) throws CacheException, InterruptedException
-  {
+  public List take(int batchSize) throws CacheException, InterruptedException {
-      }
-      else {
+      } else {
-  protected boolean checkPrevAcks()
-  {
+  protected boolean checkPrevAcks() {
-  
-  protected boolean checkEventForRemoval(Long counter, ThreadIdentifier threadid, long sequenceId)
-  {
+
+  protected boolean checkEventForRemoval(Long counter, ThreadIdentifier threadid, long sequenceId) {
-  protected void setPeekedEvents()
-  {
+  protected void setPeekedEvents() {
-  
+
-   * Removes the events that were peeked by this thread. The events are
-   * destroyed from the queue and conflation map and DispatchedAndCurrentEvents
-   * are updated accordingly.
+   * Removes the events that were peeked by this thread. The events are destroyed from the queue and
+   * conflation map and DispatchedAndCurrentEvents are updated accordingly.
+   * 
-  public void remove() throws InterruptedException 
-  {
-    List peekedIds = (List)HARegionQueue.peekedEventsContext.get();
+  public void remove() throws InterruptedException {
+    List peekedIds = (List) HARegionQueue.peekedEventsContext.get();
-    
+
-      Long counter = (Long)iter.next();
+      Long counter = (Long) iter.next();
-      Conflatable event = (Conflatable)this.region.get(counter);
+      Conflatable event = (Conflatable) this.region.get(counter);
-        
+
-        if ((countersList = (List)groupedThreadIDs.get(threadid)) != null) {
+        if ((countersList = (List) groupedThreadIDs.get(threadid)) != null) {
-        }
-        else {
+        } else {
-      }
-      else {
-        //if (logger.isDebugEnabled()) {
+      } else {
+        // if (logger.isDebugEnabled()) {
-      Map.Entry element = (Map.Entry)iter.next();
-      ThreadIdentifier tid = (ThreadIdentifier)element.getKey();
-      List removedEvents = (List)element.getValue();
-      long lastDispatchedId = ((Long)removedEvents.remove(0)).longValue();
-      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)this.eventsMap
-          .get(tid);
+      Map.Entry element = (Map.Entry) iter.next();
+      ThreadIdentifier tid = (ThreadIdentifier) element.getKey();
+      List removedEvents = (List) element.getValue();
+      long lastDispatchedId = ((Long) removedEvents.remove(0)).longValue();
+      DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents) this.eventsMap.get(tid);
-          dace.setLastDispatchedIDAndRemoveEvents(removedEvents,
-              lastDispatchedId);
-        }
-        catch (CacheException e) {
+          dace.setLastDispatchedIDAndRemoveEvents(removedEvents, lastDispatchedId);
+        } catch (CacheException e) {
-          logger.error(LocalizedMessage.create(LocalizedStrings.HARegionQueue_EXCEPTION_OCCURED_WHILE_TRYING_TO_SET_THE_LAST_DISPATCHED_ID), e);
+          logger.error(
+              LocalizedMessage.create(
+                  LocalizedStrings.HARegionQueue_EXCEPTION_OCCURED_WHILE_TRYING_TO_SET_THE_LAST_DISPATCHED_ID),
+              e);
-      //Periodic ack from the client will add to the addDispatchMessage Map.
-      //This method gets called from cacheClientNotifier upon receiving the ack from client.
-      //addDispatchedMessage(tid, lastDispatchedId);
+      // Periodic ack from the client will add to the addDispatchMessage Map.
+      // This method gets called from cacheClientNotifier upon receiving the ack from client.
+      // addDispatchedMessage(tid, lastDispatchedId);
-    
+
-  protected Object getNextAvailableIDFromList() throws InterruptedException
-  {
+  protected Object getNextAvailableIDFromList() throws InterruptedException {
-  
-  protected void storePeekedID(Long id)
-  {
-    // ARB: Implemented in DurableHARegionQueue. 
+
+  protected void storePeekedID(Long id) {
+    // ARB: Implemented in DurableHARegionQueue.
-  
-  public Object peek() throws  InterruptedException 
-  {
-    if (Thread.interrupted()) throw new InterruptedException();
+
+  public Object peek() throws InterruptedException {
+    if (Thread.interrupted())
+      throw new InterruptedException();
-        next = (Long)this.getNextAvailableIDFromList();
+        next = (Long) this.getNextAvailableIDFromList();
-      }
-      catch (TimeoutException te) {
+      } catch (TimeoutException te) {
-      object = (Conflatable)this.region.get(next);
+      object = (Conflatable) this.region.get(next);
-        object = (object instanceof HAEventWrapper) ? (Conflatable)this.haContainer
-            .get(object)
+        object = (object instanceof HAEventWrapper) ? (Conflatable) this.haContainer.get(object)
-            
+
-            List peekedEvents;
-            if ((peekedEvents = (List)HARegionQueue.peekedEventsContext.get()) != null) {
-              peekedEvents.add(next);
-            }
-            else {
-              peekedEvents = new LinkedList();
-              peekedEvents.add(next);
-              HARegionQueue.peekedEventsContext.set(peekedEvents);
-            }
-            this.storePeekedID(next);
-            break;
+          List peekedEvents;
+          if ((peekedEvents = (List) HARegionQueue.peekedEventsContext.get()) != null) {
+            peekedEvents.add(next);
+          } else {
+            peekedEvents = new LinkedList();
+            peekedEvents.add(next);
+            HARegionQueue.peekedEventsContext.set(peekedEvents);
+          }
+          this.storePeekedID(next);
+          break;
-  public List peek(int batchSize) throws InterruptedException
-  {
+  public List peek(int batchSize) throws InterruptedException {
-    }
-    finally {
+    } finally {
-    
+
-  
+
-   * Peeks either a batchSize number of elements from the queue or until
-   * timeToWait milliseconds have elapsed (whichever comes first). If it has
-   * peeked batchSize number of elements from the queue before timeToWait
-   * milliseconds have elapsed, it stops peeking. If timeToWait milliseconds
-   * elapse before batchSize number of elements has been peeked, it stops. All
-   * the counters peeked for the batch are added to the thread-context, so that
-   * upon calling of remove(), all the peeked events of the batch are removed
-   * from the queue.
+   * Peeks either a batchSize number of elements from the queue or until timeToWait milliseconds
+   * have elapsed (whichever comes first). If it has peeked batchSize number of elements from the
+   * queue before timeToWait milliseconds have elapsed, it stops peeking. If timeToWait milliseconds
+   * elapse before batchSize number of elements has been peeked, it stops. All the counters peeked
+   * for the batch are added to the thread-context, so that upon calling of remove(), all the peeked
+   * events of the batch are removed from the queue.
-   * If the Queue is non blocking multiple peek operations can proceed but if it
-   * is of type non blocking only one peek operation will proceed as the
-   * blocking queue does not use ReadWriteLock
+   * If the Queue is non blocking multiple peek operations can proceed but if it is of type non
+   * blocking only one peek operation will proceed as the blocking queue does not use ReadWriteLock
-   * @param batchSize
-   *          The number of objects to peek from the queue
-   * @param timeToWait
-   *          The number of milliseconds to attempt to peek
+   * @param batchSize The number of objects to peek from the queue
+   * @param timeToWait The number of milliseconds to attempt to peek
-   * @throws InterruptedException 
+   * @throws InterruptedException
-  public List peek(int batchSize, int timeToWait) throws InterruptedException 
-  {
+  public List peek(int batchSize, int timeToWait) throws InterruptedException {
-      logger.trace("{}: Peek start time={} end time={} time to wait={}", this, start, end, timeToWait);
+      logger.trace("{}: Peek start time={} end time={} time to wait={}", this, start, end,
+          timeToWait);
-    
+
-      
+
-      }
-      catch (InterruptedException e) {
+      } catch (InterruptedException e) {
-      }
-      finally {
+      } finally {
-   * This method prepares the batch of events and updates the thread-context
-   * with corresponding counters, so that when remove is called by this thread,
-   * these events are destroyed from the queue.This method should always be
-   * invoked within the <code>rwLock</code>.
+   * This method prepares the batch of events and updates the thread-context with corresponding
+   * counters, so that when remove is called by this thread, these events are destroyed from the
+   * queue.This method should always be invoked within the <code>rwLock</code>.
-   * @param batchSize -
-   *          number of events to be peeked
+   * @param batchSize - number of events to be peeked
-  private List getBatchAndUpdateThreadContext(int batchSize)      
-  {
+  private List getBatchAndUpdateThreadContext(int batchSize) {
-    if ((peekedEventsThreadContext = (List)HARegionQueue.peekedEventsContext.get()) == null) {
+    if ((peekedEventsThreadContext = (List) HARegionQueue.peekedEventsContext.get()) == null) {
-      Long counter = (Long)itr.next();
+      Long counter = (Long) itr.next();
-          event = ((HAEventWrapper)eventOrWrapper).getClientUpdateMessage();
+          event = ((HAEventWrapper) eventOrWrapper).getClientUpdateMessage();
-  public void addCacheListener(CacheListener listener)
-  {
+  public void addCacheListener(CacheListener listener) {
-  public void removeCacheListener()
-  {
+  public void removeCacheListener() {
-   * It adds the entry to a static data structure dispatchedMessagesMap which 
-   * is periodically operated upon by the QRM thread. 
+   * It adds the entry to a static data structure dispatchedMessagesMap which is periodically
+   * operated upon by the QRM thread.
-   * <p>author Asif
-   * @param tid -
-   *          the ThreadIdentifier object for this event
-   * @param sequenceId -
-   *          the sequence id for this event
+   * <p>
+   * author Asif
+   * 
+   * @param tid - the ThreadIdentifier object for this event
+   * @param sequenceId - the sequence id for this event
-  public void addDispatchedMessage(ThreadIdentifier tid, long sequenceId)
-  {   
+  public void addDispatchedMessage(ThreadIdentifier tid, long sequenceId) {
-        }
-        else {
+        } else {
-          oldvalue = (Long)internalMap.put(tid, lastSequenceNumber);
+          oldvalue = (Long) internalMap.put(tid, lastSequenceNumber);
-      //Assert.assertTrue(!dispatchedMessagesMap.containsKey(this.regionName));
-      //dispatchedMessagesMap.put(this.regionName, this.threadIdToSeqId);
-      Map tempDispatchedMessagesMap = dispatchedMessagesMap ;
-      if(tempDispatchedMessagesMap!= null){
-        Object old = ((ConcurrentMap)tempDispatchedMessagesMap).putIfAbsent(
-            this.regionName, this.threadIdToSeqId);
+      // Assert.assertTrue(!dispatchedMessagesMap.containsKey(this.regionName));
+      // dispatchedMessagesMap.put(this.regionName, this.threadIdToSeqId);
+      Map tempDispatchedMessagesMap = dispatchedMessagesMap;
+      if (tempDispatchedMessagesMap != null) {
+        Object old = ((ConcurrentMap) tempDispatchedMessagesMap).putIfAbsent(this.regionName,
+            this.threadIdToSeqId);
-        Assert.assertTrue(old == null);        
+        Assert.assertTrue(old == null);
-  
-  public void createAckedEventsMap() 
-  {
-     
+
+  public void createAckedEventsMap() {
+
-  public void setAckedEvents() 
-  {
-    
+  public void setAckedEvents() {
+
-  public static Map getDispatchedMessagesMapForTesting()
-  {
+  public static Map getDispatchedMessagesMapForTesting() {
-  Map getConflationMapForTesting()
-  {
+  Map getConflationMapForTesting() {
-  public HARegionQueueStats getStatistics()
-  {
+  public HARegionQueueStats getStatistics() {
-   * @return Map object containing DispatchedAndCurrentEvents object for a
-   *         ThreadIdentifier
+   * @return Map object containing DispatchedAndCurrentEvents object for a ThreadIdentifier
-  Map getEventsMapForTesting()
-  {
+  Map getEventsMapForTesting() {
-  
-  
+
+
-   * Used for testing purposes only. Returns the set of current counters for the
-   * given ThreadIdentifier
+   * Used for testing purposes only. Returns the set of current counters for the given
+   * ThreadIdentifier
-   * @param id -
-   *          the EventID object
+   * @param id - the EventID object
-  Set getCurrentCounterSet(EventID id)
-  {
+  Set getCurrentCounterSet(EventID id) {
-    DispatchedAndCurrentEvents wrapper = (DispatchedAndCurrentEvents)this.eventsMap
-        .get(tid);
+    DispatchedAndCurrentEvents wrapper = (DispatchedAndCurrentEvents) this.eventsMap.get(tid);
-   * Used for testing purposes only. Returns the last dispatched sequenceId for
-   * the given ThreadIdentifier
+   * Used for testing purposes only. Returns the last dispatched sequenceId for the given
+   * ThreadIdentifier
-   * @param id -
-   *          the EventID object
+   * @param id - the EventID object
-  long getLastDispatchedSequenceId(EventID id)
-  {
+  long getLastDispatchedSequenceId(EventID id) {
-    DispatchedAndCurrentEvents wrapper = (DispatchedAndCurrentEvents)this.eventsMap
-        .get(tid);
+    DispatchedAndCurrentEvents wrapper = (DispatchedAndCurrentEvents) this.eventsMap.get(tid);
-  Set getAvalaibleIds()
-  {
+  Set getAvalaibleIds() {
-    }
-    finally {
+    } finally {
-   * This method is invoked by the QRM to remove the IDs which have already been
-   * dispatched by the primary node. It sets the last dispatched sequence ID in
-   * the DACE iff the sequenceID received is more than the current. If the
-   * renoval emssage arrives before the DACE was created, it creates a DACE.
-   * Only one QRM operates at a time on a DACE & any other mesasge will be
-   * waiting for the current thread to exit. This is accomplished by taking a
-   * lock on QRM_LOCK object in the DACE.
+   * This method is invoked by the QRM to remove the IDs which have already been dispatched by the
+   * primary node. It sets the last dispatched sequence ID in the DACE iff the sequenceID received
+   * is more than the current. If the renoval emssage arrives before the DACE was created, it
+   * creates a DACE. Only one QRM operates at a time on a DACE & any other mesasge will be waiting
+   * for the current thread to exit. This is accomplished by taking a lock on QRM_LOCK object in the
+   * DACE.
-   * <p>author Asif
-   * @param lastDispatched
-   *          EventID containing the ThreadIdentifier and the last dispatched
-   *          sequence Id
+   * <p>
+   * author Asif
+   * 
+   * @param lastDispatched EventID containing the ThreadIdentifier and the last dispatched sequence
+   *        Id
-  void removeDispatchedEvents(EventID lastDispatched) throws CacheException, InterruptedException 
-  {
+  void removeDispatchedEvents(EventID lastDispatched) throws CacheException, InterruptedException {
-    DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents)this.eventsMap
-        .get(ti);
+    DispatchedAndCurrentEvents dace = (DispatchedAndCurrentEvents) this.eventsMap.get(ti);
-    }
-    else if (dace == null) {
+    } else if (dace == null) {
-      DispatchedAndCurrentEvents oldDace = (DispatchedAndCurrentEvents)this.eventsMap
-          .putIfAbsent(ti, dace);
+      DispatchedAndCurrentEvents oldDace =
+          (DispatchedAndCurrentEvents) this.eventsMap.putIfAbsent(ti, dace);
-      }
-      else {
+      } else {
-        //update the stats
-        //if (logger.isDebugEnabled()) {
+        // update the stats
+        // if (logger.isDebugEnabled()) {
-        //}
+        // }
-  public int size()
-  {
+  public int size() {
-    }
-    finally {
+    } finally {
-  void decrementTakeSidePutPermits()
-  {
+  void decrementTakeSidePutPermits() {
-  void incrementTakeSidePutPermits()
-  {
+  void incrementTakeSidePutPermits() {
-  
-  //called from dace on a put.  
-  //Increment ha queue stats and cq stats
+
+  // called from dace on a put.
+  // Increment ha queue stats and cq stats
-  
+
-          
-          
+
+
-            if (((ClientUpdateMessage) event).hasCqs() && ((ClientUpdateMessage) event).hasCqs(clientProxyID)) {
+            if (((ClientUpdateMessage) event).hasCqs()
+                && ((ClientUpdateMessage) event).hasCqs(clientProxyID)) {
-                  InternalCqQuery cq = ((InternalCqQuery) cqService.getClientCqFromServer(clientProxyID, cqName));
+                  InternalCqQuery cq =
+                      ((InternalCqQuery) cqService.getClientCqFromServer(clientProxyID, cqName));
-  boolean internalIsEmpty()
-  {
+  boolean internalIsEmpty() {
-  
+
+   * 
-   * Acquires the write Lock for the non blocking class. This method is
-   * overridden in the BlockingHARegionQueue class which acquires the lock on a
-   * ReentrantLock instead of ReentrantReadWriteLock of this class. A write lock
-   * is aquired by any thread which intends to modify the idsAvailable HashSet ,
-   * which can be either a put ,remove , take , QRM message or expiry thread
+   * Acquires the write Lock for the non blocking class. This method is overridden in the
+   * BlockingHARegionQueue class which acquires the lock on a ReentrantLock instead of
+   * ReentrantReadWriteLock of this class. A write lock is aquired by any thread which intends to
+   * modify the idsAvailable HashSet , which can be either a put ,remove , take , QRM message or
+   * expiry thread
-   * All invocations of this method need to have {@link #releaseWriteLock()} in
-   * a matching finally block.
+   * All invocations of this method need to have {@link #releaseWriteLock()} in a matching finally
+   * block.
-   * <p>author Asif
+   * <p>
+   * author Asif
-  void acquireWriteLock() 
-  {
+  void acquireWriteLock() {
-   * Acquires the read Lock for the non blocking class. This method is
-   * overridden in the BlockingHARegionQueue class which acquires the lock on a
-   * ReentrantLock instead of ReentrantReadWriteLock of this class. A read lock
-   * is aquired by a non blocking peek while operating on the idsAvailable
-   * LinkedHashSet without structurally modifying it.
+   * Acquires the read Lock for the non blocking class. This method is overridden in the
+   * BlockingHARegionQueue class which acquires the lock on a ReentrantLock instead of
+   * ReentrantReadWriteLock of this class. A read lock is aquired by a non blocking peek while
+   * operating on the idsAvailable LinkedHashSet without structurally modifying it.
-   * All invocations of this method must have {@link #releaseReadLock()} in a
-   * matching finally block.
+   * All invocations of this method must have {@link #releaseReadLock()} in a matching finally
+   * block.
-   * <p>author Asif
+   * <p>
+   * author Asif
-  void acquireReadLock() 
-  {
+  void acquireReadLock() {
-   *  
+   * 
-  void releaseReadLock()
-  {
+  void releaseReadLock() {
-   *  
+   * 
-  void releaseWriteLock()
-  {
+  void releaseWriteLock() {
-   * <p>author Asif
+   * <p>
+   * author Asif
-  void notifyPeekAndTakeThreads()
-  {
-    //NO Op for blocking queue
+  void notifyPeekAndTakeThreads() {
+    // NO Op for blocking queue
-   * Always returns false for a HARegionQueue class. Suitably overridden in
-   * BlockingHARegionQueue class.
+   * Always returns false for a HARegionQueue class. Suitably overridden in BlockingHARegionQueue
+   * class.
-   * <p>author Asif
+   * <p>
+   * author Asif
+   * 
-   *  
+   * 
-  boolean waitForData() throws InterruptedException
-  {
+  boolean waitForData() throws InterruptedException {
-   * @param eventId
-   *          EventID object
+   * @param eventId EventID object
-  protected static ThreadIdentifier getThreadIdentifier(EventID eventId)
-  {
-    return new ThreadIdentifier(eventId.getMembershipID(), eventId
-        .getThreadID());
+  protected static ThreadIdentifier getThreadIdentifier(EventID eventId) {
+    return new ThreadIdentifier(eventId.getMembershipID(), eventId.getThreadID());
-  static void stopQRMThread()
-  {
+  static void stopQRMThread() {
-   * Calls the createMessageList method of QueueRemovalThread for testing
-   * purposes
+   * Calls the createMessageList method of QueueRemovalThread for testing purposes
-  static List createMessageListForTesting()
-  {
+  static List createMessageListForTesting() {
-   * Creates a HARegionQueue object with default attributes
-   * Used by tests
+   * Creates a HARegionQueue object with default attributes Used by tests
-   * @param regionName
-   *          uniquely identifies the HARegionQueue in the VM.For HARegionQueues
-   *          across the VM to communicate with each other , the name should be
-   *          identical
-   * @param cache
-   *          Gemfire Cache instance
-   * @param haRgnQType
-   *          int identifying whether the HARegionQueue is of type blocking or
-   *          non blocking
+   * @param regionName uniquely identifies the HARegionQueue in the VM.For HARegionQueues across the
+   *        VM to communicate with each other , the name should be identical
+   * @param cache Gemfire Cache instance
+   * @param haRgnQType int identifying whether the HARegionQueue is of type blocking or non blocking
-   * @throws CacheException   
+   * @throws CacheException
-  public static HARegionQueue getHARegionQueueInstance(String regionName,
-      Cache cache, final int haRgnQType, final boolean isDurable) throws IOException, ClassNotFoundException, CacheException, InterruptedException
-  {
+  public static HARegionQueue getHARegionQueueInstance(String regionName, Cache cache,
+      final int haRgnQType, final boolean isDurable)
+      throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-    }
-    else {
+    } else {
-    return getHARegionQueueInstance(regionName, (GemFireCacheImpl)cache,
-        HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES, haRgnQType, isDurable, 
-        container, null, HandShake.CONFLATION_DEFAULT, false, Boolean.FALSE);
-  } 
+    return getHARegionQueueInstance(regionName, (GemFireCacheImpl) cache,
+        HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES, haRgnQType, isDurable, container, null,
+        HandShake.CONFLATION_DEFAULT, false, Boolean.FALSE);
+  }
-   * @param regionName
-   *          uniquely identifies the HARegionQueue in the VM.For HARegionQueues
-   *          across the VM to communicate with each other , the name should be
-   *          identical
-   * @param cache
-   *          Gemfire Cache instance
-   * @param hrqa
-   *          HARegionQueueAttribute instance used for configuring the
-   *          HARegionQueue
-   * @param haRgnQType
-   *          int identifying whether the HARegionQueue is of type blocking or
-   *          non blocking
+   * @param regionName uniquely identifies the HARegionQueue in the VM.For HARegionQueues across the
+   *        VM to communicate with each other , the name should be identical
+   * @param cache Gemfire Cache instance
+   * @param hrqa HARegionQueueAttribute instance used for configuring the HARegionQueue
+   * @param haRgnQType int identifying whether the HARegionQueue is of type blocking or non blocking
-   * @param  canHandleDelta
-   *          boolean indicating whether the HARegionQueue can handle delta or not           
+   * @param canHandleDelta boolean indicating whether the HARegionQueue can handle delta or not
-  public static HARegionQueue getHARegionQueueInstance(String regionName,
-      GemFireCacheImpl cache, HARegionQueueAttributes hrqa, final int haRgnQType,
-      final boolean isDurable, Map haContainer, ClientProxyMembershipID clientProxyId,
-      final byte clientConflation, boolean isPrimary, boolean canHandleDelta)
-      throws IOException, ClassNotFoundException, CacheException, InterruptedException
-  {
+  public static HARegionQueue getHARegionQueueInstance(String regionName, GemFireCacheImpl cache,
+      HARegionQueueAttributes hrqa, final int haRgnQType, final boolean isDurable, Map haContainer,
+      ClientProxyMembershipID clientProxyId, final byte clientConflation, boolean isPrimary,
+      boolean canHandleDelta)
+      throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-    case BLOCKING_HA_QUEUE:
-      if (!isDurable && !canHandleDelta) {
-      hrq = new BlockingHARegionQueue(regionName, cache, hrqa, haContainer,
-          clientProxyId, clientConflation, isPrimary);
-      }
-      else {
-        hrq = new DurableHARegionQueue(regionName, cache, hrqa, haContainer,
-            clientProxyId, clientConflation, isPrimary);
-      }
-      break;
-    case NON_BLOCKING_HA_QUEUE:
-      hrq = new HARegionQueue(regionName, cache, hrqa, haContainer, 
-          clientProxyId, clientConflation, isPrimary);
-      break;
-    default : 
-      throw new IllegalArgumentException(LocalizedStrings.HARegionQueue_HARGNQTYPE_CAN_EITHER_BE_BLOCKING_0_OR_NON_BLOCKING_1.toLocalizedString(new Object[] {Integer.valueOf(BLOCKING_HA_QUEUE), Integer.valueOf(NON_BLOCKING_HA_QUEUE)}));  
+      case BLOCKING_HA_QUEUE:
+        if (!isDurable && !canHandleDelta) {
+          hrq = new BlockingHARegionQueue(regionName, cache, hrqa, haContainer, clientProxyId,
+              clientConflation, isPrimary);
+        } else {
+          hrq = new DurableHARegionQueue(regionName, cache, hrqa, haContainer, clientProxyId,
+              clientConflation, isPrimary);
+        }
+        break;
+      case NON_BLOCKING_HA_QUEUE:
+        hrq = new HARegionQueue(regionName, cache, hrqa, haContainer, clientProxyId,
+            clientConflation, isPrimary);
+        break;
+      default:
+        throw new IllegalArgumentException(
+            LocalizedStrings.HARegionQueue_HARGNQTYPE_CAN_EITHER_BE_BLOCKING_0_OR_NON_BLOCKING_1
+                .toLocalizedString(new Object[] {Integer.valueOf(BLOCKING_HA_QUEUE),
+                    Integer.valueOf(NON_BLOCKING_HA_QUEUE)}));
-    if(!isDurable){
-      Integer expiryTime = Integer.getInteger(REGION_ENTRY_EXPIRY_TIME, hrqa
-          .getExpiryTime());
+    if (!isDurable) {
+      Integer expiryTime = Integer.getInteger(REGION_ENTRY_EXPIRY_TIME, hrqa.getExpiryTime());
-      ExpirationAttributes ea = new ExpirationAttributes(hrqa.getExpiryTime(),
-          ExpirationAction.LOCAL_INVALIDATE);
+      ExpirationAttributes ea =
+          new ExpirationAttributes(hrqa.getExpiryTime(), ExpirationAction.LOCAL_INVALIDATE);
-  /** 
-   * Creates a HARegionQueue object with default attributes.
-   * used by tests 
+  /**
+   * Creates a HARegionQueue object with default attributes. used by tests
-  public static HARegionQueue getHARegionQueueInstance(String regionName,
-      Cache cache, HARegionQueueAttributes hrqa, final int haRgnQType,
-      final boolean isDurable)
-      throws IOException, ClassNotFoundException, CacheException, InterruptedException
-  {
+  public static HARegionQueue getHARegionQueueInstance(String regionName, Cache cache,
+      HARegionQueueAttributes hrqa, final int haRgnQType, final boolean isDurable)
+      throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-    }
-    else {
+    } else {
-    return getHARegionQueueInstance(regionName, (GemFireCacheImpl)cache, hrqa, haRgnQType,
+    return getHARegionQueueInstance(regionName, (GemFireCacheImpl) cache, hrqa, haRgnQType,
-  
+
-    synchronized(this.threadIdToSeqId.list) {
+    synchronized (this.threadIdToSeqId.list) {
-  
+
-      //Get all available Ids for the HA Region Queue
+      // Get all available Ids for the HA Region Queue
-  
+
-        Long counter = (Long)availableIds[i];
+        Long counter = (Long) availableIds[i];
-       
-        //Since this method is invoked in a readlock , the entry in HARegion
+
+        // Since this method is invoked in a readlock , the entry in HARegion
-        
+
-          //If no more interest and no more cqs remove from available ids and backing region
+          // If no more interest and no more cqs remove from available ids and backing region
-              }
-              catch (InterruptedException e) {
+              } catch (InterruptedException e) {
-    }
-    finally {
+    } finally {
-  
-  
+
+
-   * This is an implemention of RegionQueue where peek() & take () are blocking
-   * operation and will not return unless it gets some legitimate value The Lock
-   * object used by this class is a ReentrantLock & not a ReadWriteLock as in
-   * the base class. This reduces the concurrency of peek operations, but it
-   * enables the condition object of the ReentrantLock used to guard the
-   * idsAvailable Set for notifying blocking peek & take operations. Previously
-   * a separate Lock object was used by the BlockingQueue for wait notify. This
-   * class will be performant if there is a single peek thread.
+   * This is an implemention of RegionQueue where peek() & take () are blocking operation and will
+   * not return unless it gets some legitimate value The Lock object used by this class is a
+   * ReentrantLock & not a ReadWriteLock as in the base class. This reduces the concurrency of peek
+   * operations, but it enables the condition object of the ReentrantLock used to guard the
+   * idsAvailable Set for notifying blocking peek & take operations. Previously a separate Lock
+   * object was used by the BlockingQueue for wait notify. This class will be performant if there is
+   * a single peek thread.
-   *  
+   * 
-  private static class BlockingHARegionQueue extends HARegionQueue
-  {
+  private static class BlockingHARegionQueue extends HARegionQueue {
-     * Lock on which the put thread waits for permit & on which take/remove
-     * thread issue notify
+     * Lock on which the put thread waits for permit & on which take/remove thread issue notify
-    //Lock on which the take & remove threads block awaiting data from put
+    // Lock on which the take & remove threads block awaiting data from put
-    private final StoppableCondition blockCond;
+    protected final StoppableCondition blockCond;
-     * @param hrqa
-     *          HARegionQueueAttributes through which expiry time etc for the
-     *          HARegionQueue can be set
+     * @param hrqa HARegionQueueAttributes through which expiry time etc for the HARegionQueue can
+     *        be set
-        HARegionQueueAttributes hrqa, Map haContainer,  
-        ClientProxyMembershipID clientProxyId, final byte clientConflation, 
-        boolean isPrimary) throws IOException, ClassNotFoundException, 
-        CacheException, InterruptedException {
-      super(regionName, cache, hrqa, haContainer, clientProxyId, clientConflation
-          , isPrimary);
+        HARegionQueueAttributes hrqa, Map haContainer, ClientProxyMembershipID clientProxyId,
+        final byte clientConflation, boolean isPrimary)
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
+      super(regionName, cache, hrqa, haContainer, clientProxyId, clientConflation, isPrimary);
-      }
-      finally {
+      } finally {
-    
+
-     * Checks whether a put operation should block or proceed based on the
-     * capacity constraint of the Queue. Initially it checks only via Put Side
-     * Put Permits. If it is exhausted it checks the take side put permits using
-     * the appropriate lock. If the queue's capacity is exhausted then the
-     * thread goes into a finite wait state holding the Put Guard lock for the
-     * duration of EVENT_ENQUEUE_WAIT_TIME after which the thread proceeds to
-     * enqueue the event, allowing the putPermits go negative, if needed. Thus,
-     * no put thread is blocked for more than EVENT_ENQUEUE_WAIT_TIME.
+     * Checks whether a put operation should block or proceed based on the capacity constraint of
+     * the Queue. Initially it checks only via Put Side Put Permits. If it is exhausted it checks
+     * the take side put permits using the appropriate lock. If the queue's capacity is exhausted
+     * then the thread goes into a finite wait state holding the Put Guard lock for the duration of
+     * EVENT_ENQUEUE_WAIT_TIME after which the thread proceeds to enqueue the event, allowing the
+     * putPermits go negative, if needed. Thus, no put thread is blocked for more than
+     * EVENT_ENQUEUE_WAIT_TIME.
-     * This effectively makes the blocking queue behave like a non-blocking
-     * queue which throttles puts if it reaches its capacity. This was changed
-     * in 8.1, see #51400. This function is NOOP in the HARegionQueue.
+     * This effectively makes the blocking queue behave like a non-blocking queue which throttles
+     * puts if it reaches its capacity. This was changed in 8.1, see #51400. This function is NOOP
+     * in the HARegionQueue.
-    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value="TLW_TWO_LOCK_WAIT")
+    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "TLW_TWO_LOCK_WAIT")
-                      logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_CLIENT_QUEUE_FOR_0_IS_FULL, new Object[] {region.getName()}));
+                      logger.warn(LocalizedMessage.create(
+                          LocalizedStrings.HARegionQueue_CLIENT_QUEUE_FOR_0_IS_FULL,
+                          new Object[] {region.getName()}));
-//                    for (;;) {
-                      this.region.checkReadiness(); // fix for bug 37581
-                      this.permitMon.wait(CacheClientNotifier.eventEnqueueWaitTime);
-                      this.region.checkReadiness(); // fix for bug 37581
-                      // Fix for #51400. Allow the queue to grow beyond its
-                      // capacity/maxQueueSize, if it is taking a long time to
-                      // drain the queue, either due to a slower client or the
-                      // deadlock scenario mentioned in the ticket.
-                      reconcilePutPermits();
-//                    }
+                    // for (;;) {
+                    this.region.checkReadiness(); // fix for bug 37581
+                    this.permitMon.wait(CacheClientNotifier.eventEnqueueWaitTime);
+                    this.region.checkReadiness(); // fix for bug 37581
+                    // Fix for #51400. Allow the queue to grow beyond its
+                    // capacity/maxQueueSize, if it is taking a long time to
+                    // drain the queue, either due to a slower client or the
+                    // deadlock scenario mentioned in the ticket.
+                    reconcilePutPermits();
+                    // }
-                      logger.info(LocalizedMessage.create(LocalizedStrings.HARegionQueue_RESUMING_WITH_PROCESSING_PUTS));
+                      logger.info(LocalizedMessage
+                          .create(LocalizedStrings.HARegionQueue_RESUMING_WITH_PROCESSING_PUTS));
-            }  // synchronized (this.permitMon)
-          }  // if (putPermits <= 0)
+            } // synchronized (this.permitMon)
+          } // if (putPermits <= 0)
-        }  // synchronized (this.putGuard)
+        } // synchronized (this.putGuard)
-     * This function should always be called under a lock on putGuard &
-     * permitMon obejct
+     * This function should always be called under a lock on putGuard & permitMon obejct
-     * <p>author Asif
+     * <p>
+     * author Asif
+     * 
-    private int reconcilePutPermits()
-    {
+    private int reconcilePutPermits() {
-     * Implemented to reduce contention between concurrent take/remove
-     * operations and put . The reconciliation between take side put permits &
-     * put side put permits happens only if theput side put permits are
-     * exhausted. In HARehionQueue base class this is a NOOP function. This was
-     * added in case a put operation which has reduced the put permit
-     * optmistically but due to some reason ( most likely because of duplicate
-     * event) was not added in the queue. In such case it will increment take
-     * side permit without notifying any waiting thread
+     * Implemented to reduce contention between concurrent take/remove operations and put . The
+     * reconciliation between take side put permits & put side put permits happens only if theput
+     * side put permits are exhausted. In HARehionQueue base class this is a NOOP function. This was
+     * added in case a put operation which has reduced the put permit optmistically but due to some
+     * reason ( most likely because of duplicate event) was not added in the queue. In such case it
+     * will increment take side permit without notifying any waiting thread
-     * <p>author Asif
-     *  
+     * <p>
+     * author Asif
+     * 
-    void incrementTakeSidePutPermitsWithoutNotify()
-    {
+    void incrementTakeSidePutPermitsWithoutNotify() {
-     * Implemented to reduce contention between concurrent take/remove
-     * operations and put . The reconciliation between take side put permits &
-     * put side put permits happens only if theput side put permits are
-     * exhausted. In HARehionQueue base class this is a NOOP function
+     * Implemented to reduce contention between concurrent take/remove operations and put . The
+     * reconciliation between take side put permits & put side put permits happens only if theput
+     * side put permits are exhausted. In HARehionQueue base class this is a NOOP function
-     * <p>author Asif
-     *  
+     * <p>
+     * author Asif
+     * 
-    void incrementTakeSidePutPermits()
-    {
+    void incrementTakeSidePutPermits() {
-      synchronized (this.permitMon) {
-        ++this.takeSidePutPermits;
-        this.permitMon.notify();
-      }
+        synchronized (this.permitMon) {
+          ++this.takeSidePutPermits;
+          this.permitMon.notify();
+        }
-     * Identical to the acquireReadLock as there is only one type of Lock object
-     * in this class.
+     * Identical to the acquireReadLock as there is only one type of Lock object in this class.
-    void acquireWriteLock(){
+    void acquireWriteLock() {
-     * Identical to the acquireWriteLock as there is only one type of Lock
-     * object in this class.
+     * Identical to the acquireWriteLock as there is only one type of Lock object in this class.
-    void acquireReadLock() 
-    {
-        this.lock.lock();      
+    void acquireReadLock() {
+      this.lock.lock();
-     * This method is called by the publish method when a valid Long position is
-     * added to the idsAvailable set. It should always be called after acquiring
-     * the ReentrantLock. It notifies the waiting peek & take threads.
+     * This method is called by the publish method when a valid Long position is added to the
+     * idsAvailable set. It should always be called after acquiring the ReentrantLock. It notifies
+     * the waiting peek & take threads.
-     * <p>author Asif
+     * <p>
+     * author Asif
-    void notifyPeekAndTakeThreads()
-    {
+    void notifyPeekAndTakeThreads() {
-     * Returns true if data is available in the queue. This method should always
-     * be invoked after acquiring the lock on ReentrantLock object. It blocks
-     * the thread if the queue is empty or returns true otherwise . This will
-     * always return true indicating that data is available for retrieval or
-     * throw an Exception.It can never return false.
-     * @throws InterruptedException
+     * Returns true if data is available in the queue. This method should always be invoked after
+     * acquiring the lock on ReentrantLock object. It blocks the thread if the queue is empty or
+     * returns true otherwise . This will always return true indicating that data is available for
+     * retrieval or throw an Exception.It can never return false.
-     * <p>author Asif
+     * @throws InterruptedException
-    boolean waitForData() throws InterruptedException 
-    {
+    boolean waitForData() throws InterruptedException {
-        }
-        catch (InterruptedException ie) {
+        } catch (InterruptedException ie) {
-        }
-        finally {
-          if (interrupted) Thread.currentThread().interrupt();
+        } finally {
+          if (interrupted)
+            Thread.currentThread().interrupt();
-     * Noop method to prevent HARegionQueue population before the constructor of
-     * BlockingQueue is complete.
+     * Noop method to prevent HARegionQueue population before the constructor of BlockingQueue is
+     * complete.
-     * <p>author Asif
+     * <p>
+     * author Asif
-    void putGIIDataInRegion()
-    {
+    void putGIIDataInRegion() {
-     * Identical to the releaseWriteLock as there is only one type of Lock
-     * object in this class.
-     *  
+     * Identical to the releaseWriteLock as there is only one type of Lock object in this class.
+     * 
-    void releaseReadLock()
-    {
+    void releaseReadLock() {
-     * Identical to the releaseReadLock as there is only one type of Lock object
-     * in this class.
+     * Identical to the releaseReadLock as there is only one type of Lock object in this class.
-     * <p>author Asif
-     *  
+     * <p>
+     * author Asif
+     * 
-    void releaseWriteLock()
-    {
+    void releaseWriteLock() {
-    
+
-    
+
-        HARegionQueueAttributes hrqa, Map haContainer,
-        ClientProxyMembershipID clientProxyId, final byte clientConflation,
-        boolean isPrimary) throws IOException,
-        ClassNotFoundException, CacheException, InterruptedException
-    {
+        HARegionQueueAttributes hrqa, Map haContainer, ClientProxyMembershipID clientProxyId,
+        final byte clientConflation, boolean isPrimary)
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-      
+
-    
+
-    protected Object getNextAvailableIDFromList() throws InterruptedException
-    {
+    boolean waitForData() throws InterruptedException {
+      region.getCache().getCancelCriterion().checkCancelInProgress(null);
+      boolean interrupted = Thread.currentThread().isInterrupted();
+      try {
+        blockCond.await(StoppableCondition.TIME_TO_WAIT);
+      } catch (InterruptedException ie) {
+        interrupted = true;
+        region.getCache().getCancelCriterion().checkCancelInProgress(ie);
+        throw new TimeoutException(ie);
+      } finally {
+        if (interrupted)
+          Thread.currentThread().interrupt();
+      }
+      return !this.internalIsEmpty();
+    }
+
+    @Override
+    protected Object getNextAvailableIDFromList() throws InterruptedException {
-    protected Long getAndRemoveNextAvailableID() throws InterruptedException 
-    {
+    protected Long getAndRemoveNextAvailableID() throws InterruptedException {
-            next = (Long)itr.next();
+            next = (Long) itr.next();
-        }
-        else {
+        } else {
-          next = (Long)itr.next();
+          next = (Long) itr.next();
-      }
-      finally {
+      } finally {
-    protected void storePeekedID(Long id)
-    {
+    protected void storePeekedID(Long id) {
-      }
-      finally {
+      } finally {
-    protected boolean checkPrevAcks()
-    {
+    protected boolean checkPrevAcks() {
-          this.currDurableMap.putAll((Map)this.threadIdToSeqId.list.remove(0));
+          this.currDurableMap.putAll((Map) this.threadIdToSeqId.list.remove(0));
-    
-@Override
-protected boolean checkEventForRemoval(Long counter, ThreadIdentifier threadid, long sequenceId)
-    {
+
+    @Override
+    protected boolean checkEventForRemoval(Long counter, ThreadIdentifier threadid,
+        long sequenceId) {
-      Long seqId = (Long)this.currDurableMap.get(threadid);
+      Long seqId = (Long) this.currDurableMap.get(threadid);
-      }
-      else {
+      } else {
-    
+
-    protected void setPeekedEvents()
-    {
+    protected void setPeekedEvents() {
-    
+
-    protected boolean removeFromOtherLists(Long position)
-    {
+    protected boolean removeFromOtherLists(Long position) {
-    public void initializeTransients()
-    {
+    public void initializeTransients() {
-      // durableIDsList: list of counters from which dispatcher peeks. Used instead of availableIds list,
+      // durableIDsList: list of counters from which dispatcher peeks. Used instead of availableIds
+      // list,
-      
+
-          
+
-          
+
-            logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_DURABLE_CLIENT_QUEUE_INITIALIZATION_TOOK_0_MS, Long.toString(end - start)));
+            logger.warn(LocalizedMessage.create(
+                LocalizedStrings.HARegionQueue_DURABLE_CLIENT_QUEUE_INITIALIZATION_TOOK_0_MS,
+                Long.toString(end - start)));
-        }
-        finally {
+        } finally {
-       * ashetkar: Setting this threadlocal variable to null has no use as the
-       * current thread never uses it. Instead it should really be set null by
-       * message dispatcher thread while starting or resuming. This was added in
-       * revision 20914. Need to check if it really needs to be thread local.
+       * ashetkar: Setting this threadlocal variable to null has no use as the current thread never
+       * uses it. Instead it should really be set null by message dispatcher thread while starting
+       * or resuming. This was added in revision 20914. Need to check if it really needs to be
+       * thread local.
-    protected int availableIDsSize()
-    {
+    protected int availableIDsSize() {
-    
+
-    protected Object[] availableIDsArray()
-    {
+    protected Object[] availableIDsArray() {
-    
+
-    public int size()
-    { 
+    public int size() {
-      }
-      finally {
+      } finally {
-    
+
-      ackedEvents =  new HashMap();
+      ackedEvents = new HashMap();
-    
+
-    }   
+    }
-   * A static class which is created only for for testing prposes as some
-   * existing tests extend the HARegionQueue. Since teh constructors of
-   * HAregionQueue are private , this class can act as a bridge between the user
-   * defined HARegionQueue class & the actual class. This class object will be
-   * buggy as it will tend to publish the Object o QRM thread & the expiry
-   * thread before the complete creation of the HARegionQueue instance
+   * A static class which is created only for for testing prposes as some existing tests extend the
+   * HARegionQueue. Since teh constructors of HAregionQueue are private , this class can act as a
+   * bridge between the user defined HARegionQueue class & the actual class. This class object will
+   * be buggy as it will tend to publish the Object o QRM thread & the expiry thread before the
+   * complete creation of the HARegionQueue instance
-  static class TestOnlyHARegionQueue extends HARegionQueue
-  {
+  static class TestOnlyHARegionQueue extends HARegionQueue {
-        throws IOException, ClassNotFoundException, CacheException,
-        InterruptedException {
-      this(regionName, (GemFireCacheImpl)cache, HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES,
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
+      this(regionName, (GemFireCacheImpl) cache, HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES,
-    TestOnlyHARegionQueue(String regionName, Cache cache) throws IOException,
-        ClassNotFoundException, CacheException, InterruptedException {
-      this(regionName, (GemFireCacheImpl)cache, HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES,
+    TestOnlyHARegionQueue(String regionName, Cache cache)
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
+      this(regionName, (GemFireCacheImpl) cache, HARegionQueueAttributes.DEFAULT_HARQ_ATTRIBUTES,
-    TestOnlyHARegionQueue(String regionName, GemFireCacheImpl cache,
-        HARegionQueueAttributes hrqa, Map haContainer,
-        final byte clientConflation, boolean isPrimary) throws IOException,
-        ClassNotFoundException, CacheException, InterruptedException {
+    TestOnlyHARegionQueue(String regionName, GemFireCacheImpl cache, HARegionQueueAttributes hrqa,
+        Map haContainer, final byte clientConflation, boolean isPrimary)
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
-      ExpirationAttributes ea = new ExpirationAttributes(hrqa.getExpiryTime(),
-          ExpirationAction.LOCAL_INVALIDATE);
+      ExpirationAttributes ea =
+          new ExpirationAttributes(hrqa.getExpiryTime(), ExpirationAction.LOCAL_INVALIDATE);
-     * Overloaded constructor to pass an <code>HashMap</code> instance as a
-     * haContainer.
+     * Overloaded constructor to pass an <code>HashMap</code> instance as a haContainer.
-    TestOnlyHARegionQueue(String regionName, Cache cache,
-        HARegionQueueAttributes hrqa) throws IOException,
-        ClassNotFoundException, CacheException, InterruptedException {
-      this(regionName, (GemFireCacheImpl)cache, hrqa, new HashMap(),
-          HandShake.CONFLATION_DEFAULT, false);
+    TestOnlyHARegionQueue(String regionName, Cache cache, HARegionQueueAttributes hrqa)
+        throws IOException, ClassNotFoundException, CacheException, InterruptedException {
+      this(regionName, (GemFireCacheImpl) cache, hrqa, new HashMap(), HandShake.CONFLATION_DEFAULT,
+          false);
-   * This thread will check for messages which have been dispatched. After a
-   * configurable time or size is reached, it will create a new
-   * <code>QueueRemovalMessage</code> and send it to all the nodes in the
-   * DistributedSystem
+   * This thread will check for messages which have been dispatched. After a configurable time or
+   * size is reached, it will create a new <code>QueueRemovalMessage</code> and send it to all the
+   * nodes in the DistributedSystem
-   * <p>author Mitul Bid
-   *  
+   * <p>
+   * author Mitul Bid
+   * 
-  private static class QueueRemovalThread extends Thread
-  {
+  private static class QueueRemovalThread extends Thread {
-    
+
-    
+
-     * The thread will check the dispatchedMessages map for messages that have
-     * been dispatched. It will create a new <code>QueueRemovalMessage</code>
-     * and send it to the other nodes
+     * The thread will check the dispatchedMessages map for messages that have been dispatched. It
+     * will create a new <code>QueueRemovalMessage</code> and send it to the other nodes
-     * The thread will check the dispatchedMessages map for messages that have
-     * been dispatched. It will create a new <code>QueueRemovalMessage</code>
-     * and send it to the other nodes
+     * The thread will check the dispatchedMessages map for messages that have been dispatched. It
+     * will create a new <code>QueueRemovalMessage</code> and send it to the other nodes
-            }
-            catch (InterruptedException e) {
+            } catch (InterruptedException e) {
-              logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_INTERRUPTEDEXCEPTION_OCCURED_IN_QUEUEREMOVALTHREAD_WHILE_WAITING), e);
+              logger.warn(
+                  LocalizedMessage.create(
+                      LocalizedStrings.HARegionQueue_INTERRUPTEDEXCEPTION_OCCURED_IN_QUEUEREMOVALTHREAD_WHILE_WAITING),
+                  e);
-            }
-            finally {
+            } finally {
-            if (queueRemovalMessageList != null
-                && !queueRemovalMessageList.isEmpty()) { // messages exist
+            if (queueRemovalMessageList != null && !queueRemovalMessageList.isEmpty()) { // messages
+                                                                                         // exist
-              List<CacheServerImpl> servers = this.cache.getCacheServers();
+              List<CacheServer> servers = this.cache.getCacheServers();
-              for (CacheServerImpl server: servers) {
-                recipients.addAll(server.getCacheServerAdvisor().adviseBridgeServers());
+              for (CacheServer server : servers) {
+                recipients.addAll(CacheServerImpl.class.cast(server).getCacheServerAdvisor()
+                    .adviseBridgeServers());
-          }
-          catch (VirtualMachineError err) {
+          } catch (VirtualMachineError err) {
-          }
-          catch (Throwable t) {
+          } catch (Throwable t) {
-      }
-      finally {
-        logger.info(LocalizedMessage.create(LocalizedStrings.HARegionQueue_THE_QUEUEREMOVALTHREAD_IS_DONE));
+      } finally {
+        logger.info(
+            LocalizedMessage.create(LocalizedStrings.HARegionQueue_THE_QUEUEREMOVALTHREAD_IS_DONE));
-     * Creates a list containing the eventIds that have been dispatched by the
-     * clients. The QRM thread while operating on the MapWrapper for a given
-     * region , sets a new map object so that put operations are not blocked
-     * while the QRM thread is iterating over the map contained in MapWrapper &
-     * the put operations will continue using the new internal Ma.
+     * Creates a list containing the eventIds that have been dispatched by the clients. The QRM
+     * thread while operating on the MapWrapper for a given region , sets a new map object so that
+     * put operations are not blocked while the QRM thread is iterating over the map contained in
+     * MapWrapper & the put operations will continue using the new internal Ma.
-    protected List createMessageList()
-    {
+    protected List createMessageList() {
-        entry = (Map.Entry)iterator.next();
-        regionName = (String)entry.getKey(); // key will be the string
+        entry = (Map.Entry) iterator.next();
+        regionName = (String) entry.getKey(); // key will be the string
-        threadIdToSequenceIdMap = (MapWrapper)entry.getValue();
+        threadIdToSequenceIdMap = (MapWrapper) entry.getValue();
-        /*if (threadIdToSequenceIdMap.keepPrevAcks) {
-          synchronized (threadIdToSequenceIdMap.list) {
-            threadIdToSequenceIdMap.list.add(internalMap);
-          }
-        }*/
+        /*
+         * if (threadIdToSequenceIdMap.keepPrevAcks) { synchronized (threadIdToSequenceIdMap.list) {
+         * threadIdToSequenceIdMap.list.add(internalMap); } }
+         */
-          internalEntry = (Map.Entry)internalIterator.next();
-          tid = (ThreadIdentifier)internalEntry.getKey();
-          sequenceId = (Long)internalEntry.getValue();
-          eventId = new EventID(tid.getMembershipID(), tid.getThreadID(),
-              sequenceId.longValue());
+          internalEntry = (Map.Entry) internalIterator.next();
+          tid = (ThreadIdentifier) internalEntry.getKey();
+          sequenceId = (Long) internalEntry.getValue();
+          eventId = new EventID(tid.getMembershipID(), tid.getThreadID(), sequenceId.longValue());
-     *  
+     * 
-      
-      //Asif:Do not exit till QRM thread is dead , else the QRM thread
-      //may operate on Null dispatchedMessagesMap //Bug 37046
+
+      // Asif:Do not exit till QRM thread is dead , else the QRM thread
+      // may operate on Null dispatchedMessagesMap //Bug 37046
-      }
-      catch (InterruptedException e) {
+      } catch (InterruptedException e) {
-      }
-      finally {
+      } finally {
-      if (this.isAlive()){
-        logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_QUEUEREMOVALTHREAD_IGNORED_CANCELLATION));
+      if (this.isAlive()) {
+        logger.warn(LocalizedMessage
+            .create(LocalizedStrings.HARegionQueue_QUEUEREMOVALTHREAD_IGNORED_CANCELLATION));
-   * Class whick keeps track of the positions ( keys) of underlying Region
-   * object for the events placed in the Queue. It also keeps track of the last
-   * sequence ID dispatched. Thus all the events with sequence ID less than that
-   * dispatched are eligible for removal
+   * Class whick keeps track of the positions ( keys) of underlying Region object for the events
+   * placed in the Queue. It also keeps track of the last sequence ID dispatched. Thus all the
+   * events with sequence ID less than that dispatched are eligible for removal
-   * <p>author Asif
-   *  
+   * <p>
+   * author Asif
+   * 
-  public static class DispatchedAndCurrentEvents implements DataSerializableFixedID, Serializable
-  {
+  public static class DispatchedAndCurrentEvents implements DataSerializableFixedID, Serializable {
-     * Keeps the track of last dispatched sequence ID. This field should be
-     * updated by the Dispatcher thread or the QRM message
+     * Keeps the track of last dispatched sequence ID. This field should be updated by the
+     * Dispatcher thread or the QRM message
-    /** Counters corresponding to this ThreadIdentifier.
-     * Note that LinkedHashMap is used instead of LinkedHashSet to save some memory.
-     * All we really put into this map is the key.
-     * This field is null until the first add.
+    /**
+     * Counters corresponding to this ThreadIdentifier. Note that LinkedHashMap is used instead of
+     * LinkedHashSet to save some memory. All we really put into this map is the key. This field is
+     * null until the first add.
-    
+
-    
+
-    
+
-    
-    /**
-     * for deserialization.  To be usable, the owningQueue of a DACE
-     * created with this method must be established.  That isn't done
-     * by deserialization.
-     */
-    public DispatchedAndCurrentEvents() {
-    }
-     * Used for debugging purpose to ensure that in no situation , for a given
-     * ThreadIdentifier the order gets violated
+     * for deserialization. To be usable, the owningQueue of a DACE created with this method must be
+     * established. That isn't done by deserialization.
+     */
+    public DispatchedAndCurrentEvents() {}
+
+    /**
+     * Used for debugging purpose to ensure that in no situation , for a given ThreadIdentifier the
+     * order gets violated
-     * <p>author Asif
-     *  
+     * <p>
+     * author Asif
+     * 
-     * This method adds to the conflation map & counters set if the add
-     * operation has not yet been dispatched. Also it is the responsibility of
-     * this method to remove the old conflated entry. As such we can assume only
-     * one thread can enter this function at a time because this DACE object
-     * gets created for every ThreadIdentifier . And a given thread (
-     * corresponding to this thread identifier) is doing operation in sequence &
-     * a new add operation in DACE cannot happen till the old one is done.
+     * This method adds to the conflation map & counters set if the add operation has not yet been
+     * dispatched. Also it is the responsibility of this method to remove the old conflated entry.
+     * As such we can assume only one thread can enter this function at a time because this DACE
+     * object gets created for every ThreadIdentifier . And a given thread ( corresponding to this
+     * thread identifier) is doing operation in sequence & a new add operation in DACE cannot happen
+     * till the old one is done.
-     * @param event
-     *          Object to be added to the queue
-     * @param sequenceID
-     *          Sequence ID of the event originating from a unqiue thread
-     *          identified by its ThreadIdentifier
+     * @param event Object to be added to the queue
+     * @param sequenceID Sequence ID of the event originating from a unqiue thread identified by its
+     *        ThreadIdentifier
-    protected boolean putObject(Conflatable event, long sequenceID) throws CacheException, InterruptedException       
-    {
-//      logger.debug("BRUCE: putObject() lastSequenceIDPut="+lastSequenceIDPut
-//          +"; adding sequenceID="+sequenceID + " for " + event);
-//      logger.info("putObject, sequenceID = " + sequenceID + "; lastSequenceIDPut = " + lastSequenceIDPut, new Exception("putObject"));
+    protected boolean putObject(Conflatable event, long sequenceID)
+        throws CacheException, InterruptedException {
+      // logger.debug("BRUCE: putObject() lastSequenceIDPut="+lastSequenceIDPut
+      // +"; adding sequenceID="+sequenceID + " for " + event);
+      // logger.info("putObject, sequenceID = " + sequenceID + "; lastSequenceIDPut = " +
+      // lastSequenceIDPut, new Exception("putObject"));
-      if (isDebugEnabled_BS && this.lastSequenceIDPut >= sequenceID && !owningQueue.puttingGIIDataInQueue) {
-        logger.trace(LogMarker.BRIDGE_SERVER, "HARegionQueue::DACE:putObject: Given sequence ID is already present ({}).\nThis may be a recovered operation via P2P or a GetInitialImage.\nlastSequenceIDPut = {} ; event = {};\n", sequenceID, lastSequenceIDPut, event);
+      if (isDebugEnabled_BS && this.lastSequenceIDPut >= sequenceID
+          && !owningQueue.puttingGIIDataInQueue) {
+        logger.trace(LogMarker.BRIDGE_SERVER,
+            "HARegionQueue::DACE:putObject: Given sequence ID is already present ({}).\nThis may be a recovered operation via P2P or a GetInitialImage.\nlastSequenceIDPut = {} ; event = {};\n",
+            sequenceID, lastSequenceIDPut, event);
-        }
-        else if (!owningQueue.puttingGIIDataInQueue) {
+        } else if (!owningQueue.puttingGIIDataInQueue) {
-            logger.trace(LogMarker.BRIDGE_SERVER, "{} eliding event with ID {}, because it is not greater than the last sequence ID ({}). The rejected event has key <{}> and value <{}>", this, event.getEventId(), this.lastSequenceIDPut, event.getKeyToConflate(), event.getValueToConflate());
+            logger.trace(LogMarker.BRIDGE_SERVER,
+                "{} eliding event with ID {}, because it is not greater than the last sequence ID ({}). The rejected event has key <{}> and value <{}>",
+                this, event.getEventId(), this.lastSequenceIDPut, event.getKeyToConflate(),
+                event.getValueToConflate());
-          //increase take side put permits instead of increasing put side permits
-          owningQueue.incrementTakeSidePutPermits();//WithoutNotify();
+          // increase take side put permits instead of increasing put side permits
+          owningQueue.incrementTakeSidePutPermits();// WithoutNotify();
-            ccn.getClientProxy(owningQueue.clientProxyID).getStatistics()
-                .incMessagesFailedQueued();
+            ccn.getClientProxy(owningQueue.clientProxyID).getStatistics().incMessagesFailedQueued();
-          
+
-        }
-        else {
+        } else {
-        owningQueue.incrementTakeSidePutPermits();//WithoutNotify();
+        owningQueue.incrementTakeSidePutPermits();// WithoutNotify();
-          ccn.getClientProxy(owningQueue.clientProxyID).getStatistics()
-              .incMessagesFailedQueued();
+          ccn.getClientProxy(owningQueue.clientProxyID).getStatistics().incMessagesFailedQueued();
-      }
-      else {
+      } else {
-        Conflatable old = (Conflatable)owningQueue.region
-            .get(oldPosition);
+        Conflatable old = (Conflatable) owningQueue.region.get(oldPosition);
-          ThreadIdentifier oldTi = HARegionQueue.getThreadIdentifier(old
-              .getEventId());
-          DispatchedAndCurrentEvents oldDace = (DispatchedAndCurrentEvents)owningQueue.eventsMap
-              .get(oldTi);
+          ThreadIdentifier oldTi = HARegionQueue.getThreadIdentifier(old.getEventId());
+          DispatchedAndCurrentEvents oldDace =
+              (DispatchedAndCurrentEvents) owningQueue.eventsMap.get(oldTi);
-    
+
-     * Destroys the the old entry ( which got replaced by the new entry due to
-     * conflation) from the availableIDs , Region & Counters set. Since this is
-     * executed within a synch block by the new entry thread, it is guaranteed
-     * that the old entry thread will exit first , placing the poistion etc in
-     * the available IDs set. Also the new entry thraed & old entry thread are
+     * Destroys the the old entry ( which got replaced by the new entry due to conflation) from the
+     * availableIDs , Region & Counters set. Since this is executed within a synch block by the new
+     * entry thread, it is guaranteed that the old entry thread will exit first , placing the
+     * poistion etc in the available IDs set. Also the new entry thraed & old entry thread are
-        throws CacheException, InterruptedException
-    {
+        throws CacheException, InterruptedException {
-        Conflatable conflatable = (Conflatable)owningQueue.region
-            .get(oldPosition);
+        Conflatable conflatable = (Conflatable) owningQueue.region.get(oldPosition);
-            owningQueue
-                .decAndRemoveFromHAContainer((HAEventWrapper)conflatable);
+            owningQueue.decAndRemoveFromHAContainer((HAEventWrapper) conflatable);
-          //if (logger.isDebugEnabled()) {
-          
+          // if (logger.isDebugEnabled()) {
+
-          if ( ! (conflatable instanceof ClientMarkerMessageImpl)) {
+          if (!(conflatable instanceof ClientMarkerMessageImpl)) {
-          }
-          else {
+          } else {
-     * Removes the Entry from the Counters Set contained in DACE & from the
-     * conflation Map. This method should be invoked only if the removal from
-     * available ID set returns true.
+     * Removes the Entry from the Counters Set contained in DACE & from the conflation Map. This
+     * method should be invoked only if the removal from available ID set returns true.
-     * @param position
-     *          Long position to be removed from the Counter Set
-     * @param key
-     *          Object used as the key in the conflation Map
-     * @param rName
-     *          String region name against which the conflation map is stored
+     * @param position Long position to be removed from the Counter Set
+     * @param key Object used as the key in the conflation Map
+     * @param rName String region name against which the conflation map is stored
-    protected void destroy(Long position, Object key, String rName)
-    {
+    protected void destroy(Long position, Object key, String rName) {
-      ConcurrentMap conflationMap = (ConcurrentMap)owningQueue.indexes.get(rName);
+      ConcurrentMap conflationMap = (ConcurrentMap) owningQueue.indexes.get(rName);
-    protected synchronized void destroy(Long position)
-    {
+    protected synchronized void destroy(Long position) {
-    
+
-     * Invoked by the Cache Listner attached on the HARegion when the entries
-     * experience expiry. This callabck is used to check whether
-     * DispatchedAndCurrentEvens object for a ThreadIdentifier is eligible for
-     * removal or not. A DACE object is removed if the last dispatched sequenec
-     * Id matches the expVal & the size of the counters set is 0
+     * Invoked by the Cache Listner attached on the HARegion when the entries experience expiry.
+     * This callabck is used to check whether DispatchedAndCurrentEvens object for a
+     * ThreadIdentifier is eligible for removal or not. A DACE object is removed if the last
+     * dispatched sequenec Id matches the expVal & the size of the counters set is 0
-     * @param expVal
-     *          long value indicating the sequence with which the
-     *          ThreadIdentifier was last updated for expiry.
-     * @param ti
-     *          ThreadIdentifier object corresponding to the thread which is
-     *          being expired ( whose DispatchedAndCurrent Events object is
-     *          being removed)
-     * @return boolean true if the ThreadIdentifier object for a given DACE was
-     *         expired .
+     * @param expVal long value indicating the sequence with which the ThreadIdentifier was last
+     *        updated for expiry.
+     * @param ti ThreadIdentifier object corresponding to the thread which is being expired ( whose
+     *        DispatchedAndCurrent Events object is being removed)
+     * @return boolean true if the ThreadIdentifier object for a given DACE was expired .
-    protected boolean expireOrUpdate(long expVal, ThreadIdentifier ti)
-    {
+    protected boolean expireOrUpdate(long expVal, ThreadIdentifier ti) {
-            try {
-              // Remove the ThreadIdentifier from the Region which was added for
-              // expiry
-              owningQueue.destroyFromQueue(ti);
-              this.lastDispatchedSequenceId = TOKEN_DESTROYED;
-              owningQueue.eventsMap.remove(ti);
-              expired = true;
-              this.owningQueue.getStatistics().decThreadIdentifiers();
+          try {
+            // Remove the ThreadIdentifier from the Region which was added for
+            // expiry
+            owningQueue.destroyFromQueue(ti);
+            this.lastDispatchedSequenceId = TOKEN_DESTROYED;
+            owningQueue.eventsMap.remove(ti);
+            expired = true;
+            this.owningQueue.getStatistics().decThreadIdentifiers();
+          } catch (RegionDestroyedException ignore) {
+            if (!owningQueue.destroyInProgress && logger.isDebugEnabled()) {
+              logger.debug(
+                  "DispatchedAndCurrentEvents::expireOrUpdate: Queue found destroyed while removing expiry entry for ThreadIdentifier={} and expiry value={}",
+                  ti, expVal, ignore);
-            catch (RegionDestroyedException ignore) {
-              if (!owningQueue.destroyInProgress && logger.isDebugEnabled()) {
-                logger.debug("DispatchedAndCurrentEvents::expireOrUpdate: Queue found destroyed while removing expiry entry for ThreadIdentifier={} and expiry value={}", ti, expVal, ignore);
-              }
-            }
-            catch (EntryNotFoundException enfe) {
-              if (!owningQueue.destroyInProgress) {
-                logger.error(LocalizedMessage.create(LocalizedStrings.HARegionQueue_DISPATCHEDANDCURRENTEVENTSEXPIREORUPDATE_UNEXPECTEDLY_ENCOUNTERED_EXCEPTION_WHILE_REMOVING_EXPIRY_ENTRY_FOR_THREADIDENTIFIER_0_AND_EXPIRY_VALUE_1, new Object[] {ti, Long.valueOf(expVal), enfe}));
-              }
+          } catch (EntryNotFoundException enfe) {
+            if (!owningQueue.destroyInProgress) {
+              logger.error(LocalizedMessage.create(
+                  LocalizedStrings.HARegionQueue_DISPATCHEDANDCURRENTEVENTSEXPIREORUPDATE_UNEXPECTEDLY_ENCOUNTERED_EXCEPTION_WHILE_REMOVING_EXPIRY_ENTRY_FOR_THREADIDENTIFIER_0_AND_EXPIRY_VALUE_1,
+                  new Object[] {ti, Long.valueOf(expVal), enfe}));
+      }
-          owningQueue.region.put(ti, Long.valueOf(
-              this.lastDispatchedSequenceId));
-        }
-        catch (CancelException e) {
+          owningQueue.region.put(ti, Long.valueOf(this.lastDispatchedSequenceId));
+        } catch (CancelException e) {
-        }
-        catch (Exception e) {
+        } catch (Exception e) {
-            logger.error(LocalizedMessage.create(LocalizedStrings.HARegionQueue_DISPATCHEDANDCURRENTEVENTSEXPIREORUPDATE_UNEXPECTEDLY_ENCOUNTERED_EXCEPTION_WHILE_UPDATING_EXPIRY_ID_FOR_THREADIDENTIFIER_0, ti), e);
+            logger.error(LocalizedMessage.create(
+                LocalizedStrings.HARegionQueue_DISPATCHEDANDCURRENTEVENTSEXPIREORUPDATE_UNEXPECTEDLY_ENCOUNTERED_EXCEPTION_WHILE_UPDATING_EXPIRY_ID_FOR_THREADIDENTIFIER_0,
+                ti), e);
-     * Invoked by the by the QRM message . This method sets the LastDispatched
-     * sequence ID in the DACE & destroys all the sequence Ids which are less
-     * than the last dispatched sequence ID. At a time only one thread operates
-     * on it which is accomplished by the QRM_LOCK. The lock on the DACE is
-     * minimized by copying the Counters Set & then identifying the positions
-     * which need to be removed
+     * Invoked by the by the QRM message . This method sets the LastDispatched sequence ID in the
+     * DACE & destroys all the sequence Ids which are less than the last dispatched sequence ID. At
+     * a time only one thread operates on it which is accomplished by the QRM_LOCK. The lock on the
+     * DACE is minimized by copying the Counters Set & then identifying the positions which need to
+     * be removed
-     * @param lastDispatchedSeqId
-     *          long indicating the last dispatched ID which gets set in a DACE
+     * @param lastDispatchedSeqId long indicating the last dispatched ID which gets set in a DACE
-        throws CacheException, InterruptedException
-    {
+        throws CacheException, InterruptedException {
-        
+
-        for (int i=0; i < countersCopy.length; i++) {
-          Long counter = countersCopy[i];
-          Conflatable event = (Conflatable)owningQueue.region
-              .get(counter);
-          if (event == null) {
-//            this.destroy(counter); event already destroyed?
-            continue;
-          }
-
-          long seqId = event.getEventId().getSequenceID();
-          if (seqId > this.lastDispatchedSequenceId) {
-            break; // we're done
-          }
-
-          if (!owningQueue.destroyFromAvailableIDsAndRegion(counter)) {
-            continue; // still valid
-          }
-
-          if (event instanceof HAEventWrapper) {
-            if (((HAEventWrapper)event).getReferenceCount() == 0 && logger.isDebugEnabled()) {
-              logger.debug("Reference count is already zero for event {}", event.getEventId());
+          for (int i = 0; i < countersCopy.length; i++) {
+            Long counter = countersCopy[i];
+            Conflatable event = (Conflatable) owningQueue.region.get(counter);
+            if (event == null) {
+              // this.destroy(counter); event already destroyed?
+              continue;
-            owningQueue.decAndRemoveFromHAContainer((HAEventWrapper)event);
-          }
-          
-          // At this point we know we're going to remove the event,
-          // so increment the statistic
-          owningQueue.stats.incEventsRemovedByQrm();
-          if (!owningQueue.shouldBeConflated(event)) {
-            // Just update the counters set
-            this.destroy(counter);
-            continue; // we're done
-          }
+            long seqId = event.getEventId().getSequenceID();
+            if (seqId > this.lastDispatchedSequenceId) {
+              break; // we're done
+            }
-          Object key = event.getKeyToConflate();
-          String r = event.getRegionToConflate();
-          // Update the counters set and the conflation map.
-          this.destroy(counter, key, r);
-        } // for
+            if (!owningQueue.destroyFromAvailableIDsAndRegion(counter)) {
+              continue; // still valid
+            }
+
+            if (event instanceof HAEventWrapper) {
+              if (((HAEventWrapper) event).getReferenceCount() == 0 && logger.isDebugEnabled()) {
+                logger.debug("Reference count is already zero for event {}", event.getEventId());
+              }
+              owningQueue.decAndRemoveFromHAContainer((HAEventWrapper) event);
+            }
+
+            // At this point we know we're going to remove the event,
+            // so increment the statistic
+            owningQueue.stats.incEventsRemovedByQrm();
+
+            if (!owningQueue.shouldBeConflated(event)) {
+              // Just update the counters set
+              this.destroy(counter);
+              continue; // we're done
+            }
+
+            Object key = event.getKeyToConflate();
+            String r = event.getRegionToConflate();
+            // Update the counters set and the conflation map.
+            this.destroy(counter, key, r);
+          } // for
-     * Invoked by the by the remove method . This method sets the LastDispatched
-     * sequence ID in the DACE & destroys all the sequence Ids which are less
-     * than the last dispatched sequence ID. The lock on the DACE is minimized
-     * by copying the Counters Set & then identifying the positions which need
-     * to be removed
+     * Invoked by the by the remove method . This method sets the LastDispatched sequence ID in the
+     * DACE & destroys all the sequence Ids which are less than the last dispatched sequence ID. The
+     * lock on the DACE is minimized by copying the Counters Set & then identifying the positions
+     * which need to be removed
-     * @param removedEventInfoList
-     *          List containing objects of RemovedEventInfo class representing
-     *          Events which have been peeked & are now candidate for removal.
-     *          It has to be guaranteed that the sequence IDs of all the other
-     *          counters is less than the last dispatched
-     * @param lastDispatchedSeqId
-     *          long indicating the last dispatched ID which gets set in a DACE
+     * @param removedEventInfoList List containing objects of RemovedEventInfo class representing
+     *        Events which have been peeked & are now candidate for removal. It has to be guaranteed
+     *        that the sequence IDs of all the other counters is less than the last dispatched
+     * @param lastDispatchedSeqId long indicating the last dispatched ID which gets set in a DACE
-        long lastDispatchedSeqId) throws CacheException, InterruptedException
-    {
-     
+        long lastDispatchedSeqId) throws CacheException, InterruptedException {
+
-        RemovedEventInfo info = (RemovedEventInfo)it.next();
+        RemovedEventInfo info = (RemovedEventInfo) it.next();
-        Conflatable wrapper = (Conflatable)owningQueue.region.get(counter);
+        Conflatable wrapper = (Conflatable) owningQueue.region.get(counter);
-          }
-          else {
+          } else {
-            owningQueue
-                .decAndRemoveFromHAContainer((HAEventWrapper)wrapper);
+            owningQueue.decAndRemoveFromHAContainer((HAEventWrapper) wrapper);
-        }else{
+        } else {
-     * This method is invoked by the take function. Before invoking it , the
-     * take has already removed the poistion from the available IDs set.
+     * This method is invoked by the take function. Before invoking it , the take has already
+     * removed the poistion from the available IDs set.
-     * @param info
-     *          Data object of type RemovedEventInfo which contains info like
-     *          position countre, key & region name
-     * @param sequenceID
-     *          sequence ID of the event being removed from HARegionQueue
+     * @param info Data object of type RemovedEventInfo which contains info like position countre,
+     *        key & region name
+     * @param sequenceID sequence ID of the event being removed from HARegionQueue
-    protected void removeEventAndSetSequenceID(RemovedEventInfo info,
-        long sequenceID)
-    {
+    protected void removeEventAndSetSequenceID(RemovedEventInfo info, long sequenceID) {
-      }
-      catch (EntryNotFoundException enfe) {
+      } catch (EntryNotFoundException enfe) {
-          logger.error(LocalizedMessage.create(LocalizedStrings.HARegionQueue_DACEREMOVEEVENTANDSETSEQUENCEID_SINCE_THE_EVENT_WAS_SUCCESSULY_REMOVED_BY_TAKE_OPERATION_IT_SHOULD_HAVE_EXISTED_IN_THE_REGION), enfe);
+          logger.error(
+              LocalizedMessage.create(
+                  LocalizedStrings.HARegionQueue_DACEREMOVEEVENTANDSETSEQUENCEID_SINCE_THE_EVENT_WAS_SUCCESSULY_REMOVED_BY_TAKE_OPERATION_IT_SHOULD_HAVE_EXISTED_IN_THE_REGION),
+              enfe);
-      }
-      else {
+      } else {
-    /* (non-Javadoc)
+    /*
+     * (non-Javadoc)
+     * 
-    public void fromData(DataInput in) throws IOException,
-        ClassNotFoundException {
+    public void fromData(DataInput in) throws IOException, ClassNotFoundException {
-    /* (non-Javadoc)
+    /*
+     * (non-Javadoc)
+     * 
-    /* (non-Javadoc)
+    /*
+     * (non-Javadoc)
+     * 
-    
+
-      return "DACE(put="+this.lastSequenceIDPut
-             +"sent="+this.lastDispatchedSequenceId+")";
+      return "DACE(put=" + this.lastSequenceIDPut + "sent=" + this.lastDispatchedSequenceId + ")";
-  public void remove(int top)
-  {
-    throw new UnsupportedOperationException(LocalizedStrings.HARegionQueue_HAREGIONQUEUE_AND_ITS_DERIVED_CLASS_DO_NOT_SUPPORT_THIS_OPERATION.toLocalizedString());
+  public void remove(int top) {
+    throw new UnsupportedOperationException(
+        LocalizedStrings.HARegionQueue_HAREGIONQUEUE_AND_ITS_DERIVED_CLASS_DO_NOT_SUPPORT_THIS_OPERATION
+            .toLocalizedString());
-   * destroys the underlying HARegion and removes its reference from the
-   * dispatched messages map
+   * destroys the underlying HARegion and removes its reference from the dispatched messages map
-  public void destroy() throws CacheWriterException
-  {
+  public void destroy() throws CacheWriterException {
-    Map tempDispatchedMessagesMap = dispatchedMessagesMap ; 
+    Map tempDispatchedMessagesMap = dispatchedMessagesMap;
-    }   
+    }
-      }
-      catch (RegionDestroyedException e) {
+      } catch (RegionDestroyedException e) {
-      }
-      catch (CancelException e) {
+      } catch (CancelException e) {
-      
+
-      }
-      catch (RegionDestroyedException e) {
+      } catch (RegionDestroyedException e) {
+        // keep going
+      } catch (CancelException e) {
-      catch (CancelException e) {
-        // keep going
-      }
-      ((HAContainerWrapper)haContainer).removeProxy(regionName);
-        }
-    finally {
+      ((HAContainerWrapper) haContainer).removeProxy(regionName);
+    } finally {
-   * If the event is an instance of HAEventWrapper, put it into the haContainer
-   * and then into the ha region. Otherwise, simply put it into the ha region.
+   * If the event is an instance of HAEventWrapper, put it into the haContainer and then into the ha
+   * region. Otherwise, simply put it into the ha region.
-      HAEventWrapper haEventWrapper = (HAEventWrapper)event;
+      HAEventWrapper haEventWrapper = (HAEventWrapper) event;
-        }
-        else {
+        } else {
-          //synchronized (this.haContainer) {
+          // synchronized (this.haContainer) {
-            ClientUpdateMessageImpl old = (ClientUpdateMessageImpl) ((HAContainerWrapper) this.haContainer).putIfAbsent(haEventWrapper,
-                haEventWrapper.getClientUpdateMessage());
+            ClientUpdateMessageImpl old =
+                (ClientUpdateMessageImpl) ((HAContainerWrapper) this.haContainer)
+                    .putIfAbsent(haEventWrapper, haEventWrapper.getClientUpdateMessage());
-              original = (HAEventWrapper) ((HAContainerWrapper) this.haContainer).getKey(haEventWrapper);
+              original =
+                  (HAEventWrapper) ((HAContainerWrapper) this.haContainer).getKey(haEventWrapper);
-                  addClientCQsAndInterestList(old, haEventWrapper, this.haContainer, this.regionName);
+                  addClientCQsAndInterestList(old, haEventWrapper, this.haContainer,
+                      this.regionName);
-          /*  entry = (Map.Entry)((HAContainerWrapper)this.haContainer)
-                .getEntry(haEventWrapper);
-            if (entry == null) {
-              entryFound = false;
-              putEntryConditionallyIntoHAContainer(haEventWrapper);
-            }
-            else {
-              entryFound = true;
-              // Do not assign entry.getKey() to haEventWrapper right now.
-              ((HAEventWrapper)entry.getKey()).incAndGetReferenceCount();
-            }
-          }//haContainer synchronized ends
-          if (entryFound) {
-            addClientCQsAndInterestList(entry, haEventWrapper, haContainer,
-                regionName);
-            haEventWrapper = (HAEventWrapper)entry.getKey();
-          }
-          else { // entry not found
-            if (!haEventWrapper.getPutInProgress()) {
-              // This means that this is a GII'ed event. Hence we must
-              // explicitly set 'clientUpdateMessage' to null.
-              haEventWrapper.setClientUpdateMessage(null);
-            }
-            haEventWrapper.setIsRefFromHAContainer(true);
-          }*/
+          /*
+           * entry = (Map.Entry)((HAContainerWrapper)this.haContainer) .getEntry(haEventWrapper); if
+           * (entry == null) { entryFound = false;
+           * putEntryConditionallyIntoHAContainer(haEventWrapper); } else { entryFound = true; // Do
+           * not assign entry.getKey() to haEventWrapper right now.
+           * ((HAEventWrapper)entry.getKey()).incAndGetReferenceCount(); } }//haContainer
+           * synchronized ends if (entryFound) { addClientCQsAndInterestList(entry, haEventWrapper,
+           * haContainer, regionName); haEventWrapper = (HAEventWrapper)entry.getKey(); } else { //
+           * entry not found if (!haEventWrapper.getPutInProgress()) { // This means that this is a
+           * GII'ed event. Hence we must // explicitly set 'clientUpdateMessage' to null.
+           * haEventWrapper.setClientUpdateMessage(null); }
+           * haEventWrapper.setIsRefFromHAContainer(true); }
+           */
-//      else{
-//        if(!haEventWrapper.getIsRefFromHAContainer()){
-//          haEventWrapper =(HAEventWrapper)((HAContainerWrapper)haContainer).getKey(haEventWrapper);
-//        }
-//      }
+      // else{
+      // if(!haEventWrapper.getIsRefFromHAContainer()){
+      // haEventWrapper =(HAEventWrapper)((HAContainerWrapper)haContainer).getKey(haEventWrapper);
+      // }
+      // }
-//      logger.info(LocalizedStrings.DEBUG, "added message at position " + position);
-    }
-    else { // (event instanceof ClientMarkerMessageImpl OR ConflatableObject OR ClientInstantiatorMessage)
+      // logger.info(LocalizedStrings.DEBUG, "added message at position " + position);
+    } else { // (event instanceof ClientMarkerMessageImpl OR ConflatableObject OR
+             // ClientInstantiatorMessage)
-//      logger.info(LocalizedStrings.DEBUG, "added non-msg at position " + position);
+      // logger.info(LocalizedStrings.DEBUG, "added non-msg at position " + position);
-  
-  public static void addClientCQsAndInterestList(ClientUpdateMessageImpl msg, HAEventWrapper haEventWrapper, Map haContainer, String regionName) {
+
+  public static void addClientCQsAndInterestList(ClientUpdateMessageImpl msg,
+      HAEventWrapper haEventWrapper, Map haContainer, String regionName) {
-    ClientUpdateMessageImpl clientMsg = (ClientUpdateMessageImpl) haEventWrapper.getClientUpdateMessage();
+    ClientUpdateMessageImpl clientMsg =
+        (ClientUpdateMessageImpl) haEventWrapper.getClientUpdateMessage();
-  
+
-   * If the wrapper's referenceCount becomes 1 after increment, then set this
-   * haEventWrapper and its clientUpdateMessage into the haContainer as <key,
-   * value>.
+   * If the wrapper's referenceCount becomes 1 after increment, then set this haEventWrapper and its
+   * clientUpdateMessage into the haContainer as <key, value>.
-   * @param haEventWrapper
-   *          An instance of <code>HAEventWrapper</code>
+   * @param haEventWrapper An instance of <code>HAEventWrapper</code>
-  protected void putEntryConditionallyIntoHAContainer(
-      HAEventWrapper haEventWrapper) {
+  protected void putEntryConditionallyIntoHAContainer(HAEventWrapper haEventWrapper) {
-//      if (logger.isDebugEnabled()) {
-//        logger.fine("Putting event in haContainer: " + haEventWrapper);
-//      }
+      // if (logger.isDebugEnabled()) {
+      // logger.fine("Putting event in haContainer: " + haEventWrapper);
+      // }
-      this.haContainer.put(haEventWrapper, haEventWrapper
-          .getClientUpdateMessage());
+      this.haContainer.put(haEventWrapper, haEventWrapper.getClientUpdateMessage());
+   * 
-  protected int availableIDsSize()
-  {
+  protected int availableIDsSize() {
-  
+
+   * 
-  protected Object[] availableIDsArray()
-  {
+  protected Object[] availableIDsArray() {
-  
+
-  
+
-  
+
-  
+
-   * Called from destroy(), this method decrements the referenceCount of all the
-   * HAEventWrapper instances held by this queue. Also, removes those instances
-   * whose referenceCount becomes zero.
+   * Called from destroy(), this method decrements the referenceCount of all the HAEventWrapper
+   * instances held by this queue. Also, removes those instances whose referenceCount becomes zero.
-  private void updateHAContainer()
-  {
+  private void updateHAContainer() {
-      }
-      finally {
+      } finally {
-      if(wrapperArray != null) {
+      if (wrapperArray != null) {
-        for(int i=0; i<wrapperArray.length; i++) {
+        for (int i = 0; i < wrapperArray.length; i++) {
-                Conflatable conflatable = (Conflatable)iter.next();
+                Conflatable conflatable = (Conflatable) iter.next();
-                  HARegionQueue.this
-                      .decAndRemoveFromHAContainer((HAEventWrapper)conflatable);
+                  HARegionQueue.this.decAndRemoveFromHAContainer((HAEventWrapper) conflatable);
-            }
-            catch (CancelException e) {
+            } catch (CancelException e) {
-            }
-            catch (Exception e) {
+            } catch (Exception e) {
-                logger.debug("Exception in regionCleanupTask thread of HARegionQueue.updateHAContainer$run()", e);
+                logger.debug(
+                    "Exception in regionCleanupTask thread of HARegionQueue.updateHAContainer$run()",
+                    e);
-    }
-    catch (CancelException e) {
+    } catch (CancelException e) {
-      
+
-      
-      // If we get back, this is Really Weird.  Treat it like the
+
+      // If we get back, this is Really Weird. Treat it like the
-      logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_TASK_TO_DECREMENT_THE_REF_COUNT_MAY_NOT_HAVE_BEEN_STARTED), e);
+      logger.warn(
+          LocalizedMessage.create(
+              LocalizedStrings.HARegionQueue_TASK_TO_DECREMENT_THE_REF_COUNT_MAY_NOT_HAVE_BEEN_STARTED),
+          e);
-   * If the conflatable is an instance of HAEventWrapper, and if the
-   * corresponding entry is present in the haContainer, then decrements its
-   * reference count. If the decremented ref count is zero and put is not in
-   * progress, removes the entry from the haContainer, before returning the
+   * If the conflatable is an instance of HAEventWrapper, and if the corresponding entry is present
+   * in the haContainer, then decrements its reference count. If the decremented ref count is zero
+   * and put is not in progress, removes the entry from the haContainer, before returning the
-  public Conflatable getAndRemoveFromHAContainer(Conflatable conflatable) 
-  {
+  public Conflatable getAndRemoveFromHAContainer(Conflatable conflatable) {
-      HAEventWrapper wrapper = (HAEventWrapper)conflatable;
-      msg = (Conflatable)HARegionQueue.this.haContainer.get(wrapper);
+      HAEventWrapper wrapper = (HAEventWrapper) conflatable;
+      msg = (Conflatable) HARegionQueue.this.haContainer.get(wrapper);
-    }
-    else {
+    } else {
-  
+
-   * The wrapper passed here must be the authentic wrapper, i.e. it must be the
-   * one referred by the HARegion underlying this queue. <br>
-   * Decrements wrapper's reference count by one. If the decremented ref count
-   * is zero and put is not in progress, removes the entry from the haContainer.
+   * The wrapper passed here must be the authentic wrapper, i.e. it must be the one referred by the
+   * HARegion underlying this queue. <br>
+   * Decrements wrapper's reference count by one. If the decremented ref count is zero and put is
+   * not in progress, removes the entry from the haContainer.
-  public void decAndRemoveFromHAContainer(HAEventWrapper wrapper) 
-  {
-    if (wrapper.decAndGetReferenceCount() == 0L
-        && !wrapper.getPutInProgress()) {
+  public void decAndRemoveFromHAContainer(HAEventWrapper wrapper) {
+    if (wrapper.decAndGetReferenceCount() == 0L && !wrapper.getPutInProgress()) {
-            logger.debug("Removing event from {}: {}", this.region.getFullPath(), wrapper.getEventId());
+            logger.debug("Removing event from {}: {}", this.region.getFullPath(),
+                wrapper.getEventId());
-  
+
-   * @return the true if dispatcher for this HARegionQueue is active(primary
-   *         node)
+   * @return the true if dispatcher for this HARegionQueue is active(primary node)
-  public boolean isPrimary()
-  {
+  public boolean isPrimary() {
-  
+
-   * Set whether the dispatcher of this node is active or not (i.e. primary or
-   * secondary node). If <code>flag</code> is set to <code>true</code>, disables 
-   * Entry Expiry Tasks.
+   * Set whether the dispatcher of this node is active or not (i.e. primary or secondary node). If
+   * <code>flag</code> is set to <code>true</code>, disables Entry Expiry Tasks.
-   * @param flag
-   *          the value to set isPrimary to
+   * @param flag the value to set isPrimary to
-    if (flag) {//fix for #41878
+    if (flag) {// fix for #41878
-    }    
+    }
-  
+
-                                      ExpirationAction.LOCAL_INVALIDATE);
+          ExpirationAction.LOCAL_INVALIDATE);
-      logger.info(LocalizedMessage.create(LocalizedStrings.HARegionQueue_ENYTRY_EXPIRY_TASKS_DISABLED_BECAUSE_QUEUE_BECAME_PRIMARY_OLD_MSG_TTL_0, new Object[] {Integer.valueOf(oldTimeToLive)}));
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.HARegionQueue_ENYTRY_EXPIRY_TASKS_DISABLED_BECAUSE_QUEUE_BECAME_PRIMARY_OLD_MSG_TTL_0,
+          new Object[] {Integer.valueOf(oldTimeToLive)}));
-  
+
-   * Set client conflation override 
+   * Set client conflation override
+   * 
-    if (value != HandShake.CONFLATION_OFF && 
-        value != HandShake.CONFLATION_ON &&
-        value != HandShake.CONFLATION_DEFAULT
-        ) {
+    if (value != HandShake.CONFLATION_OFF && value != HandShake.CONFLATION_ON
+        && value != HandShake.CONFLATION_DEFAULT) {
-  
-  public void initializeTransients()
-  {
-  }
+
+  public void initializeTransients() {}
-  public boolean isClientSlowReciever(){
+
+  public boolean isClientSlowReciever() {
-  
-    /**
-     * A simple check to validate that the peek() method has been executed
-     * as it initializes some structures used by other methods.
-     * 
-     * @return true if peeking returns a non-null value
-     */
-    public boolean isPeekInitialized(){
-      return HARegionQueue.peekedEventsContext.get()!=null;
-      
+
+  /**
+   * A simple check to validate that the peek() method has been executed as it initializes some
+   * structures used by other methods.
+   * 
+   * @return true if peeking returns a non-null value
+   */
+  public boolean isPeekInitialized() {
+    return HARegionQueue.peekedEventsContext.get() != null;
+
-  
+
+
- * A wrapper class whose underlying map gets replaced with a fresh one when QRM
- * thread is operating on it. This wrapper acts as a means of communication
- * between the QRM thread & the MapWrapper object contained in the HARegionQueue
+ * A wrapper class whose underlying map gets replaced with a fresh one when QRM thread is operating
+ * on it. This wrapper acts as a means of communication between the QRM thread & the MapWrapper
+ * object contained in the HARegionQueue
- * <p>author ashahid
+ * <p>
+ * author ashahid
-class MapWrapper
-{
+class MapWrapper {
-  
+
-  
+
-  void put(Object key, Object o)
-  {
+  void put(Object key, Object o) {
+
- * A wrapper class that has counter, key and the region-name for an event which
- * was peeked and needs to be removed. The key and regionName fields will be set
- * only if conflation is true for the event.
+ * A wrapper class that has counter, key and the region-name for an event which was peeked and needs
+ * to be removed. The key and regionName fields will be set only if conflation is true for the
+ * event.
- * <p>author dpatel
- *  
+ * <p>
+ * author dpatel
+ * 
-class RemovedEventInfo
-{
+class RemovedEventInfo {
+
-class ThreadIdentifierCustomExpiry implements CustomExpiry
-{
-  private static final ExpirationAttributes DEFAULT_THREAD_ID_EXP_ATTS = new ExpirationAttributes(HARegionQueue.DEFAULT_THREAD_ID_EXPIRY_TIME, ExpirationAction.LOCAL_INVALIDATE);
+class ThreadIdentifierCustomExpiry implements CustomExpiry {
+  private static final ExpirationAttributes DEFAULT_THREAD_ID_EXP_ATTS = new ExpirationAttributes(
+      HARegionQueue.DEFAULT_THREAD_ID_EXPIRY_TIME, ExpirationAction.LOCAL_INVALIDATE);
-  
+
-          // save the expiration attributes in a static to prevent tests from creating lots of instances.
+          // save the expiration attributes in a static to prevent tests from creating lots of
+          // instances.
