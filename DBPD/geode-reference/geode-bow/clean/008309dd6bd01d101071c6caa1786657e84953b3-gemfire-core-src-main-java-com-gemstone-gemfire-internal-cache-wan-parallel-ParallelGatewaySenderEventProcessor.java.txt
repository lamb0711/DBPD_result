Merge branch 'release/1.0.0-incubating.M1'

-/*=========================================================================
- * Copyright (c) 2010-2014 Pivotal Software, Inc. All Rights Reserved.
- * This product is protected by U.S. and international copyright
- * and intellectual property laws. Pivotal products are covered by
- * one or more patents listed at http://www.pivotal.io/patents.
- *=========================================================================
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSBucketRegionQueue;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSGatewayEventImpl;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSParallelGatewaySenderQueue;
+import com.gemstone.gemfire.internal.cache.Conflatable;
+import com.gemstone.gemfire.internal.cache.ForceReattemptException;
+import com.gemstone.gemfire.internal.cache.PartitionedRegion;
+import com.gemstone.gemfire.internal.size.SingleObjectSizer;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.concurrent.BlockingQueue;
+    if (sender.getIsHDFSQueue())
+      this.queue = new HDFSParallelGatewaySenderQueue(this.sender, targetRs, this.index, this.nDispatcher);
+    else
-    GatewayQueueEvent gatewayQueueEvent = null;
+    GatewaySenderEventImpl gatewayQueueEvent = null;
+	 if (!sender.getIsHDFSQueue())
+    else
+      gatewayQueueEvent = new HDFSGatewayEventImpl(operation,
+          event, substituteValue, true, eventID.getBucketID());
-      if (getSender().beforeEnque(gatewayQueueEvent)) {
+      if (getSender().beforeEnqueue(gatewayQueueEvent)) {
+          gatewayQueueEvent = null;
-      //merge44012: this try finally has came from cheetah. this change is related to offheap.
-//      if (gatewayQueueEvent != null) {
-//        // it was not queued for some reason
-//         gatewayQueueEvent.release();
-//      }
+      if (gatewayQueueEvent != null) {
+        // it was not queued for some reason
+        gatewayQueueEvent.release();
+      }
+  public void clear(PartitionedRegion pr, int bucketId) {
+  	((ParallelGatewaySenderQueue)this.queue).clear(pr, bucketId);
+  }
+  
+  /*public int size(PartitionedRegion pr, int bucketId)
+      throws ForceReattemptException {
+  	return ((ParallelGatewaySenderQueue)this.queue).size(pr, bucketId);
+  }*/
+  
+  public void notifyEventProcessorIfRequired(int bucketId) {
+    ((ParallelGatewaySenderQueue)this.queue).notifyEventProcessorIfRequired();
+  }
+  
+  public BlockingQueue<GatewaySenderEventImpl> getBucketTmpQueue(int bucketId) {
+    return ((ParallelGatewaySenderQueue)this.queue).getBucketToTempQueueMap().get(bucketId);
+  }
+  
+  public PartitionedRegion getRegion(String prRegionName) {
+    return ((ParallelGatewaySenderQueue)this.queue).getRegion(prRegionName);
+  }
+  
+  public void removeShadowPR(String prRegionName) {
+  	((ParallelGatewaySenderQueue)this.queue).removeShadowPR(prRegionName);
+  }
+  
+  public void conflateEvent(Conflatable conflatableObject, int bucketId,
+      Long tailKey) {
+  	((ParallelGatewaySenderQueue)this.queue).conflateEvent(conflatableObject, bucketId, tailKey);
+  }
+  
+  public HDFSGatewayEventImpl get(PartitionedRegion region, byte[] regionKey,
+    int bucketId) throws ForceReattemptException {
+    return ((HDFSParallelGatewaySenderQueue)this.queue).get(region, regionKey, bucketId);
+  }
+  
+  public HDFSBucketRegionQueue getBucketRegionQueue(PartitionedRegion region,
+    int bucketId) throws ForceReattemptException {
+  	return ((HDFSParallelGatewaySenderQueue)this.queue).getBucketRegionQueue(region, bucketId);
+  }
+  
+  public void addShadowPartitionedRegionForUserPR(PartitionedRegion pr) {
+	// TODO Auto-generated method stub
+	((ParallelGatewaySenderQueue)this.queue).addShadowPartitionedRegionForUserPR(pr);
+  }
+  
+  public void addShadowPartitionedRegionForUserRR(DistributedRegion userRegion) {
+	// TODO Auto-generated method stub
+	((ParallelGatewaySenderQueue)this.queue).addShadowPartitionedRegionForUserRR(userRegion);
+  }
+  
