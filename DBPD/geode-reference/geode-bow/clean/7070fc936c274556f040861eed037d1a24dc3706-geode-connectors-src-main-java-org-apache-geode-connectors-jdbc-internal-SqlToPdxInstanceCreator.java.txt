GEODE-4872: handle Blob when reading from JDBC (#1692)

When a pdx BYTE_ARRAY or OBJECT field is read and
the column type is BLOB, getBlob is called and
its value is converted to a byte[].

+import java.sql.Blob;
+  private final PdxInstanceFactory factory;
+    this.factory = createPdxInstanceFactory();
-    PdxInstanceFactory factory = getPdxInstanceFactory(cache, regionMapping);
-    PdxInstance pdxInstance = null;
-    if (resultSet.next()) {
-      ResultSetMetaData metaData = resultSet.getMetaData();
-      int ColumnsNumber = metaData.getColumnCount();
-      TypeRegistry typeRegistry = cache.getPdxRegistry();
-      for (int i = 1; i <= ColumnsNumber; i++) {
-        String columnName = metaData.getColumnName(i);
-        if (regionMapping.isPrimaryKeyInValue()
-            || !tableMetaData.getKeyColumnName().equalsIgnoreCase(columnName)) {
-          String fieldName = regionMapping.getFieldNameForColumn(columnName, typeRegistry);
-          FieldType fieldType =
-              getFieldType(typeRegistry, regionMapping.getPdxClassName(), fieldName);
-          writeField(factory, resultSet, i, fieldName, fieldType, columnName);
-        }
-      }
-      if (resultSet.next()) {
-        throw new JdbcConnectorException(
-            "Multiple rows returned for query: " + resultSet.getStatement().toString());
-      }
-      pdxInstance = factory.create();
+    if (!resultSet.next()) {
+      return null;
-    return pdxInstance;
+    TypeRegistry typeRegistry = cache.getPdxRegistry();
+    ResultSetMetaData metaData = resultSet.getMetaData();
+    final int columnCount = metaData.getColumnCount();
+    for (int i = 1; i <= columnCount; i++) {
+      String columnName = metaData.getColumnName(i);
+      if (regionMapping.isPrimaryKeyInValue()
+          || !tableMetaData.getKeyColumnName().equalsIgnoreCase(columnName)) {
+        String fieldName = regionMapping.getFieldNameForColumn(columnName, typeRegistry);
+        FieldType fieldType = getFieldType(typeRegistry, fieldName);
+        writeField(columnName, i, fieldName, fieldType);
+      }
+    }
+    if (resultSet.next()) {
+      throw new JdbcConnectorException(
+          "Multiple rows returned for query: " + resultSet.getStatement());
+    }
+    return factory.create();
-  private PdxInstanceFactory getPdxInstanceFactory(InternalCache cache,
-      RegionMapping regionMapping) {
+  private PdxInstanceFactory createPdxInstanceFactory() {
-    PdxInstanceFactory factory;
-      factory = cache.createPdxInstanceFactory(valueClassName);
+      return cache.createPdxInstanceFactory(valueClassName);
-      factory = cache.createPdxInstanceFactory("no class", false);
+      return cache.createPdxInstanceFactory("no class", false);
-    return factory;
-  private void writeField(PdxInstanceFactory factory, ResultSet resultSet, int columnIndex,
-      String fieldName, FieldType fieldType, String columnName) throws SQLException {
+  private void writeField(String columnName, int columnIndex, String fieldName, FieldType fieldType)
+      throws SQLException {
-        factory.writeByteArray(fieldName, resultSet.getBytes(columnIndex));
+        byte[] byteData;
+        if (isBlobColumn(columnName)) {
+          byteData = getBlobData(columnIndex);
+        } else {
+          byteData = resultSet.getBytes(columnIndex);
+        }
+        factory.writeByteArray(fieldName, byteData);
-      case OBJECT:
-        Object v = resultSet.getObject(columnIndex);
-        if (v instanceof java.util.Date) {
-          if (v instanceof java.sql.Date) {
-            java.sql.Date sqlDate = (java.sql.Date) v;
-            v = new java.util.Date(sqlDate.getTime());
-          } else if (v instanceof java.sql.Time) {
-            java.sql.Time sqlTime = (java.sql.Time) v;
-            v = new java.util.Date(sqlTime.getTime());
-          } else if (v instanceof java.sql.Timestamp) {
-            java.sql.Timestamp sqlTimestamp = (java.sql.Timestamp) v;
-            v = new java.util.Date(sqlTimestamp.getTime());
+      case OBJECT: {
+        Object v;
+        if (isBlobColumn(columnName)) {
+          v = getBlobData(columnIndex);
+        } else {
+          v = resultSet.getObject(columnIndex);
+          if (v instanceof java.util.Date) {
+            if (v instanceof java.sql.Date) {
+              java.sql.Date sqlDate = (java.sql.Date) v;
+              v = new java.util.Date(sqlDate.getTime());
+            } else if (v instanceof java.sql.Time) {
+              java.sql.Time sqlTime = (java.sql.Time) v;
+              v = new java.util.Date(sqlTime.getTime());
+            } else if (v instanceof java.sql.Timestamp) {
+              java.sql.Timestamp sqlTimestamp = (java.sql.Timestamp) v;
+              v = new java.util.Date(sqlTimestamp.getTime());
+            }
+      }
+    }
+  }
+
+  private boolean isBlobColumn(String columnName) throws SQLException {
+    return this.tableMetaData.getColumnDataType(columnName) == Types.BLOB;
+  }
+
+  /**
+   * If the given column contains a Blob returns its data as a byte array;
+   * otherwise return null.
+   *
+   * @throws JdbcConnectorException if blob is too big to fit in a byte array
+   */
+  private byte[] getBlobData(int columnIndex) throws SQLException {
+    Blob blob = resultSet.getBlob(columnIndex);
+    if (blob == null) {
+      return null;
+    }
+    try {
+      long blobLength = blob.length();
+      if (blobLength > Integer.MAX_VALUE) {
+        throw new JdbcConnectorException(
+            "Blob of length " + blobLength + " is too big to be converted to a byte array.");
+      }
+      return blob.getBytes(1, (int) blobLength);
+    } finally {
+      blob.free();
-  private FieldType getFieldType(TypeRegistry typeRegistry, String pdxClassName, String fieldName) {
+  private FieldType getFieldType(TypeRegistry typeRegistry, String fieldName) {
+    String pdxClassName = regionMapping.getPdxClassName();
-
-
-
-
