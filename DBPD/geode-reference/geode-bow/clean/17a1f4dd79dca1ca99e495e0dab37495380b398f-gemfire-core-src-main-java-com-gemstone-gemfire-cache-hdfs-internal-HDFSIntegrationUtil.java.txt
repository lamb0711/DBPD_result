Merge remote-tracking branch 'origin/develop' into feature/GEODE-77

-
-import com.gemstone.gemfire.cache.hdfs.HDFSEventQueueAttributes;
-import com.gemstone.gemfire.cache.hdfs.HDFSEventQueueAttributesFactory;
-  
-  public static <K, V> AsyncEventQueue createDefaultAsyncQueueForHDFS(Cache cache, 
-     boolean writeOnly, String regionPath)
-  {
-    // Create default event attributes 
-    HDFSEventQueueAttributesFactory  hdfsqueueFactory = new HDFSEventQueueAttributesFactory();
-    return createAsyncQueueForHDFS(cache,
-        regionPath, writeOnly, hdfsqueueFactory.create());
-  }
-  
-  public static AsyncEventQueue createAsyncQueueForHDFS(Cache cache,
-      String regionPath, boolean writeOnly, HDFSEventQueueAttributes eventAttribs)
-   {
-     LogWriterI18n logger = cache.getLoggerI18n();
-     String defaultAsyncQueueName = HDFSStoreFactoryImpl.getEventQueueName(regionPath);
-     AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory();
-     factory.setBatchSize(eventAttribs.getBatchSizeMB());
-     factory.setPersistent(eventAttribs.isPersistent());
-     factory.setDiskStoreName(eventAttribs.getDiskStoreName());
-     factory.setMaximumQueueMemory(eventAttribs.getMaximumQueueMemory());
-     factory.setBatchTimeInterval(eventAttribs.getBatchTimeInterval());
-     factory.setDiskSynchronous(eventAttribs.isDiskSynchronous());
-     factory.setDiskSynchronous(eventAttribs.isDiskSynchronous());
-     factory.setDispatcherThreads(eventAttribs.getDispatcherThreads());
-     factory.setParallel(true);
-     factory.addGatewayEventFilter(new HDFSEventQueueFilter(logger));
-     ((AsyncEventQueueFactoryImpl)factory).setBucketSorted(!writeOnly);
-     ((AsyncEventQueueFactoryImpl)factory).setIsHDFSQueue(true);
-     
-     AsyncEventQueue asyncQ = null;
-     
-     if (!writeOnly)
-       asyncQ = factory.create(defaultAsyncQueueName, new HDFSEventListener(cache.getLoggerI18n()));
-     else
-       asyncQ = factory.create(defaultAsyncQueueName, new HDFSWriteOnlyStoreEventListener(cache.getLoggerI18n()));
-     
-     logger.fine("HDFS: async queue created for HDFS. Id: " + asyncQ.getId() + ". Disk store: " + asyncQ.getDiskStoreName() + 
-         ". Batch size: " + asyncQ.getBatchSize() + ". bucket sorted:  " + !writeOnly) ;
-     return asyncQ;
-     
-   }
-  
-  public static  void createAndAddAsyncQueue(String regionPath,
-      RegionAttributes regionAttributes, Cache cache) {
-    if(!regionAttributes.getDataPolicy().withHDFS()) {
-      return;
+  public static <K, V> AsyncEventQueue createDefaultAsyncQueueForHDFS(Cache cache, boolean writeOnly, String regionPath) {
+    return createAsyncQueueForHDFS(cache, regionPath, writeOnly, null);
+  }
+
+  private static AsyncEventQueue createAsyncQueueForHDFS(Cache cache, String regionPath, boolean writeOnly,
+      HDFSStore configView) {
+    LogWriterI18n logger = cache.getLoggerI18n();
+    String defaultAsyncQueueName = HDFSStoreFactoryImpl.getEventQueueName(regionPath);
+
+    if (configView == null) {
+      configView = new HDFSStoreFactoryImpl(cache).getConfigView();
+
+    AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory();
+    factory.setBatchSize(configView.getBatchSize());
+    factory.setPersistent(configView.getBufferPersistent());
+    factory.setDiskStoreName(configView.getDiskStoreName());
+    factory.setMaximumQueueMemory(configView.getMaxMemory());
+    factory.setBatchTimeInterval(configView.getBatchInterval());
+    factory.setDiskSynchronous(configView.getSynchronousDiskWrite());
+    factory.setDispatcherThreads(configView.getDispatcherThreads());
+    factory.setParallel(true);
+    factory.addGatewayEventFilter(new HDFSEventQueueFilter(logger));
+    ((AsyncEventQueueFactoryImpl) factory).setBucketSorted(!writeOnly);
+    ((AsyncEventQueueFactoryImpl) factory).setIsHDFSQueue(true);
+
+    AsyncEventQueue asyncQ = null;
+
+    if (!writeOnly)
+      asyncQ = factory.create(defaultAsyncQueueName, new HDFSEventListener(cache.getLoggerI18n()));
+    else
+      asyncQ = factory.create(defaultAsyncQueueName, new HDFSWriteOnlyStoreEventListener(cache.getLoggerI18n()));
+
+    logger.fine("HDFS: async queue created for HDFS. Id: " + asyncQ.getId() + ". Disk store: "
+        + asyncQ.getDiskStoreName() + ". Batch size: " + asyncQ.getBatchSize() + ". bucket sorted:  " + !writeOnly);
+    return asyncQ;
+
+  }
+
+  public static void createAndAddAsyncQueue(String regionPath, RegionAttributes regionAttributes, Cache cache) {
+    if (!regionAttributes.getDataPolicy().withHDFS()) {
+      return;
+    }
+
-    
+
-      if (regionAttributes.getHDFSStoreName() != null && regionAttributes.getPartitionAttributes() != null 
+      if (regionAttributes.getHDFSStoreName() != null && regionAttributes.getPartitionAttributes() != null
-        HDFSStore store = ((GemFireCacheImpl)cache).findHDFSStore(regionAttributes.getHDFSStoreName());
+        HDFSStore store = ((GemFireCacheImpl) cache).findHDFSStore(regionAttributes.getHDFSStoreName());
-              LocalizedStrings.HOPLOG_HDFS_STORE_NOT_FOUND
-                  .toLocalizedString(regionAttributes.getHDFSStoreName()));
+              LocalizedStrings.HOPLOG_HDFS_STORE_NOT_FOUND.toLocalizedString(regionAttributes.getHDFSStoreName()));
-        HDFSEventQueueAttributes queueAttrs = store.getHDFSEventQueueAttributes();
-        if(queueAttrs == null) {
-          // no async queue is specified for region with a HDFS store. Create a async queue with default 
-          // properties and set the bucketsorted=true.
-          HDFSIntegrationUtil.createDefaultAsyncQueueForHDFS(cache, regionAttributes.getHDFSWriteOnly(), leaderRegionPath);
-        }
-        else {
-          HDFSIntegrationUtil.createAsyncQueueForHDFS(cache, leaderRegionPath, regionAttributes.getHDFSWriteOnly(), queueAttrs);
-        }
+        HDFSIntegrationUtil
+            .createAsyncQueueForHDFS(cache, leaderRegionPath, regionAttributes.getHDFSWriteOnly(), store);
-  private static String getLeaderRegionPath(String regionPath,
-      RegionAttributes regionAttributes, Cache cache) {
+  private static String getLeaderRegionPath(String regionPath, RegionAttributes regionAttributes, Cache cache) {
-    while(regionAttributes.getPartitionAttributes() != null 
+    while (regionAttributes.getPartitionAttributes() != null
-      GemFireCacheImpl gfc = (GemFireCacheImpl)cache;
+      GemFireCacheImpl gfc = (GemFireCacheImpl) cache;
-      if(colocatedRegion == null) {
+      if (colocatedRegion == null) {
