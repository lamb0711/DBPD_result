Merge remote-tracking branch 'origin/develop' into feature/GEODE-11

-/*=========================================================================
- * Copyright (c) 2002-2014 Pivotal Software, Inc. All Rights Reserved.
- * This product is protected by U.S. and international copyright
- * and intellectual property laws. Pivotal products are covered by
- * more patents listed at http://www.pivotal.io/patents.
- *=========================================================================
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
-      case PARTITION_HDFS: {
-    	  AttributesFactory af = new AttributesFactory();
-          af.setDataPolicy(DataPolicy.HDFS_PARTITION);
-          PartitionAttributesFactory paf = new PartitionAttributesFactory();
-          af.setPartitionAttributes(paf.create());
-          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-          af.setHDFSWriteOnly(false);
-          c.setRegionAttributes(pra.toString(), af.create());
-          break;
-        }
-      case PARTITION_REDUNDANT_HDFS: {
-    	  AttributesFactory af = new AttributesFactory();
-          af.setDataPolicy(DataPolicy.HDFS_PARTITION);
-          PartitionAttributesFactory paf = new PartitionAttributesFactory();
-          paf.setRedundantCopies(1);
-          af.setPartitionAttributes(paf.create());
-          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-          af.setHDFSWriteOnly(false);
-          c.setRegionAttributes(pra.toString(), af.create());
-          break;
-        }
-      case PARTITION_WRITEONLY_HDFS_STORE: {
-        AttributesFactory af = new AttributesFactory();
-          af.setDataPolicy(DataPolicy.HDFS_PARTITION);
-          PartitionAttributesFactory paf = new PartitionAttributesFactory();
-          af.setPartitionAttributes(paf.create());
-          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-          af.setHDFSWriteOnly(true);
-          c.setRegionAttributes(pra.toString(), af.create());
-          break;
-        }
-      case PARTITION_REDUNDANT_WRITEONLY_HDFS_STORE: {
-        AttributesFactory af = new AttributesFactory();
-          af.setDataPolicy(DataPolicy.HDFS_PARTITION);
-          PartitionAttributesFactory paf = new PartitionAttributesFactory();
-          paf.setRedundantCopies(1);
-          af.setPartitionAttributes(paf.create());
-          af.setEvictionAttributes(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));
-          af.setHDFSWriteOnly(true);
-          c.setRegionAttributes(pra.toString(), af.create());
-          break;
-        }
-  @Override
-  public HDFSStoreFactory createHDFSStoreFactory() {
-    // TODO Auto-generated method stub
-    return new HDFSStoreFactoryImpl(this);
-  }
-  
