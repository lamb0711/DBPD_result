GEODE-10: Absorb review comments

Reviewers posted useful comments on javadoc and methods names. Link to the
reviewboard: https://reviews.apache.org/r/36397

- * <li>[Optional] Creates a Disk store for reliability
- * <li>HDFS buffers will use local persistence till it is persisted on HDFS
- * <li>Creates a HDFS Store
- * <li>Creates a Region connected to HDFS Store Uses region API to create and
- * query data
+ * <li>[Optional] Creates a DiskStore for HDFS buffer reliability (HDFS buffers
+ * will be persisted locally till data lands on HDFS)
+ * <li>Creates a HDFS Store (connects to DiskStore created earlier)
+ * <li>Creates a Region connected to HDFS Store
+ * <li>Uses region API to create and query data
-  public static final int DEFAULT_MAX_WRITE_ONLY_FILE_SIZE = 256; 
+  public static final int DEFAULT_WRITE_ONLY_FILE_SIZE_LIMIT = 256;
-  
+
-  
+
-  public static final int DEFAULT_MAX_INPUT_FILE_SIZE_MB = 512;
-  public static final int DEFAULT_MAX_INPUT_FILE_COUNT = 10;
-  public static final int DEFAULT_MIN_INPUT_FILE_COUNT = 4;
-  
+  public static final int DEFAULT_INPUT_FILE_SIZE_MAX_MB = 512;
+  public static final int DEFAULT_INPUT_FILE_COUNT_MAX = 10;
+  public static final int DEFAULT_INPUT_FILE_COUNT_MIN = 4;
+
-   * files in the classpath. NameNode URL provided in this way is also fine.
+   * files in the classpath. The following precedence order is applied
+   * <ol>
+   * <li>URL explicitly configured in the HdfsStore
+   * <li>URL provided in client configuration file:
+   * {@link #getHDFSClientConfigFile()}
+   * <li>URL provided in default configuration files loaded by hdfs-client
+   * </ol>
+   * 
+   * HDFSStore will use the selected URL only. It will fail if the selected URL
+   * is not reachable.
-   * 0 ... 100
+   *         0 ... 100
-   * data is persisted on HDFS. A higher value means that less number of bigger
-   * batches are persisted to HDFS and hence big files are created on HDFS. But,
-   * bigger batches consume memory.
+   * data is persisted on HDFS. A higher value causes fewer and bigger batches
+   * to be persisted to HDFS and hence big files are created on HDFS. But,
+   * bigger batches consume more memory.
-   * @return batchsize in MB
+   * @return batch size in MB
-  
+
-   * BatchInterval defines the maximum time that can elapse between writing
-   * batches to HDFS. This parameter, along with BatchSize determines the rate
-   * at which data is persisted on HDFS.
+   * BatchInterval defines the number of milliseconds that can elapse between
+   * writing batches to HDFS. This parameter, along with BatchSize determines
+   * the rate at which data is persisted on HDFS.
-   * @return interval in seconds
+   * @return batch interval in milliseconds
-  
+
-  
+
-   * on HDFS yet, should be persisted to a local disk to buffer prevent data
-   * loss. Persisting data may impact write performance. If performance is
-   * critical and buffer data loss is acceptable, disable persistence.
+   * on HDFS yet, should be persisted to a local disk to prevent buffer data
+   * loss. Persisting buffer data may impact write performance. If performance
+   * is critical and buffer data loss is acceptable, disable persistence.
-   * Synchronous flag indicates if synchronous disk writes are enabled or not.
+   * HDFS buffers can be persisted on local disk. Each region update record is
+   * written to the disk synchronously if synchronous disk write is enabled.
+   * Enable this option if the data being persisted is critical and no record
+   * should be lost in case of a crash. This high reliability mode may increase
+   * write latency. If synchronous mode is disabled, data is persisted in
+   * batches which usually results in better performance.
-  
+
-   * writing to a new file. This clause is ignored for HDFS read/write regions.
+   * writing to a new file. This option is ignored for HDFS read/write regions.
-  public int getMaxWriteOnlyFileSize();
-  
+  public int getWriteOnlyFileSizeLimit();
+
-   * For HDFS write-only regions, this defines the maximum time that can elapse
-   * before HDFSStore closes an HDFS file and begins writing to a new file. This
-   * configuration is ignored for HDFS read/write regions.
+   * For HDFS write-only regions, this defines the number of seconds that can
+   * elapse before HDFSStore closes an HDFS file and begins writing to a new
+   * file. This configuration is ignored for HDFS read/write regions.
-   * @return interval in seconds 
+   * @return interval in seconds
-  
+
-   * MinorCompactionThreads.
+   * MinorCompactionThreads. Minor compaction is not applicable to write-only
+   * regions.
+   * Minor compaction is not applicable to write-only regions.
-   * MajorCompactionInterval and MajorCompactionThreads.
+   * MajorCompactionInterval and MajorCompactionThreads. Major compaction is not
+   * applicable to write-only regions.
-   * The amount of time after which HDFSStore performs the next major compaction
-   * cycle.
+   * The number of minutes after which HDFSStore performs the next major
+   * compaction cycle. Major compaction is not applicable to write-only regions.
-   * @return interval in seconds
+   * @return interval in minutes
+   * Major compaction is not applicable to write-only regions.
-  
+
-   * HDFSStore creates new files as part of periodic maintenance activity.
-   * Existing files are deleted asynchronously. PurgeInterval defines the amount
-   * of time old files remain available and could be externally, e.g. read by MR
-   * jobs. After this interval has passed, old files are deleted.
+   * HDFSStore may create new files as part of periodic maintenance activity. It
+   * deletes old files asynchronously. PurgeInterval defines the number of
+   * minutes for which old files will remain available to be consumed
+   * externally, e.g. read by MR jobs. After this interval, old files are
+   * deleted. This configuration is not applicable to write-only regions
-   * @return interval configuration that guides deletion of old files
+   * @return old file purge interval in minutes
-  
+
-   * Permanently deletes all HDFS files associated with this this
-   * {@link HDFSStore}. This operation will fail ( {@link IllegalStateException}
-   * ) if any region is still using this store for persistence.
+   * Permanently deletes all HDFS files associated with this {@link HDFSStore}.
+   * This operation will fail if any region is still using this store for
+   * persistence.
+   * 
+   * @exception IllegalStateException
+   *              if any region using this hdfsStore still exists
-  
+
-  
+
-   * This advanced configuration affects minor compaction.
-   * @return size threshold (in MB). A file larger than this size will not be
-   *         considered for compaction
+   * A file larger than this size, in megabytes, will not be compacted by minor
+   * compactor. Increasing this value will result in compaction of bigger files.
+   * This will lower the number of files on HDFS at the cost of increased IO.
+   * This option is for advanced users and will need tuning in special cases
+   * only. This option is not applicable to write-only regions.
+   * 
+   * @return size threshold (in MB)
-  public int getMaxInputFileSizeMB();
+  public int getInputFileSizeMax();
-   * This advanced configuration affects minor compaction.
-   * @return minimum count threshold. Compaction cycle will commence if the
-   *         number of files to be compacted is more than this number
+   * A minimum number of files must exist in a bucket directory on HDFS before
+   * minor compaction will start compaction. Keeping a higher value for this
+   * option will reduce the frequency of minor compaction, which in turn may
+   * result in reduced IO overhead. However it may result in increased pressure
+   * on HDFS NameNode. This option is for advanced users and will need tuning in
+   * special cases only. This option is not applicable to write-only regions.
+   * 
+   * @return minimum number of files for minor compaction to get triggered
-  public int getMinInputFileCount();
+  public int getInputFileCountMin();
-   * This advanced configuration affects minor compaction.
-   * @return maximum count threshold.  Compaction cycle will not include more
-   *          files than the maximum
+   * The maximum number of files compacted by Minor compactor in a cycle.
+   * Keeping a higher value for this option will reduce the frequency of minor
+   * compaction, which in turn may result in reduced IO overhead. However it may
+   * result in large number of concurrent IO operations which in-turn may
+   * degrade the performance. This option is for advanced users and will need
+   * tuning in special cases only. This option is not applicable to write-only
+   * regions.
+   * 
+   * @return maximum number of files minor compacted in one cycle
-  public int getMaxInputFileCount();
+  public int getInputFileCountMax();
