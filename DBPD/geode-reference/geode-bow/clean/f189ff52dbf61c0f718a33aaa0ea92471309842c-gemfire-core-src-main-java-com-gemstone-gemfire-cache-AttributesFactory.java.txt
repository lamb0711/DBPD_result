Merge remote-tracking branch 'origin/develop' into feature/GEODE-11

-/*=========================================================================
- * Copyright (c) 2002-2014 Pivotal Software, Inc. All Rights Reserved.
- * This product is protected by U.S. and international copyright
- * and intellectual property laws. Pivotal products are covered by
- * more patents listed at http://www.pivotal.io/patents.
- *=========================================================================
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
-import com.gemstone.gemfire.cache.hdfs.HDFSStore;
-    this.regionAttributes.hdfsStoreName = regionAttributes.getHDFSStoreName();
-    this.regionAttributes.hdfsWriteOnly = regionAttributes.getHDFSWriteOnly();
-    if (regionAttributes instanceof UserSpecifiedRegionAttributes) {
-      this.regionAttributes.setHasHDFSWriteOnly(((UserSpecifiedRegionAttributes<K,V>) regionAttributes).hasHDFSWriteOnly());
-    }
-   * Sets the HDFSStore name attribute.
-   * This causes the region to use the {@link HDFSStore}.
-   * @param name the name of the HDFSstore
-   */
-  public void setHDFSStoreName(String name) {
-    //TODO:HDFS throw an exception if the region is already configured for a disk store and 
-    // vice versa
-    this.regionAttributes.hdfsStoreName = name;
-    this.regionAttributes.setHasHDFSStoreName(true);
-  }
-  
-  /**
-   * Sets the HDFS write only attribute. if the region
-   * is configured to be write only to HDFS, events that have 
-   * been evicted from memory cannot be read back from HDFS.
-   * Events are written to HDFS in the order in which they occurred.
-   */
-  public void setHDFSWriteOnly(boolean writeOnly) {
-    //TODO:HDFS throw an exception if the region is already configured for a disk store and 
-    // vice versa
-    this.regionAttributes.hdfsWriteOnly = writeOnly;
-    this.regionAttributes.setHasHDFSWriteOnly(true);
-  }
-  
-  /**
-      if ((regionIdleTimeout.getAction().isInvalidate() && regionIdleTimeout.getTimeout() > 0)
-          || (regionIdleTimeout.getAction().isLocalInvalidate() && regionIdleTimeout.getTimeout() > 0)
-          || (regionTimeToLive.getAction().isInvalidate() && regionTimeToLive.getTimeout() > 0)
-          || (regionTimeToLive.getAction().isLocalInvalidate()) && regionTimeToLive.getTimeout() > 0 ) {
-        throw new IllegalStateException(
-            LocalizedStrings.AttributesFactory_INVALIDATE_REGION_NOT_SUPPORTED_FOR_PR.toLocalizedString());
-      }
-      
-      if ((regionIdleTimeout.getAction().isDestroy() && regionIdleTimeout.getTimeout() > 0)
-          || (regionIdleTimeout.getAction().isLocalDestroy() && regionIdleTimeout.getTimeout() > 0)
-          || (regionTimeToLive.getAction().isDestroy() && regionTimeToLive.getTimeout() > 0)
-          || (regionTimeToLive.getAction().isLocalDestroy() && regionTimeToLive.getTimeout() > 0)) {
-        throw new IllegalStateException(
-            LocalizedStrings.AttributesFactory_DESTROY_REGION_NOT_SUPPORTED_FOR_PR
-                .toLocalizedString());
-      }
+      AbstractRegion.validatePRRegionExpirationAttributes(regionIdleTimeout);
+      AbstractRegion.validatePRRegionExpirationAttributes(regionTimeToLive);
