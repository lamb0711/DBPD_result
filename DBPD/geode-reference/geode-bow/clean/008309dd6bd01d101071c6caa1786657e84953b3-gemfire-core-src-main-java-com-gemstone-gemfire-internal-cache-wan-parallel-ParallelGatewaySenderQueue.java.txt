Merge branch 'release/1.0.0-incubating.M1'

-/*=========================================================================
- * Copyright (c) 2010-2014 Pivotal Software, Inc. All Rights Reserved.
- * This product is protected by U.S. and international copyright
- * and intellectual property laws. Pivotal products are covered by
- * one or more patents listed at http://www.pivotal.io/patents.
- *=========================================================================
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+import com.gemstone.gemfire.cache.RegionDestroyedException;
-  private static final Logger logger = LogService.getLogger();
+  protected static final Logger logger = LogService.getLogger();
+      GatewaySenderEventImpl event = (GatewaySenderEventImpl)conflatableObject;
-        String regionPath = ColocationHelper.getLeaderRegion(
-            (PartitionedRegion)((GatewaySenderEventImpl)conflatableObject)
-                .getRegion()).getFullPath();
+        String regionPath = ColocationHelper.getLeaderRegion((PartitionedRegion)event.getRegion()).getFullPath();
-            this, deserialize(conflatableObject.getValueToConflate()), conflatableObject.getKeyToConflate(), prQ.getName());
+            this, conflatableObject.getValueToConflate(), conflatableObject.getKeyToConflate(), prQ.getName());
-    if( this.buckToDispatchLock == null) {
-      this.buckToDispatchLock = new StoppableReentrantLock(sender.getCancelCriterion());
+    if( buckToDispatchLock == null) {
+      buckToDispatchLock = new StoppableReentrantLock(sender.getCancelCriterion());
-    if(this.regionToDispatchedKeysMapEmpty == null) {
-      this.regionToDispatchedKeysMapEmpty = this.buckToDispatchLock.newCondition();
+    if(regionToDispatchedKeysMapEmpty == null) {
+      regionToDispatchedKeysMapEmpty = buckToDispatchLock.newCondition();
-      if (this.removalThread == null) {
-        this.removalThread = new BatchRemovalThread(
+      if (removalThread == null) {
+        removalThread = new BatchRemovalThread(
-        this.removalThread.start();
+        removalThread.start();
-       * Here, enqueTempEvents need to be invoked when a sender is already
+         * Here, enqueueTempEvents need to be invoked when a sender is already
-       * started later, the enqueTempEvents is done in the start() method of
+       * started later, the enqueueTempEvents is done in the start() method of
-        ((AbstractGatewaySender)sender).enqueTempEvents();
+        ((AbstractGatewaySender)sender).enqueueTempEvents();
-      if(userPR.getDataPolicy().withPersistence() && !sender.isPersistenceEnabled()){
+      if(!isUsedForHDFS() && userPR.getDataPolicy().withPersistence() && !sender.isPersistenceEnabled()){
-            prQName, ra, null, cache, sender);
+            prQName, ra, null, cache, sender, isUsedForHDFS());
+          // at this point we should be able to assert prQ == meta; 
-       * Here, enqueTempEvents need to be invoked when a sender is already
+       * Here, enqueueTempEvents need to be invoked when a sender is already
-       * started later, the enqueTempEvents is done in the start() method of
+       * started later, the enqueueTempEvents is done in the start() method of
-        ((AbstractGatewaySender)sender).enqueTempEvents();
+        ((AbstractGatewaySender)sender).enqueueTempEvents();
+  protected boolean isUsedForHDFS()
+  {
+    return false;
+  }
-  private void cleanupConflationThreadPool() {
+  private static void cleanupConflationThreadPool(AbstractGatewaySender sender) {
-      if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS))
-        logger.warn(LocalizedMessage.create(LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL, this.sender));
+        if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
+          logger
+              .warn(LocalizedMessage
+                  .create(
+                      LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL,
+                      (sender == null ? "all" : sender)));
+        }
+//      value.freeOffHeapValue();
+      value.release();
+        value.release();
-            //value.freeOffHeapValue();
+            value.release();
-              //value.freeOffHeapValue();
+              value.release();
-          //value.freeOffHeapValue();
+          value.release();
+    boolean addedValueToQueue = false;
-        brq.addToQueue(key, value);
+        addedValueToQueue = brq.addToQueue(key, value);
+    } finally {
+      if (!addedValueToQueue) {
+        value.release();
+      }
+      try {
+      } finally {
+        event.release();
+      }
-    return object;
+    return object; // OFFHEAP: ok since only callers uses it to check for empty queue
-    buckToDispatchLock.lock();
-    boolean wasEmpty = regionToDispatchedKeysMap.isEmpty();
-    try {
-      Map bucketIdToDispatchedKeys = (Map)regionToDispatchedKeysMap.get(prQ.getFullPath());
-      if (bucketIdToDispatchedKeys == null) {
-        bucketIdToDispatchedKeys = new ConcurrentHashMap();
-        regionToDispatchedKeysMap.put(prQ.getFullPath(), bucketIdToDispatchedKeys);
+    StoppableReentrantLock lock = buckToDispatchLock;
+    if (lock != null) {
+      lock.lock();
+      boolean wasEmpty = regionToDispatchedKeysMap.isEmpty();
+      try {
+        Map bucketIdToDispatchedKeys = (Map)regionToDispatchedKeysMap.get(prQ.getFullPath());
+        if (bucketIdToDispatchedKeys == null) {
+          bucketIdToDispatchedKeys = new ConcurrentHashMap();
+          regionToDispatchedKeysMap.put(prQ.getFullPath(), bucketIdToDispatchedKeys);
+        }
+        addRemovedEventToMap(bucketIdToDispatchedKeys, bucketId, key);
+        if (wasEmpty) {
+          regionToDispatchedKeysMapEmpty.signal();        
+        }
-      addRemovedEventToMap(bucketIdToDispatchedKeys, bucketId, key);
-      if (wasEmpty) {
-        regionToDispatchedKeysMapEmpty.signal();        
+      finally {
+        lock.unlock();  
-    finally {
-      buckToDispatchLock.unlock();  
-    }
-    Object object = null;
-    int bId = -1;
+    int bId = -1;
-        object = peekAhead(prQ, bId);
+        GatewaySenderEventImpl object = (GatewaySenderEventImpl) peekAhead(prQ, bId);
+        if (object != null) {
+          GatewaySenderEventImpl copy = object.makeHeapCopyIfOffHeap();
+          if (copy == null) {
+            continue;
+          }
+          object = copy;
+        }
-          peekedEvents.add((GatewaySenderEventImpl)object);
+          peekedEvents.add(object);
-    return object;
+    return object; // OFFHEAP: ok since callers are careful to do destroys on region queue after finished with peeked object.
-    if(buckToDispatchLock != null){
-      this.buckToDispatchLock = null;
-    }
-    if(regionToDispatchedKeysMapEmpty != null) {
-      this.regionToDispatchedKeysMapEmpty = null;
-    }
-    this.regionToDispatchedKeysMap.clear();
+    cleanUpStatics(this.sender);
+  }
+
+  /**
+   * @param sender
+   *          can be null.
+   */
+  public static void cleanUpStatics(AbstractGatewaySender sender) {
+    buckToDispatchLock = null;
+    regionToDispatchedKeysMapEmpty = null;
+    regionToDispatchedKeysMap.clear();
-      if (this.removalThread != null) {
-        this.removalThread.shutdown();
-        this.removalThread = null;
+      if (removalThread != null) {
+        removalThread.shutdown();
+        removalThread = null;
-      cleanupConflationThreadPool();
-      this.conflationExecutor = null;
+      cleanupConflationThreadPool(sender);
+      conflationExecutor = null;
-  
+
+  @Override
+  public void close() {
+    // Because of bug 49060 do not close the regions of a parallel queue
+//    for (Region r: getRegions()) {
+//      if (r != null && !r.isDestroyed()) {
+//        try {
+//          r.close();
+//        } catch (RegionDestroyedException e) {
+//        }
+//      }
+//    }
+  }
+
+      this( regionName, attrs, parentRegion, cache, pgSender, false);
+    }
+    public ParallelGatewaySenderQueueMetaRegion(String regionName,
+        RegionAttributes attrs, LocalRegion parentRegion,
+        GemFireCacheImpl cache, AbstractGatewaySender pgSender, boolean isUsedForHDFS) {
-              .setParallelGatewaySender((AbstractGatewaySender)pgSender));
+              .setParallelGatewaySender((AbstractGatewaySender)pgSender)
+              .setIsUsedForHDFSParallelGatewaySenderQueue(isUsedForHDFS));
