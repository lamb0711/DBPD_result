Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
+import org.apache.geode.internal.tcp.ByteBufferInputStream;
- * Implementation code in this class must be careful to not directly call
- * super class state. Instead it must call {@link #getUnmodifiableReader()} and
- * access the super class state using it.
- * This class could be changed to not extend PdxReaderImpl but to instead have
- * an instance variable that is a PdxReaderImpl but that would cause this class
- * to use more memory.
+ * Implementation code in this class must be careful to not directly call super class state. Instead
+ * it must call {@link #getUnmodifiableReader()} and access the super class state using it. This
+ * class could be changed to not extend PdxReaderImpl but to instead have an instance variable that
+ * is a PdxReaderImpl but that would cause this class to use more memory.
- * We do not use this normal java io serialization
- * when serializing this class in GemFire because Sendable takes precedence over Serializable.
+ * We do not use this normal java io serialization when serializing this class in GemFire because
+ * Sendable takes precedence over Serializable.
-public class PdxInstanceImpl extends PdxReaderImpl implements PdxInstance, Sendable, ConvertableToBytes {
+public class PdxInstanceImpl extends PdxReaderImpl
+    implements PdxInstance, Sendable, ConvertableToBytes {
-  private static final boolean USE_STATIC_MAPPER = Boolean.getBoolean("PdxInstance.use-static-mapper");
+  private static final boolean USE_STATIC_MAPPER =
+      Boolean.getBoolean("PdxInstance.use-static-mapper");
-  static final ObjectMapper mapper = USE_STATIC_MAPPER? createObjectMapper() : null;
+  static final ObjectMapper mapper = USE_STATIC_MAPPER ? createObjectMapper() : null;
-    mapper.configure(com.fasterxml.jackson.core.JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES, true);
+    mapper.configure(com.fasterxml.jackson.core.JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES,
+        true);
-   * Computes the hash code once and stores it. This is added to address the
-   * issue of identity value getting changed for each hash code call (as new objects
-   * instances are created in each call for the same object). 
-   * The value 0 means the hash code is not yet computed (this avoids using 
-   * extra variable for this), if the computation returns 0, it will be set to 1. This 
-   * doesn't break the equality rule, where hash code can be same for non-equal
-   * objects. 
+   * Computes the hash code once and stores it. This is added to address the issue of identity value
+   * getting changed for each hash code call (as new objects instances are created in each call for
+   * the same object). The value 0 means the hash code is not yet computed (this avoids using extra
+   * variable for this), if the computation returns 0, it will be set to 1. This doesn't break the
+   * equality rule, where hash code can be same for non-equal objects.
-  
+
-  
+
-  
+
-  
+
-      dis = new PdxInstanceInputStream((PdxInputStream) in, len);
+      dis = new PdxInputStream((ByteBufferInputStream) in, len);
-      dis = new PdxInstanceInputStream(bytes);
+      dis = new PdxInputStream(bytes);
-  
+
-  
+
-  
+
-    GemFireCacheImpl gfc = GemFireCacheImpl.getForPdx("PDX registry is unavailable because the Cache has been closed.");
+    GemFireCacheImpl gfc = GemFireCacheImpl
+        .getForPdx("PDX registry is unavailable because the Cache has been closed.");
-    for (PdxField field: pt.getFields()) {
+    for (PdxField field : pt.getFields()) {
-  
+
-    out.write(DSCODE.PDX);
-    out.writeInt(ur.basicSize());
-    out.writeInt(ur.getPdxType().getTypeId());
-    ur.basicSendTo(out);
+      out.write(DSCODE.PDX);
+      out.writeInt(ur.basicSize());
+      out.writeInt(ur.getPdxType().getTypeId());
+      ur.basicSendTo(out);
-  
+
-    byte[] result = new byte[PdxWriterImpl.HEADER_SIZE + ur.basicSize()];
-    ByteBuffer bb = ByteBuffer.wrap(result);
-    bb.put(DSCODE.PDX);
-    bb.putInt(ur.basicSize());
-    bb.putInt(ur.getPdxType().getTypeId());
-    ur.basicSendTo(bb);
-    return result;
+      byte[] result = new byte[PdxWriterImpl.HEADER_SIZE + ur.basicSize()];
+      ByteBuffer bb = ByteBuffer.wrap(result);
+      bb.put(DSCODE.PDX);
+      bb.putInt(ur.basicSize());
+      bb.putInt(ur.getPdxType().getTypeId());
+      ur.basicSendTo(bb);
+      return result;
-    Object result = this.cachedObjectForm; 
+    Object result = this.cachedObjectForm;
-    
-  private String extractTypeMetaData(){
+
+  private String extractTypeMetaData() {
-         return (String)type;
-      }else {
+        return (String) type;
+      } else {
-    }else {
-     return null; 
-    }  
+    } else {
+      return null;
+    }
-    if (getPdxType().getNoDomainClass()) { 
-      //In case of Developer Rest APIs, All PdxInstances converted from Json will have a className =__GEMFIRE_JSON.
-      //Following code added to convert Json/PdxInstance into the Java object.
-      if(this.getClassName().equals("__GEMFIRE_JSON")){
-        
-        //introspect the JSON, does the @type meta-data exist.
+    if (getPdxType().getNoDomainClass()) {
+      // In case of Developer Rest APIs, All PdxInstances converted from Json will have a className
+      // =__GEMFIRE_JSON.
+      // Following code added to convert Json/PdxInstance into the Java object.
+      if (this.getClassName().equals("__GEMFIRE_JSON")) {
+
+        // introspect the JSON, does the @type meta-data exist.
-        
-        if(StringUtils.isNotBlank(className)) {
+
+        if (StringUtils.isNotBlank(className)) {
-            ObjectMapper objMapper = USE_STATIC_MAPPER? mapper : createObjectMapper();
-            Object classInstance = objMapper.readValue(JSON, ClassPathLoader.getLatest().forName(className));
+            ObjectMapper objMapper = USE_STATIC_MAPPER ? mapper : createObjectMapper();
+            Object classInstance =
+                objMapper.readValue(JSON, ClassPathLoader.getLatest().forName(className));
-          }catch(Exception e){
-            throw new PdxSerializationException("Could not deserialize as java class type could not resolved", e);
+          } catch (Exception e) {
+            throw new PdxSerializationException(
+                "Could not deserialize as java class type could not resolved", e);
-  
+
-    
+
-    for(PdxField ft: fields) {
+    for (PdxField ft : fields) {
-      case CHAR:
-      case BOOLEAN:
-      case BYTE:
-      case SHORT:
-      case INT:
-      case LONG:
-      case DATE:
-      case FLOAT:
-      case DOUBLE:
-      case STRING:
-      case BOOLEAN_ARRAY:
-      case CHAR_ARRAY:
-      case BYTE_ARRAY:
-      case SHORT_ARRAY:
-      case INT_ARRAY:
-      case LONG_ARRAY:
-      case FLOAT_ARRAY:
-      case DOUBLE_ARRAY:
-      case STRING_ARRAY:
-      case ARRAY_OF_BYTE_ARRAYS: {
-        ByteSource buffer = ur.getRaw(ft);
-        if (!buffer.equals(ByteSourceFactory.create(ft.getFieldType().getDefaultBytes()))) {
-          hashCode = hashCode *31  + buffer.hashCode();
-        }
-        break;
-      }
-      case OBJECT_ARRAY: {
-        Object[] oArray = ur.readObjectArray(ft);
-        if (oArray != null) {
-          // default value of null does not modify hashCode.
-          hashCode = hashCode *31  + Arrays.deepHashCode(oArray);
-        }
-        break;
-      }
-      case OBJECT: {
-        Object objectValue = ur.readObject(ft);
-        if (objectValue == null) {
-          // default value of null does not modify hashCode.
-        } else if (objectValue.getClass().isArray()) {
-          Class<?> myComponentType = objectValue.getClass().getComponentType();
-          if (myComponentType.isPrimitive()) {
-            ByteSource buffer = getRaw(ft);
-            hashCode = hashCode *31  + buffer.hashCode();
-          } else {
-            hashCode = hashCode *31  + Arrays.deepHashCode((Object[])objectValue);
+        case CHAR:
+        case BOOLEAN:
+        case BYTE:
+        case SHORT:
+        case INT:
+        case LONG:
+        case DATE:
+        case FLOAT:
+        case DOUBLE:
+        case STRING:
+        case BOOLEAN_ARRAY:
+        case CHAR_ARRAY:
+        case BYTE_ARRAY:
+        case SHORT_ARRAY:
+        case INT_ARRAY:
+        case LONG_ARRAY:
+        case FLOAT_ARRAY:
+        case DOUBLE_ARRAY:
+        case STRING_ARRAY:
+        case ARRAY_OF_BYTE_ARRAYS: {
+          ByteSource buffer = ur.getRaw(ft);
+          if (!buffer.equals(ByteSourceFactory.create(ft.getFieldType().getDefaultBytes()))) {
+            hashCode = hashCode * 31 + buffer.hashCode();
-        } else {
-          hashCode = hashCode *31  + objectValue.hashCode();
+          break;
-        break;
-      }
-      default:
-        throw new InternalGemFireException("Unhandled field type " + ft.getFieldType());
+        case OBJECT_ARRAY: {
+          Object[] oArray = ur.readObjectArray(ft);
+          if (oArray != null) {
+            // default value of null does not modify hashCode.
+            hashCode = hashCode * 31 + Arrays.deepHashCode(oArray);
+          }
+          break;
+        }
+        case OBJECT: {
+          Object objectValue = ur.readObject(ft);
+          if (objectValue == null) {
+            // default value of null does not modify hashCode.
+          } else if (objectValue.getClass().isArray()) {
+            Class<?> myComponentType = objectValue.getClass().getComponentType();
+            if (myComponentType.isPrimitive()) {
+              ByteSource buffer = getRaw(ft);
+              hashCode = hashCode * 31 + buffer.hashCode();
+            } else {
+              hashCode = hashCode * 31 + Arrays.deepHashCode((Object[]) objectValue);
+            }
+          } else {
+            hashCode = hashCode * 31 + objectValue.hashCode();
+          }
+          break;
+        }
+        default:
+          throw new InternalGemFireException("Unhandled field type " + ft.getFieldType());
-    int result = (hashCode == UNUSED_HASH_CODE)?(hashCode + 1):hashCode;
+    int result = (hashCode == UNUSED_HASH_CODE) ? (hashCode + 1) : hashCode;
-  
+
-    if (obj == this) return true;
-    
-    if(obj == null) {
-      //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#0 o1=<" + this + "> o2=<" + obj + ">");
+    if (obj == this)
+      return true;
+
+    if (obj == null) {
+      // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#0 o1=<" + this + "> o2=<" +
+      // obj + ">");
-      //      if (!result) {
-      //        GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#1 o1=<" + this + "> o2=<" + obj + ">");
-      //      }
+      // if (!result) {
+      // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#1 o1=<" + this + "> o2=<" +
+      // obj + ">");
+      // }
-    
-    if(!ur1.getPdxType().getClassName().equals(ur2.getPdxType().getClassName())) {
-      //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#2 o1=<" + this + "> o2=<" + obj + ">");
+
+    if (!ur1.getPdxType().getClassName().equals(ur2.getPdxType().getClassName())) {
+      // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#2 o1=<" + this + "> o2=<" +
+      // obj + ">");
-    
+
-    
-      Iterator<PdxField> myFieldIterator = myFields.iterator();
-      Iterator<PdxField> otherFieldIterator = otherFields.iterator();
-      while(myFieldIterator.hasNext()) {
-        PdxField myType = myFieldIterator.next();
-        PdxField otherType = otherFieldIterator.next();
-        switch (myType.getFieldType()) {
+    Iterator<PdxField> myFieldIterator = myFields.iterator();
+    Iterator<PdxField> otherFieldIterator = otherFields.iterator();
+    while (myFieldIterator.hasNext()) {
+      PdxField myType = myFieldIterator.next();
+      PdxField otherType = otherFieldIterator.next();
+
+      switch (myType.getFieldType()) {
-          if(!myBuffer.equals(otherBuffer)) {
-            //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#4 o1=<" + this + "> o2=<" + obj + ">");
+          if (!myBuffer.equals(otherBuffer)) {
+            // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#4 o1=<" + this + ">
+            // o2=<" + obj + ">");
-          }}
-        break;
+          }
+        }
+          break;
-          if(!Arrays.deepEquals(myArray, otherArray)) {
-            //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#5 o1=<" + this + "> o2=<" + obj + ">");
+          if (!Arrays.deepEquals(myArray, otherArray)) {
+            // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#5 o1=<" + this + ">
+            // o2=<" + obj + ">");
-          }}
-        break;
+          }
+        }
+          break;
-          if(myObject != otherObject) {
-            if(myObject == null) {
-              //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#6 o1=<" + this + "> o2=<" + obj + ">");
+          if (myObject != otherObject) {
+            if (myObject == null) {
+              // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#6 o1=<" + this + ">
+              // o2=<" + obj + ">");
-            if(otherObject == null) {
-              //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#7 o1=<" + this + "> o2=<" + obj + ">");
+            if (otherObject == null) {
+              // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#7 o1=<" + this + ">
+              // o2=<" + obj + ">");
-                //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#8 o1=<" + this + "> o2=<" + obj + ">");
+                // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#8 o1=<" + this + ">
+                // o2=<" + obj + ">");
-                if(!myBuffer.equals(otherBuffer)) {
-                  //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#9 o1=<" + this + "> o2=<" + obj + ">");
+                if (!myBuffer.equals(otherBuffer)) {
+                  // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#9 o1=<" + this +
+                  // "> o2=<" + obj + ">");
-                if (!Arrays.deepEquals((Object[])myObject, (Object[])otherObject)) {
-                  //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#10 o1=<" + this + "> o2=<" + obj + ">");
+                if (!Arrays.deepEquals((Object[]) myObject, (Object[]) otherObject)) {
+                  // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#10 o1=<" + this +
+                  // "> o2=<" + obj + ">");
-              //GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#11 fn=" + myType.getFieldName() + " myFieldClass=" + myObject.getClass() + " otherFieldCLass=" + otherObject.getClass() + " o1=<" + this + "> o2=<" + obj + ">" + "myObj=<" + myObject + "> otherObj=<" + otherObject + ">");
+              // GemFireCacheImpl.getInstance().getLogger().info("DEBUG equals#11 fn=" +
+              // myType.getFieldName() + " myFieldClass=" + myObject.getClass() + "
+              // otherFieldCLass=" + otherObject.getClass() + " o1=<" + this + "> o2=<" + obj + ">"
+              // + "myObj=<" + myObject + "> otherObj=<" + otherObject + ">");
-          }}
-        break;
+          }
+        }
+          break;
-        }
-      return true;
+    }
+    return true;
-    
+
-   * Any fields that are in otherFields but not in myFields
-   * are added to myFields as defaults. When adding fields they
-   * are inserted in the natural sort order.
-   * Note: myFields may be modified by this call.
+   * Any fields that are in otherFields but not in myFields are added to myFields as defaults. When
+   * adding fields they are inserted in the natural sort order. Note: myFields may be modified by
+   * this call.
-  private static void addDefaultFields(SortedSet<PdxField> myFields, SortedSet<PdxField> otherFields) {
-    for (PdxField f: otherFields) {
+  private static void addDefaultFields(SortedSet<PdxField> myFields,
+      SortedSet<PdxField> otherFields) {
+    for (PdxField f : otherFields) {
-    result.append("PDX[").append(ur.getPdxType().getTypeId()).append(",").append(ur.getPdxType().getClassName())
-    //.append(",limit=").append(this.dis.size())
-    .append("]{");
+    result.append("PDX[").append(ur.getPdxType().getTypeId()).append(",")
+        .append(ur.getPdxType().getClassName())
+        // .append(",limit=").append(this.dis.size())
+        .append("]{");
-    for(PdxField fieldType : ur.getPdxType().getSortedIdentityFields()) {
-      if(firstElement) {firstElement= false;} else {result.append(", ");};
+    for (PdxField fieldType : ur.getPdxType().getSortedIdentityFields()) {
+      if (firstElement) {
+        firstElement = false;
+      } else {
+        result.append(", ");
+      } ;
-      //result.append(':').append(fieldType.getTypeIdString()); // DEBUG
-      //result.append(':').append(getAbsolutePosition(fieldType)); // DEBUG
+      // result.append(':').append(fieldType.getTypeIdString()); // DEBUG
+      // result.append(':').append(getAbsolutePosition(fieldType)); // DEBUG
-  
+
+
-  
+
+
-  
+
-  public
-  synchronized Object readObject(PdxField ft) {
+  public synchronized Object readObject(PdxField ft) {
-  protected synchronized void basicSendTo(DataOutput out)  throws IOException {
+  protected synchronized void basicSendTo(DataOutput out) throws IOException {
-  
+
-  
-  public Object getRawField(String fieldName){
+
+  public Object getRawField(String fieldName) {
-  
-  
- public Object getDefaultValueIfFieldExistsInAnyPdxVersions(String fieldName,
-     String className) throws FieldNotFoundInPdxVersion {
-   PdxType pdxType = GemFireCacheImpl
-       .getForPdx(
-           "PDX registry is unavailable because the Cache has been closed.")
-       .getPdxRegistry().getPdxTypeForField(fieldName, className);
-   if (pdxType == null) {
-     throw new FieldNotFoundInPdxVersion("PdxType with field "
-         + fieldName + " is not found for class " + className);
-   }
-   return pdxType.getPdxField(fieldName).getFieldType().getDefaultValue();
- }
+
+
+  public Object getDefaultValueIfFieldExistsInAnyPdxVersions(String fieldName, String className)
+      throws FieldNotFoundInPdxVersion {
+    PdxType pdxType =
+        GemFireCacheImpl.getForPdx("PDX registry is unavailable because the Cache has been closed.")
+            .getPdxRegistry().getPdxTypeForField(fieldName, className);
+    if (pdxType == null) {
+      throw new FieldNotFoundInPdxVersion(
+          "PdxType with field " + fieldName + " is not found for class " + className);
+    }
+    return pdxType.getPdxField(fieldName).getFieldType().getDefaultValue();
+  }
