GEODE-3928: createIndex on existing region creates lucene indexes for existing data

+import java.io.Serializable;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Set;
+import org.apache.geode.cache.CacheClosedException;
+import org.apache.geode.cache.EntryDestroyedException;
+import org.apache.geode.cache.Region;
+import org.apache.geode.cache.query.internal.DefaultQuery;
+import org.apache.geode.distributed.LockServiceDestroyedException;
+import org.apache.geode.internal.cache.ColocationHelper;
+import org.apache.geode.internal.cache.EntrySnapshot;
+import org.apache.geode.internal.cache.PartitionRegionConfig;
+  public static final String APACHE_GEODE_INDEX_COMPLETE = "APACHE_GEODE_INDEX_COMPLETE";
+    // We need to ensure that all members have created the fileAndChunk region before continuing
+    Region prRoot = PartitionedRegionHelper.getPRRoot(fileRegion.getCache());
+    PartitionRegionConfig prConfig =
+        (PartitionRegionConfig) prRoot.get(fileRegion.getRegionIdentifier());
+    while (!prConfig.isColocationComplete()) {
+      prConfig = (PartitionRegionConfig) prRoot.get(fileRegion.getRegionIdentifier());
+    }
+
+    DefaultQuery.setPdxReadSerialized(true);
-      RegionDirectory dir = new RegionDirectory(getBucketTargetingMap(fileAndChunkBucket, bucketId),
-          indexForPR.getFileSystemStats());
+      // bucketTargetingMap handles partition resolver (via bucketId as callbackArg)
+      Map bucketTargetingMap = getBucketTargetingMap(fileAndChunkBucket, bucketId);
+      RegionDirectory dir =
+          new RegionDirectory(bucketTargetingMap, indexForPR.getFileSystemStats());
-      success = true;
+      success = false;
+      // fileRegion ops (get/put) need bucketId as a callbackArg for PartitionResolver
+      if (null != fileRegion.get(APACHE_GEODE_INDEX_COMPLETE, bucketId)) {
+        success = true;
+        return repo;
+      } else {
+        Set<IndexRepository> affectedRepos = new HashSet<IndexRepository>();
+
+        Iterator keysIterator = dataBucket.keySet().iterator();
+        while (keysIterator.hasNext()) {
+          Object key = keysIterator.next();
+          Object value = getValue(userRegion.getEntry(key));
+          if (value != null) {
+            repo.update(key, value);
+          } else {
+            repo.delete(key);
+          }
+          affectedRepos.add(repo);
+        }
+
+        for (IndexRepository affectedRepo : affectedRepos) {
+          affectedRepo.commit();
+        }
+        // fileRegion ops (get/put) need bucketId as a callbackArg for PartitionResolver
+        fileRegion.put(APACHE_GEODE_INDEX_COMPLETE, APACHE_GEODE_INDEX_COMPLETE, bucketId);
+        success = true;
+      }
+    } catch (CacheClosedException e) {
+      logger.info("CacheClosedException thrown while constructing Lucene Index for bucket:"
+          + bucketId + " for file region:" + fileAndChunkBucket.getFullPath());
+      throw e;
+        DefaultQuery.setPdxReadSerialized(false);
+  }
+  private Object getValue(Region.Entry entry) {
+    final EntrySnapshot es = (EntrySnapshot) entry;
+    Object value;
+    try {
+      value = es == null ? null : es.getRawValue(true);
+    } catch (EntryDestroyedException e) {
+      value = null;
+    }
+    return value;
