Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
-  
-  protected final Map<String, PartitionedRegion> userRegionNameToshadowPRMap = new ConcurrentHashMap<String, PartitionedRegion>();
+
+  protected final Map<String, PartitionedRegion> userRegionNameToshadowPRMap =
+      new ConcurrentHashMap<String, PartitionedRegion>();
-  
-  private static StoppableCondition regionToDispatchedKeysMapEmpty; 
+
+  private static StoppableCondition regionToDispatchedKeysMapEmpty;
-  
+
-  
+
-   * False signal is fine on this condition.
-   * As processor will loop again and find out if it was a false signal.
-   * However, make sure that whatever scenario can cause an entry to be peeked
-   * shoudld signal the processor to unblock.
+   * False signal is fine on this condition. As processor will loop again and find out if it was a
+   * false signal. However, make sure that whatever scenario can cause an entry to be peeked shoudld
+   * signal the processor to unblock.
-  
+
-  
+
-  
-  
-  
-  /**
-   * There will be one shadow pr for each of the the PartitionedRegion which has added the GatewaySender
-   * Fix for Bug#45917
-   * We maintain a tempQueue to queue events when buckets are not available locally.
-   */
-  private final ConcurrentMap<Integer, BlockingQueue<GatewaySenderEventImpl>> bucketToTempQueueMap = new ConcurrentHashMap<Integer, BlockingQueue<GatewaySenderEventImpl>>();
+
+
-   * The default frequency (in milliseconds) at which a message will be sent by the
-   * primary to all the secondary nodes to remove the events which have already
-   * been dispatched from the queue.
+   * There will be one shadow pr for each of the the PartitionedRegion which has added the
+   * GatewaySender Fix for Bug#45917 We maintain a tempQueue to queue events when buckets are not
+   * available locally.
+   */
+  private final ConcurrentMap<Integer, BlockingQueue<GatewaySenderEventImpl>> bucketToTempQueueMap =
+      new ConcurrentHashMap<Integer, BlockingQueue<GatewaySenderEventImpl>>();
+
+  /**
+   * The default frequency (in milliseconds) at which a message will be sent by the primary to all
+   * the secondary nodes to remove the events which have already been dispatched from the queue.
-  //TODO:REF: how to change the message sync interval ? should it be common for serial and parallel  
+  // TODO:REF: how to change the message sync interval ? should it be common for serial and parallel
-  //TODO:REF: name change for thread, as it appears in the log
+  // TODO:REF: name change for thread, as it appears in the log
-  protected BlockingQueue<GatewaySenderEventImpl> peekedEvents = new LinkedBlockingQueue<GatewaySenderEventImpl>();
+  protected BlockingQueue<GatewaySenderEventImpl> peekedEvents =
+      new LinkedBlockingQueue<GatewaySenderEventImpl>();
-   * The peekedEventsProcessing queue is used when the batch size is reduced due to a MessageTooLargeException
+   * The peekedEventsProcessing queue is used when the batch size is reduced due to a
+   * MessageTooLargeException
-  private BlockingQueue<GatewaySenderEventImpl> peekedEventsProcessing = new LinkedBlockingQueue<GatewaySenderEventImpl>();
+  private BlockingQueue<GatewaySenderEventImpl> peekedEventsProcessing =
+      new LinkedBlockingQueue<GatewaySenderEventImpl>();
-   * The peekedEventsProcessingInProgress boolean denotes that processing existing peeked events is in progress
+   * The peekedEventsProcessingInProgress boolean denotes that processing existing peeked events is
+   * in progress
-  public final AbstractGatewaySender sender ;
-  
+  public final AbstractGatewaySender sender;
+
-  
+
-   * Fixed size Thread pool for conflating the events in the queue. The size of
-   * the thread pool is set to the number of processors available to the JVM.
-   * There will be one thread pool per ParallelGatewaySender on a node.
+   * Fixed size Thread pool for conflating the events in the queue. The size of the thread pool is
+   * set to the number of processors available to the JVM. There will be one thread pool per
+   * ParallelGatewaySender on a node.
-   * This class carries out the actual removal of the previousTailKey from QPR.
-   * The class implements Runnable and the destroy operation is done in the run
-   * method. The Runnable is executed by the one of the threads in the
-   * conflation thread pool configured above.
+   * This class carries out the actual removal of the previousTailKey from QPR. The class implements
+   * Runnable and the destroy operation is done in the run method. The Runnable is executed by the
+   * one of the threads in the conflation thread pool configured above.
-    public ConflationHandler(Conflatable conflatableObject, int bId,
-        Long previousTailKey) {
+    public ConflationHandler(Conflatable conflatableObject, int bId, Long previousTailKey) {
-      GatewaySenderEventImpl event = (GatewaySenderEventImpl)conflatableObject;
+      GatewaySenderEventImpl event = (GatewaySenderEventImpl) conflatableObject;
-        String regionPath = ColocationHelper.getLeaderRegion((PartitionedRegion)event.getRegion()).getFullPath();
+        String regionPath =
+            ColocationHelper.getLeaderRegion((PartitionedRegion) event.getRegion()).getFullPath();
-          logger.debug("{}: Not conflating {} due to EntryNotFoundException", this, conflatableObject.getKeyToConflate());
+          logger.debug("{}: Not conflating {} due to EntryNotFoundException", this,
+              conflatableObject.getKeyToConflate());
-        logger.debug("{}: Conflated {} for key={} in queue for region={}",
-            this, conflatableObject.getValueToConflate(), conflatableObject.getKeyToConflate(), prQ.getName());
+        logger.debug("{}: Conflated {} for key={} in queue for region={}", this,
+            conflatableObject.getValueToConflate(), conflatableObject.getKeyToConflate(),
+            prQ.getName());
-        byte[] serializedBytesCast = (byte[])serializedBytes;
+        byte[] serializedBytesCast = (byte[]) serializedBytes;
-  
-  final protected int index; 
+
+  final protected int index;
-  
+
-   * A transient queue to maintain the eventSeqNum of the events that are to be
-   * sent to remote site. It is cleared when the queue is cleared.
+   * A transient queue to maintain the eventSeqNum of the events that are to be sent to remote site.
+   * It is cleared when the queue is cleared.
-  //private final BlockingQueue<Long> eventSeqNumQueue;
-  
-  public ParallelGatewaySenderQueue(AbstractGatewaySender sender,
-      Set<Region> userRegions, int idx, int nDispatcher) {
+  // private final BlockingQueue<Long> eventSeqNumQueue;
+
+  public ParallelGatewaySenderQueue(AbstractGatewaySender sender, Set<Region> userRegions, int idx,
+      int nDispatcher) {
-  
-  ParallelGatewaySenderQueue(AbstractGatewaySender sender,
-      Set<Region> userRegions, int idx, int nDispatcher, MetaRegionFactory metaRegionFactory) {
-  
+
+  ParallelGatewaySenderQueue(AbstractGatewaySender sender, Set<Region> userRegions, int idx,
+      int nDispatcher, MetaRegionFactory metaRegionFactory) {
+
-    
+
-    
+
-    //eventSeqNumQueue = new LinkedBlockingQueue<Long>();
+    // eventSeqNumQueue = new LinkedBlockingQueue<Long>();
-    
+
-      if(userRegion instanceof PartitionedRegion){
-        addShadowPartitionedRegionForUserPR((PartitionedRegion)userRegion);  
-      }
-      else {
-        //Fix for Bug#51491. Once decided to support this configuration we have call addShadowPartitionedRegionForUserRR
-        if (this.sender.getId().contains(
-            AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX)) {
+      if (userRegion instanceof PartitionedRegion) {
+        addShadowPartitionedRegionForUserPR((PartitionedRegion) userRegion);
+      } else {
+        // Fix for Bug#51491. Once decided to support this configuration we have call
+        // addShadowPartitionedRegionForUserRR
+        if (this.sender.getId().contains(AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX)) {
-              LocalizedStrings.ParallelAsyncEventQueue_0_CAN_NOT_BE_USED_WITH_REPLICATED_REGION_1.toLocalizedString(new Object[] {
-                  AsyncEventQueueImpl
-                      .getAsyncEventQueueIdFromSenderId(this.sender.getId()),
-                  userRegion.getFullPath() }));
+              LocalizedStrings.ParallelAsyncEventQueue_0_CAN_NOT_BE_USED_WITH_REPLICATED_REGION_1
+                  .toLocalizedString(new Object[] {
+                      AsyncEventQueueImpl.getAsyncEventQueueIdFromSenderId(this.sender.getId()),
+                      userRegion.getFullPath()}));
-                .toLocalizedString(new Object[] { this.sender.getId(),
-                    userRegion.getFullPath() }));
+                .toLocalizedString(new Object[] {this.sender.getId(), userRegion.getFullPath()}));
-    
-    if( buckToDispatchLock == null) {
+
+    if (buckToDispatchLock == null) {
-    if(regionToDispatchedKeysMapEmpty == null) {
+    if (regionToDispatchedKeysMapEmpty == null) {
-    
+
-    
-    //initialize the conflation thread pool if conflation is enabled
+
+    // initialize the conflation thread pool if conflation is enabled
-  /**Start the background batch removal thread. */
+  /** Start the background batch removal thread. */
-    //at present, this won't be accessed by multiple threads, 
-    //still, it is safer approach to synchronize it
+    // at present, this won't be accessed by multiple threads,
+    // still, it is safer approach to synchronize it
-        removalThread = new BatchRemovalThread(
-          (GemFireCacheImpl)this.sender.getCache(), this);
+        removalThread = new BatchRemovalThread((GemFireCacheImpl) this.sender.getCache(), this);
-  public void addShadowPartitionedRegionForUserRR(
-      DistributedRegion userRegion) {
+  public void addShadowPartitionedRegionForUserRR(DistributedRegion userRegion) {
-      logger.debug("addShadowPartitionedRegionForUserRR: Going to create shadowpr for userRegion {}", userRegion.getFullPath());
+      logger.debug(
+          "addShadowPartitionedRegionForUserRR: Going to create shadowpr for userRegion {}",
+          userRegion.getFullPath());
-      
+
-      GemFireCacheImpl cache = (GemFireCacheImpl)sender.getCache();
+      GemFireCacheImpl cache = (GemFireCacheImpl) sender.getCache();
-      prQ = (PartitionedRegion)cache.getRegion(prQName);
+      prQ = (PartitionedRegion) cache.getRegion(prQName);
-        //Fix for 48621 - don't enable concurrency checks 
-        //for queue buckets., event with persistence
+        // Fix for 48621 - don't enable concurrency checks
+        // for queue buckets., event with persistence
-        pfact.setTotalNumBuckets(sender.getMaxParallelismForReplicatedRegion()); 
-        int localMaxMemory = userRegion.getDataPolicy().withStorage() ? sender
-            .getMaximumQueueMemory() : 0;
+        pfact.setTotalNumBuckets(sender.getMaxParallelismForReplicatedRegion());
+        int localMaxMemory =
+            userRegion.getDataPolicy().withStorage() ? sender.getMaximumQueueMemory() : 0;
-        pfact.setRedundantCopies(3); //TODO:Kishor : THis need to be handled nicely
+        pfact.setRedundantCopies(3); // TODO:Kishor : THis need to be handled nicely
-        
+
-        
+
-      //optimize with above check of enable persistence
+        // optimize with above check of enable persistence
-        ParallelGatewaySenderQueueMetaRegion meta = new ParallelGatewaySenderQueueMetaRegion(
-            prQName, ra, null, cache, sender);
+        ParallelGatewaySenderQueueMetaRegion meta =
+            new ParallelGatewaySenderQueueMetaRegion(prQName, ra, null, cache, sender);
-          prQ = (PartitionedRegion)cache.createVMRegion(prQName, ra,
-              new InternalRegionArguments().setInternalMetaRegion(meta)
-                  .setDestroyLockFlag(true).setSnapshotInputStream(null)
-                  .setImageTarget(null));
+          prQ = (PartitionedRegion) cache.createVMRegion(prQName, ra,
+              new InternalRegionArguments().setInternalMetaRegion(meta).setDestroyLockFlag(true)
+                  .setSnapshotInputStream(null).setImageTarget(null));
-            logger.debug("Region created  : {} partition Attributes : {}", prQ, prQ.getPartitionAttributes());
+            logger.debug("Region created  : {} partition Attributes : {}", prQ,
+                prQ.getPartitionAttributes());
-          
+
-            Iterator<Integer> itr = prQ.getRegionAdvisor().getBucketSet()
-                .iterator();
+            Iterator<Integer> itr = prQ.getRegionAdvisor().getBucketSet().iterator();
-       // In case of Replicated Region it may not be necessary.
-          
-//          if (sender.isPersistenceEnabled()) {
-//            //Kishor: I need to write a test for this code.
-//            Set<Integer> allBucketsClone = new HashSet<Integer>();
-//            // allBucketsClone.addAll(allBuckets);*/
-//            for (int i = 0; i < sender.getMaxParallelismForReplicatedRegion(); i++)
-//              allBucketsClone.add(i);
-//
-//            while (!(allBucketsClone.size() == 0)) {
-//              Iterator<Integer> itr = allBucketsClone.iterator();
-//              while (itr.hasNext()) {
-//                InternalDistributedMember node = prQ.getNodeForBucketWrite(
-//                    itr.next(), null);
-//                if (node != null) {
-//                  itr.remove();
-//                }
-//              }
-//              // after the iteration is over, sleep for sometime before trying
-//              // again
-//              try {
-//                Thread.sleep(WAIT_CYCLE_SHADOW_BUCKET_LOAD);
-//              }
-//              catch (InterruptedException e) {
-//                logger.error(e);
-//              }
-//            }
-//          }
-        }
-        catch (IOException veryUnLikely) {
+          // In case of Replicated Region it may not be necessary.
+
+          // if (sender.isPersistenceEnabled()) {
+          // //Kishor: I need to write a test for this code.
+          // Set<Integer> allBucketsClone = new HashSet<Integer>();
+          // // allBucketsClone.addAll(allBuckets);*/
+          // for (int i = 0; i < sender.getMaxParallelismForReplicatedRegion(); i++)
+          // allBucketsClone.add(i);
+          //
+          // while (!(allBucketsClone.size() == 0)) {
+          // Iterator<Integer> itr = allBucketsClone.iterator();
+          // while (itr.hasNext()) {
+          // InternalDistributedMember node = prQ.getNodeForBucketWrite(
+          // itr.next(), null);
+          // if (node != null) {
+          // itr.remove();
+          // }
+          // }
+          // // after the iteration is over, sleep for sometime before trying
+          // // again
+          // try {
+          // Thread.sleep(WAIT_CYCLE_SHADOW_BUCKET_LOAD);
+          // }
+          // catch (InterruptedException e) {
+          // logger.error(e);
+          // }
+          // }
+          // }
+        } catch (IOException veryUnLikely) {
-        }
-        catch (ClassNotFoundException alsoUnlikely) {
+        } catch (ClassNotFoundException alsoUnlikely) {
-      }
-      else {
+      } else {
-      	if(this.index == 0) //HItesh: for first processor only
-        	handleShadowPRExistsScenario(cache, prQ);
+        if (this.index == 0) // HItesh: for first processor only
+          handleShadowPRExistsScenario(cache, prQ);
-         * Here, enqueueTempEvents need to be invoked when a sender is already
-       * running and userPR is created later. When the flow comes here through
-       * start() method of sender i.e. userPR already exists and sender is
-       * started later, the enqueueTempEvents is done in the start() method of
-       * ParallelGatewaySender
+       * Here, enqueueTempEvents need to be invoked when a sender is already running and userPR is
+       * created later. When the flow comes here through start() method of sender i.e. userPR
+       * already exists and sender is started later, the enqueueTempEvents is done in the start()
+       * method of ParallelGatewaySender
-        ((AbstractGatewaySender)sender).enqueueTempEvents();
+        ((AbstractGatewaySender) sender).enqueueTempEvents();
-    }
-    finally {
+    } finally {
-	      this.userRegionNameToshadowPRMap.put(userRegion.getFullPath(), prQ);
+        this.userRegionNameToshadowPRMap.put(userRegion.getFullPath(), prQ);
-  
+
-    //return fullPath.replaceAll("/", "_");
+    // return fullPath.replaceAll("/", "_");
-      logger.debug("{} addShadowPartitionedRegionForUserPR: Attempting to create queue region: {}", this, userPR.getDisplayName());
+      logger.debug("{} addShadowPartitionedRegionForUserPR: Attempting to create queue region: {}",
+          this, userPR.getDisplayName());
-    
+
-      String leaderRegionName = ColocationHelper.getLeaderRegion(userPR)
-          .getFullPath();
-      if(!regionName.equals(leaderRegionName)) {
-        //Fix for defect #50364. Allow user to attach GatewaySender to child PR (without attaching to leader PR) 
-    	//though, internally, colocate the GatewaySender's shadowPR with the leader PR in colocation chain
+      String leaderRegionName = ColocationHelper.getLeaderRegion(userPR).getFullPath();
+      if (!regionName.equals(leaderRegionName)) {
+        // Fix for defect #50364. Allow user to attach GatewaySender to child PR (without attaching
+        // to leader PR)
+        // though, internally, colocate the GatewaySender's shadowPR with the leader PR in
+        // colocation chain
-        	addShadowPartitionedRegionForUserPR(ColocationHelper.getLeaderRegion(userPR));
+          addShadowPartitionedRegionForUserPR(ColocationHelper.getLeaderRegion(userPR));
-        return;  
+        return;
-      
-      if(userPR.getDataPolicy().withPersistence() && !sender.isPersistenceEnabled()){
+
+      if (userPR.getDataPolicy().withPersistence() && !sender.isPersistenceEnabled()) {
-                .toLocalizedString(new Object[] { this.sender.getId(),
-                    userPR.getFullPath() }));
+                .toLocalizedString(new Object[] {this.sender.getId(), userPR.getFullPath()}));
-      
-      GemFireCacheImpl cache = (GemFireCacheImpl)sender.getCache();
+
+      GemFireCacheImpl cache = (GemFireCacheImpl) sender.getCache();
-      
-      final String prQName = sender.getId()
-          + QSTRING + convertPathToName(userPR.getFullPath());
-      prQ = (PartitionedRegion)cache.getRegion(prQName);
+
+      final String prQName = sender.getId() + QSTRING + convertPathToName(userPR.getFullPath());
+      prQ = (PartitionedRegion) cache.getRegion(prQName);
-        //TODO:REF:Avoid deprecated apis
-        
+        // TODO:REF:Avoid deprecated apis
+
-        int localMaxMemory = isAccessor ? 0 : sender
-            .getMaximumQueueMemory();
+        int localMaxMemory = isAccessor ? 0 : sender.getMaximumQueueMemory();
-        
+
-        
-        if(sender.isPersistenceEnabled() && !isAccessor) {
+
+        if (sender.isPersistenceEnabled() && !isAccessor) {
-        
+
-        
-        //if persistence is enabled, set the diskSyncronous to whatever user has set
-        //else set it to false
+
+        // if persistence is enabled, set the diskSyncronous to whatever user has set
+        // else set it to false
-        
+
-        
+
-        ParallelGatewaySenderQueueMetaRegion meta = metaRegionFactory.newMetataRegion(cache,
-            prQName, ra, sender);
+        ParallelGatewaySenderQueueMetaRegion meta =
+            metaRegionFactory.newMetataRegion(cache, prQName, ra, sender);
-          prQ = (PartitionedRegion)cache
-              .createVMRegion(prQName, ra, new InternalRegionArguments()
-                  .setInternalMetaRegion(meta).setDestroyLockFlag(true).setInternalRegion(true)
-                  .setSnapshotInputStream(null).setImageTarget(null));
-          // at this point we should be able to assert prQ == meta; 
-          
-          //Suranjan: TODO This should not be set on the PR but on the GatewaySender
-          prQ.enableConflation(sender
-              .isBatchConflationEnabled());
+          prQ = (PartitionedRegion) cache.createVMRegion(prQName, ra,
+              new InternalRegionArguments().setInternalMetaRegion(meta).setDestroyLockFlag(true)
+                  .setInternalRegion(true).setSnapshotInputStream(null).setImageTarget(null));
+          // at this point we should be able to assert prQ == meta;
+
+          // Suranjan: TODO This should not be set on the PR but on the GatewaySender
+          prQ.enableConflation(sender.isBatchConflationEnabled());
-          //Wait for buckets to be recovered.
+          // Wait for buckets to be recovered.
-          logger.fatal(LocalizedMessage.create(LocalizedStrings.SingleWriteSingleReadRegionQueue_UNEXPECTED_EXCEPTION_DURING_INIT_OF_0,
-                  this.getClass()), veryUnLikely);
+          logger.fatal(LocalizedMessage.create(
+              LocalizedStrings.SingleWriteSingleReadRegionQueue_UNEXPECTED_EXCEPTION_DURING_INIT_OF_0,
+              this.getClass()), veryUnLikely);
-        if(this.index == 0) //HItesh:for first parallelGatewaySenderQueue only 
-        	handleShadowPRExistsScenario(cache, prQ);
+        if (this.index == 0) // HItesh:for first parallelGatewaySenderQueue only
+          handleShadowPRExistsScenario(cache, prQ);
-	
+
-       * Here, enqueueTempEvents need to be invoked when a sender is already
-       * running and userPR is created later. When the flow comes here through
-       * start() method of sender i.e. userPR already exists and sender is
-       * started later, the enqueueTempEvents is done in the start() method of
-       * ParallelGatewaySender
+       * Here, enqueueTempEvents need to be invoked when a sender is already running and userPR is
+       * created later. When the flow comes here through start() method of sender i.e. userPR
+       * already exists and sender is started later, the enqueueTempEvents is done in the start()
+       * method of ParallelGatewaySender
-        ((AbstractGatewaySender)sender).enqueueTempEvents();
+        ((AbstractGatewaySender) sender).enqueueTempEvents();
-    //Note: The region will not be null if the sender is started again after stop operation
+    // Note: The region will not be null if the sender is started again after stop operation
-      logger.debug("{}: No need to create the region as the region has been retrieved: {}", this, prQ);
+      logger.debug("{}: No need to create the region as the region has been retrieved: {}", this,
+          prQ);
-    Set<BucketRegion> localBucketRegions = prQ.getDataStore()
-        .getAllLocalBucketRegions();
+    Set<BucketRegion> localBucketRegions = prQ.getDataStore().getAllLocalBucketRegions();
-  protected void afterRegionAdd (PartitionedRegion userPR) {
+
+  protected void afterRegionAdd(PartitionedRegion userPR) {
+
-   * Initialize the thread pool, setting the number of threads that is equal 
-   * to the number of processors available to the JVM.
+   * Initialize the thread pool, setting the number of threads that is equal to the number of
+   * processors available to the JVM.
-      final LoggingThreadGroup loggingThreadGroup = LoggingThreadGroup
-          .createThreadGroup("WAN Queue Conflation Logger Group", logger);
+      final LoggingThreadGroup loggingThreadGroup =
+          LoggingThreadGroup.createThreadGroup("WAN Queue Conflation Logger Group", logger);
-          final Thread thread = new Thread(loggingThreadGroup, task,
-              "WAN Queue Conflation Thread");
+          final Thread thread = new Thread(loggingThreadGroup, task, "WAN Queue Conflation Thread");
-      conflationExecutor = Executors.newFixedThreadPool(Runtime.getRuntime()
-          .availableProcessors(), threadFactory);
+      conflationExecutor =
+          Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors(), threadFactory);
-  
+
-   * Cleans up the conflation thread pool. 
-   * Initially, shutdown is done to avoid accepting any newly submitted tasks.
-   * Wait a while for existing tasks to terminate. If the existing tasks still don't 
-   * complete, cancel them by calling shutdownNow. 
+   * Cleans up the conflation thread pool. Initially, shutdown is done to avoid accepting any newly
+   * submitted tasks. Wait a while for existing tasks to terminate. If the existing tasks still
+   * don't complete, cancel them by calling shutdownNow.
-    
+
-    if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
-      conflationExecutor.shutdownNow(); // Cancel currently executing tasks
-      // Wait a while for tasks to respond to being cancelled
+      if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
+        conflationExecutor.shutdownNow(); // Cancel currently executing tasks
+        // Wait a while for tasks to respond to being cancelled
-          logger
-              .warn(LocalizedMessage
-                  .create(
-                      LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL,
-                      (sender == null ? "all" : sender)));
+          logger.warn(LocalizedMessage.create(
+              LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL,
+              (sender == null ? "all" : sender)));
-    }
+      }
-  
+
-    //Suranjan : Can this region ever be null? Should we work with regionName and not with region instance. 
+    // Suranjan : Can this region ever be null? Should we work with regionName and not with region
+    // instance.
-    GatewaySenderEventImpl value = (GatewaySenderEventImpl)object;
+    GatewaySenderEventImpl value = (GatewaySenderEventImpl) object;
-    
-//    if (isDREvent(value)) {
-//      putInShadowPRForReplicatedRegion(object);
-//      value.freeOffHeapValue();
-//      return;
-//    }
-    
+
+    // if (isDREvent(value)) {
+    // putInShadowPRForReplicatedRegion(object);
+    // value.freeOffHeapValue();
+    // return;
+    // }
+
-    }
-    else {
-      regionPath = ColocationHelper.getLeaderRegion((PartitionedRegion)region)
-          .getFullPath();
+    } else {
+      regionPath = ColocationHelper.getLeaderRegion((PartitionedRegion) region).getFullPath();
-      logger.warn(LocalizedMessage.create(LocalizedStrings.NOT_QUEUING_AS_USERPR_IS_NOT_YET_CONFIGURED, value));        
-      //does not put into queue
+      logger.warn(LocalizedMessage
+          .create(LocalizedStrings.NOT_QUEUING_AS_USERPR_IS_NOT_YET_CONFIGURED, value));
+      // does not put into queue
-    
+
-    if(!isDREvent){
+    if (!isDREvent) {
-      
-      if ((Long)key == -1) {
+
+      if ((Long) key == -1) {
-          logger.debug("ParallelGatewaySenderOrderedQueue not putting key {} : Value : {}", key, value);
+          logger.debug("ParallelGatewaySenderOrderedQueue not putting key {} : Value : {}", key,
+              value);
-        //does not put into queue
+        // does not put into queue
-      }  
-    }else{
+      }
+    } else {
-    
+
-    AbstractBucketRegionQueue brq = (AbstractBucketRegionQueue)prQ.getDataStore()
-        .getLocalBucketById(bucketId);
-    
+    AbstractBucketRegionQueue brq =
+        (AbstractBucketRegionQueue) prQ.getDataStore().getLocalBucketById(bucketId);
+
-        int oldLevel = LocalRegion
-            .setThreadInitLevelRequirement(LocalRegion.BEFORE_INITIAL_IMAGE);
+        int oldLevel = LocalRegion.setThreadInitLevelRequirement(LocalRegion.BEFORE_INITIAL_IMAGE);
-          final String bucketFullPath = Region.SEPARATOR
-              + PartitionedRegionHelper.PR_ROOT_REGION_NAME + Region.SEPARATOR
-              + prQ.getBucketName(bucketId);
+          final String bucketFullPath =
+              Region.SEPARATOR + PartitionedRegionHelper.PR_ROOT_REGION_NAME + Region.SEPARATOR
+                  + prQ.getBucketName(bucketId);
-          brq = (AbstractBucketRegionQueue)prQ.getCache().getRegionByPath(
-              bucketFullPath);
+          brq = (AbstractBucketRegionQueue) prQ.getCache().getRegionByPath(bucketFullPath);
-            logger.debug("ParallelGatewaySenderOrderedQueue : The bucket in the cache is bucketRegionName : {} bucket : {}",
+            logger.debug(
+                "ParallelGatewaySenderOrderedQueue : The bucket in the cache is bucketRegionName : {} bucket : {}",
-            if (((PartitionedRegion)prQ.getColocatedWithRegion())
-                .getRegionAdvisor().getBucketAdvisor(bucketId)
-                .getShadowBucketDestroyed()) {
+            if (((PartitionedRegion) prQ.getColocatedWithRegion()).getRegionAdvisor()
+                .getBucketAdvisor(bucketId).getShadowBucketDestroyed()) {
-                logger.debug("ParallelGatewaySenderOrderedQueue not putting key {} : Value : {} as shadowPR bucket is destroyed.",
+                logger.debug(
+                    "ParallelGatewaySenderOrderedQueue not putting key {} : Value : {} as shadowPR bucket is destroyed.",
-               * This is to prevent data loss, in the scenario when bucket is
-               * not available in the cache but we know that it will be created.
+               * This is to prevent data loss, in the scenario when bucket is not available in the
+               * cache but we know that it will be created.
-                brq = (AbstractBucketRegionQueue)prQ.getCache()
-                    .getRegionByPath(bucketFullPath);
+                brq = (AbstractBucketRegionQueue) prQ.getCache().getRegionByPath(bucketFullPath);
-                    logger.debug("The value {} is enqueued to the tempQueue for the BucketRegionQueue.", value);
+                    logger.debug(
+                        "The value {} is enqueued to the tempQueue for the BucketRegionQueue.",
+                        value);
-          thisbucketDestroyed = ((PartitionedRegion)prQ
-              .getColocatedWithRegion()).getRegionAdvisor()
-              .getBucketAdvisor(bucketId).getShadowBucketDestroyed()
-              || brq.isDestroyed();
+          thisbucketDestroyed =
+              ((PartitionedRegion) prQ.getColocatedWithRegion()).getRegionAdvisor()
+                  .getBucketAdvisor(bucketId).getShadowBucketDestroyed() || brq.isDestroyed();
-            logger.debug("ParallelGatewaySenderOrderedQueue not putting key {} : Value : {} as shadowPR bucket is destroyed.",
+            logger.debug(
+                "ParallelGatewaySenderOrderedQueue not putting key {} : Value : {} as shadowPR bucket is destroyed.",
-    //putter thread should not take lock every time
-    if(isQueueEmpty) {
+    // putter thread should not take lock every time
+    if (isQueueEmpty) {
-        if(logger.isDebugEnabled()) {
+        if (logger.isDebugEnabled()) {
-        if(logger.isDebugEnabled()) {
+        if (logger.isDebugEnabled()) {
-//        if (brq.getBucketAdvisor().isPrimary()) {
-//          this.stats.incQueueSize();
-//        }
-      } 
+        // if (brq.getBucketAdvisor().isPrimary()) {
+        // this.stats.incQueueSize();
+        // }
+      }
-            brq.getPartitionedRegion().getRegionAdvisor().getBucketAdvisor(brq.getId()).getBucketRedundancy());
+            brq.getPartitionedRegion().getRegionAdvisor().getBucketAdvisor(brq.getId())
+                .getBucketRedundancy());
-        logger.debug("getInitializedBucketForId: Got ForceReattemptException for {} for bucket = {}", this, brq.getId());
+        logger.debug(
+            "getInitializedBucketForId: Got ForceReattemptException for {} for bucket = {}", this,
+            brq.getId());
-  } 
+  }
-    return this.userRegionNameToshadowPRMap.size() == 1 ? (Region)this.userRegionNameToshadowPRMap
-        .values().toArray()[0] : null;
+    return this.userRegionNameToshadowPRMap.size() == 1
+        ? (Region) this.userRegionNameToshadowPRMap.values().toArray()[0] : null;
-    }
-    finally {
+    } finally {
-  
+
-  
-  // TODO: Suranjan Find optimal way to get Random shadow pr as this will be called in each put and peek.
+
+  // TODO: Suranjan Find optimal way to get Random shadow pr as this will be called in each put and
+  // peek.
-      prQ = (PartitionedRegion)this.userRegionNameToshadowPRMap.values().toArray()[randomIndex];
+      prQ = (PartitionedRegion) this.userRegionNameToshadowPRMap.values().toArray()[randomIndex];
-//    if (this.userPRToshadowPRMap.values().size() > 0
-//        && (prQ == null)) {
-//      prQ = getRandomShadowPR();
-//    }
+    // if (this.userPRToshadowPRMap.values().size() > 0
+    // && (prQ == null)) {
+    // prQ = getRandomShadowPR();
+    // }
-  
-  private boolean isDREvent(GatewaySenderEventImpl event){
+
+  private boolean isDREvent(GatewaySenderEventImpl event) {
+
-    //merge42180.
+    // merge42180.
-  
+
+   * 
-    if( prQ != null) {
+    if (prQ != null) {
-      final List<Integer> buckets = new ArrayList<Integer>(
-          ds.getAllLocalPrimaryBucketIds());
+      final List<Integer> buckets = new ArrayList<Integer>(ds.getAllLocalPrimaryBucketIds());
-      final BucketRegionQueue brq = (BucketRegionQueue)ds
-          .getLocalBucketById(brqId);
+      final BucketRegionQueue brq = (BucketRegionQueue) ds.getLocalBucketById(brqId);
-  
+
-  
+
-      
+
-      
+
-        logger.debug("getRandomPrimaryBucket: total {} for this processor: {}", allBuckets.size(), thisProcessorBuckets.size());
-      }           
-      
-      int nTry =  thisProcessorBuckets.size();
-      
-      while(nTry-- > 0) {
-        if(pickBucketId >= thisProcessorBuckets.size())
+        logger.debug("getRandomPrimaryBucket: total {} for this processor: {}", allBuckets.size(),
+            thisProcessorBuckets.size());
+      }
+
+      int nTry = thisProcessorBuckets.size();
+
+      while (nTry-- > 0) {
+        if (pickBucketId >= thisProcessorBuckets.size())
-        BucketRegionQueue br = getBucketRegionQueueByBucketId(prQ, thisProcessorBuckets.get(pickBucketId++));
+        BucketRegionQueue br =
+            getBucketRegionQueueByBucketId(prQ, thisProcessorBuckets.get(pickBucketId++));
-      
+
-      /*Collections.shuffle(thisProcessorBuckets);
-      for (Integer bucketId : thisProcessorBuckets) {
-        BucketRegionQueue br = (BucketRegionQueue)prQ.getDataStore()
-            .getBucketRegionQueueByBucketId(bucketId);
-        
-        if (br != null && br.isReadyForPeek()) {
-          return br.getId();
-        }
-      }*/
+      /*
+       * Collections.shuffle(thisProcessorBuckets); for (Integer bucketId : thisProcessorBuckets) {
+       * BucketRegionQueue br = (BucketRegionQueue)prQ.getDataStore()
+       * .getBucketRegionQueueByBucketId(bucketId);
+       * 
+       * if (br != null && br.isReadyForPeek()) { return br.getId(); } }
+       */
-  
+
-    //merge42180
+    // merge42180
-      // PartitionedRegion prQ = this.userPRToshadowPRMap.get(ColocationHelper
-      // .getLeaderRegion((PartitionedRegion)event.getRegion()).getFullPath());
-      //
-      PartitionedRegion prQ = null;
-      int bucketId = -1;
-      Object key = null;
-      if (event.getRegion() != null) {
-        if (isDREvent(event)) {
-          prQ = this.userRegionNameToshadowPRMap.get(event.getRegion()
-              .getFullPath());
-          bucketId = event.getEventId().getBucketID();
-          key = event.getEventId();
-        } else {
-          prQ = this.userRegionNameToshadowPRMap.get(ColocationHelper
-              .getLeaderRegion((PartitionedRegion)event.getRegion())
-              .getFullPath());
-          bucketId = event.getBucketId();
-          key = event.getShadowKey();
-        }
-      } else {
-        String regionPath = event.getRegionPath();
-        GemFireCacheImpl cache = (GemFireCacheImpl)this.sender.getCache();
-        Region region = (PartitionedRegion)cache.getRegion(regionPath);
-        if (region != null && !region.isDestroyed()) {
-          // TODO: Suranjan We have to get colocated parent region for this
-          // region
-          if (region instanceof DistributedRegion) {
-            prQ = this.userRegionNameToshadowPRMap.get(region.getFullPath());
-            event.getBucketId();
+        // PartitionedRegion prQ = this.userPRToshadowPRMap.get(ColocationHelper
+        // .getLeaderRegion((PartitionedRegion)event.getRegion()).getFullPath());
+        //
+        PartitionedRegion prQ = null;
+        int bucketId = -1;
+        Object key = null;
+        if (event.getRegion() != null) {
+          if (isDREvent(event)) {
+            prQ = this.userRegionNameToshadowPRMap.get(event.getRegion().getFullPath());
+            bucketId = event.getEventId().getBucketID();
-                .getLeaderRegion((PartitionedRegion)region).getFullPath());
-            event.getBucketId();
+                .getLeaderRegion((PartitionedRegion) event.getRegion()).getFullPath());
+            bucketId = event.getBucketId();
+        } else {
+          String regionPath = event.getRegionPath();
+          GemFireCacheImpl cache = (GemFireCacheImpl) this.sender.getCache();
+          Region region = (PartitionedRegion) cache.getRegion(regionPath);
+          if (region != null && !region.isDestroyed()) {
+            // TODO: Suranjan We have to get colocated parent region for this
+            // region
+            if (region instanceof DistributedRegion) {
+              prQ = this.userRegionNameToshadowPRMap.get(region.getFullPath());
+              event.getBucketId();
+              key = event.getEventId();
+            } else {
+              prQ = this.userRegionNameToshadowPRMap
+                  .get(ColocationHelper.getLeaderRegion((PartitionedRegion) region).getFullPath());
+              event.getBucketId();
+              key = event.getShadowKey();
+            }
+          }
-      }
-      if (prQ != null) {
-        destroyEventFromQueue(prQ, bucketId, key);
-      }
+        if (prQ != null) {
+          destroyEventFromQueue(prQ, bucketId, key);
+        }
-  private void destroyEventFromQueue(PartitionedRegion prQ, int bucketId,
-      Object key) {
-    boolean isPrimary = prQ.getRegionAdvisor().getBucketAdvisor(bucketId)
-        .isPrimary();
+  private void destroyEventFromQueue(PartitionedRegion prQ, int bucketId, Object key) {
+    boolean isPrimary = prQ.getRegionAdvisor().getBucketAdvisor(bucketId).isPrimary();
-          logger.debug("ParallelGatewaySenderQueue#remove: Got EntryNotFoundException while removing key {} for {} for bucket = {} for GatewaySender {}",
+          logger.debug(
+              "ParallelGatewaySenderQueue#remove: Got EntryNotFoundException while removing key {} for {} for bucket = {} for GatewaySender {}",
-          logger.debug("Caught RegionDestroyedException attempting to remove key {} from bucket {} in {}", key, bucketId, prQ.getFullPath());
+          logger.debug(
+              "Caught RegionDestroyedException attempting to remove key {} from bucket {} in {}",
+              key, bucketId, prQ.getFullPath());
-  
+
-    
+
-    if (prQ != null && prQ.getDataStore().getAllLocalBucketRegions()
-        .size() > 0
+    if (prQ != null && prQ.getDataStore().getAllLocalBucketRegions().size() > 0
-        brq = ((BucketRegionQueue)prQ.getDataStore()
-            .getInitializedBucketForId(null, bucketId));
+        brq = ((BucketRegionQueue) prQ.getDataStore().getInitializedBucketForId(null, bucketId));
-        return object;//since this is not set, it would be null
+        return object;// since this is not set, it would be null
-  
+
-        Map bucketIdToDispatchedKeys = (Map)regionToDispatchedKeysMap.get(prQ.getFullPath());
+        Map bucketIdToDispatchedKeys = (Map) regionToDispatchedKeysMap.get(prQ.getFullPath());
-          regionToDispatchedKeysMapEmpty.signal();        
+          regionToDispatchedKeysMapEmpty.signal();
-      }
-      finally {
-        lock.unlock();  
+      } finally {
+        lock.unlock();
-  private void addRemovedEventToMap(Map bucketIdToDispatchedKeys, int bucketId,
-      Object key) {
-    List dispatchedKeys = (List)bucketIdToDispatchedKeys.get(bucketId);
+  private void addRemovedEventToMap(Map bucketIdToDispatchedKeys, int bucketId, Object key) {
+    List dispatchedKeys = (List) bucketIdToDispatchedKeys.get(bucketId);
-  protected void addRemovedEvents(PartitionedRegion prQ, int bucketId,
-      List<Object> shadowKeys) {
-    buckToDispatchLock.lock(); 
+  protected void addRemovedEvents(PartitionedRegion prQ, int bucketId, List<Object> shadowKeys) {
+    buckToDispatchLock.lock();
-      Map bucketIdToDispatchedKeys = (Map)regionToDispatchedKeysMap.get(prQ.getFullPath());
+      Map bucketIdToDispatchedKeys = (Map) regionToDispatchedKeysMap.get(prQ.getFullPath());
-        regionToDispatchedKeysMapEmpty.signal();        
+        regionToDispatchedKeysMapEmpty.signal();
-    }
-    finally {
+    } finally {
-  protected void addRemovedEvents(String prQPath, int bucketId,
-      List<Object> shadowKeys) {
+  protected void addRemovedEvents(String prQPath, int bucketId, List<Object> shadowKeys) {
-      Map bucketIdToDispatchedKeys = (Map)regionToDispatchedKeysMap.get(prQPath);
+      Map bucketIdToDispatchedKeys = (Map) regionToDispatchedKeysMap.get(prQPath);
-        regionToDispatchedKeysMapEmpty.signal();        
+        regionToDispatchedKeysMapEmpty.signal();
-    }
-    finally {
+    } finally {
-  
-  private void addRemovedEventsToMap(Map bucketIdToDispatchedKeys,
-      int bucketId, List keys) {
-    List dispatchedKeys = (List)bucketIdToDispatchedKeys.get(bucketId);
+
+  private void addRemovedEventsToMap(Map bucketIdToDispatchedKeys, int bucketId, List keys) {
+    List dispatchedKeys = (List) bucketIdToDispatchedKeys.get(bucketId);
-  
+
-  public List peek(int batchSize, int timeToWait) throws InterruptedException,
-      CacheException {
+  public List peek(int batchSize, int timeToWait) throws InterruptedException, CacheException {
-    
+
-    
+
-      if (areLocalBucketQueueRegionsPresent()
-          && ((bId = getRandomPrimaryBucket(prQ)) != -1)) {
+      if (areLocalBucketQueueRegionsPresent() && ((bId = getRandomPrimaryBucket(prQ)) != -1)) {
-            if (isDebugEnabled) {
+          if (isDebugEnabled) {
-      if (isDebugEnabled) {
+    if (isDebugEnabled) {
-      //Remove all entries from peekedEvents for buckets that are not longer primary
-      //This will prevent repeatedly trying to dispatch non-primary events
-      for(Iterator<GatewaySenderEventImpl> iterator = peekedEvents.iterator(); iterator.hasNext(); ) {
+      // Remove all entries from peekedEvents for buckets that are not longer primary
+      // This will prevent repeatedly trying to dispatch non-primary events
+      for (Iterator<GatewaySenderEventImpl> iterator = peekedEvents.iterator(); iterator
+          .hasNext();) {
-        if(!region.getRegionAdvisor().isPrimaryForBucket(bucketId)) {
+        if (!region.getRegionAdvisor().isPrimaryForBucket(bucketId)) {
-        // reduced due to MessageTooLargeException. Create a batch from the peekedEventsProcessing queue.
+        // reduced due to MessageTooLargeException. Create a batch from the peekedEventsProcessing
+        // queue.
-    for (int i=0; i<batchSize; i++) {
+    for (int i = 0; i < batchSize; i++) {
-      //while (isQueueEmpty) { 
-      if(isQueueEmpty) { //merge44610: this if condition came from cheetah 44610
+      // while (isQueueEmpty) {
+      if (isQueueEmpty) { // merge44610: this if condition came from cheetah 44610
-        queueEmptyCondition.await(1000); 
-        //merge44610: this time waiting came from cheetah 44610
-        //isQueueEmpty = this.localSize() == 0;
+        queueEmptyCondition.await(1000);
+        // merge44610: this time waiting came from cheetah 44610
+        // isQueueEmpty = this.localSize() == 0;
-  }  
+  }
-      logger.debug("{}: Peekahead for the bucket {}",this, bucketId);
+      logger.debug("{}: Peekahead for the bucket {}", this, bucketId);
-      //BucketRegionQueue unavailable. Can be due to the BucketRegionQueue being destroyed.
-      return object;//this will be null
+      // BucketRegionQueue unavailable. Can be due to the BucketRegionQueue being destroyed.
+      return object;// this will be null
-      logger.debug("{}: Peeked object from bucket {} object: {}",this, bucketId, object);
+      logger.debug("{}: Peeked object from bucket {} object: {}", this, bucketId, object);
-    return object; // OFFHEAP: ok since callers are careful to do destroys on region queue after finished with peeked object.
+    return object; // OFFHEAP: ok since callers are careful to do destroys on region queue after
+                   // finished with peeked object.
-  protected BucketRegionQueue getBucketRegionQueueByBucketId(final PartitionedRegion prQ, final int bucketId) {
-    return (BucketRegionQueue)prQ
-        .getDataStore().getLocalBucketById(bucketId);
+  protected BucketRegionQueue getBucketRegionQueueByBucketId(final PartitionedRegion prQ,
+      final int bucketId) {
+    return (BucketRegionQueue) prQ.getDataStore().getLocalBucketById(bucketId);
-      if(prQ != null && prQ.getDataStore() != null) {
-        size += prQ.getDataStore()
-            .getSizeOfLocalPrimaryBuckets();  
+      if (prQ != null && prQ.getDataStore() != null) {
+        size += prQ.getDataStore().getSizeOfLocalPrimaryBuckets();
-        logger.debug("The name of the queue region is {} and the size is {}", prQ.getFullPath(), size);
+        logger.debug("The name of the queue region is {} and the size is {}", prQ.getFullPath(),
+            size);
-    return size /*+ sender.getTmpQueuedEventSize()*/;
+    return size /* + sender.getTmpQueuedEventSize() */;
-  
+
-      if(((PartitionedRegion)prQ.getRegion()).getDataStore() != null) {
-        Set<BucketRegion> primaryBuckets = ((PartitionedRegion)prQ.getRegion()).getDataStore().getAllLocalPrimaryBucketRegions();
-        
+      if (((PartitionedRegion) prQ.getRegion()).getDataStore() != null) {
+        Set<BucketRegion> primaryBuckets =
+            ((PartitionedRegion) prQ.getRegion()).getDataStore().getAllLocalPrimaryBucketRegions();
+
-          if(br.getId() % this.nDispatcher == this.index)
+          if (br.getId() % this.nDispatcher == this.index)
-        }         
+        }
-        logger.debug("The name of the queue region is {} and the size is {}", prQ.getFullPath(), size);
+        logger.debug("The name of the queue region is {} and the size is {}", prQ.getFullPath(),
+            size);
-    return size /*+ sender.getTmpQueuedEventSize()*/;
+    return size /* + sender.getTmpQueuedEventSize() */;
-  
+
-    
+
-  
+
-    for(PartitionedRegion prQ: this.userRegionNameToshadowPRMap.values()) {
+    for (PartitionedRegion prQ : this.userRegionNameToshadowPRMap.values()) {
-  
+
-    ConflationHandler conflationHandler = new ConflationHandler(
-        conflatableObject, bucketId, tailKey);
+    ConflationHandler conflationHandler =
+        new ConflationHandler(conflatableObject, bucketId, tailKey);
-  
+
-    for(PartitionedRegion prQ: this.userRegionNameToshadowPRMap.values()) {
+    for (PartitionedRegion prQ : this.userRegionNameToshadowPRMap.values()) {
-          logger.debug("{}: DiskRegionStats for shadow PR is null. Returning the numEntriesOverflowOnDisk as 0", this);
+          logger.debug(
+              "{}: DiskRegionStats for shadow PR is null. Returning the numEntriesOverflowOnDisk as 0",
+              this);
-        logger.debug("{}: DiskRegionStats for shadow PR is NOT null. Returning the numEntriesOverflowOnDisk obtained from DiskRegionStats", this);
+        logger.debug(
+            "{}: DiskRegionStats for shadow PR is NOT null. Returning the numEntriesOverflowOnDisk obtained from DiskRegionStats",
+            this);
-      numEntriesOnDisk += diskStats.getNumOverflowOnDisk();  
+      numEntriesOnDisk += diskStats.getNumOverflowOnDisk();
-  
+
-          logger.debug("{}: DiskRegionStats for shadow PR is null. Returning the numEntriesInVM as 0", this);
+          logger.debug(
+              "{}: DiskRegionStats for shadow PR is null. Returning the numEntriesInVM as 0", this);
-        logger.debug("{}: DiskRegionStats for shadow PR is NOT null. Returning the numEntriesInVM obtained from DiskRegionStats", this);
+        logger.debug(
+            "{}: DiskRegionStats for shadow PR is NOT null. Returning the numEntriesInVM obtained from DiskRegionStats",
+            this);
-  
+
-   * This method does the cleanup of any threads, sockets, connection that are held up
-   * by the queue. Note that this cleanup doesn't clean the data held by the queue.
+   * This method does the cleanup of any threads, sockets, connection that are held up by the queue.
+   * Note that this cleanup doesn't clean the data held by the queue.
-   * @param sender
-   *          can be null.
+   * @param sender can be null.
-//    for (Region r: getRegions()) {
-//      if (r != null && !r.isDestroyed()) {
-//        try {
-//          r.close();
-//        } catch (RegionDestroyedException e) {
-//        }
-//      }
-//    }
+    // for (Region r: getRegions()) {
+    // if (r != null && !r.isDestroyed()) {
+    // try {
+    // r.close();
+    // } catch (RegionDestroyedException e) {
+    // }
+    // }
+    // }
-  
+
-  
+
-  
+
-    //The queue id is everything after the leading / and before the QSTRING
+    // The queue id is everything after the leading / and before the QSTRING
-  
-  //TODO:REF: Name for this class should be appropriate?
+
+  // TODO:REF: Name for this class should be appropriate?
-    
+
-      //TODO:REF: Name for this thread ?
+      // TODO:REF: Name for this thread ?
-                logger.debug("BatchRemovalThread about to query the batch removal map {}", regionToDispatchedKeysMap);
-              }
-              finally {
-                buckToDispatchLock.unlock();  
+                logger.debug("BatchRemovalThread about to query the batch removal map {}",
+                    regionToDispatchedKeysMap);
+              } finally {
+                buckToDispatchLock.unlock();
-            final HashMap<String, Map<Integer, List>> temp = new HashMap<String, Map<Integer, List>>();
+            final HashMap<String, Map<Integer, List>> temp =
+                new HashMap<String, Map<Integer, List>>();
-              if (wasEmpty) continue;
+              if (wasEmpty)
+                continue;
-            }
-            finally {
+            } finally {
-            Set<InternalDistributedMember> recipients = getAllRecipients(cache,
-                temp);
-            cache.getDistributionManager().removeMembersWithSameOrNewerVersion(
-                recipients, Version.GFE_80);
+            Set<InternalDistributedMember> recipients = getAllRecipients(cache, temp);
+            cache.getDistributionManager().removeMembersWithSameOrNewerVersion(recipients,
+                Version.GFE_80);
-              for (Map.Entry<String, Map<Integer, List>> mapEntry : temp
-                  .entrySet()) {
+              for (Map.Entry<String, Map<Integer, List>> mapEntry : temp.entrySet()) {
-                PartitionedRegion prQ = (PartitionedRegion)cache
-                    .getRegion(mapEntry.getKey());
-                Set<InternalDistributedMember> memberForPRQ = prQ
-                    .getRegionAdvisor().adviseDataStore();
+                PartitionedRegion prQ = (PartitionedRegion) cache.getRegion(mapEntry.getKey());
+                Set<InternalDistributedMember> memberForPRQ =
+                    prQ.getRegionAdvisor().adviseDataStore();
-                ParallelQueueBatchRemovalResponse response = ParallelQueueBatchRemovalMessage
-                    .send(memberForPRQ, prQ, mapEntry.getValue());
+                ParallelQueueBatchRemovalResponse response =
+                    ParallelQueueBatchRemovalMessage.send(memberForPRQ, prQ, mapEntry.getValue());
-                }
-                catch (ForceReattemptException e) {
+                } catch (ForceReattemptException e) {
-                    logger.debug("ParallelQueueBatchRemovalMessage got ForceReattemptException. Will continue.");
+                    logger.debug(
+                        "ParallelQueueBatchRemovalMessage got ForceReattemptException. Will continue.");
-            cache.getDistributionManager().retainMembersWithSameOrNewerVersion(
-                recipients, Version.GFE_80);
+            cache.getDistributionManager().retainMembersWithSameOrNewerVersion(recipients,
+                Version.GFE_80);
-              ParallelQueueRemovalMessage pqrm = new ParallelQueueRemovalMessage(
-                  temp);
+              ParallelQueueRemovalMessage pqrm = new ParallelQueueRemovalMessage(temp);
-            if (t instanceof Error
-                && SystemFailure.isJVMFailureError(err = (Error)t)) {
+            if (t instanceof Error && SystemFailure.isJVMFailureError(err = (Error) t)) {
-        logger.info(LocalizedMessage.create(LocalizedStrings.HARegionQueue_THE_QUEUEREMOVALTHREAD_IS_DONE));
+        logger.info(
+            LocalizedMessage.create(LocalizedStrings.HARegionQueue_THE_QUEUEREMOVALTHREAD_IS_DONE));
-    private Set<InternalDistributedMember> getAllRecipients(
-        GemFireCacheImpl cache, Map map) {
+    private Set<InternalDistributedMember> getAllRecipients(GemFireCacheImpl cache, Map map) {
-        recipients.addAll(((PartitionedRegion)(cache.getRegion((String)pr)))
-            .getRegionAdvisor().adviseDataStore());
+        recipients.addAll(((PartitionedRegion) (cache.getRegion((String) pr))).getRegionAdvisor()
+            .adviseDataStore());
-        logger.warn(LocalizedMessage.create(LocalizedStrings.HARegionQueue_QUEUEREMOVALTHREAD_IGNORED_CANCELLATION));
+        logger.warn(LocalizedMessage
+            .create(LocalizedStrings.HARegionQueue_QUEUEREMOVALTHREAD_IGNORED_CANCELLATION));
-  protected static class ParallelGatewaySenderQueueMetaRegion extends
-      PartitionedRegion {
-    
+  protected static class ParallelGatewaySenderQueueMetaRegion extends PartitionedRegion {
+
-    public ParallelGatewaySenderQueueMetaRegion(String regionName,
-        RegionAttributes attrs, LocalRegion parentRegion,
-        GemFireCacheImpl cache, AbstractGatewaySender pgSender) {
+
+    public ParallelGatewaySenderQueueMetaRegion(String regionName, RegionAttributes attrs,
+        LocalRegion parentRegion, GemFireCacheImpl cache, AbstractGatewaySender pgSender) {
-          new InternalRegionArguments().setDestroyLockFlag(true)
-              .setRecreateFlag(false).setSnapshotInputStream(null)
-              .setImageTarget(null)
+          new InternalRegionArguments().setDestroyLockFlag(true).setRecreateFlag(false)
+              .setSnapshotInputStream(null).setImageTarget(null)
-              .setParallelGatewaySender((AbstractGatewaySender)pgSender));
-      this.sender = (AbstractGatewaySender)pgSender;
-      
+              .setParallelGatewaySender((AbstractGatewaySender) pgSender));
+      this.sender = (AbstractGatewaySender) pgSender;
+
-    //Prevent this region from using concurrency checks
+    // Prevent this region from using concurrency checks
-    
+
-    
-    final public AbstractGatewaySender getParallelGatewaySender(){
+
+    final public AbstractGatewaySender getParallelGatewaySender() {
-  
+
-        + sizer.sizeof(userRegionNameToshadowPRMap)
-        + sizer.sizeof(bucketToTempQueueMap) + sizer.sizeof(peekedEvents)
-        + sizer.sizeof(conflationExecutor);
+        + sizer.sizeof(userRegionNameToshadowPRMap) + sizer.sizeof(bucketToTempQueueMap)
+        + sizer.sizeof(peekedEvents) + sizer.sizeof(conflationExecutor);
+
-  	throw new RuntimeException("This method(clear)is not supported by ParallelGatewaySenderQueue");
+    throw new RuntimeException("This method(clear)is not supported by ParallelGatewaySenderQueue");
-  
-  public int size(PartitionedRegion pr, int bucketId) throws ForceReattemptException{
-  	throw new RuntimeException("This method(size)is not supported by ParallelGatewaySenderQueue");
+
+  public int size(PartitionedRegion pr, int bucketId) throws ForceReattemptException {
+    throw new RuntimeException("This method(size)is not supported by ParallelGatewaySenderQueue");
-  
+
-    ParallelGatewaySenderQueueMetaRegion newMetataRegion(
-        GemFireCacheImpl cache, final String prQName, final RegionAttributes ra, AbstractGatewaySender sender) {
-      ParallelGatewaySenderQueueMetaRegion meta = new ParallelGatewaySenderQueueMetaRegion(
-          prQName, ra, null, cache, sender);
+    ParallelGatewaySenderQueueMetaRegion newMetataRegion(GemFireCacheImpl cache,
+        final String prQName, final RegionAttributes ra, AbstractGatewaySender sender) {
+      ParallelGatewaySenderQueueMetaRegion meta =
+          new ParallelGatewaySenderQueueMetaRegion(prQName, ra, null, cache, sender);
