GEODE-7830: fix race in rebalance start (#4769)

* The result from doing a start will now be consistent.
Previously the OperationState used to compute the result
could be changing while making the result causing the result
to be inconsistent. Now a copy of the OperationState is made
in a thread safe manner and then that immutable copy is used
to compute the result.

* A snapshot of the operationState is now taken BEFORE
the async thread is started so that the result of "start"
will only have info about the start.

* Now if a rebalance is done of the entire cluster it
will no longer be an error if it does not find any
regions to rebalance. Instead it will report success
with the status message: "Distributed system has no regions that can be rebalanced".
Also if it a member departs during the rebalance such that a region
it was hosting can no longer be rebalanced, then that region is now
ignored by rebalance instead of an error being reported.

+import org.apache.geode.annotations.VisibleForTesting;
-      result = (RebalanceResultImpl) executeRebalanceOnDS((InternalCache) cache,
-          String.valueOf(simulate), excludeRegions);
+      result =
+          (RebalanceResultImpl) executeRebalanceOnDS(ManagementService.getManagementService(cache),
+              (InternalCache) cache,
+              String.valueOf(simulate), excludeRegions, new FunctionExecutor());
-  private static List<MemberPRInfo> getMemberRegionList(InternalCache cache,
+  private static List<MemberPRInfo> getMemberRegionList(ManagementService managementService,
+      InternalCache cache,
-        ManagementService.getManagementService(cache).getDistributedSystemMXBean().listRegions();
+        managementService.getDistributedSystemMXBean().listRegions();
-      DistributedRegionMXBean bean =
-          ManagementService.getManagementService(cache).getDistributedRegionMXBean(regionName);
+      DistributedRegionMXBean bean = managementService.getDistributedRegionMXBean(regionName);
-  private static boolean checkResultList(List<String> errors, List resultList,
+  private static boolean checkResultList(List<String> errors, List<Object> resultList,
-  private static RebalanceResult executeRebalanceOnDS(InternalCache cache, String simulate,
-      List<String> excludeRegionsList) {
+  /**
+   * This class was introduced so that it can be mocked
+   * to all executeRebalanceOnDS to be unit tested
+   */
+  @VisibleForTesting
+  static class FunctionExecutor {
+    public List<Object> execute(Function rebalanceFunction, Object[] functionArgs,
+        DistributedMember dsMember) {
+      return (List<Object>) ManagementUtils.executeFunction(rebalanceFunction,
+          functionArgs, Collections.singleton(dsMember)).getResult();
+    }
+  }
+
+  @VisibleForTesting
+  static RebalanceResult executeRebalanceOnDS(ManagementService managementService,
+      InternalCache cache, String simulate,
+      List<String> excludeRegionsList, FunctionExecutor functionExecutor) {
-    List<MemberPRInfo> listMemberRegion = getMemberRegionList(cache, excludeRegionsList);
+    List<MemberPRInfo> listMemberRegion =
+        getMemberRegionList(managementService, cache, excludeRegionsList);
+      rebalanceResult.setSuccess(true);
-            List resultList = new ArrayList();
+            List<Object> resultList = new ArrayList<>();
-                resultList = (ArrayList) ManagementUtils.executeFunction(rebalanceFunction,
-                    functionArgs, Collections.singleton(dsMember)).getResult();
-
+                resultList = functionExecutor.execute(rebalanceFunction, functionArgs, dsMember);
-                  errors.add(
-                      MessageFormat.format(
-                          CliStrings.REBALANCE__MSG__NO_EXECUTION_FOR_REGION_0_ON_MEMBERS_1,
-                          memberPR.region, listOfAllMembers(memberPR.dsMemberList)) + ", " +
-                          CliStrings.REBALANCE__MSG__MEMBERS_MIGHT_BE_DEPARTED);
+                  // The last member hosting this region departed so no need to rebalance it.
+                  // So act as if we never tried to rebalance this region.
+                  // Break to get out of this inner loop and try the next region (if any).
+                  break;
