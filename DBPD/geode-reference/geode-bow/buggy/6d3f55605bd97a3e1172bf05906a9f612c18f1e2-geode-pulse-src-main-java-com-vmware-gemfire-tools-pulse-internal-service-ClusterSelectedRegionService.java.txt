GEODE-907: Converted core functionality to use jackson

+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.ArrayNode;
+import com.fasterxml.jackson.databind.node.ObjectNode;
+import com.vmware.gemfire.tools.pulse.internal.controllers.PulseController;
+import com.vmware.gemfire.tools.pulse.internal.data.Cluster;
+import com.vmware.gemfire.tools.pulse.internal.data.PulseConstants;
+import com.vmware.gemfire.tools.pulse.internal.data.Repository;
+import com.vmware.gemfire.tools.pulse.internal.log.PulseLogWriter;
+import com.vmware.gemfire.tools.pulse.internal.util.StringUtils;
+import com.vmware.gemfire.tools.pulse.internal.util.TimeUtils;
+import org.springframework.context.annotation.Scope;
+import org.springframework.stereotype.Component;
+import org.springframework.stereotype.Service;
+
+import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletRequest;
-
-import org.springframework.context.annotation.Scope;
-import org.springframework.stereotype.Component;
-import org.springframework.stereotype.Service;
-
-import com.vmware.gemfire.tools.pulse.internal.controllers.PulseController;
-import com.vmware.gemfire.tools.pulse.internal.data.Cluster;
-import com.vmware.gemfire.tools.pulse.internal.data.PulseConstants;
-import com.vmware.gemfire.tools.pulse.internal.data.Repository;
-import com.vmware.gemfire.tools.pulse.internal.json.JSONArray;
-import com.vmware.gemfire.tools.pulse.internal.json.JSONException;
-import com.vmware.gemfire.tools.pulse.internal.json.JSONObject;
-import com.vmware.gemfire.tools.pulse.internal.log.PulseLogWriter;
-import com.vmware.gemfire.tools.pulse.internal.util.StringUtils;
-import com.vmware.gemfire.tools.pulse.internal.util.TimeUtils;
-
+  private final ObjectMapper mapper = new ObjectMapper();
+
-  private static Comparator<Cluster.Member> memberCurrentHeapUsageComparator = new Comparator<Cluster.Member>() {
-    @Override
-    public int compare(Cluster.Member m1, Cluster.Member m2) {
-      long m1HeapUsage = m1.getCurrentHeapSize();
-      long m2HeapUsage = m2.getCurrentHeapSize();
-      if (m1HeapUsage < m2HeapUsage) {
-        return -1;
-      } else if (m1HeapUsage > m2HeapUsage) {
-        return 1;
-      } else {
-        return 0;
-      }
+  private static Comparator<Cluster.Member> memberCurrentHeapUsageComparator = (m1, m2) -> {
+    long m1HeapUsage = m1.getCurrentHeapSize();
+    long m2HeapUsage = m2.getCurrentHeapSize();
+    if (m1HeapUsage < m2HeapUsage) {
+      return -1;
+    } else if (m1HeapUsage > m2HeapUsage) {
+      return 1;
+    } else {
+      return 0;
-  public JSONObject execute(final HttpServletRequest request) throws Exception {
+  public ObjectNode tempExecute(final HttpServletRequest request) throws Exception {
-    JSONObject parameterMap = new JSONObject(pulseData);
-    String selectedRegionFullPath = parameterMap.getJSONObject("ClusterSelectedRegion").getString("regionFullPath");
+    JsonNode parameterMap = mapper.readTree(pulseData);
+    String selectedRegionFullPath = parameterMap.get("ClusterSelectedRegion").get("regionFullPath").textValue();
-    JSONObject responseJSON = new JSONObject();
+    ObjectNode responseJSON = mapper.createObjectNode();
-    try {
-      // getting cluster's Regions
-      responseJSON.put("clusterName", cluster.getServerName());
-      responseJSON.put("userName", userName);
-      responseJSON.put("selectedRegion", getSelectedRegionJson(cluster, selectedRegionFullPath));
-      // Send json response
-      return responseJSON;
-    } catch (JSONException e) {
-      throw new Exception(e);
-    }
+    // getting cluster's Regions
+    responseJSON.put("clusterName", cluster.getServerName());
+    responseJSON.put("userName", userName);
+    responseJSON.put("selectedRegion", getSelectedRegionJson(cluster, selectedRegionFullPath));
+
+    // Send json response
+    return responseJSON;
-   * @return JSONObject Array List
+   * @return ObjectNode Array List
-  private JSONObject getSelectedRegionJson(Cluster cluster, String selectedRegionFullPath) throws JSONException {
+  private ObjectNode getSelectedRegionJson(Cluster cluster, String selectedRegionFullPath) {
-    if(reg != null){
-      JSONObject regionJSON = new JSONObject();
+    if (reg != null){
+      ObjectNode regionJSON = mapper.createObjectNode();
-      DecimalFormat df2 = new DecimalFormat(
-          PulseConstants.DECIMAL_FORMAT_PATTERN);
+      DecimalFormat df2 = new DecimalFormat(PulseConstants.DECIMAL_FORMAT_PATTERN);
-      // return sorted member list by heap usage
-      JSONArray memberArray = new JSONArray();
-      for (Cluster.Member member : clusterMembersL) {
-          JSONObject regionMember = new JSONObject();
+      // return sorted member list by heap usage
+      ArrayNode memberArray = mapper.createArrayNode();
+      for (Cluster.Member member : clusterMembersL) {
+          ObjectNode regionMember = mapper.createObjectNode();
-          memberArray.put(regionMember);
+          memberArray.add(regionMember);
-      Boolean persistent = reg.getPersistentEnabled();
-      if (persistent) {
-        regionJSON.put("persistence", PulseService.VALUE_ON);
-      } else {
-        regionJSON.put("persistence", PulseService.VALUE_OFF);
-      }
+      regionJSON.put("persistence", reg.getPersistentEnabled() ? PulseService.VALUE_ON : PulseService.VALUE_OFF);
-      Boolean isEnableOffHeapMemory = reg.isEnableOffHeapMemory();
-      if (isEnableOffHeapMemory) {
-        regionJSON.put("isEnableOffHeapMemory", PulseService.VALUE_ON);
-      } else {
-        regionJSON.put("isEnableOffHeapMemory", PulseService.VALUE_OFF);
-      }
+      regionJSON.put("isEnableOffHeapMemory", reg.isEnableOffHeapMemory() ? PulseService.VALUE_ON : PulseService.VALUE_OFF);
-      Boolean isHDFSWriteOnly = reg.isHdfsWriteOnly();
-        if (isHDFSWriteOnly) {
-          regionJSON.put("isHDFSWriteOnly", PulseService.VALUE_ON);
-        } else {
-          regionJSON.put("isHDFSWriteOnly", PulseService.VALUE_OFF);
-        }
+        regionJSON.put("isHDFSWriteOnly", reg.isHdfsWriteOnly() ? PulseService.VALUE_ON : PulseService.VALUE_OFF);
-      if (PulseConstants.PRODUCT_NAME_SQLFIRE.equalsIgnoreCase(PulseController
-          .getPulseProductSupport())) {
+      if (PulseConstants.PRODUCT_NAME_SQLFIRE.equalsIgnoreCase(PulseController.getPulseProductSupport())) {
-        regionJSON.put("regionPath",
-            StringUtils.getTableNameFromRegionName(reg.getFullPath()));
+        regionJSON.put("regionPath", StringUtils.getTableNameFromRegionName(reg.getFullPath()));
-      regionJSON
-          .put(
-              "memoryReadsTrend",
-              new JSONArray(
-                  reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_GETS_PER_SEC_TREND)));
-      regionJSON
-          .put(
-              "memoryWritesTrend",
-              new JSONArray(
-                  reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_PUTS_PER_SEC_TREND)));
-      regionJSON
-          .put(
-              "diskReadsTrend",
-              new JSONArray(
-                  reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_DISK_READS_PER_SEC_TREND)));
-      regionJSON
-          .put(
-              "diskWritesTrend",
-              new JSONArray(
-                  reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_DISK_WRITES_PER_SEC_TREND)));
+      regionJSON.put("memoryReadsTrend",
+          mapper.valueToTree(reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_GETS_PER_SEC_TREND)));
+      regionJSON.put("memoryWritesTrend",
+          mapper.valueToTree(reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_PUTS_PER_SEC_TREND)));
+      regionJSON.put("diskReadsTrend",
+          mapper.valueToTree(reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_DISK_READS_PER_SEC_TREND)));
+      regionJSON.put("diskWritesTrend",
+          mapper.valueToTree(reg.getRegionStatisticTrend(Cluster.Region.REGION_STAT_DISK_WRITES_PER_SEC_TREND)));
+
-      JSONObject responseJSON = new JSONObject();
-      responseJSON.put("errorOnRegion", "Region [" + selectedRegionFullPath
-          + "] is not available");
+      ObjectNode responseJSON = mapper.createObjectNode();
+      responseJSON.put("errorOnRegion", "Region [" + selectedRegionFullPath + "] is not available");
