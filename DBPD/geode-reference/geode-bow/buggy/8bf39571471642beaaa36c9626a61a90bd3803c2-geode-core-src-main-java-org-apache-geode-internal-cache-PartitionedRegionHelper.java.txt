Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
-public class PartitionedRegionHelper
-  {
+public class PartitionedRegionHelper {
-  
+
-//  static final String PARTITIONED_REGION_CONFIG_NAME = "__Config";
+  // static final String PARTITIONED_REGION_CONFIG_NAME = "__Config";
-//  static final String BUCKET_2_NODE_TABLE_PREFIX = "_B2N_";
+  // static final String BUCKET_2_NODE_TABLE_PREFIX = "_B2N_";
-   * The administrative region used for storing Partitioned Region meta data sub
-   * regions *
+   * The administrative region used for storing Partitioned Region meta data sub regions *
-   * This should not be used normally. Internally, GemFire uses global locks to
-   * modify shared meta-data and this property controls the delay before giving
-   * up trying to acquire a global lock
+   * This should not be used normally. Internally, GemFire uses global locks to modify shared
+   * meta-data and this property controls the delay before giving up trying to acquire a global lock
-  static final String VM_OWNERSHIP_WAIT_TIME_PROPERTY = DistributionConfig.GEMFIRE_PREFIX + "VM_OWNERSHIP_WAIT_TIME";
+  static final String VM_OWNERSHIP_WAIT_TIME_PROPERTY =
+      DistributionConfig.GEMFIRE_PREFIX + "VM_OWNERSHIP_WAIT_TIME";
-  public static final int DEFAULT_TOTAL_WAIT_RETRY_ITERATION = 
-    60 * 60 * 1000
-    ; // milliseconds
+  public static final int DEFAULT_TOTAL_WAIT_RETRY_ITERATION = 60 * 60 * 1000; // milliseconds
-  
-  static final Object dlockMonitor = new Object(); 
+
+  static final Object dlockMonitor = new Object();
-//    policies.add(DataPolicy.NORMAL);
+    // policies.add(DataPolicy.NORMAL);
-  
-  
-  /** 
-   * This function is used for cleaning the config meta data for the failed or closed 
+
+
+  /**
+   * This function is used for cleaning the config meta data for the failed or closed
-   * @param failedNode
-   *          The failed PartitionedRegion Node
-   * @param regionIdentifier
-   *          The PartitionedRegion for which the cleanup is required
-   * @param cache
-   *          GemFire cache.
-   */  
-  static void removeGlobalMetadataForFailedNode(Node failedNode,
-      String regionIdentifier, GemFireCacheImpl cache){
+   * @param failedNode The failed PartitionedRegion Node
+   * @param regionIdentifier The PartitionedRegion for which the cleanup is required
+   * @param cache GemFire cache.
+   */
+  static void removeGlobalMetadataForFailedNode(Node failedNode, String regionIdentifier,
+      GemFireCacheImpl cache) {
-  
+
-   * This function is used for cleaning the config meta data for the failed or closed 
+   * This function is used for cleaning the config meta data for the failed or closed
-   * @param failedNode
-   *          The failed PartitionedRegion Node
-   * @param regionIdentifier
-   *          The PartitionedRegion for which the cleanup is required
-   * @param cache
-   *          GemFire cache.
-   * @param lock
-   *          True if this removal should acquire and release the RegionLock
+   * @param failedNode The failed PartitionedRegion Node
+   * @param regionIdentifier The PartitionedRegion for which the cleanup is required
+   * @param cache GemFire cache.
+   * @param lock True if this removal should acquire and release the RegionLock
-  static void removeGlobalMetadataForFailedNode(Node failedNode,
-      String regionIdentifier, GemFireCacheImpl cache, final boolean lock)
-  {
+  static void removeGlobalMetadataForFailedNode(Node failedNode, String regionIdentifier,
+      GemFireCacheImpl cache, final boolean lock) {
-//    Region allPartitionedRegions = PartitionedRegionHelper.getPRConfigRegion(
-//        root, cache);
-    PartitionRegionConfig prConfig = (PartitionRegionConfig)root
-        .get(regionIdentifier);
+    // Region allPartitionedRegions = PartitionedRegionHelper.getPRConfigRegion(
+    // root, cache);
+    PartitionRegionConfig prConfig = (PartitionRegionConfig) root.get(regionIdentifier);
-    final PartitionedRegion.RegionLock rl = PartitionedRegion.getRegionLock(regionIdentifier, cache);
+    final PartitionedRegion.RegionLock rl =
+        PartitionedRegion.getRegionLock(regionIdentifier, cache);
-//        if (!rl.lock()) {
-//          return;
-//        }
+        // if (!rl.lock()) {
+        // return;
+        // }
-      prConfig = (PartitionRegionConfig)root.get(regionIdentifier);
-      if ( prConfig != null  && prConfig.containsNode(failedNode)  ) {
-        if(logger.isDebugEnabled()) {
+      prConfig = (PartitionRegionConfig) root.get(regionIdentifier);
+      if (prConfig != null && prConfig.containsNode(failedNode)) {
+        if (logger.isDebugEnabled()) {
-          if(logger.isDebugEnabled()) {
+          if (logger.isDebugEnabled()) {
-                LocalizedStrings.PartitionedRegionHelper_GOT_ENTRYNOTFOUNDEXCEPTION_IN_DESTROY_OP_FOR_ALLPRREGION_KEY_0, 
+                LocalizedStrings.PartitionedRegionHelper_GOT_ENTRYNOTFOUNDEXCEPTION_IN_DESTROY_OP_FOR_ALLPRREGION_KEY_0,
-        }
-        else {
+        } else {
-          if(prConfig.getNumberOfNodes() == 0) {
+          if (prConfig.getNumberOfNodes() == 0) {
-    }
-    finally {
-      if (lock) {      
+    } finally {
+      if (lock) {
-      }        
+      }
-   * Return a region that is the root for all Partitioned Region metadata on this
-   * node
+   * Return a region that is the root for all Partitioned Region metadata on this node
-  
+
-   * Return a region that is the root for all PartitionedRegion meta data on
-   * this Node. The main administrative Regions contained within are
-   * <code>allPartitionedRegion</code> (Scope DISTRIBUTED_ACK) and
-   * <code>bucket2Node</code> (Scope DISTRIBUTED_ACK) and dataStore regions.
+   * Return a region that is the root for all PartitionedRegion meta data on this Node. The main
+   * administrative Regions contained within are <code>allPartitionedRegion</code> (Scope
+   * DISTRIBUTED_ACK) and <code>bucket2Node</code> (Scope DISTRIBUTED_ACK) and dataStore regions.
-   * @return a GLOBLAL scoped root region used for PartitionedRegion
-   *         administration
+   * @return a GLOBLAL scoped root region used for PartitionedRegion administration
-  public static LocalRegion getPRRoot(final Cache cache, boolean createIfAbsent)
-  {
+  public static LocalRegion getPRRoot(final Cache cache, boolean createIfAbsent) {
-      if(logger.isDebugEnabled()) {
-        logger.debug("Creating root Partitioned Admin Region {}", PartitionedRegionHelper.PR_ROOT_REGION_NAME);
+      if (logger.isDebugEnabled()) {
+        logger.debug("Creating root Partitioned Admin Region {}",
+            PartitionedRegionHelper.PR_ROOT_REGION_NAME);
-        factory.addCacheListener( new CacheListenerAdapter() {
+        factory.addCacheListener(new CacheListenerAdapter() {
-          public void afterCreate(EntryEvent event)
-          {
+          public void afterCreate(EntryEvent event) {
-              logger.debug("Create Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
-                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(), event.getDistributedMember(),
-                  event.getOperation().isNetSearch());
+              logger.debug(
+                  "Create Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
+                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(),
+                  event.getDistributedMember(), event.getOperation().isNetSearch());
-          public void afterUpdate(EntryEvent event)
-          {
+          public void afterUpdate(EntryEvent event) {
-              logger.debug("Update Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
-                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(), event.getDistributedMember(),
-                  event.getOperation().isNetSearch());
+              logger.debug(
+                  "Update Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
+                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(),
+                  event.getDistributedMember(), event.getOperation().isNetSearch());
-          public void afterDestroy(EntryEvent event)
-          {
+          public void afterDestroy(EntryEvent event) {
-              logger.debug("Destroy Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
-                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(), event.getDistributedMember(),
-                  event.getOperation().isNetSearch());
+              logger.debug(
+                  "Destroy Event for allPR: key = {} oldVal = {} newVal = {} Op = {} origin = {} isNetSearch = {}",
+                  event.getKey(), event.getOldValue(), event.getNewValue(), event.getOperation(),
+                  event.getDistributedMember(), event.getOperation().isNetSearch());
-        
+
-          public void beforeUpdate(EntryEvent event) throws CacheWriterException
-          {
+          public void beforeUpdate(EntryEvent event) throws CacheWriterException {
-            if (newConf != oldConf &&            
-                ! newConf.isGreaterNodeListVersion(oldConf) ) {
-              throw new CacheWriterException(LocalizedStrings.PartitionedRegionHelper_NEW_PARTITIONEDREGIONCONFIG_0_DOES_NOT_HAVE_NEWER_VERSION_THAN_PREVIOUS_1.toLocalizedString(new Object[] {newConf, oldConf}));
+            if (newConf != oldConf && !newConf.isGreaterNodeListVersion(oldConf)) {
+              throw new CacheWriterException(
+                  LocalizedStrings.PartitionedRegionHelper_NEW_PARTITIONEDREGIONCONFIG_0_DOES_NOT_HAVE_NEWER_VERSION_THAN_PREVIOUS_1
+                      .toLocalizedString(new Object[] {newConf, oldConf}));
-        public CachePerfStats getCachePerfStats()
-        {
+        public CachePerfStats getCachePerfStats() {
-        root = (DistributedRegion) gemCache.createVMRegion(PR_ROOT_REGION_NAME, ra, 
-            new InternalRegionArguments()
-            .setIsUsedForPartitionedRegionAdmin(true)
-            .setInternalRegion(true)
-            .setCachePerfStatsHolder(prMetaStatsHolder));
+        root = (DistributedRegion) gemCache.createVMRegion(PR_ROOT_REGION_NAME, ra,
+            new InternalRegionArguments().setIsUsedForPartitionedRegionAdmin(true)
+                .setInternalRegion(true).setCachePerfStatsHolder(prMetaStatsHolder));
-      }
-      catch (RegionExistsException silly) {
+      } catch (RegionExistsException silly) {
-    Assert.assertTrue(root!=null, "Can not obtain internal Partitioned Region configuration root");
+    Assert.assertTrue(root != null,
+        "Can not obtain internal Partitioned Region configuration root");
-  
-//TODO rebalancing - this code was added here in the merge of -r22804:23093 from trunk
-  //because of changes made on trunk that require this method, which was removed on
-  //prRebalancing. It probably needs refactoring.
-  //The idea here is to remove meta data from the partitioned region for a node that
-  //has left the cache. 
-  //A couple options that didn't work
-  //   - remove metadata in region advisor for PR instead - this doesn't work because 
-  //the a member can close it's cache and then recreate the same region. Another member
-  //might end up removing meta data after the region is recreated, leading to inconsistent metadata
+
+  // TODO rebalancing - this code was added here in the merge of -r22804:23093 from trunk
+  // because of changes made on trunk that require this method, which was removed on
+  // prRebalancing. It probably needs refactoring.
+  // The idea here is to remove meta data from the partitioned region for a node that
+  // has left the cache.
+  // A couple options that didn't work
+  // - remove metadata in region advisor for PR instead - this doesn't work because
+  // the a member can close it's cache and then recreate the same region. Another member
+  // might end up removing meta data after the region is recreated, leading to inconsistent metadata
-  //we can't do region operations after isClosing is set to true (to remove metadata). Removing metadata
-  //before is closing is set to true results operations being silently ignored because of inconsistent metadata
-  //and regions.
+  // we can't do region operations after isClosing is set to true (to remove metadata). Removing
+  // metadata
+  // before is closing is set to true results operations being silently ignored because of
+  // inconsistent metadata
+  // and regions.
-   * Clean the config meta data for a DistributedMember which has left the
-   * DistributedSystem, one PartitionedRegion at a time.
+   * Clean the config meta data for a DistributedMember which has left the DistributedSystem, one
+   * PartitionedRegion at a time.
-  public static void cleanUpMetaDataOnNodeFailure(DistributedMember failedMemId)
-  {
+  public static void cleanUpMetaDataOnNodeFailure(DistributedMember failedMemId) {
-      if(cache == null || cache.getCancelCriterion().isCancelInProgress()) {
+      if (cache == null || cache.getCancelCriterion().isCancelInProgress()) {
-      DM dm = cache.getDistributedSystem().getDistributionManager(); 
+      DM dm = cache.getDistributedSystem().getDistributionManager();
-      for (String prName : ks ) {
+      for (String prName : ks) {
-    } catch(CancelException e) {
-      //ignore
+    } catch (CancelException e) {
+      // ignore
-  
-  public static void cleanUpMetaDataForRegion(final GemFireCacheImpl cache,
-      final String prName, final DistributedMember failedMemId,
-      final Runnable postCleanupTask) {
-    boolean runPostCleanUp = true; 
-    try {
-    final PartitionRegionConfig prConf;
-    Region rootReg = PartitionedRegionHelper.getPRRoot(cache, false);
-    if (rootReg == null) {
-      return;
-    }
-    try {
-      prConf = (PartitionRegionConfig)rootReg.get(prName);
-    }
-    catch (EntryDestroyedException ede) {
-      return;
-    }
-    if (prConf == null) {
-      // darrel says: I'm seeing an NPE in this code after pr->rem
-      // merge
-      // so I added this check and continue
-      return;
-    }
-    Set<Node> nodeList = prConf.getNodes();
-    if (nodeList == null) {
-      return;
-    }
-    for (final Node node1 : nodeList) {
-      if (cache.getCancelCriterion().isCancelInProgress()) {
+  public static void cleanUpMetaDataForRegion(final GemFireCacheImpl cache, final String prName,
+      final DistributedMember failedMemId, final Runnable postCleanupTask) {
+    boolean runPostCleanUp = true;
+    try {
+      final PartitionRegionConfig prConf;
+      Region rootReg = PartitionedRegionHelper.getPRRoot(cache, false);
+      if (rootReg == null) {
-      if (node1.getMemberId().equals(failedMemId)) {
-        //Do the cleanup in another thread so we don't have the advisor locked.
-        //Fix for #45365, we don't schedule an asynchronous task until
-        //we have determined the node to remove (Which includes the 
-        //serial number).
-        cache.getDistributionManager().getPrMetaDataCleanupThreadPool().execute(new Runnable() {
-          public void run() {
-            cleanPartitionedRegionMetaDataForNode(cache,
-                node1, prConf, prName);
-            if(postCleanupTask != null) {
-              postCleanupTask.run();
+      try {
+        prConf = (PartitionRegionConfig) rootReg.get(prName);
+      } catch (EntryDestroyedException ede) {
+        return;
+      }
+      if (prConf == null) {
+        // darrel says: I'm seeing an NPE in this code after pr->rem
+        // merge
+        // so I added this check and continue
+        return;
+      }
+      Set<Node> nodeList = prConf.getNodes();
+      if (nodeList == null) {
+        return;
+      }
+
+      for (final Node node1 : nodeList) {
+        if (cache.getCancelCriterion().isCancelInProgress()) {
+          return;
+        }
+        if (node1.getMemberId().equals(failedMemId)) {
+          // Do the cleanup in another thread so we don't have the advisor locked.
+          // Fix for #45365, we don't schedule an asynchronous task until
+          // we have determined the node to remove (Which includes the
+          // serial number).
+          cache.getDistributionManager().getPrMetaDataCleanupThreadPool().execute(new Runnable() {
+            public void run() {
+              cleanPartitionedRegionMetaDataForNode(cache, node1, prConf, prName);
+              if (postCleanupTask != null) {
+                postCleanupTask.run();
+              }
-          }
-        });
-        runPostCleanUp = false;
-        return;
+          });
+          runPostCleanUp = false;
+          return;
+        }
-    }
-      if(runPostCleanUp && postCleanupTask != null) {
+      if (runPostCleanUp && postCleanupTask != null) {
-  
+
-   * This is a function for cleaning the config meta data (both the
-   * configuration data and the buckets) for a Node that hosted a
-   * PartitionedRegion
+   * This is a function for cleaning the config meta data (both the configuration data and the
+   * buckets) for a Node that hosted a PartitionedRegion
-      PartitionRegionConfig prConf, String regionIdentifier)
-  {
+      PartitionRegionConfig prConf, String regionIdentifier) {
-      logger.debug("Cleaning PartitionedRegion meta data for node={} for Partitioned Region={} configuration={}",
+      logger.debug(
+          "Cleaning PartitionedRegion meta data for node={} for Partitioned Region={} configuration={}",
-    PartitionedRegionHelper.removeGlobalMetadataForFailedNode(node, regionIdentifier,
-        cache);
-    
+    PartitionedRegionHelper.removeGlobalMetadataForFailedNode(node, regionIdentifier, cache);
+
-      logger.debug("Done Cleaning PartitionedRegion meta data for memberId={} for {}", node, regionIdentifier);
+      logger.debug("Done Cleaning PartitionedRegion meta data for memberId={} for {}", node,
+          regionIdentifier);
-   * Runs hashCode() on given key producing a long value and then finds absolute
-   * value of the modulus with bucketSize. For better key distribution, possibly
-   * use MD5 or SHA or any unique ID generator for the hash function.
+   * Runs hashCode() on given key producing a long value and then finds absolute value of the
+   * modulus with bucketSize. For better key distribution, possibly use MD5 or SHA or any unique ID
+   * generator for the hash function.
-   * @param pr
-   *          the partitioned region on which to operate
-   * @param key
-   *          the key on which to determine the hash key
+   * @param pr the partitioned region on which to operate
+   * @param key the key on which to determine the hash key
-  // private static int NOSIGN = 0x7fffffff; 
- /* public static int getHashKey(PartitionedObject key)
-  {
-    PartitionedRegion pRegion = (PartitionedRegion)entryOp.getRegion();
-    RoutingResolver resolver = pRegion.getRoutingResolver();
-    
-    int totalNumberOfBuckets = pRegion.getTotalNumberOfBuckets();
-    Object resolveKey = null;
-    if (resolver == null) {
-      resolveKey = key;
-    } else {
-    	
-      //resolveKey = resolver.getPartitionKey(key);
-    	resolveKey = resolver.getRoutingObject((EntryOperation)key);
-    }
-    int hc = resolveKey.hashCode();
-    int bucketId = hc % totalNumberOfBuckets;
-    // Force positive bucket ids only
-    return Math.abs(bucketId);
-    // We should use the same hash code spreader as most other java.util hash tables.
-//    h += ~(h << 9);
-//    h ^=  (h >>> 14);
-//    h +=  (h << 4);
-//    h ^=  (h >>> 10);
-//    h &= NOSIGN;
-//    return h % totalNumberOfBuckets;
-  }
-**/
+  // private static int NOSIGN = 0x7fffffff;
+  /*
+   * public static int getHashKey(PartitionedObject key) { PartitionedRegion pRegion =
+   * (PartitionedRegion)entryOp.getRegion(); RoutingResolver resolver =
+   * pRegion.getRoutingResolver();
+   * 
+   * int totalNumberOfBuckets = pRegion.getTotalNumberOfBuckets(); Object resolveKey = null; if
+   * (resolver == null) { resolveKey = key; } else {
+   * 
+   * //resolveKey = resolver.getPartitionKey(key); resolveKey =
+   * resolver.getRoutingObject((EntryOperation)key); } int hc = resolveKey.hashCode(); int bucketId
+   * = hc % totalNumberOfBuckets; // Force positive bucket ids only return Math.abs(bucketId); // We
+   * should use the same hash code spreader as most other java.util hash tables. // h += ~(h << 9);
+   * // h ^= (h >>> 14); // h += (h << 4); // h ^= (h >>> 10); // h &= NOSIGN; // return h %
+   * totalNumberOfBuckets; }
+   **/
-  static private PartitionResolver getResolver(PartitionedRegion pr,
-      Object key, Object callbackArgument) {
+  static private PartitionResolver getResolver(PartitionedRegion pr, Object key,
+      Object callbackArgument) {
-    
+
-    if (key != null  && key instanceof PartitionResolver) {
-      return (PartitionResolver)key;
+    if (key != null && key instanceof PartitionResolver) {
+      return (PartitionResolver) key;
-    
+
-    if (callbackArgument != null
-        && callbackArgument instanceof PartitionResolver) {
-      return (PartitionResolver)callbackArgument;
+    if (callbackArgument != null && callbackArgument instanceof PartitionResolver) {
+      return (PartitionResolver) callbackArgument;
-    
+
-   * Runs hashCode() on given key/routing object producing a long value and then
-   * finds absolute value of the modulus with bucketSize. For better key
-   * distribution, possibly use MD5 or SHA or any unique ID generator for the
-   * hash function.
+   * Runs hashCode() on given key/routing object producing a long value and then finds absolute
+   * value of the modulus with bucketSize. For better key distribution, possibly use MD5 or SHA or
+   * any unique ID generator for the hash function.
-   * @param pr
-   *                the partitioned region on which to operate
-   * @param operation
-   *                operation
-   * @param key
-   *                the key on which to determine the hash key
-   * @param callbackArgument
-   *                the callbackArgument is passed to
-   *                <code>PartitionResolver</code> to get Routing object
+   * @param pr the partitioned region on which to operate
+   * @param operation operation
+   * @param key the key on which to determine the hash key
+   * @param callbackArgument the callbackArgument is passed to <code>PartitionResolver</code> to get
+   *        Routing object
-  public static int getHashKey(PartitionedRegion pr, Operation operation,
-      Object key, Object value, Object callbackArgument) {
+  public static int getHashKey(PartitionedRegion pr, Operation operation, Object key, Object value,
+      Object callbackArgument) {
-   * Runs hashCode() on given key/routing object producing a long value and then
-   * finds absolute value of the modulus with bucketSize. For better key
-   * distribution, possibly use MD5 or SHA or any unique ID generator for the
-   * hash function.
+   * Runs hashCode() on given key/routing object producing a long value and then finds absolute
+   * value of the modulus with bucketSize. For better key distribution, possibly use MD5 or SHA or
+   * any unique ID generator for the hash function.
-   * @param event
-   *                entry event created for this entry operation
+   * @param event entry event created for this entry operation
-   * Runs hashCode() on given key/routing object producing a long value and then
-   * finds absolute value of the modulus with bucketSize. For better key
-   * distribution, possibly use MD5 or SHA or any unique ID generator for the
-   * hash function.
+   * Runs hashCode() on given key/routing object producing a long value and then finds absolute
+   * value of the modulus with bucketSize. For better key distribution, possibly use MD5 or SHA or
+   * any unique ID generator for the hash function.
-   * @param event
-   *                entry event created for this entry operation; can be null
-   * @param pr
-   *                the partitioned region on which to operate
-   * @param operation
-   *                operation
-   * @param key
-   *                the key on which to determine the hash key
-   * @param callbackArgument
-   *                the callbackArgument is passed to
-   *                <code>PartitionResolver</code> to get Routing object
+   * @param event entry event created for this entry operation; can be null
+   * @param pr the partitioned region on which to operate
+   * @param operation operation
+   * @param key the key on which to determine the hash key
+   * @param callbackArgument the callbackArgument is passed to <code>PartitionResolver</code> to get
+   *        Routing object
-  private static int getHashKey(EntryOperation event, PartitionedRegion pr,
-      Operation operation, Object key, Object value, Object callbackArgument) {
+  private static int getHashKey(EntryOperation event, PartitionedRegion pr, Operation operation,
+      Object key, Object value, Object callbackArgument) {
-      pr = (PartitionedRegion)event.getRegion();
+      pr = (PartitionedRegion) event.getRegion();
-      String partition = null ;
+      String partition = null;
-          event = new EntryOperationImpl(pr, operation, key, value,
-              callbackArgument);
+          event = new EntryOperationImpl(pr, operation, key, value, callbackArgument);
-        partition = ((FixedPartitionResolver)resolver).getPartitionName(
-            event, partitionMap.keySet());
+        partition =
+            ((FixedPartitionResolver) resolver).getPartitionName(event, partitionMap.keySet());
-          Object[] prms = new Object[] { pr.getName(), resolver };
+          Object[] prms = new Object[] {pr.getName(), resolver};
-          Object[] prms = new Object[] { pr.getName(), partition };
+          Object[] prms = new Object[] {pr.getName(), partition};
-      }
-      else if (resolver == null) {
+      } else if (resolver == null) {
-      }
-      else if (!(resolver instanceof FixedPartitionResolver)) {
-        Object[] prms = new Object[] { pr.getName(), resolver };
+      } else if (!(resolver instanceof FixedPartitionResolver)) {
+        Object[] prms = new Object[] {pr.getName(), resolver};
-    }
-    else {
+    } else {
-      }
-      else {
+      } else {
-          event = new EntryOperationImpl(pr, operation, key, value,
-              callbackArgument);
+          event = new EntryOperationImpl(pr, operation, key, value, callbackArgument);
-  private static int assignFixedBucketId(PartitionedRegion pr,
-      String partition, Object resolveKey) {
+  private static int assignFixedBucketId(PartitionedRegion pr, String partition,
+      Object resolveKey) {
-    List<FixedPartitionAttributesImpl> localFPAs = pr
-        .getFixedPartitionAttributesImpl();
-    
+    List<FixedPartitionAttributesImpl> localFPAs = pr.getFixedPartitionAttributesImpl();
+
-      List<FixedPartitionAttributesImpl> remoteFPAs = pr.getRegionAdvisor()
-          .adviseAllFixedPartitionAttributes();
+      List<FixedPartitionAttributesImpl> remoteFPAs =
+          pr.getRegionAdvisor().adviseAllFixedPartitionAttributes();
-        Object[] prms = new Object[] { pr.getName(), partition };
+        Object[] prms = new Object[] {pr.getName(), partition};
-      Object[] prms = new Object[] { pr.getName(), partition };
+      Object[] prms = new Object[] {pr.getName(), partition};
-  
+
-  public static PartitionedRegion getPartitionedRegion(String prName,
-      Cache cache)
-  {
+  public static PartitionedRegion getPartitionedRegion(String prName, Cache cache) {
-        return (PartitionedRegion)region;
+        return (PartitionedRegion) region;
-  
-  /** 
+
+  /**
-   * @param cache 
+   * 
+   * @param cache
-  public static Bucket getProxyBucketRegion(Cache cache, String fullPath, boolean postInit) throws PRLocallyDestroyedException {
-    if(cache == null) {
-      //No cache
+  public static Bucket getProxyBucketRegion(Cache cache, String fullPath, boolean postInit)
+      throws PRLocallyDestroyedException {
+    if (cache == null) {
+      // No cache
-    
+
-//    PartitionedRegion region = 
-//        PartitionedRegion.getPRFromId(Integer.parseInt(prid));
-    
+    // PartitionedRegion region =
+    // PartitionedRegion.getPRFromId(Integer.parseInt(prid));
+
-    int oldLevel =         // Set thread local flag to allow entrance through initialization Latch
-      LocalRegion.setThreadInitLevelRequirement(LocalRegion.ANY_INIT);
+    int oldLevel = // Set thread local flag to allow entrance through initialization Latch
+        LocalRegion.setThreadInitLevelRequirement(LocalRegion.ANY_INIT);
-    region = cache.getRegion(prid);
+      region = cache.getRegion(prid);
-    
-    PartitionedRegion pr = (PartitionedRegion) region; 
-    
+
+    PartitionedRegion pr = (PartitionedRegion) region;
+
-    }
-    else if ( ! ra.areBucketsInitialized()) {  
+    } else if (!ra.areBucketsInitialized()) {
-    } 
-    else {
-      return ra.getBucket(bid);      
+    } else {
+      return ra.getBucket(bid);
-  
-  private final static String BUCKET_FULL_PATH_PREFIX = PR_ROOT_REGION_NAME + Region.SEPARATOR + BUCKET_REGION_PREFIX;  
-  /** 
+
+  private final static String BUCKET_FULL_PATH_PREFIX =
+      PR_ROOT_REGION_NAME + Region.SEPARATOR + BUCKET_REGION_PREFIX;
+
+  /**
+   * 
-  
+
-    
+
-    
+
-  
+
-  
-  
+
+
-  
+
-  
+
-    + PartitionedRegionHelper.escapePRPath(prPath)
-    + PartitionedRegion.BUCKET_NAME_SEPARATOR + bucketId;
+        + PartitionedRegionHelper.escapePRPath(prPath) + PartitionedRegion.BUCKET_NAME_SEPARATOR
+        + bucketId;
-    int pridIdx = 
-        PartitionedRegionHelper.BUCKET_REGION_PREFIX.length();
-    int bidSepIdx = 
-        bucketName.lastIndexOf(PartitionedRegion.BUCKET_NAME_SEPARATOR);
-    Assert.assertTrue(bidSepIdx > -1, 
-                      "getProxyBucketRegion failed on " + bucketName);
+    int pridIdx = PartitionedRegionHelper.BUCKET_REGION_PREFIX.length();
+    int bidSepIdx = bucketName.lastIndexOf(PartitionedRegion.BUCKET_NAME_SEPARATOR);
+    Assert.assertTrue(bidSepIdx > -1, "getProxyBucketRegion failed on " + bucketName);
+
-    int bidSepIdx = 
-        bucketName.lastIndexOf(PartitionedRegion.BUCKET_NAME_SEPARATOR);
-    String bid = bucketName.substring(bidSepIdx+1);
+    int bidSepIdx = bucketName.lastIndexOf(PartitionedRegion.BUCKET_NAME_SEPARATOR);
+    String bid = bucketName.substring(bidSepIdx + 1);
-    
+
-   * This method returns true if the last region in provided fullPath is a
-   * sub-region else it returns false. If fullPath is "/REGION1" it would return
-   * false and if it is "/REGION1/REGION2", it would return true, which means
-   * that Region2 is a sub-region.
+   * This method returns true if the last region in provided fullPath is a sub-region else it
+   * returns false. If fullPath is "/REGION1" it would return false and if it is "/REGION1/REGION2",
+   * it would return true, which means that Region2 is a sub-region.
-   * @param fullPath
-   *          full path of the region
+   * @param fullPath full path of the region
-  public static boolean isSubRegion(String fullPath)
-  {
+  public static boolean isSubRegion(String fullPath) {
-  
+
-   * This method returns true if the member is found in the membership list of
-   * this member, else false. 
+   * This method returns true if the member is found in the membership list of this member, else
+   * false.
+   * 
-  }  
-  
+  }
+
+   * 
-    return cache.getDistributedSystem().getDistributionManager()
-        .getDistributionManagerIds();
+    return cache.getDistributedSystem().getDistributionManager().getDistributionManagerIds();
-   * Utility method to print warning when nodeList in b2n region is found empty.
-   * This will signify potential data loss scenario.
+   * Utility method to print warning when nodeList in b2n region is found empty. This will signify
+   * potential data loss scenario.
+   * 
-  public static void logForDataLoss(PartitionedRegion partitionedRegion, int bucketId, String callingMethod) {
+  public static void logForDataLoss(PartitionedRegion partitionedRegion, int bucketId,
+      String callingMethod) {
-//    Region allPartitionedRegions = PartitionedRegionHelper.getPRConfigRegion(
-//        root, partitionedRegion.getCache());
-    PartitionRegionConfig prConfig = (PartitionRegionConfig)root
-        .get(partitionedRegion.getRegionIdentifier());
-    if( prConfig == null )
-    	return;
-    
-    Set members = partitionedRegion.getDistributionManager()
-    .getDistributionManagerIds(); 
+    // Region allPartitionedRegions = PartitionedRegionHelper.getPRConfigRegion(
+    // root, partitionedRegion.getCache());
+    PartitionRegionConfig prConfig =
+        (PartitionRegionConfig) root.get(partitionedRegion.getRegionIdentifier());
+    if (prConfig == null)
+      return;
+
+    Set members = partitionedRegion.getDistributionManager().getDistributionManagerIds();
-        new Object[] {callingMethod, printCollection(prConfig.getNodes())})); 
+        new Object[] {callingMethod, printCollection(prConfig.getNodes())}));
-  
+
+   * 
-      while(itr.hasNext()) {
+      while (itr.hasNext()) {
-  
+
-   * Destroys and removes the distributed lock service.
-   * This is called from cache closure operation.
+   * Destroys and removes the distributed lock service. This is called from cache closure operation.
-     synchronized (dlockMonitor) {
-     	dls = DistributedLockService
-    	.getServiceNamed(PARTITION_LOCK_SERVICE_NAME);
-     }
-     if(dls != null) {  
-     		try {
-     	         DistributedLockService.destroy(PARTITION_LOCK_SERVICE_NAME);
-     	       } catch (IllegalArgumentException ex) {
-     	         // Our dlockService is already destroyed,
-     	         // probably by another thread - ignore     	  
-     	       }
-     	}
-     }
+    synchronized (dlockMonitor) {
+      dls = DistributedLockService.getServiceNamed(PARTITION_LOCK_SERVICE_NAME);
+    }
+    if (dls != null) {
+      try {
+        DistributedLockService.destroy(PARTITION_LOCK_SERVICE_NAME);
+      } catch (IllegalArgumentException ex) {
+        // Our dlockService is already destroyed,
+        // probably by another thread - ignore
+      }
+    }
+  }
-  
+
-    List<FixedPartitionAttributesImpl> fpaList = region.getRegionAdvisor()
-        .adviseSameFPAs(fpa);
-    
+    List<FixedPartitionAttributesImpl> fpaList = region.getRegionAdvisor().adviseSameFPAs(fpa);
+
-    List<FixedPartitionAttributesImpl> localFPAs = pr
-        .getFixedPartitionAttributesImpl();
+    List<FixedPartitionAttributesImpl> localFPAs = pr.getFixedPartitionAttributesImpl();
-    List<FixedPartitionAttributesImpl> remoteFPAs = pr.getRegionAdvisor()
-        .adviseAllFixedPartitionAttributes();
+    List<FixedPartitionAttributesImpl> remoteFPAs =
+        pr.getRegionAdvisor().adviseAllFixedPartitionAttributes();
-    Object[] prms = new Object[] { pr.getName(), Integer.valueOf(bucketId) };
+    Object[] prms = new Object[] {pr.getName(), Integer.valueOf(bucketId)};
-    List<FixedPartitionAttributesImpl> localFPAs = region
-        .getFixedPartitionAttributesImpl();
+    List<FixedPartitionAttributesImpl> localFPAs = region.getFixedPartitionAttributesImpl();
-    List<FixedPartitionAttributesImpl> remoteFPAs = region.getRegionAdvisor()
-        .adviseAllFixedPartitionAttributes();
+    List<FixedPartitionAttributesImpl> remoteFPAs =
+        region.getRegionAdvisor().adviseAllFixedPartitionAttributes();
-  
-  public static Set<FixedPartitionAttributes> getAllFixedPartitionAttributes(PartitionedRegion region) {
+
+  public static Set<FixedPartitionAttributes> getAllFixedPartitionAttributes(
+      PartitionedRegion region) {
-    List<FixedPartitionAttributesImpl> localFPAs = region
-        .getFixedPartitionAttributesImpl();
+    List<FixedPartitionAttributesImpl> localFPAs = region.getFixedPartitionAttributesImpl();
-    List<FixedPartitionAttributesImpl> remoteFPAs = region.getRegionAdvisor()
-        .adviseAllFixedPartitionAttributes();
+    List<FixedPartitionAttributesImpl> remoteFPAs =
+        region.getRegionAdvisor().adviseAllFixedPartitionAttributes();
-  
+
-      
+
-    public void memberSuspect(InternalDistributedMember id,
-        InternalDistributedMember whoSuspected, String reason) {
-    }
-    
-    public void quorumLost(Set<InternalDistributedMember> failures, List<InternalDistributedMember> remaining) {
-    }
-    
+    public void memberSuspect(InternalDistributedMember id, InternalDistributedMember whoSuspected,
+        String reason) {}
+
+    public void quorumLost(Set<InternalDistributedMember> failures,
+        List<InternalDistributedMember> remaining) {}
+
+
-    PartitionRegionConfig prConfig = (PartitionRegionConfig)event.getNewValue();
+    PartitionRegionConfig prConfig = (PartitionRegionConfig) event.getNewValue();
-    PartitionRegionConfig prConfig = (PartitionRegionConfig)event.getNewValue();
+    PartitionRegionConfig prConfig = (PartitionRegionConfig) event.getNewValue();
-    
+
-          partitionMap.put(fxPrAttr.getPartitionName(), new Integer[] {
-              fxPrAttr.getStartingBucketID(), fxPrAttr.getNumBuckets() });
+          partitionMap.put(fxPrAttr.getPartitionName(),
+              new Integer[] {fxPrAttr.getStartingBucketID(), fxPrAttr.getNumBuckets()});
-      logger.debug("PRLocallyDestroyedException : Region ={} is locally destroyed on this node", prConfig.getPRId(), e);
+      logger.debug("PRLocallyDestroyedException : Region ={} is locally destroyed on this node",
+          prConfig.getPRId(), e);
