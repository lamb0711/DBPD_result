Initial import of geode-1.0.0.0-SNAPSHOT-2.
All the new sub-project directories (like jvsd) were not imported.
A diff was done to confirm that this commit is exactly the same as
the open directory the snapshot was made from.

+import com.gemstone.gemfire.cache.hdfs.internal.HDFSBucketRegionQueue;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSGatewayEventImpl;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSParallelGatewaySenderQueue;
+import com.gemstone.gemfire.internal.cache.Conflatable;
+import com.gemstone.gemfire.internal.cache.ForceReattemptException;
+import com.gemstone.gemfire.internal.cache.PartitionedRegion;
+import com.gemstone.gemfire.internal.size.SingleObjectSizer;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.concurrent.BlockingQueue;
+    if (sender.getIsHDFSQueue())
+      this.queue = new HDFSParallelGatewaySenderQueue(this.sender, targetRs, this.index, this.nDispatcher);
+    else
-    GatewayQueueEvent gatewayQueueEvent = null;
+    GatewaySenderEventImpl gatewayQueueEvent = null;
+	 if (!sender.getIsHDFSQueue())
+    else
+      gatewayQueueEvent = new HDFSGatewayEventImpl(operation,
+          event, substituteValue, true, eventID.getBucketID());
+          gatewayQueueEvent = null;
-      //merge44012: this try finally has came from cheetah. this change is related to offheap.
-//      if (gatewayQueueEvent != null) {
-//        // it was not queued for some reason
-//         gatewayQueueEvent.release();
-//      }
+      if (gatewayQueueEvent != null) {
+        // it was not queued for some reason
+        gatewayQueueEvent.release();
+      }
+  public void clear(PartitionedRegion pr, int bucketId) {
+  	((ParallelGatewaySenderQueue)this.queue).clear(pr, bucketId);
+  }
+  
+  /*public int size(PartitionedRegion pr, int bucketId)
+      throws ForceReattemptException {
+  	return ((ParallelGatewaySenderQueue)this.queue).size(pr, bucketId);
+  }*/
+  
+  public void notifyEventProcessorIfRequired(int bucketId) {
+    ((ParallelGatewaySenderQueue)this.queue).notifyEventProcessorIfRequired();
+  }
+  
+  public BlockingQueue<GatewaySenderEventImpl> getBucketTmpQueue(int bucketId) {
+    return ((ParallelGatewaySenderQueue)this.queue).getBucketToTempQueueMap().get(bucketId);
+  }
+  
+  public PartitionedRegion getRegion(String prRegionName) {
+    return ((ParallelGatewaySenderQueue)this.queue).getRegion(prRegionName);
+  }
+  
+  public void removeShadowPR(String prRegionName) {
+  	((ParallelGatewaySenderQueue)this.queue).removeShadowPR(prRegionName);
+  }
+  
+  public void conflateEvent(Conflatable conflatableObject, int bucketId,
+      Long tailKey) {
+  	((ParallelGatewaySenderQueue)this.queue).conflateEvent(conflatableObject, bucketId, tailKey);
+  }
+  
+  public HDFSGatewayEventImpl get(PartitionedRegion region, byte[] regionKey,
+    int bucketId) throws ForceReattemptException {
+    return ((HDFSParallelGatewaySenderQueue)this.queue).get(region, regionKey, bucketId);
+  }
+  
+  public HDFSBucketRegionQueue getBucketRegionQueue(PartitionedRegion region,
+    int bucketId) throws ForceReattemptException {
+  	return ((HDFSParallelGatewaySenderQueue)this.queue).getBucketRegionQueue(region, bucketId);
+  }
+  
+  public void addShadowPartitionedRegionForUserPR(PartitionedRegion pr) {
+	// TODO Auto-generated method stub
+	((ParallelGatewaySenderQueue)this.queue).addShadowPartitionedRegionForUserPR(pr);
+  }
+  
+  public void addShadowPartitionedRegionForUserRR(DistributedRegion userRegion) {
+	// TODO Auto-generated method stub
+	((ParallelGatewaySenderQueue)this.queue).addShadowPartitionedRegionForUserRR(userRegion);
+  }
+  
