GEODE-77: bug fixes

GMSHealthMonitorJUnitTest was incorrectly using Mockito's any() when it should
have used isA().  Fixing this exposed a lot of problems in the health monitor
that this checkin addresses.  I've also renamed a number of entities so that we
now have more uniform use of the term "heartbeat" instead of "check".

GMSHealthMonitor now has a positive heartbeat sender thread that determines
who might be watching it and sends unsolicited heartbeats to those members.

GMSHealthMonitor now sends the viewID of its membership ID in TCP/IP
health checks.  This enables the receiver to differentiate between the
received UUID/viewID and its own information when it is a reconnected
member (using auto-reconnect).  The response threads are now also moved
to a cached thread-pool to decrease the cost of these checks.  Responses
now have soLinger set on them (experimental) because I was seeing a lot
of checks fail with EOF even though the member wrote an OK status.

The health monitor now uses suspectMembersInView to avoid suspecting the
same member over and over again.  This means that it can't be used to
avoid duplicate final-checks.  I've also disabled the collection thread for
suspect events because it was adding unnecessary delay in initiating
final-checks on crashed members and I have yet to see it collect more than
one event.

SuspectMembersMessage processing now checks to see if the receiver is the
target of the suspicion and, if so, send a heartbeat to the sender.  This
seems to happen a lot when the membership coordinator is a locator because
the locator doesn't push operations out to other members very often.  The
positive heartbeat sender will also help with this.

This change-set also turns off the JGroups thread pools because they were found
to be causing our performance problem.  This exposed a bug in JGroups that they
are fixing, but for now there is a workaround in StatRecorder.  Along with the
removal of thread pools we now need to pass messages through
handleOrDeferMessage() in GMSMembershipManager since processMessage() can be
blocked during initialization, causing a new process to time out trying to join
the distributed system.

GMSJoinLeave was not setting the failure detection ports on a new view if it
abandoned a view that it could not prepare.

The Connection class had some incorrect checks for shutdown conditions when
the shared/ordered connection to another member is shut down.  This should
improve our detection time for crashed members.

+import java.util.Arrays;
-      logger.debug("received no join response");
+      if (!isJoined) {
+        logger.debug("received no join response");
+      }
-    return false;
+    return isJoined;
+    if (v == null) {
+      recordViewRequest(incomingRequest);
+      return;
+    }
+    
+    
+      newView.setFailureDetectionPort(localAddress, services.getHealthMonitor().getFailureDetectionPort());
-        viewCreator = new ViewCreator("GemFire Membership View Creator", Services.getThreadGroup());
+        viewCreator = new ViewCreator("Geode Membership View Creator", Services.getThreadGroup());
-        viewCreator = new ViewCreator("GemFire Membership View Creator", Services.getThreadGroup());
+        viewCreator = new ViewCreator("Geode Membership View Creator", Services.getThreadGroup());
-    logger.info((preparing ? "preparing" : "sending") + " new view " + view);
+    StringBuilder s = new StringBuilder();
+    int[] ports = view.getFailureDetectionPorts();
+    int numMembers = view.size();
+    for (int i=0; i<numMembers; i++) {
+      if (i > 0) {
+        s.append(' ');
+      }
+      s.append(ports[i]);
+    }
+    logger.info((preparing ? "preparing" : "sending") + " new view " + view
+        + "\nfailure detection ports: " + s.toString());
-    logger.debug("Membership: processing {}", m);
-
+        if (!this.isJoined) {
+          // if we're still waiting for a join response and we're in this view we
+          // should install the view so join() can finish its work
+          for (InternalDistributedMember mbr: view.getMembers()) {
+            if (localAddress.compareTo(mbr) == 0) {
+              installView(view);
+              break;
+            }
+          }
+        }
-        ackView(m);
+        if (!m.isRebroadcast()) { // no need to ack a rebroadcast view
+          ackView(m);
+        }
-            isJoined = true;
-      if (isNetworkPartition(newView)) {
+      if (isJoined && isNetworkPartition(newView)) {
+      isJoined = true;
+      synchronized(joinResponse) {
+        joinResponse.notify();
+      }
+
-    logger.debug("JoinLeave processing {}", m);
+    logger.debug("processing {}", m);
+        recips.remove(localAddress);
-        services.getMessenger().send(msg);
+        // use sendUnreliably since we are sending to crashed members &
+        // don't want any retransmission tasks set up for them
+        services.getMessenger().sendUnreliably(msg);
-                  sleep(100);
+                  viewRequests.wait(100);
-        if (logger.isDebugEnabled()) {
-          logger.debug("Established failure detection ports for new view: {}", newView.getFailureDetectionPorts());
-        }
-          newView = new NetView(localAddress, newView.getViewId() + 1, newMembers, leaveReqs, removalReqs);
+          NetView nextView = new NetView(localAddress, newView.getViewId() + 1, newMembers, leaveReqs, removalReqs);
+          for (InternalDistributedMember mbr: newView.getMembers()) {
+            nextView.setFailureDetectionPort(mbr, newView.getFailureDetectionPort(mbr));
+          }
-              "GemFire View Creator verification thread " + i.incrementAndGet());
+              "Geode View Creator verification thread " + i.incrementAndGet());
