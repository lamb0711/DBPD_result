Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
-  
+
-    * The maximum size of this single queue before we start blocking puts
-    * The system property is in megabytes.
-    */
-  private final long maximumSize = 1024 * 1024 * Long.getLong(DistributionConfig.GEMFIRE_PREFIX + "GATEWAY_QUEUE_THROTTLE_SIZE_MB", -1);
-  private final long throttleTime = Long.getLong(DistributionConfig.GEMFIRE_PREFIX + "GATEWAY_QUEUE_THROTTLE_TIME_MS", 100);
-  
-  private final LRUStatistics stats;
-  
-  private final ReentrantReadWriteLock initializationLock = new ReentrantReadWriteLock();
-  
-  private final GatewaySenderStats gatewaySenderStats;
-  
-  protected volatile boolean initialized = false;
-  
-  /**
-   * Holds keys for those events that were not found in BucketRegionQueue during 
-   * processing of ParallelQueueRemovalMessage. This can occur due to the scenario
-   * mentioned in #49196.
+   * The maximum size of this single queue before we start blocking puts The system property is in
+   * megabytes.
-  private final ConcurrentHashSet<Object> failedBatchRemovalMessageKeys = 
-    new ConcurrentHashSet<Object>();
+  private final long maximumSize = 1024 * 1024
+      * Long.getLong(DistributionConfig.GEMFIRE_PREFIX + "GATEWAY_QUEUE_THROTTLE_SIZE_MB", -1);
+  private final long throttleTime =
+      Long.getLong(DistributionConfig.GEMFIRE_PREFIX + "GATEWAY_QUEUE_THROTTLE_TIME_MS", 100);
+
+  private final LRUStatistics stats;
+
+  private final ReentrantReadWriteLock initializationLock = new ReentrantReadWriteLock();
+
+  private final GatewaySenderStats gatewaySenderStats;
+
+  protected volatile boolean initialized = false;
+
+  /**
+   * Holds keys for those events that were not found in BucketRegionQueue during processing of
+   * ParallelQueueRemovalMessage. This can occur due to the scenario mentioned in #49196.
+   */
+  private final ConcurrentHashSet<Object> failedBatchRemovalMessageKeys =
+      new ConcurrentHashSet<Object>();
-    gatewaySenderStats = this.getPartitionedRegion().getParallelGatewaySender()
-        .getStatistics();
+    gatewaySenderStats = this.getPartitionedRegion().getParallelGatewaySender().getStatistics();
-  
-//Prevent this region from using concurrency checks 
+
+  // Prevent this region from using concurrency checks
-  
+
-  protected void distributeUpdateOperation(EntryEventImpl event,
-      long lastModified) {
+  protected void distributeUpdateOperation(EntryEventImpl event, long lastModified) {
-//  /**
-//   * In case of update we need not take lock as we are doing local
-//   * operation.
-//   * After BatchRemovalThread: We don't need lock for destroy as well. 
-//   * @param event
-//   * @return if we can skip taking the lock or not
-//   */
-//  
-//  protected boolean skipWriteLock(EntryEventImpl event) {
-//    return true;
-//  }
-  
-  
+  // /**
+  // * In case of update we need not take lock as we are doing local
+  // * operation.
+  // * After BatchRemovalThread: We don't need lock for destroy as well.
+  // * @param event
+  // * @return if we can skip taking the lock or not
+  // */
+  //
+  // protected boolean skipWriteLock(EntryEventImpl event) {
+  // return true;
+  // }
+
+
-  
+
-  protected long basicPutPart2(EntryEventImpl event, RegionEntry entry,
-      boolean isInitialized, long lastModified, boolean clearConflict) {
+  protected long basicPutPart2(EntryEventImpl event, RegionEntry entry, boolean isInitialized,
+      long lastModified, boolean clearConflict) {
-  
+
-     * We are doing local destroy on this bucket. No need to send destroy
-     * operation to remote nodes.
+     * We are doing local destroy on this bucket. No need to send destroy operation to remote nodes.
-      logger.debug("For Key {}, BasicDestroyBeforeRemoval: no need to send destroy operation to remote nodes. This will be done using BatchRemoval Message.",
-        event.getKey());
+      logger.debug(
+          "For Key {}, BasicDestroyBeforeRemoval: no need to send destroy operation to remote nodes. This will be done using BatchRemoval Message.",
+          event.getKey());
-   * Overridden to allow clear operation on ShadowBucketRegion. Do nothing here,
-   * so clear operations proceeds smoothly.
+   * Overridden to allow clear operation on ShadowBucketRegion. Do nothing here, so clear operations
+   * proceeds smoothly.
-    
+
-  
+
-    /**
-   * Does a get that attempts to not fault values in from disk or make the entry
-   * the most recent in the LRU.
-   */
-/*  protected Object optimalGet(Object k) {
-    // Get the object at that key (to remove the index).
-    Object object = null;
-    try {
-      object = getValueInVM(k); // OFFHEAP deserialize
-      if (object == null) {
-        // must be on disk
-        // fault it in w/o putting it back in the region
-        object = getValueOnDiskOrBuffer(k);
-        if (object == null) {
-          // try memory one more time in case it was already faulted back in
-          object = getValueInVM(k); // OFFHEAP deserialize
-          if (object == null) {
-            // if we get this far give up and just do a get
-            object = get(k);
-          } else {
-            if (object instanceof CachedDeserializable) {
-              object = ((CachedDeserializable)object).getDeserializedValue(
-                  this, this.getRegionEntry(k));
-            }
-          }
-        }
-      } else {
-        if (object instanceof CachedDeserializable) {
-          object = ((CachedDeserializable)object).getDeserializedValue(this,
-              this.getRegionEntry(k));
-        }
-      }
-    } catch (EntryNotFoundException ok) {
-      // just return null;
-    }
-    if (object == Token.TOMBSTONE) {
-      object = null;
-    }
-    return object;
-  }*/
-  
+  /**
+   * Does a get that attempts to not fault values in from disk or make the entry the most recent in
+   * the LRU.
+   */
+  /*
+   * protected Object optimalGet(Object k) { // Get the object at that key (to remove the index).
+   * Object object = null; try { object = getValueInVM(k); // OFFHEAP deserialize if (object ==
+   * null) { // must be on disk // fault it in w/o putting it back in the region object =
+   * getValueOnDiskOrBuffer(k); if (object == null) { // try memory one more time in case it was
+   * already faulted back in object = getValueInVM(k); // OFFHEAP deserialize if (object == null) {
+   * // if we get this far give up and just do a get object = get(k); } else { if (object instanceof
+   * CachedDeserializable) { object = ((CachedDeserializable)object).getDeserializedValue( this,
+   * this.getRegionEntry(k)); } } } } else { if (object instanceof CachedDeserializable) { object =
+   * ((CachedDeserializable)object).getDeserializedValue(this, this.getRegionEntry(k)); } } } catch
+   * (EntryNotFoundException ok) { // just return null; } if (object == Token.TOMBSTONE) { object =
+   * null; }
+   * 
+   * return object; }
+   */
+
-    @Released EntryEventImpl event = getPartitionedRegion().newDestroyEntryEvent(key,
-        null);
+    @Released
+    EntryEventImpl event = getPartitionedRegion().newDestroyEntryEvent(key, null);
-          throw new ForceReattemptException(
-              "Bucket moved",
+          throw new ForceReattemptException("Bucket moved",
-                      .toLocalizedString(), getPartitionedRegion()
-                      .getFullPath()));
+                      .toLocalizedString(),
+                  getPartitionedRegion().getFullPath()));
-        throw new ForceReattemptException("Bucket moved while destroying key "
-            + key, rde);
+        throw new ForceReattemptException("Bucket moved while destroying key " + key, rde);
-  
+
-  
+
-  
+
-  
+
-    Set queues = this.getPartitionedRegion().getParallelGatewaySender()
-        .getQueues();
+    Set queues = this.getPartitionedRegion().getParallelGatewaySender().getQueues();
-      ConcurrentParallelGatewaySenderQueue prq = (ConcurrentParallelGatewaySenderQueue)queues
-          .toArray()[0];
+      ConcurrentParallelGatewaySenderQueue prq =
+          (ConcurrentParallelGatewaySenderQueue) queues.toArray()[0];
-         // .getBucketToTempQueueMap().get(getId());
+      // .getBucketToTempQueueMap().get(getId());
-          //ParallelQueueRemovalMessage checks for the key in BucketRegionQueue
-          //and if not found there, it removes it from tempQueue. When tempQueue 
-          //is getting loaded in BucketRegionQueue, it may not find the key in both.
-          //To fix this race, load the events in writeLock.
-          getInitializationLock().writeLock().lock();
-          // add the events from tempQueue to the region
-          GatewaySenderEventImpl event;
-          while ((event = tempQueue.poll()) != null) {
-            try {
-              event.setPossibleDuplicate(true);
-              if (this.addToQueue(event.getShadowKey(), event)) {
-                event = null;
+            // ParallelQueueRemovalMessage checks for the key in BucketRegionQueue
+            // and if not found there, it removes it from tempQueue. When tempQueue
+            // is getting loaded in BucketRegionQueue, it may not find the key in both.
+            // To fix this race, load the events in writeLock.
+            getInitializationLock().writeLock().lock();
+            // add the events from tempQueue to the region
+            GatewaySenderEventImpl event;
+            while ((event = tempQueue.poll()) != null) {
+              try {
+                event.setPossibleDuplicate(true);
+                if (this.addToQueue(event.getShadowKey(), event)) {
+                  event = null;
+                }
+              } catch (ForceReattemptException e) {
+                if (logger.isDebugEnabled()) {
+                  logger.debug("For bucket {} , enqueing event {} caused exception", getId(), event,
+                      e);
+                }
+              } finally {
+                if (event != null) {
+                  event.release();
+                }
-            catch (ForceReattemptException e) {
-              if (logger.isDebugEnabled()) {
-                logger.debug("For bucket {} , enqueing event {} caused exception", getId(), event, e);
-              }
-            } finally {
-              if (event != null) {
-                event.release();
-              }
-            }
-          }
-              for (GatewaySenderEventImpl e: tempQueue) {
+              for (GatewaySenderEventImpl e : tempQueue) {
-      
+
-  
+
-   * Marks batchSize number of events in the iterator as duplicate 
+   * Marks batchSize number of events in the iterator as duplicate
-      Object senderEvent = 
-          getNoLRU(key, true, false, false);
-      
+      Object senderEvent = getNoLRU(key, true, false, false);
+
-        ((GatewaySenderEventImpl)senderEvent).setPossibleDuplicate(true);
+        ((GatewaySenderEventImpl) senderEvent).setPossibleDuplicate(true);
-  
+
-  
+
-  protected boolean virtualPut(EntryEventImpl event, boolean ifNew,
-      boolean ifOld, Object expectedOldValue, boolean requireOldValue,
-      long lastModified, boolean overwriteDestroyed) throws TimeoutException,
-      CacheWriterException {
+  protected boolean virtualPut(EntryEventImpl event, boolean ifNew, boolean ifOld,
+      Object expectedOldValue, boolean requireOldValue, long lastModified,
+      boolean overwriteDestroyed) throws TimeoutException, CacheWriterException {
-      boolean success = super.virtualPut(event, ifNew, ifOld, expectedOldValue,
-          requireOldValue, lastModified, overwriteDestroyed);
+      boolean success = super.virtualPut(event, ifNew, ifOld, expectedOldValue, requireOldValue,
+          lastModified, overwriteDestroyed);
-        }      
+        }
-    
+
+
-  protected void basicDestroy(final EntryEventImpl event,
-      final boolean cacheWrite, Object expectedOldValue)
+  protected void basicDestroy(final EntryEventImpl event, final boolean cacheWrite,
+      Object expectedOldValue)
-    Map<String, PartitionedRegion> colocatedPRs = ColocationHelper
-        .getAllColocationRegions(getPartitionedRegion());
+    Map<String, PartitionedRegion> colocatedPRs =
+        ColocationHelper.getAllColocationRegions(getPartitionedRegion());
-        BucketRegion parentBucket = colocatedPR.getDataStore()
-            .getLocalBucketById(getId());
+        BucketRegion parentBucket = colocatedPR.getDataStore().getLocalBucketById(getId());
-    return pr.getParallelGatewaySenderIds().contains(
-        getPartitionedRegion().getParallelGatewaySender().getId());
+    return pr.getParallelGatewaySenderIds()
+        .contains(getPartitionedRegion().getParallelGatewaySender().getId());
-  
+
-   * It should be an atomic operation. If the key has been added to the
-   * eventSeqNumQueue then make sure that the value is in the Bucket before the
-   * eventSeqNumQueue is available for peek/remove/take from other thread.
+   * It should be an atomic operation. If the key has been added to the eventSeqNumQueue then make
+   * sure that the value is in the Bucket before the eventSeqNumQueue is available for
+   * peek/remove/take from other thread.
-  public boolean addToQueue(Object key, Object value)
-      throws ForceReattemptException {
-    
-    //if the key exists in failedBatchRemovalMessageKeys, then 
-    //remove it from there and return. Handling of a scenario in #49196.
+  public boolean addToQueue(Object key, Object value) throws ForceReattemptException {
+
+    // if the key exists in failedBatchRemovalMessageKeys, then
+    // remove it from there and return. Handling of a scenario in #49196.
-    
+
-    EntryEventImpl event = EntryEventImpl.create(this, Operation.UPDATE, key,
-        value, null, false, getMyId());
+    EntryEventImpl event =
+        EntryEventImpl.create(this, Operation.UPDATE, key, value, null, false, getMyId());
-    
+
-      
+
-    
-    //check again if the key exists in failedBatchRemovalMessageKeys, 
-    //if yes, then remove it from there and destroy the key from BucketRegionQueue. 
-    //This is to reduce the window of race condition described by Darrel in #49196.
+
+    // check again if the key exists in failedBatchRemovalMessageKeys,
+    // if yes, then remove it from there and destroy the key from BucketRegionQueue.
+    // This is to reduce the window of race condition described by Darrel in #49196.
+
-    
+
-  
+
-  
+
+
-  
+
-  
+
-    AbstractGatewaySender sender = getPartitionedRegion().getParallelGatewaySender(); 
+    AbstractGatewaySender sender = getPartitionedRegion().getParallelGatewaySender();
-        ConcurrentParallelGatewaySenderQueue queue = (ConcurrentParallelGatewaySenderQueue)ep.getQueue();
+        ConcurrentParallelGatewaySenderQueue queue =
+            (ConcurrentParallelGatewaySenderQueue) ep.getQueue();
-          logger.debug("notifyEventProcessor : {} event processor {} queue {}", sender, ep, queue);  
+          logger.debug("notifyEventProcessor : {} event processor {} queue {}", sender, ep, queue);
-  
+
-  
+
-  
+
-	  return this.failedBatchRemovalMessageKeys;
+    return this.failedBatchRemovalMessageKeys;
-  
+
