GEODE-2632: change dependencies on GemFireCacheImpl to InternalCache

* misc cleanup of code where possible

-import static org.apache.geode.distributed.ConfigurationProperties.CACHE_XML_FILE;
-import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;
-import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;
+import static org.apache.geode.distributed.ConfigurationProperties.*;
+
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.net.InetAddress;
+import java.nio.channels.ClosedByInterruptException;
+import java.nio.channels.FileChannel;
+import java.nio.channels.FileLock;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Properties;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.Future;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock.ReadLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock.WriteLock;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import org.apache.logging.log4j.Logger;
+
+import org.apache.geode.cache.CacheFactory;
-import org.apache.logging.log4j.Logger;
-
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.FilenameFilter;
-import java.io.IOException;
-import java.io.PrintStream;
-import java.net.InetAddress;
-import java.nio.channels.ClosedByInterruptException;
-import java.nio.channels.FileChannel;
-import java.nio.channels.FileLock;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Properties;
-import java.util.Set;
-import java.util.TreeSet;
-import java.util.UUID;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.Future;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.RejectedExecutionException;
-import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.atomic.AtomicReference;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock.ReadLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock.WriteLock;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
- * 
- * 
+ *
+
+
+
+
+
+
+
-  /**
-   *
-   */
+
+
+
-  // /** delay for slowing down recovery, for testing purposes only */
-  // public static volatile int recoverDelay = 0;
-
-  // //////////////////// Instance Fields ///////////////////////
-
-  private final GemFireCacheImpl cache;
+  private final InternalCache cache;
-   * Asif:Added as stop gap arrangement to fix bug 39380. It is not a clean fix as keeping track of
-   * the threads acquiring read lock, etc is not a good idea to solve the issue
+   * Added as stop gap arrangement to fix bug 39380. It is not a clean fix as keeping track of the
+   * threads acquiring read lock, etc is not a good idea to solve the issue
+
+
-  // complex vars
+
+
+
-  // private boolean isThreadWaitingForSpace = false;
-
-  /**
-   * Get the next available dir
-   */
-
-  // /**
-  // * Max timed wait for disk space to become available for an entry operation
-  // ,
-  // * in milliseconds. This will be the maximum time for which a
-  // * create/modify/remove operation will wait so as to allow switch over & get
-  // a
-  // * new Oplog for writing. If no space is available in that time,
-  // * DiskAccessException will be thrown. The default wait will be for 120
-  // * seconds
-  // */
-  // private static final long MAX_WAIT_FOR_SPACE = Integer.getInteger(
-  // "MAX_WAIT_FOR_SPACE", 20).intValue() * 1000;
-
-
+
+
+
-  private volatile Future lastDelayedWrite;
-  // ///////////////////// Constructors /////////////////////////
+  private volatile Future lastDelayedWrite;
-   * Creates a new <code>DiskRegion</code> that access disk on behalf of the given region.
+   * Creates a new {@code DiskRegion} that access disk on behalf of the given region.
-  DiskStoreImpl(Cache cache, DiskStoreAttributes props) {
+  DiskStoreImpl(InternalCache cache, DiskStoreAttributes props) {
-  DiskStoreImpl(Cache cache, DiskStoreAttributes props, boolean ownedByRegion,
+  DiskStoreImpl(InternalCache cache, DiskStoreAttributes props, boolean ownedByRegion,
-  DiskStoreImpl(Cache cache, String name, DiskStoreAttributes props, boolean ownedByRegion,
+  DiskStoreImpl(InternalCache cache, String name, DiskStoreAttributes props, boolean ownedByRegion,
-    this.cache = (GemFireCacheImpl) cache;
+    this.cache = cache;
-    /**
+    /*
-        LoggingThreadGroup.createThreadGroup("Oplog Compactor Thread Group", this.logger);
+        LoggingThreadGroup.createThreadGroup("Oplog Compactor Thread Group", logger);
-        LoggingThreadGroup.createThreadGroup("Oplog Delete Thread Group", this.logger);
+        LoggingThreadGroup.createThreadGroup("Oplog Delete Thread Group", logger);
-   * Returns the <code>DiskStoreStats</code> for this store
+   * Returns the {@code DiskStoreStats} for this store
-   * @throws IllegalArgumentException If <code>id</code> is less than zero
+   * @throws IllegalArgumentException If {@code id} is less than zero
-   * @param bb
-   * @param bb
-   * @throws IllegalArgumentException If <code>id</code> is less than zero, no action is taken.
+   * @throws IllegalArgumentException If {@code id} is less than zero, no action is taken.
-   * @throws IllegalArgumentException If <code>id</code> is {@linkplain #INVALID_ID invalid}or is
-   *         less than zero, no action is taken.
+   * @throws IllegalArgumentException If {@code id} is {@linkplain #INVALID_ID invalid}or is less
+   *         than zero, no action is taken.
-          this.closeRegionGuard.notify();
+          this.closeRegionGuard.notifyAll();
-   * @param id
-    } catch (RegionDestroyedException ex) {
+    } catch (RegionDestroyedException ignore) {
-      int drainCount = asyncQueue.drainTo(this.drainList);
-      return drainCount;
+      return asyncQueue.drainTo(this.drainList);
-   * 
-   * @param rvv
-    } catch (InterruptedException ie) {
+    } catch (InterruptedException ignore) {
-  public GemFireCacheImpl getCache() {
+  public InternalCache getCache() {
-                } catch (RegionDestroyedException ex) {
+                } catch (RegionDestroyedException ignore) {
-  /** For Testing * */
-  // void addToOplogSet(int oplogID, File opFile, DirectoryHolder dirHolder) {
-  // Oplog oplog = new Oplog(oplogID, this);
-  // oplog.addRecoveredFile(opFile, dirHolder);
-  // // @todo check callers to see if they need drf support
-  // this.oplogSet.add(oplog);
-  // }
-
-  /** For Testing * */
-   * 
-   * 
-   * @param rvv
-      } catch (InterruptedException e) {
+      } catch (InterruptedException ignore) {
-          } catch (CancelException e) {
+          } catch (CancelException ignore) {
-                // Asif: I am quite sure that it should also be Ok if instead
+                // I am quite sure that it should also be Ok if instead
-                // has acquired thelock, it is bound to see the isRegionClose as
+                // has acquired the lock, it is bound to see the isRegionClose as
-                // and so will realse teh lock causing decrement to zeo , before
+                // and so will release the lock causing decrement to zero , before
+                    // TODO: calling wait while holding two locks
-                  } catch (InterruptedException ie) {
+                  } catch (InterruptedException ignored) {
-   * 
-   * @param dr
-            } catch (InterruptedException ex) {
+            } catch (InterruptedException ignore) {
-    return l.toArray(new CompactableOplog[0]);
+    return l.toArray(new CompactableOplog[l.size()]);
-   * @throws IOException
-    return oplogList.toArray(new Oplog[] {});
+    return oplogList.toArray(new Oplog[oplogList.size()]);
-
-
-        } catch (InterruptedException ex) {
+        } catch (InterruptedException ignore) {
-        // // Stop the compactor if running, without taking lock.
-        // if (this.oplogCompactor != null) {
-        // try {
-        // this.oplogCompactor.stopCompactor();
-        // }
-        // catch (CancelException ignore) {
-        // // Asif:To fix Bug 39380 , ignore the cache closed exception here.
-        // // allow it to call super .close so that it would be able to close
-        // the
-        // // oplogs
-        // // Though I do not think this exception will be thrown by
-        // // the stopCompactor. Still not taking chance and ignoring it
-        // }
-        // }
-        // // if (!isSync()) {
-        // stopAsyncFlusher(true); // do this before writeLock
-        // // }
-          } catch (CancelException e) {
+          } catch (CancelException ignore) {
+                  // TODO: calling wait while holding two locks
-                } catch (InterruptedException ie) {
+                } catch (InterruptedException ignore) {
-                    new Object[] {Integer.valueOf(loopCount), dr.getName()}));
+                    new Object[] {loopCount, dr.getName()}));
+                    // TODO: calling wait while holding two locks
-                  } catch (InterruptedException ie) {
+                  } catch (InterruptedException ignore) {
-    } catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException ignore) {
-   * 
-   * @param targetDir
-   * @param baselineInspector
-   * @param restoreScript
-   * @throws IOException
-        Object childLock = childOplog.lock;;
+        Object childLock = childOplog.lock;
-   * 
-   * @param backupManager
-   * @throws IOException
-    Cache c = org.apache.geode.cache.CacheFactory.create(ds);
-    offlineCache = c;
-    org.apache.geode.cache.DiskStoreFactory dsf = c.createDiskStoreFactory();
+    InternalCache cache = (InternalCache) CacheFactory.create(ds);
+    offlineCache = cache;
+    DiskStoreFactory dsf = cache.createDiskStoreFactory();
-    DiskStoreImpl dsi = new DiskStoreImpl(c, dsName,
+    DiskStoreImpl dsi = new DiskStoreImpl(cache, dsName,
-    ((GemFireCacheImpl) c).addDiskStore(dsi);
+    cache.addDiskStore(dsi);
-        } catch (InterruptedException e) {
+        } catch (InterruptedException ignore) {
-      } catch (InterruptedException e) {
+      } catch (InterruptedException ignore) {
-      } catch (Exception e) {
+      } catch (Exception ignore) {
-    } catch (InterruptedException e) {
+    } catch (InterruptedException ignore) {
