GEODE-2632: change dependencies on GemFireCacheImpl to InternalCache

* misc cleanup of code where possible

-
+import static org.apache.geode.internal.lang.SystemUtils.*;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Hashtable;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.NoSuchElementException;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.Lock;
+
+import org.apache.logging.log4j.Logger;
+
-import org.apache.geode.cache.*;
+import org.apache.geode.cache.AttributesFactory;
+import org.apache.geode.cache.AttributesMutator;
+import org.apache.geode.cache.Cache;
+import org.apache.geode.cache.CacheClosedException;
+import org.apache.geode.cache.CacheException;
+import org.apache.geode.cache.CacheListener;
+import org.apache.geode.cache.CacheLoader;
+import org.apache.geode.cache.CacheLoaderException;
+import org.apache.geode.cache.CacheStatistics;
+import org.apache.geode.cache.CacheWriter;
+import org.apache.geode.cache.CacheWriterException;
+import org.apache.geode.cache.CustomExpiry;
+import org.apache.geode.cache.DataPolicy;
+import org.apache.geode.cache.DiskAccessException;
+import org.apache.geode.cache.EntryExistsException;
+import org.apache.geode.cache.EntryNotFoundException;
+import org.apache.geode.cache.ExpirationAttributes;
+import org.apache.geode.cache.InterestPolicy;
+import org.apache.geode.cache.InterestRegistrationEvent;
+import org.apache.geode.cache.LoaderHelper;
+import org.apache.geode.cache.LowMemoryException;
+import org.apache.geode.cache.Operation;
+import org.apache.geode.cache.PartitionAttributes;
+import org.apache.geode.cache.PartitionResolver;
+import org.apache.geode.cache.PartitionedRegionDistributionException;
+import org.apache.geode.cache.PartitionedRegionStorageException;
+import org.apache.geode.cache.Region;
+import org.apache.geode.cache.RegionAttributes;
+import org.apache.geode.cache.RegionDestroyedException;
+import org.apache.geode.cache.RegionEvent;
+import org.apache.geode.cache.RegionExistsException;
+import org.apache.geode.cache.RegionMembershipListener;
+import org.apache.geode.cache.TransactionDataNotColocatedException;
+import org.apache.geode.cache.TransactionDataRebalancedException;
+import org.apache.geode.cache.TransactionException;
-import org.apache.geode.cache.client.internal.*;
-import org.apache.geode.cache.execute.*;
+import org.apache.geode.cache.client.internal.ClientMetadataService;
+import org.apache.geode.cache.execute.EmptyRegionFunctionException;
+import org.apache.geode.cache.execute.Function;
+import org.apache.geode.cache.execute.FunctionContext;
+import org.apache.geode.cache.execute.FunctionException;
+import org.apache.geode.cache.execute.FunctionService;
+import org.apache.geode.cache.execute.ResultCollector;
-import org.apache.geode.cache.query.*;
-import org.apache.geode.cache.query.internal.*;
-import org.apache.geode.cache.query.internal.index.*;
+import org.apache.geode.cache.query.FunctionDomainException;
+import org.apache.geode.cache.query.Index;
+import org.apache.geode.cache.query.IndexCreationException;
+import org.apache.geode.cache.query.IndexExistsException;
+import org.apache.geode.cache.query.IndexInvalidException;
+import org.apache.geode.cache.query.IndexNameConflictException;
+import org.apache.geode.cache.query.IndexType;
+import org.apache.geode.cache.query.MultiIndexCreationException;
+import org.apache.geode.cache.query.NameResolutionException;
+import org.apache.geode.cache.query.QueryException;
+import org.apache.geode.cache.query.QueryInvocationTargetException;
+import org.apache.geode.cache.query.SelectResults;
+import org.apache.geode.cache.query.TypeMismatchException;
+import org.apache.geode.cache.query.internal.Bag;
+import org.apache.geode.cache.query.internal.CompiledSelect;
+import org.apache.geode.cache.query.internal.DefaultQuery;
+import org.apache.geode.cache.query.internal.ExecutionContext;
+import org.apache.geode.cache.query.internal.QCompiler;
+import org.apache.geode.cache.query.internal.QueryExecutor;
+import org.apache.geode.cache.query.internal.ResultsBag;
+import org.apache.geode.cache.query.internal.ResultsCollectionWrapper;
+import org.apache.geode.cache.query.internal.ResultsSet;
+import org.apache.geode.cache.query.internal.index.AbstractIndex;
+import org.apache.geode.cache.query.internal.index.IndexCreationData;
+import org.apache.geode.cache.query.internal.index.IndexManager;
+import org.apache.geode.cache.query.internal.index.IndexUtils;
+import org.apache.geode.cache.query.internal.index.PartitionedIndex;
-import org.apache.geode.distributed.internal.*;
+import org.apache.geode.distributed.internal.DM;
+import org.apache.geode.distributed.internal.DistributionAdvisee;
+import org.apache.geode.distributed.internal.DistributionAdvisor;
+import org.apache.geode.distributed.internal.DistributionConfig;
+import org.apache.geode.distributed.internal.DistributionManager;
+import org.apache.geode.distributed.internal.InternalDistributedSystem;
+import org.apache.geode.distributed.internal.MembershipListener;
+import org.apache.geode.distributed.internal.ProfileListener;
+import org.apache.geode.distributed.internal.ReplyException;
+import org.apache.geode.distributed.internal.ReplyProcessor21;
-import org.apache.geode.internal.cache.execute.*;
+import org.apache.geode.internal.cache.execute.AbstractExecution;
+import org.apache.geode.internal.cache.execute.FunctionExecutionNodePruner;
+import org.apache.geode.internal.cache.execute.FunctionRemoteContext;
+import org.apache.geode.internal.cache.execute.InternalFunctionInvocationTargetException;
+import org.apache.geode.internal.cache.execute.LocalResultCollector;
+import org.apache.geode.internal.cache.execute.PartitionedRegionFunctionExecutor;
+import org.apache.geode.internal.cache.execute.PartitionedRegionFunctionResultSender;
+import org.apache.geode.internal.cache.execute.PartitionedRegionFunctionResultWaiter;
+import org.apache.geode.internal.cache.execute.RegionFunctionContextImpl;
+import org.apache.geode.internal.cache.execute.ServerToClientFunctionResultSender;
-import org.apache.geode.internal.cache.partitioned.*;
+import org.apache.geode.internal.cache.lru.Sizeable;
+import org.apache.geode.internal.cache.partitioned.ContainsKeyValueMessage;
+import org.apache.geode.internal.cache.partitioned.DestroyMessage;
+import org.apache.geode.internal.cache.partitioned.DestroyRegionOnDataStoreMessage;
+import org.apache.geode.internal.cache.partitioned.DumpAllPRConfigMessage;
+import org.apache.geode.internal.cache.partitioned.DumpB2NRegion;
+import org.apache.geode.internal.cache.partitioned.DumpBucketsMessage;
+import org.apache.geode.internal.cache.partitioned.FetchBulkEntriesMessage;
+import org.apache.geode.internal.cache.partitioned.FetchEntriesMessage;
+import org.apache.geode.internal.cache.partitioned.FetchEntryMessage;
+import org.apache.geode.internal.cache.partitioned.FetchKeysMessage;
+import org.apache.geode.internal.cache.partitioned.GetMessage;
+import org.apache.geode.internal.cache.partitioned.IdentityRequestMessage;
+import org.apache.geode.internal.cache.partitioned.IdentityUpdateMessage;
+import org.apache.geode.internal.cache.partitioned.IndexCreationMsg;
+import org.apache.geode.internal.cache.partitioned.InterestEventMessage;
+import org.apache.geode.internal.cache.partitioned.InvalidateMessage;
+import org.apache.geode.internal.cache.partitioned.PREntriesIterator;
+import org.apache.geode.internal.cache.partitioned.PRLocallyDestroyedException;
+import org.apache.geode.internal.cache.partitioned.PRSanityCheckMessage;
+import org.apache.geode.internal.cache.partitioned.PRUpdateEntryVersionMessage;
+import org.apache.geode.internal.cache.partitioned.PartitionedRegionObserver;
+import org.apache.geode.internal.cache.partitioned.PartitionedRegionObserverHolder;
+import org.apache.geode.internal.cache.partitioned.PutAllPRMessage;
+import org.apache.geode.internal.cache.partitioned.PutMessage;
+import org.apache.geode.internal.cache.partitioned.RegionAdvisor;
+import org.apache.geode.internal.cache.partitioned.RemoveAllPRMessage;
+import org.apache.geode.internal.cache.partitioned.RemoveIndexesMessage;
+import org.apache.geode.internal.cache.partitioned.SizeMessage;
-import org.apache.logging.log4j.Logger;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.io.Serializable;
-import java.util.*;
-import java.util.concurrent.*;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.locks.Lock;
- * 
-  public static final Random rand =
+  public static final Random RANDOM =
-          NanoTimer.getTime()).longValue());
+          NanoTimer.getTime()));
-  public static final int NETWORK_HOP_TO_SAME_GROUP = 1;
+  private static final int NETWORK_HOP_TO_SAME_GROUP = 1;
-
+
-  public static final boolean DISABLE_SECONDARY_BUCKET_ACK =
+  static final boolean DISABLE_SECONDARY_BUCKET_ACK =
-      int i = rand.nextInt();
+      int i = RANDOM.nextInt();
-      return Integer.valueOf(i);
+      return i;
-  final static long VM_OWNERSHIP_WAIT_TIME = PRSystemPropertyGetter.parseLong(
+  private static final long VM_OWNERSHIP_WAIT_TIME = PRSystemPropertyGetter.parseLong(
-  public Thread locallyDestroyingThread;
+  Thread locallyDestroyingThread;
-  private ConcurrentMap<String, Integer[]> partitionsMap =
-      new ConcurrentHashMap<String, Integer[]>();
+  private final ConcurrentMap<String, Integer[]> partitionsMap = new ConcurrentHashMap<>();
-  private final ThreadLocal<Byte> networkHopType = new ThreadLocal<Byte>() {
+  private static final ThreadLocal<Byte> networkHopType = new ThreadLocal<Byte>() {
-      return Byte.valueOf((byte) NETWORK_HOP_NONE);
+      return (byte) NETWORK_HOP_NONE;
-    this.networkHopType.remove();
-    this.metadataVersion.remove();
+    networkHopType.remove();
+    metadataVersion.remove();
-    this.networkHopType.set(value);
+    networkHopType.set(value);
-   * <p>
-   * </p>
+   * <p>
-    return this.networkHopType.get().byteValue();
+    return networkHopType.get();
-  private final ThreadLocal<Byte> metadataVersion = new ThreadLocal<Byte>() {
+  private static final ThreadLocal<Byte> metadataVersion = new ThreadLocal<Byte>() {
-    this.metadataVersion.set(value);
+    metadataVersion.set(value);
-    return this.metadataVersion.get().byteValue();
+    return metadataVersion.get();
-
-
-  ////////////////// ConcurrentMap methods //////////////////
-
-
-
-  ////////////////// End of ConcurrentMap methods //////////////////
-
-
-        Cache c = GemFireCacheImpl.getInstance();
-        if (c == null) {
+        Cache cache = GemFireCacheImpl.getInstance();
+        if (cache == null) {
-          c.getCancelCriterion().checkCancelInProgress(null);
+          cache.getCancelCriterion().checkCancelInProgress(null);
-        IdentityRequestMessage.setLatestId(((Integer) key).intValue());
+        IdentityRequestMessage.setLatestId((Integer) key);
-        PartitionedRegionException pre = new PartitionedRegionException(
+        throw new PartitionedRegionException(
-        throw pre;
-      StringBuffer b = new StringBuffer("prIdToPR Map@");
-      b.append(System.identityHashCode(prIdToPR)).append(":\n");
-      Map.Entry me;
-      for (Iterator i = prIdToPR.entrySet().iterator(); i.hasNext();) {
-        me = (Map.Entry) i.next();
-        b.append(me.getKey()).append("=>").append(me.getValue());
-        if (i.hasNext()) {
-          b.append("\n");
+      StringBuilder sb = new StringBuilder("prIdToPR Map@");
+      sb.append(System.identityHashCode(prIdToPR)).append(':').append(getLineSeparator());
+      Map.Entry mapEntry;
+      for (Iterator iterator = prIdToPR.entrySet().iterator(); iterator.hasNext();) {
+        mapEntry = (Map.Entry) iterator.next();
+        sb.append(mapEntry.getKey()).append("=>").append(mapEntry.getValue());
+        if (iterator.hasNext()) {
+          sb.append(getLineSeparator());
-      return b.toString();
+      return sb.toString();
-  // final private Scope userScope;
-
-  final private Node node;
+  private final Node node;
-  /**
-   * Constructor for a PartitionedRegion. This has an accessor (Region API) functionality and
-   * contains a datastore for actual storage. An accessor can act as a local cache by having a local
-   * storage enabled. A PartitionedRegion can be created by a factory method of RegionFactory.java
-   * and also by invoking Cache.createRegion(). (Cache.xml etc to be added)
-   * 
-   */
-
-  static public final String RETRY_TIMEOUT_PROPERTY =
+  public static final String RETRY_TIMEOUT_PROPERTY =
-  public PartitionedRegion(String regionname, RegionAttributes ra, LocalRegion parentRegion,
-      GemFireCacheImpl cache, InternalRegionArguments internalRegionArgs) {
-    super(regionname, ra, parentRegion, cache, internalRegionArgs);
+  /**
+   * Constructor for a PartitionedRegion. This has an accessor (Region API) functionality and
+   * contains a datastore for actual storage. An accessor can act as a local cache by having a local
+   * storage enabled. A PartitionedRegion can be created by a factory method of RegionFactory.java
+   * and also by invoking Cache.createRegion(). (Cache.xml etc to be added)
+   */
+  public PartitionedRegion(String regionName, RegionAttributes regionAttributes,
+      LocalRegion parentRegion, InternalCache cache, InternalRegionArguments internalRegionArgs) {
+    super(regionName, regionAttributes, parentRegion, cache, internalRegionArgs);
-      logger.debug("Constructing Partitioned Region {}", regionname);
+      logger.debug("Constructing Partitioned Region {}", regionName);
-    // this.userScope = ra.getScope();
-    this.partitionAttributes = ra.getPartitionAttributes();
+    this.partitionAttributes = regionAttributes.getPartitionAttributes();
-        PartitionedRegionHelper.DEFAULT_TOTAL_WAIT_RETRY_ITERATION).intValue();
+        PartitionedRegionHelper.DEFAULT_TOTAL_WAIT_RETRY_ITERATION);
-    this.distAdvisor = RegionAdvisor.createRegionAdvisor(this); // Warning: potential early escape
-                                                                // of instance
-    this.redundancyProvider = new PRHARedundancyProvider(this); // Warning:
-                                                                // potential
-                                                                // early escape
-                                                                // instance
+
+    // Warning: potential early escape of instance
+    this.distAdvisor = RegionAdvisor.createRegionAdvisor(this);
+    // Warning: potential early escape of instance
+    this.redundancyProvider = new PRHARedundancyProvider(this);
-    this.redundantCopies = ra.getPartitionAttributes().getRedundantCopies();
-    this.prStats.setConfiguredRedundantCopies(ra.getPartitionAttributes().getRedundantCopies());
-    this.prStats.setLocalMaxMemory(ra.getPartitionAttributes().getLocalMaxMemory() * 1024L * 1024);
+    this.redundantCopies = regionAttributes.getPartitionAttributes().getRedundantCopies();
+    this.prStats.setConfiguredRedundantCopies(
+        regionAttributes.getPartitionAttributes().getRedundantCopies());
+    this.prStats.setLocalMaxMemory(
+        regionAttributes.getPartitionAttributes().getLocalMaxMemory() * 1024L * 1024);
-    this.minimumWriteRedundancy =
-        Integer
-            .getInteger(
-                DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionWriteRedundancy", 0)
-            .intValue();
-    // No redundancy required for reads
-    this.minimumReadRedundancy = Integer
-        .getInteger(DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionReadRedundancy", 0)
-        .intValue();
+    this.minimumWriteRedundancy = Integer.getInteger(
+        DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionWriteRedundancy", 0);
-    this.haveCacheLoader = ra.getCacheLoader() != null;
+    // No redundancy required for reads
+    this.minimumReadRedundancy = Integer.getInteger(
+        DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionReadRedundancy", 0);
+
+    this.haveCacheLoader = regionAttributes.getCacheLoader() != null;
-      logger.debug("Partitioned Region {} constructed {}", regionname,
+      logger.debug("Partitioned Region {} constructed {}", regionName,
-  public final boolean isShadowPR() {
+  public boolean isShadowPR() {
-      return Collections.EMPTY_SET;
+      return Collections.emptySet();
-          IllegalStateException ise = new IllegalStateException(
+          throw new IllegalStateException(
-          throw ise;
-          IllegalStateException ise = new IllegalStateException(
+          throw new IllegalStateException(
-          throw ise;
-    /* set the total number of buckets */
-    // setTotalNumOfBuckets();
-          /**
+          /*
-      // if (!rl.lock()) {
-            new Object[] {getFullPath(), Integer.valueOf(this.partitionedRegionId),
-                getRegionIdentifier()}));
+            new Object[] {getFullPath(), this.partitionedRegionId, getRegionIdentifier()}));
-            new Object[] {getFullPath(), Integer.valueOf(this.partitionedRegionId)}));
+            new Object[] {getFullPath(), this.partitionedRegionId}));
-        prIdToPR.put(Integer.valueOf(this.partitionedRegionId), this); // last
+        prIdToPR.put(this.partitionedRegionId, this); // last
-              .toLocalizedString(new Object[] {getFullPath(), prIdToPR.dump()});
+              .toLocalizedString(getFullPath(), prIdToPR.dump());
-          if (prIdToPR.containsKey(Integer.valueOf(this.partitionedRegionId))) {
-            prIdToPR.put(Integer.valueOf(this.partitionedRegionId), PRIdMap.FAILED_REGISTRATION,
-                false);
+          if (prIdToPR.containsKey(this.partitionedRegionId)) {
+            prIdToPR.put(this.partitionedRegionId, PRIdMap.FAILED_REGISTRATION, false);
-                new Object[] {Integer.valueOf(this.partitionedRegionId), this.getName()}));
+                new Object[] {this.partitionedRegionId, this.getName()}));
-      } catch (Throwable ignore) {
+      } catch (Throwable e) {
-          logger.debug("Partitioned Region creation, could not clean up after caught exception",
-              ignore);
+          logger.debug("Partitioned Region creation, could not clean up after caught exception", e);
-          logger.warn(es.getMessage(), es);
+          logger.debug(es.getMessage(), es);
-  final public String getRegionIdentifier() {
+  public String getRegionIdentifier() {
-   *
-   * @throws PartitionOfflineException
-  public final void updatePRConfig(PartitionRegionConfig prConfig, boolean putOnlyIfUpdated) {
+  public void updatePRConfig(PartitionRegionConfig prConfig, boolean putOnlyIfUpdated) {
-   * 
-   * @param keyInfo
-   * @return TODO
-    Integer bucketIdInt = Integer.valueOf(bucketId);
+    Integer bucketIdInt = bucketId;
-          logger.debug("getEntryInBucket: Encountered PRLocallyDestroyedException ");
+          logger.debug("getEntryInBucket: Encountered PRLocallyDestroyedException", pde);
-      } catch (EntryNotFoundException enfe) {
+      } catch (EntryNotFoundException ignore) {
-        retryNode = getOrCreateNodeForBucketRead(bucketIdInt.intValue());
+        retryNode = getOrCreateNodeForBucketRead(bucketIdInt);
-        getRegionAdvisor().notPrimary(bucketIdInt.intValue(), retryNode);
-        retryNode = getOrCreateNodeForBucketRead(bucketIdInt.intValue());
+        getRegionAdvisor().notPrimary(bucketIdInt, retryNode);
+        retryNode = getOrCreateNodeForBucketRead(bucketIdInt);
-              .toLocalizedString(Integer.valueOf(count)));
+              .toLocalizedString(count));
-        LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS,
-        Integer.valueOf(count)), e);
+        LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS, count), e);
-   * @throws PrimaryBucketException
-  final public Region createSubregion(String subregionName, RegionAttributes regionAttributes)
+  public Region createSubregion(String subregionName, RegionAttributes regionAttributes)
-      } catch (ForceReattemptException fre) {
+      } catch (ForceReattemptException ignore) {
-      } catch (NoSuchElementException stop) {
+      } catch (NoSuchElementException ignore) {
-        localIter = Collections.EMPTY_SET.iterator();
+        localIter = Collections.emptySet().iterator();
-      } catch (NoSuchElementException stop) {
+      } catch (NoSuchElementException ignore) {
-      } catch (InterruptedException e) {
+      } catch (InterruptedException ignore) {
-    // Asif: No need to apply the limit to the SelectResults.
+    // No need to apply the limit to the SelectResults.
-        // results = new ResultsCollectionWrapper(elementType, results.asSet(),
-        // query.getLimit(parameters));
-        SelectResults resultCount = new ResultsBag(getCachePerfStats());// Constructor with
-                                                                        // elementType not visible.
+        // Constructor with elementType not visible.
+        SelectResults resultCount = new ResultsBag(getCachePerfStats());
-        ((ResultsBag) resultCount).addAndGetOccurence(results.size());
+        ((Bag) resultCount).addAndGetOccurence(results.size());
-  // /////////////////////////////////////////////////////////////////////
-  // ////////////// Operation Supported for this release
-  // //////////////////////////////
-  // /////////////////////////////////////////////////////////////////////
-
-      InternalDistributedMember targetNode = getNodeForBucketWrite(bucketId.intValue(), null);
+      InternalDistributedMember targetNode = getNodeForBucketWrite(bucketId, null);
-          targetNode = createBucket(bucketId.intValue(), event.getNewValSizeForPR(), null);
+          targetNode = createBucket(bucketId, event.getNewValSizeForPR(), null);
-        RegionDestroyedException rde2 = new RegionDestroyedException(toString(), getFullPath());
-        rde2.initCause(rde);
-        throw rde2;
+        throw new RegionDestroyedException(toString(), getFullPath(), rde);
-    }
-    // catch (CacheWriterException cwe) {
-    // throw cwe;
-    // }
-    // catch (TimeoutException te) {
-    // throw te;
-    // }
-    // catch (RuntimeException re) {
-    // throw re;
-    // }
-    finally {
-      // event.setPutAllOperation(putAllOp_save); // Gester: temporary fix
+    } finally {
-      if (!ifNew && !ifOld && !this.concurrencyChecksEnabled) { // may fail due to concurrency
-                                                                // conflict
+      if (!ifNew && !ifOld && !this.concurrencyChecksEnabled) {
+        // may fail due to concurrency conflict
-  /*
-   * (non-Javadoc)
-   * 
-   * @see
-   * org.apache.geode.internal.cache.LocalRegion#checkIfAboveThreshold(org.apache.geode.internal.
-   * cache.EntryEventImpl)
-   */
-  public void checkIfAboveThreshold(EntryEventImpl evi) throws LowMemoryException {
-    getRegionAdvisor().checkIfBucketSick(evi.getKeyInfo().getBucketId(), evi.getKey());
+  public void checkIfAboveThreshold(EntryEventImpl entryEvent) throws LowMemoryException {
+    getRegionAdvisor().checkIfBucketSick(entryEvent.getKeyInfo().getBucketId(),
+        entryEvent.getKey());
-
-  public void postPutAllFireEvents(DistributedPutAllOperation putallOp,
+  public void postPutAllFireEvents(DistributedPutAllOperation putAllOp,
-  public void postRemoveAllFireEvents(DistributedRemoveAllOperation op,
+  public void postRemoveAllFireEvents(DistributedRemoveAllOperation removeAllOp,
-
-   * @param putallO DistributedPutAllOperation object.
+   * @param putAllOp DistributedPutAllOperation object.
-  public long postPutAllSend(DistributedPutAllOperation putallO,
+  public long postPutAllSend(DistributedPutAllOperation putAllOp,
-    try {
-      final long startTime = PartitionedRegionStats.startTime();
-      // build all the msgs by bucketid
-      HashMap prMsgMap = putallO.createPRMessages();
-      PutAllPartialResult partialKeys = new PutAllPartialResult(putallO.putAllDataSize);
+    final long startTime = PartitionedRegionStats.startTime();
+    // build all the msgs by bucketid
+    HashMap prMsgMap = putAllOp.createPRMessages();
+    PutAllPartialResult partialKeys = new PutAllPartialResult(putAllOp.putAllDataSize);
-      // clear the successfulPuts list since we're actually doing the puts here
-      // and the basicPutAll work was just a way to build the DPAO object
-      Map<Object, VersionTag> keyToVersionMap =
-          new HashMap<Object, VersionTag>(successfulPuts.size());
-      successfulPuts.clearVersions();
-      Iterator itor = prMsgMap.entrySet().iterator();
-      while (itor.hasNext()) {
-        Map.Entry mapEntry = (Map.Entry) itor.next();
-        Integer bucketId = (Integer) mapEntry.getKey();
-        PutAllPRMessage prMsg = (PutAllPRMessage) mapEntry.getValue();
-        checkReadiness();
-        long then = 0;
-        if (isDebugEnabled) {
-          then = System.currentTimeMillis();
+    // clear the successfulPuts list since we're actually doing the puts here
+    // and the basicPutAll work was just a way to build the DPAO object
+    Map<Object, VersionTag> keyToVersionMap =
+        new HashMap<Object, VersionTag>(successfulPuts.size());
+    successfulPuts.clearVersions();
+    Iterator itor = prMsgMap.entrySet().iterator();
+    while (itor.hasNext()) {
+      Map.Entry mapEntry = (Map.Entry) itor.next();
+      Integer bucketId = (Integer) mapEntry.getKey();
+      PutAllPRMessage prMsg = (PutAllPRMessage) mapEntry.getValue();
+      checkReadiness();
+      long then = 0;
+      if (isDebugEnabled) {
+        then = System.currentTimeMillis();
+      }
+      try {
+        VersionedObjectList versions = sendMsgByBucket(bucketId, prMsg);
+        if (versions.size() > 0) {
+          partialKeys.addKeysAndVersions(versions);
+          versions.saveVersions(keyToVersionMap);
+        } else if (!this.concurrencyChecksEnabled) { // no keys returned if not versioned
+          Set keys = prMsg.getKeys();
+          partialKeys.addKeys(keys);
+      } catch (PutAllPartialResultException pre) {
+        // sendMsgByBucket applied partial keys
+        if (isDebugEnabled) {
+          logger.debug("PR.postPutAll encountered PutAllPartialResultException, ", pre);
+        }
+        partialKeys.consolidate(pre.getResult());
+      } catch (Exception ex) {
+        // If failed at other exception
+        if (isDebugEnabled) {
+          logger.debug("PR.postPutAll encountered exception at sendMsgByBucket, ", ex);
+        }
+        @Released
+        EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
-          VersionedObjectList versions = sendMsgByBucket(bucketId, prMsg);
-          if (versions.size() > 0) {
-            partialKeys.addKeysAndVersions(versions);
-            versions.saveVersions(keyToVersionMap);
-          } else if (!this.concurrencyChecksEnabled) { // no keys returned if not versioned
-            Set keys = prMsg.getKeys();
-            partialKeys.addKeys(keys);
-          }
-        } catch (PutAllPartialResultException pre) {
-          // sendMsgByBucket applied partial keys
-          if (isDebugEnabled) {
-            logger.debug("PR.postPutAll encountered PutAllPartialResultException, ", pre);
-          }
-          partialKeys.consolidate(pre.getResult());
-        } catch (Exception ex) {
-          // If failed at other exception
-          if (isDebugEnabled) {
-            logger.debug("PR.postPutAll encountered exception at sendMsgByBucket, ", ex);
-          }
-          @Released
-          EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
-          try {
-            partialKeys.saveFailedKey(firstEvent.getKey(), ex);
-          } finally {
-            firstEvent.release();
-          }
-        }
-        if (isDebugEnabled) {
-          long now = System.currentTimeMillis();
-          if ((now - then) >= 10000) {
-            logger.debug("PR.sendMsgByBucket took " + (now - then) + " ms");
-          }
+          partialKeys.saveFailedKey(firstEvent.getKey(), ex);
+        } finally {
+          firstEvent.release();
-      this.prStats.endPutAll(startTime);
-      if (!keyToVersionMap.isEmpty()) {
-        for (Iterator it = successfulPuts.getKeys().iterator(); it.hasNext();) {
-          successfulPuts.addVersion(keyToVersionMap.get(it.next()));
+      if (isDebugEnabled) {
+        long now = System.currentTimeMillis();
+        if ((now - then) >= 10000) {
+          logger.debug("PR.sendMsgByBucket took " + (now - then) + " ms");
-        keyToVersionMap.clear();
+    }
+    this.prStats.endPutAll(startTime);
+    if (!keyToVersionMap.isEmpty()) {
+      for (Iterator it = successfulPuts.getKeys().iterator(); it.hasNext();) {
+        successfulPuts.addVersion(keyToVersionMap.get(it.next()));
+      }
+      keyToVersionMap.clear();
+    }
-      if (partialKeys.hasFailure()) {
-        logger.info(LocalizedMessage.create(LocalizedStrings.Region_PutAll_Applied_PartialKeys_0_1,
-            new Object[] {getFullPath(), partialKeys}));
-        if (putallO.isBridgeOperation()) {
-          if (partialKeys.getFailure() instanceof CancelException) {
-            throw (CancelException) partialKeys.getFailure();
-          } else {
-            throw new PutAllPartialResultException(partialKeys);
-          }
+    if (partialKeys.hasFailure()) {
+      logger.info(LocalizedMessage.create(LocalizedStrings.Region_PutAll_Applied_PartialKeys_0_1,
+          new Object[] {getFullPath(), partialKeys}));
+      if (putAllOp.isBridgeOperation()) {
+        if (partialKeys.getFailure() instanceof CancelException) {
+          throw (CancelException) partialKeys.getFailure();
-          if (partialKeys.getFailure() instanceof RuntimeException) {
-            throw (RuntimeException) partialKeys.getFailure();
-          } else {
-            throw new RuntimeException(partialKeys.getFailure());
-          }
+          throw new PutAllPartialResultException(partialKeys);
+        }
+      } else {
+        if (partialKeys.getFailure() instanceof RuntimeException) {
+          throw (RuntimeException) partialKeys.getFailure();
+        } else {
+          throw new RuntimeException(partialKeys.getFailure());
-    } finally {
-      /*
-       * // TODO XD OFFHEAP MERGE: do we have any events that need freeOffHeapReferences for
-       * (PutAllPRMessage.PutAllResponse resp : responses) { PutAllPRMessage.PRMsgResponseContext
-       * ctx = resp.getContextObject(); if (ctx != null) { EntryEventImpl e = ctx.getEvent(); if (e
-       * != null) { e.release(); } } }
-       */
-      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
+      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);
-            } catch (InterruptedException e) {
+            } catch (InterruptedException ignore) {
-          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-            logger.debug("PR.sendMsgByBucket: Old target was {}, Retrying", lastTarget,
+            logger.debug("PR.sendMsgByBucket: Old target was {}, Retrying {}", lastTarget,
-          getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+          getRegionAdvisor().notPrimary(bucketId, currentTarget);
-          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
+      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);
-            } catch (InterruptedException e) {
+            } catch (InterruptedException ignore) {
-          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-          getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+          getRegionAdvisor().notPrimary(bucketId, currentTarget);
-          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-          event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId.intValue()),
-          retryTimeout);
+          event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId), retryTimeout);
-          } catch (InterruptedException e) {
+          } catch (InterruptedException ignore) {
-          // final boolean cacheWrite = !event.isOriginRemote()
-          // && !event.isNetSearch();
-          // if (cacheWrite) {
-          // doCacheWriteBeforePut(event, ifNew);
-          // }
-            if (!DistributionManager.isFunctionExecutionThread.get().booleanValue()) {
+            if (!DistributionManager.isFunctionExecutionThread.get()) {
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-        getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+        getRegionAdvisor().notPrimary(bucketId, currentTarget);
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);
-            bucketStringForLogs(bucketId.intValue()), count, (timeOut - System.currentTimeMillis()),
+            bucketStringForLogs(bucketId), count, (timeOut - System.currentTimeMillis()),
-    newNode = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+    newNode = getNodeForBucketWrite(bucketId, retryTime);
-      newNode = createBucket(bucketId.intValue(), getEntrySize(event), retryTime);
+      newNode = createBucket(bucketId, getEntrySize(event), retryTime);
-   * Serialize the key and value early (prior to creating the message) to gather the size of the
-   * entry Assumes the new value from the <code>EntryEventImpl</code> is not serialized
-   * 
-   * @return sum of bytes as reported by {@link CachedDeserializable#getSizeInBytes()}
-   */
-  // private int serializeValue(EntryEventImpl event)
-  // {
-  // TODO serialize the key as well
-  // this code used to make the following call:
-  // Object val = event.getNewValue();
-  // which deserializes the value and we don't want to do that.
-  // int numBytes = 0;
-  // Object val = event.getNewValue();
-  // if (val == null) {
-  // // event.setSerializedNewValue(new byte[] {DataSerializer.NULL});
-  // return 0;
-  // }
-  // if (val instanceof byte[]) {
-  // byte[] v = (byte[]) val;
-  // numBytes = v.length;
-  // } else {
-  // if (event.getSerializedNewValue() == null) {
-  // event.setSerializedNewValue(EntryEventImpl.serialize(event.getNewValue()));
-  // }
-  // numBytes = getEntrySize(event);
-  // }
-  // return numBytes;
-  // }
-  /**
-   * Get the serialized size of an <code>EntryEventImpl</code>
+   * Get the serialized size of an {@code EntryEventImpl}
-      return ((CachedDeserializable) v).getSizeInBytes();
+      return ((Sizeable) v).getSizeInBytes();
-  // /**
-  // * Gets the Node that is managing a specific bucketId. This does consider
-  // the
-  // * failed nodes.
-  // *
-  // * @param bucketId
-  // * identifier for bucket
-  // * @param failedNodeList
-  // * of all the failedNodes to avoid these failed nodes to be picked in
-  // * the next node selection.
-  // * @return the Node managing the bucket
-  // */
-  // private Node getNodeForBucketExcludeFailedNode(final Long bucketId,
-  // final List failedNodeList) {
-  // throw new IllegalStateException("bucket2node should not be used");
-  // }
-
-                    Integer.valueOf(localSnoozer.getRetryTime()), Integer.valueOf(red),
-                    Integer.valueOf(this.minimumWriteRedundancy)}));
+                    localSnoozer.getRetryTime(), red, this.minimumWriteRedundancy}));
-
-
-    InternalDistributedMember result = getRegionAdvisor().getPreferredNode(bucketId);
-    return result;
+    return getRegionAdvisor().getPreferredNode(bucketId);
-   * @param function
-   * @param execution
-   * @param rc
-   * 
-   * @param function
-   * @param execution
-        if (execution.getFailedNodes()
-            .contains(((InternalDistributedMember) iterator.next()).getId())) {
+        if (execution.getFailedNodes().contains(((DistributedMember) iterator.next()).getId())) {
-        logger.debug("FunctionService: Executing on local node with keys.{}" + localKeys);
+        logger.debug("FunctionService: Executing on local node with keys.{}", localKeys);
-        logger.debug("FunctionService: Executing on remote nodes with member to keys map.{}"
-            + memberToKeysMap);
+        logger.debug("FunctionService: Executing on remote nodes with member to keys map.{}",
+            memberToKeysMap);
-
-   * @param function
-   * @param execution
-      bucketId = ((Integer) key).intValue();
+      bucketId = (Integer) key;
-      bucketId = Integer.valueOf(
-          PartitionedRegionHelper.getHashKey(this, Operation.FUNCTION_EXECUTION, key, null, null));
+      bucketId =
+          PartitionedRegionHelper.getHashKey(this, Operation.FUNCTION_EXECUTION, key, null, null);
-      targetNode = createBucket(bucketId.intValue(), 0, null /* retryTimeKeeper */);
+      targetNode = createBucket(bucketId, 0, null /* retryTimeKeeper */);
-                .toLocalizedString(new Object[] {function.getId(), sm}),
+                .toLocalizedString(function.getId(), sm),
-      targetNode = getOrCreateNodeForBucketRead(bucketId.intValue());
+      targetNode = getOrCreateNodeForBucketRead(bucketId);
-        // Asif: Fix for Bug # 40083
+        // Fix for Bug # 40083
-            targetNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+            targetNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-            targetNode = getOrCreateNodeForBucketRead(bucketId.intValue());
+            targetNode = getOrCreateNodeForBucketRead(bucketId);
-    } catch (NoSuchElementException done) {
+    } catch (NoSuchElementException ignore) {
+      // done
-        if (execution.getFailedNodes()
-            .contains(((InternalDistributedMember) iterator.next()).getId())) {
+        if (execution.getFailedNodes().contains(((DistributedMember) iterator.next()).getId())) {
-              .toLocalizedString(new Object[] {function.getId(), sm}),
+              .toLocalizedString(function.getId(), sm),
-    // final LocalResultCollector localResultCollector = new LocalResultCollector(function, rc,
-    // execution);
-      // final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(
-      // function.getId(), PartitionedRegion.this, execution
-      // .getArgumentsForMember(getMyId().getId()), null, ColocationHelper
-      // .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this,
-      // localBucketSet), resultSender, execution.isReExecute());
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-
-    return reply;
-
+    return resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-   * @param function
-   * @param execution
-      } catch (NoSuchElementException ex) {
+      } catch (NoSuchElementException ignore) {
-        if (execution.getFailedNodes()
-            .contains(((InternalDistributedMember) iterator.next()).getId())) {
+        if (execution.getFailedNodes().contains(((DistributedMember) iterator.next()).getId())) {
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-
-    return reply;
+    return resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-   * no docs
-   * 
-   * @param preferCD
-   * @param clientEvent TODO
-   * @param returnTombstones TODO
-          // Test hook
-          if (((LocalRegion) this).isTest())
-            ((LocalRegion) this).incCountNotFoundInLocal();
-          // TODO:Suranjan&Yogesh : there should be better way than this one
+          // TODO: there should be better way than this one
-            TransactionException ex = new TransactionDataRebalancedException(
+            throw new TransactionDataRebalancedException(
-                    .toLocalizedString(key));
-            ex.initCause(prce);
-            throw ex;
+                    .toLocalizedString(key),
+                prce);
-            TransactionException ex = new TransactionDataRebalancedException(
+            throw new TransactionDataRebalancedException(
-                    .toLocalizedString(key));
-            ex.initCause(cause);
-            throw ex;
+                    .toLocalizedString(key),
+                cause);
-            TransactionException ex = new TransactionException("Failed to get key: " + key, prce);
-            throw ex;
+            throw new TransactionException("Failed to get key: " + key, prce);
-              .toLocalizedString(Integer.valueOf(count)));
+              .toLocalizedString(count));
-    logger.warn(LocalizedMessage.create(
-        LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS,
-        Integer.valueOf(count)), e);
+    logger.warn(LocalizedMessage
+        .create(LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS, count), e);
-   * 
-
-   * 
-   * @see LocalRegion#cacheWriteBeforeRegionDestroy(RegionEventImpl)
-    InternalDistributedMember targetNode = getNodeForBucketRead(bucketId);
-    return targetNode;
+    return getNodeForBucketRead(bucketId);
-      // TODO:KIRK:OK if (re == null || Token.isRemoved(re.getValueInVM(this))) {
-   * <code>Random</code> number generator.
+   * {@code Random} number generator.
-   * @param rnd
-   * @throws IOException
-   * @throws ClassNotFoundException
-          nod = getNodeForBucketRead(buck.intValue());
+          nod = getNodeForBucketRead(buck);
-        } catch (PRLocallyDestroyedException pde) {
+        } catch (PRLocallyDestroyedException ignore) {
-    return Collections.EMPTY_SET;
+    return Collections.emptySet();
-      return Collections.EMPTY_LIST;
+      return Collections.emptyList();
+          // TODO: clean this up -- outer class is not serializable
-      } catch (ForceReattemptException e) {
+      } catch (ForceReattemptException ignore) {
-
-   * @param bucketNum
-   * @param bucketNum
-    Integer buck = Integer.valueOf(bucketNum);
+    Integer buck = bucketNum;
-      } catch (PRLocallyDestroyedException pde) {
+      } catch (PRLocallyDestroyedException ignore) {
-        nod = getNodeForBucketRead(buck.intValue());
+        nod = getNodeForBucketRead(buck);
-                    .toLocalizedString(new Object[] {getBucketName(buck.intValue()),
-                        Integer.valueOf(snoozer.getRetryTime())}));
+                    .toLocalizedString(new Object[] {getBucketName(buck), snoozer.getRetryTime()}));
-    return Collections.EMPTY_SET;
+    return Collections.emptySet();
-   * 
-   * @param nodeToBuckets
-   * @param values
-   * @param servConn
-   * @throws IOException
-          } catch (ForceReattemptException fre) {
+          } catch (ForceReattemptException ignore) {
-   * 
-   * @param retryTime
-    } catch (ForceReattemptException fre) {
+    } catch (ForceReattemptException ignore) {
-    } catch (PRLocallyDestroyedException prlde) {
+    } catch (PRLocallyDestroyedException ignore) {
-   * 
-   * @param nodeToBuckets
-   * @param failures
-   * @param values
-   * @param servConn
-   * @throws IOException
-        } catch (ForceReattemptException fre) {
-          // failures.putAll(nodeToBuckets.get(entry.getKey()));
+        } catch (ForceReattemptException ignore) {
-   * 
-   * @param nodeToBuckets
-   * @param failures
-   * @param regex
-   * @param values
-   * @param servConn
-   * @throws IOException
-        } catch (ForceReattemptException fre) {
-          // failures.addAll(nodeToBuckets.get(entry.getKey()));
+        } catch (ForceReattemptException ignore) {
-  // /**
-  // * Fetch all {@link InternalDistributedMember}s hosting a bucket using the
-  // * bucket2Node region
-  // *
-  // * @return the HashSet of unique Members hosting buckets
-  // */
-  // private HashSet getAllBucketDistributedMembers()
-  // {
-  // return getAllBucketNodes(true);
-  // }
-
-   * @return a <code>HashSet</code> of {@link InternalDistributedMember}s or an empty
-   *         <code>HashSet</code>
+   * @return a {@code HashSet} of {@link InternalDistributedMember}s or an empty {@code HashSet}
-      ret += i.intValue();
+      ret += i;
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-    return reply;
+    return resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-      // try {
-      // }
-      // catch (InterruptedException ie) {
-      // Thread.currentThread().interrupt();
-      // if (ownership) {
-      // lockService.unlock(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID);
-      // }
-      // throw new
-      // PartitionedRegionException(LocalizedStrings.PartitionedRegion_INTERRUPTEDEXCEPTION_ENCOUNTERED_GETTING_THE_MAX_PARTITIONED_REGION_ID.toLocalizedString(),
-      // ie);
-      // }
-          currentPRID = Integer.valueOf(0);
+          currentPRID = 0;
-        prid = currentPRID.intValue() + 1;
-        currentPRID = Integer.valueOf(prid);
+        prid = currentPRID + 1;
+        currentPRID = prid;
-          IdentityUpdateResponse pr =
-              IdentityUpdateMessage.send(parMembers, sys, currentPRID.intValue());
+          IdentityUpdateResponse pr = IdentityUpdateMessage.send(parMembers, sys, currentPRID);
-        } catch (ReplyException ignore) {
+        } catch (ReplyException e) {
-            logger.debug("generatePRId: Ignoring exception", ignore);
+            logger.debug("generatePRId: Ignoring exception", e);
-  public final DistributionAdvisor getDistributionAdvisor() {
+  public DistributionAdvisor getDistributionAdvisor() {
-  public final CacheDistributionAdvisor getCacheDistributionAdvisor() {
+  public CacheDistributionAdvisor getCacheDistributionAdvisor() {
-  public final RegionAdvisor getRegionAdvisor() {
+  public RegionAdvisor getRegionAdvisor() {
-    CacheWriter oldWriter = p_oldWriter;
-    super.cacheWriterChanged(oldWriter);
-    if (oldWriter == null ^ basicGetWriter() == null) {
+    super.cacheWriterChanged(p_oldWriter);
+    if (p_oldWriter == null ^ basicGetWriter() == null) {
-    CacheLoader myOldLoader = oldLoader;
-    this.dataStore.cacheLoaderChanged(basicGetLoader(), myOldLoader);
+    this.dataStore.cacheLoaderChanged(basicGetLoader(), oldLoader);
-    if (myOldLoader == null ^ basicGetLoader() == null) {
+    if (oldLoader == null ^ basicGetLoader() == null) {
-      o = prIdToPR.getRegion(Integer.valueOf(prid));
+      o = prIdToPR.getRegion(prid);
-        pr = (PartitionedRegion) prIdToPR.getRegion(Integer.valueOf(prId));
+        pr = (PartitionedRegion) prIdToPR.getRegion(prId);
-    } catch (RegionDestroyedException e) {
+    } catch (RegionDestroyedException ignore) {
-    } catch (PartitionedRegionException e) {
+    } catch (PartitionedRegionException ignore) {
-    } catch (PRLocallyDestroyedException e) {
+    } catch (PRLocallyDestroyedException ignore) {
-                new Object[] {sender.toString(), Integer.valueOf(prId), pr.getRegionIdentifier()}));
+                new Object[] {sender.toString(), prId, pr.getRegionIdentifier()}));
-              new Object[] {sender, Integer.valueOf(prId), pr.getRegionIdentifier(),
-                  Integer.valueOf(pr.getPRId())}));
+              new Object[] {sender, prId, pr.getRegionIdentifier(), pr.getPRId()}));
-
-    StringBuffer b = new StringBuffer(this.prRoot.getFullPath());
-    b.append("\n");
+    StringBuilder sb = new StringBuilder(this.prRoot.getFullPath());
+    sb.append("\n");
-      b.append(key).append("=>").append(this.prRoot.get(key));
+      sb.append(key).append("=>").append(this.prRoot.get(key));
-        b.append("\n");
+        sb.append("\n");
-    return b.toString();
+    return sb.toString();
-
-  // /////////////////////////////////////////////////////////////////////
-  // ////////////////////////// destroy method changes //
-  // ///////////////////////////
-  // /////////////////////////////////////////////////////////////////////
-
-        RegionDestroyedException rde2 = new RegionDestroyedException(toString(), getFullPath());
-        rde2.initCause(rde);
-        throw rde2;
+        throw new RegionDestroyedException(toString(), getFullPath(), rde);
-    return;
-   * 
-   * @param event
-   * @throws CacheWriterException
-          event.getKey(), event.getKey().hashCode(), targetNode,
-          bucketStringForLogs(bucketId.intValue()), retryTimeout);
+          event.getKey(), event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId),
+          retryTimeout);
-          } catch (InterruptedException e) {
+          } catch (InterruptedException ignore) {
-          if (getRegionAdvisor().getBucket(bucketId.intValue()).getBucketAdvisor()
+          if (getRegionAdvisor().getBucket(bucketId).getBucketAdvisor()
-                  .toLocalizedString(Integer.valueOf(retryTime.getRetryTime())));
+                  .toLocalizedString(retryTime.getRetryTime()));
-        currentTarget = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        currentTarget = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-        currentTarget = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        currentTarget = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-        getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+        getRegionAdvisor().notPrimary(bucketId, currentTarget);
-        currentTarget = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        currentTarget = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-  /**
-   * TODO txMerge verify
-   * 
-   * @param bucketId
-   * @param targetNode
-   */
-
-    GemFireCacheImpl c = getCache();
-    List servers = null;
+    InternalCache cache = getCache();
+    List servers;
-    servers = c.getCacheServers();
+    servers = cache.getCacheServers();
-    Collections.addAll(localServerGroups,
-        MemberAttributes.parseGroups(null, c.getSystem().getConfig().getGroups()));
+    Collections.addAll(localServerGroups, MemberAttributes.parseGroups(null,
+        cache.getInternalDistributedSystem().getConfig().getGroups()));
-      } catch (RegionDestroyedException rde) {
+      } catch (RegionDestroyedException ignore) {
-  final public int getRedundantCopies() {
+  public int getRedundantCopies() {
-          if (prIdToPR.containsKey(Integer.valueOf(this.partitionedRegionId))) {
-            prIdToPR.put(Integer.valueOf(this.partitionedRegionId), PRIdMap.FAILED_REGISTRATION,
-                false);
+          if (prIdToPR.containsKey(this.partitionedRegionId)) {
+            prIdToPR.put(this.partitionedRegionId, PRIdMap.FAILED_REGISTRATION, false);
-            this.getRegionIdentifier(), this.getGemFireCache(), true);
+            this.getRegionIdentifier(), getGemFireCache(), true);
-   * Perform cleanup when the Cache closes OVERRIDES
-   */
-  // void handleCacheClose()
-  // {
-  // super.handleCacheClose();
-  // basicClose();
-  // }
-  /**
-   * Do what needs to be done to partitioned regions state when closing.
-   */
-
-  // private void basicClose()
-  // {
-  // getPrStats().close();
-  // // isClosed = true;
-  // }
-  /**
-  static void afterRegionsClosedByCacheClose(GemFireCacheImpl cache) {
+  static void afterRegionsClosedByCacheClose(InternalCache cache) {
-  static void destroyLockService() {
-    PartitionedRegionHelper.destroyLockService();
-  }
-
-    final boolean isDebugEnabled = logger.isDebugEnabled();
-
-  protected void invalidateAllEntries(RegionEvent rgnEvent) {}
+  protected void invalidateAllEntries(RegionEvent rgnEvent) {
+    // do nothing
+  }
-              .toLocalizedString(Integer.valueOf(count)));
+              .toLocalizedString(count));
-        RegionDestroyedException rde2 = new RegionDestroyedException(toString(), getFullPath());
-        rde2.initCause(rde);
-        throw rde2;
+        throw new RegionDestroyedException(toString(), getFullPath(), rde);
-  /*
-   * We yet don't have any stats for this operation. (non-Javadoc)
-   * 
-   * @see
-   * org.apache.geode.internal.cache.LocalRegion#basicUpdateEntryVersion(org.apache.geode.internal.
-   * cache.EntryEventImpl)
-   */
-        RegionDestroyedException rde2 = new RegionDestroyedException(toString(), getFullPath());
-        rde2.initCause(rde);
-        throw rde2;
+        throw new RegionDestroyedException(toString(), getFullPath(), rde);
-
-   * 
-   * @param event
-   * @throws EntryNotFoundException
-          retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
-        } catch (TimeoutException te) {
-          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
-                                                                                    // longer
-                                                                                    // exists
+          retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
+        } catch (TimeoutException ignore) {
+          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId)) {
+            // bucket no longer exists
-        retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-        getRegionAdvisor().notPrimary(bucketId.intValue(), retryNode);
-        retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        getRegionAdvisor().notPrimary(bucketId, retryNode);
+        retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-            .toLocalizedString(Integer.valueOf(count))); // Fix for bug 36014
+            .toLocalizedString(count)); // Fix for bug 36014
-          LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS,
-          Integer.valueOf(count)));
+          LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS, count));
-   * @throws EntryExistsException
-        // if (!pr.returnValue) {
-        // throw new EntryExistsException("An entry already exists for key " +
-        // event.getKey() + " on region " + getFullPath());
-        // }
-      } catch (EntryExistsException eee) {
+      } catch (EntryExistsException ignore) {
-        availableBuckets.add(Integer.valueOf(i));
+        availableBuckets.add(i);
-          this.currentBucketId = this.bucketSetI.next().intValue();
-          // @todo: optimize this code by implementing getBucketKeysIterator.
+          this.currentBucketId = this.bucketSetI.next();
+          // TODO: optimize this code by implementing getBucketKeysIterator.
-            return Collections.EMPTY_SET.iterator();
+            return Collections.emptySet().iterator();
-        } catch (EntryNotFoundException ignore) {
+        } catch (EntryNotFoundException e) {
-            logger.debug("Caught exception during KeySetIterator remove", ignore);
+            logger.debug("Caught exception during KeySetIterator remove", e);
-      public final PartitionedRegion getPartitionedRegion() {
+      public PartitionedRegion getPartitionedRegion() {
-      public final int getBucketId() {
+      public int getBucketId() {
-
-    final protected Set<Integer> bucketSet;
+    protected final Set<Integer> bucketSet;
-  /**
-   * @param keyInfo
-   * @return TODO
-   */
-      Integer bucketIdInt = Integer.valueOf(bucketId);
+      Integer bucketIdInt = bucketId;
-          bucketStringForLogs(bucketIdInt.intValue()));
+          bucketStringForLogs(bucketIdInt));
-        retryNode = getOrCreateNodeForBucketRead(bucketIdInt.intValue());
+        retryNode = getOrCreateNodeForBucketRead(bucketIdInt);
-        retryNode = getOrCreateNodeForBucketRead(bucketIdInt.intValue());
+        retryNode = getOrCreateNodeForBucketRead(bucketIdInt);
-        getRegionAdvisor().notPrimary(bucketIdInt.intValue(), retryNode);
-        retryNode = getOrCreateNodeForBucketRead(bucketIdInt.intValue());
+        getRegionAdvisor().notPrimary(bucketIdInt, retryNode);
+        retryNode = getOrCreateNodeForBucketRead(bucketIdInt);
-          RegionDestroyedException rde2 = new RegionDestroyedException(toString(), getFullPath());
-          rde2.initCause(rde);
-          throw rde2;
+          throw new RegionDestroyedException(toString(), getFullPath(), rde);
-    Integer countInteger = Integer.valueOf(count);
+    Integer countInteger = count;
-  // fix for bug #42945 - PR.size() does not pay attention to transaction state
-  // @Override
-  // public int entryCount() {
-  // return entryCount(null);
-  // }
+  @Override
+  @Override
-
-
-   * @param targetNodes
-  static int getRandom(int max) {
-    if (max <= 0) {
-      return 0;
-    }
-    int ti = ((Integer) PartitionedRegion.threadRandom.get()).intValue();
-    return ti % max;
-  }
-
-   * Returns the lockname used by Distributed Lock service to clean the <code>
-   * allPartitionedRegions<code>
+   * Returns the lockname used by Distributed Lock service to clean the
+   * {@code allPartitionedRegions}.
-    private final GemFireCacheImpl cache;
+    private final InternalCache cache;
-    protected BucketLock(String lockName, GemFireCacheImpl cache, boolean enableAlerts) {
+    protected BucketLock(String lockName, InternalCache cache, boolean enableAlerts) {
-     * 
-     * @throws LockServiceDestroyedException
-     * @throws LockServiceDestroyedException
-
-
-                        new Object[] {Long.valueOf((ackWaitThreshold + ackSAThreshold) / 1000),
-                            lockHolder}));
+                        new Object[] {(ackWaitThreshold + ackSAThreshold) / 1000, lockHolder}));
-
-
-
-                        new Object[] {Long.valueOf(ackWaitThreshold + ackSAThreshold)
-                            / 1000 /* fix for bug 44757 */, lockHolder}));
+                        new Object[] {(ackWaitThreshold + ackSAThreshold) / 1000, lockHolder}));
-        } catch (LockServiceDestroyedException ignore) {
+        } catch (LockServiceDestroyedException e) {
-            logger.debug("BucketLock#unlock: Lock service {} was destroyed", this.lockService,
-                ignore);
+            logger.debug("BucketLock#unlock: Lock service {} was destroyed", this.lockService, e);
-  public final static class RegionLock extends BucketLock {
-    protected RegionLock(String regionIdentifier, GemFireCacheImpl cache) {
+  public static class RegionLock extends BucketLock {
+    protected RegionLock(String regionIdentifier, InternalCache cache) {
-  public final class RecoveryLock extends BucketLock {
+  public class RecoveryLock extends BucketLock {
-  public static RegionLock getRegionLock(String regionIdentifier, GemFireCacheImpl cache) {
+  public static RegionLock getRegionLock(String regionIdentifier, InternalCache cache) {
-   * 
-   *
-  public final void setHaveCacheLoader() {
+  public void setHaveCacheLoader() {
-          new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+          new Object[] {getFullPath(), getPRId()}));
-        prIdToPR.put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED, false);
+        prIdToPR.put(getPRId(), PRIdMap.LOCALLY_DESTROYED, false);
-        prIdToPR.put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED, false);
+        prIdToPR.put(getPRId(), PRIdMap.LOCALLY_DESTROYED, false);
-        new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+        new Object[] {getFullPath(), getPRId()}));
-
-  public void addMissingColocatedRegionLogger() {
-    if (missingColocatedRegionLogger == null) {
-      missingColocatedRegionLogger = new ColocationLogger(this);
-    }
-  }
-
-  /**
-   * Globally destroy the partitioned region by sending a message to a data store to do the destroy.
-   * 
-   * @return true if the region was destroyed successfully
-   */
-  private boolean destroyOnDataStore(Object aCallbackArgument) {
-    RegionAdvisor advisor = getRegionAdvisor();
-    Set<InternalDistributedMember> attempted = new HashSet<InternalDistributedMember>();
-
-    checkReadiness();
-    while (!isDestroyed()) {
-      Set<InternalDistributedMember> available = advisor.adviseInitializedDataStore();
-      available.removeAll(attempted);
-      if (available.isEmpty()) {
-        return false;
-      }
-      InternalDistributedMember next = available.iterator().next();
-      try {
-        DestroyRegionOnDataStoreMessage.send(next, this, aCallbackArgument);
-        return true;
-      } catch (ReplyException e) {
-        // try the next member
-        if (logger.isTraceEnabled()) {
-          logger.trace("Error destroying " + this + " on " + next, e);
-        }
-      }
-    }
-
-    return true;
-  }
-
-                  .toLocalizedString(new Object[] {pausedSenders, this.getName()});
+                  .toLocalizedString(pausedSenders, this.getName());
-                  .toLocalizedString(new Object[] {pausedSenders, this.getName()});
+                  .toLocalizedString(pausedSenders, this.getName());
-          } catch (InterruptedException e) {
+          } catch (InterruptedException ignore) {
-          } catch (InterruptedException e) {/* ignore */
+          } catch (InterruptedException ignore) {/* ignore */
-          new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+          new Object[] {getFullPath(), getPRId()}));
-        } catch (CancelException e) {
+        } catch (CancelException ignore) {
-        } catch (CancelException e) {
+        } catch (CancelException ignore) {
-        // fix for bug 35306 by Tushar
-          } catch (CancelException e) {
+          } catch (CancelException ignore) {
-          new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+          new Object[] {getFullPath(), getPRId()}));
-    } catch (CancelException e) {
-      return false; // global data not accessible, don't try to finish global destroy.
+    } catch (CancelException ignore) {
+      // global data not accessible, don't try to finish global destroy.
+      return false;
-    } catch (CancelException e) {
+    } catch (CancelException ignore) {
-      } catch (CancelException e) {
+      } catch (CancelException ignore) {
-    // It's possile this instance has not been initialized
+    // It's possible this instance has not been initialized
-    } catch (CancelException e) {
+    } catch (CancelException ignore) {
-    } catch (ReplyException ignore) {
+    } catch (ReplyException e) {
-          ignore);
+          e);
-        prIdToPR.remove(Integer.valueOf(getPRId()));
+        prIdToPR.remove(getPRId());
-   * @param event the RegionEvent <br>
-   *        OVERRIDES
+   * @param event the RegionEvent
-    // bruce disabled the dumping of entries to keep the size of dunit log files
-    // from growing unreasonably large
-    // if (this.dataStore != null && logger.isDebugEnabled()) {
-    // this.dataStore.dumpEntries(false);
-    // }
-    // any GII or wait for persistent recoveery will be aborted by the destroy
+    // any GII or wait for persistent recovery will be aborted by the destroy
-          } catch (CancelException e) {
+          } catch (CancelException ignore) {
-          FilterProfile.NO_PROFILES, Collections.EMPTY_SET);
+          FilterProfile.NO_PROFILES, Collections.emptySet());
-    RegionLogger.logDestroy(getName(), cache.getMyId(), null, op.isClose());
+    RegionLogger.logDestroy(getName(),
+        this.cache.getInternalDistributedSystem().getDistributedMember(), null, op.isClose());
-    boolean isAlreadyDestroyedOrOldReference = false;
-    } catch (CancelException e) {
+    } catch (CancelException ignore) {
+    boolean isAlreadyDestroyedOrOldReference = false;
-            if (logger.isDebugEnabled()) {
+            if (logger.isTraceEnabled()) {
-
-
-   * @throws ReplyException
-  /*
-   * (non-Javadoc)
-   * 
-   * @see org.apache.geode.internal.cache.LocalRegion#dumpBackingMap()
-   */
-   * PartitionedRegion with a datastore to dump just the bucket names to the system.log
-   * 
-   * @throws ReplyException
-   * @see #validateAllBuckets()
-   */
-  public void dumpJustBuckets() throws ReplyException {
-    PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor().adviseDataStore(), this,
-        false /* only validate */, true);
-    response.waitForRepliesUninterruptibly();
-    if (this.dataStore != null) {
-      this.dataStore.dumpBuckets();
-    }
-  }
-
-  /**
-   * 
-   * Send a message to all PartitionedRegion participants, telling each member of the
-   * @throws ReplyException
-   * Sends a message to all the <code>PartitionedRegion</code> participants, telling each member of
-   * the PartitionedRegion to dump the nodelist in bucket2node metadata for specified bucketId.
-   * 
-   * @param bucketId
+   * Sends a message to all the {@code PartitionedRegion} participants, telling each member of the
+   * PartitionedRegion to dump the nodelist in bucket2node metadata for specified bucketId.
-   * 
-   * @param bId
-   * 
-   * @throws ReplyException
-    StringBuffer b = new StringBuffer(this.prRoot.getFullPath());
-    b.append("Dumping allPartitionedRegions for ");
-    b.append(this);
-    b.append("\n");
-    b.append(this.prRoot.get(getRegionIdentifier()));
-    logger.debug(b.toString());
+    StringBuilder sb = new StringBuilder(this.prRoot.getFullPath());
+    sb.append("Dumping allPartitionedRegions for ");
+    sb.append(this);
+    sb.append("\n");
+    sb.append(this.prRoot.get(getRegionIdentifier()));
+    logger.debug(sb.toString());
-   * 
-   * 
-  // /**
-  // * Gets the nodeList for a bucketId from B2N Region removing the nodes that
-  // * are not found in both membershipSet and prConfig meta-data region.
-  // *
-  // * @param bucketId
-  // * @return list of nodes for bucketId
-  // */
-  // ArrayList getNodeList(Integer bucketId)
-  // {
-  // ArrayList nList = null;
-  // VersionedArrayList val = (VersionedArrayList)this.getBucket2Node().get(
-  // bucketId);
-  // if (val != null) {
-  // nList = this.getRedundancyProvider().verifyBucketNodes(val.getListCopy());
-  // if (nList.size() == 0) {
-  // PartitionedRegionHelper.logForDataLoss(this, bucketId.intValue(),
-  // "getNodeList");
-  // }
-  // }
-  // return nList;
-  // }
-
+  @Override
-   * 
-  public final static class RetryTimeKeeper {
+  public static class RetryTimeKeeper {
-      } catch (InterruptedException intEx) {
+      } catch (InterruptedException ignore) {
-  public final String getBucketName(int bucketId) {
+  public String getBucketName(int bucketId) {
-  /**
-   * Test to determine if the data store is managing the bucket appropriate for the given key
-   * 
-   * @param key the cache key
-   * @return true if the bucket that should host this key is in the data store
-   */
-  public final boolean isManagingBucket(Object key) {
-    if (this.dataStore != null) {
-      int bucketId = PartitionedRegionHelper.getHashKey(this, null, key, null, null);
-      return this.dataStore.isManagingBucket(bucketId);
-    }
-    return false;
-  }
-
-   * @throws IOException
-   * @throws IOException
-   * @param interestType
-   * @param interestArg
-   * @param collector
-   * @throws IOException
-      Integer lbucket = Integer.valueOf(bucket);
+      Integer lbucket = bucket;
-      InternalDistributedMember bucketNode = getOrCreateNodeForBucketRead(lbucket.intValue());
+      InternalDistributedMember bucketNode = getOrCreateNodeForBucketRead(lbucket);
-        } catch (PRLocallyDestroyedException pde) {
+        } catch (PRLocallyDestroyedException ignore) {
-          bucketNode = getOrCreateNodeForBucketRead(lbucket.intValue());
+          bucketNode = getOrCreateNodeForBucketRead(lbucket);
-  public static interface SetCollector {
-    public void receiveSet(Set theSet) throws IOException;
+  public interface SetCollector {
+    void receiveSet(Set theSet) throws IOException;
-    Iterator iter = this.indexes.values().iterator();
-    while (iter.hasNext()) {
-      Object ind = iter.next();
+    for (final Object ind : this.indexes.values()) {
-      return Collections.EMPTY_LIST;
+      return Collections.emptyList();
-                .toLocalizedString(
-                    new Object[] {getDataPolicy(), Long.valueOf(getLocalMaxMemory())}));
+                .toLocalizedString(getDataPolicy(), (long) getLocalMaxMemory()));
-
-            } catch (UnsupportedOperationException ex) {
+            } catch (UnsupportedOperationException ignore) {
-    } catch (InterruptedException ie) {
+    } catch (InterruptedException ignore) {
-        Throwable c = ee.getCause();
-        if (c instanceof IndexNameConflictException) {
-          throw (IndexNameConflictException) c;
-        } else if (c instanceof IndexExistsException) {
-          throw (IndexExistsException) c;
+        Throwable cause = ee.getCause();
+        if (cause instanceof IndexNameConflictException) {
+          throw (IndexNameConflictException) cause;
+        } else if (cause instanceof IndexExistsException) {
+          throw (IndexExistsException) cause;
-                .toLocalizedString(
-                    new Object[] {getDataPolicy(), Long.valueOf(getLocalMaxMemory())}));
+                .toLocalizedString(getDataPolicy(), (long) getLocalMaxMemory()));
-
-      IndexCreationMsg.IndexCreationResponse response = null;
+      IndexCreationMsg.IndexCreationResponse response;
-      } catch (UnsupportedOperationException ex) {
+      } catch (UnsupportedOperationException ignore) {
-
-    if (!this.isIndexed())
+    if (!this.isIndexed()) {
+    }
-    RegionAdvisor advisor = (RegionAdvisor) (this.getCacheDistributionAdvisor());
-    final Set recipients = advisor.adviseDataStore();
+    RegionAdvisor advisor = (RegionAdvisor) getCacheDistributionAdvisor();
+    final Set<InternalDistributedMember> recipients = advisor.adviseDataStore();
-    // this should add the member to a synchornized set and then sent this member
+    // this should add the member to a synchronized set and then sent this member
-    IndexCreationMsg.IndexCreationResponse response = null;
-    IndexCreationMsg.IndexCreationResult result = null;
+    IndexCreationMsg.IndexCreationResponse response;
+    IndexCreationMsg.IndexCreationResult result;
-    HashSet<IndexCreationData> indexDefinitions = new HashSet<IndexCreationData>();
-    Set<PartitionedIndex> indexes = new HashSet<PartitionedIndex>();
+    HashSet<IndexCreationData> indexDefinitions = new HashSet<>();
+    Set<PartitionedIndex> indexes = new HashSet<>();
-      logger.debug("Sending explictly index creation message to : {}", idM);
+      logger.debug("Sending explicitly index creation message to : {}", idM);
-      } catch (ForceReattemptException ignor) {
-        logger.info(LocalizedStrings.PartitionedRegion_FORCEREATTEMPT_EXCEPTION___0, ignor);
+      } catch (ForceReattemptException e) {
+        logger.info(LocalizedStrings.PartitionedRegion_FORCEREATTEMPT_EXCEPTION___0, e);
-
-
-   * 
-   * @throws ForceReattemptException
-   * @throws CacheException
-      Iterator bucketIterator = dataStore.getAllLocalBuckets().iterator();
-      while (bucketIterator.hasNext()) {
+      for (Object bucketEntryObject : dataStore.getAllLocalBuckets()) {
-        Map.Entry bucketEntry = (Map.Entry) bucketIterator.next();
+        Map.Entry bucketEntry = (Map.Entry) bucketEntryObject;
-      RemoveIndexesMessage.RemoveIndexesResponse response = null;
+      RemoveIndexesMessage.RemoveIndexesResponse response;
-      // this.indexes = null;
-  public int removeIndex(Index ind, boolean remotelyOrignated)
+  public int removeIndex(Index ind, boolean remotelyOriginated)
-    Index i = this.indexManager.getIndex(ind.getName());
-    if (i != null) {
-      this.indexManager.removeIndex(i);
+    Index index1 = this.indexManager.getIndex(ind.getName());
+    if (index1 != null) {
+      this.indexManager.removeIndex(index1);
-    if (!remotelyOrignated) {
+    if (!remotelyOriginated) {
-      RemoveIndexesMessage.RemoveIndexesResponse response = null;
+      RemoveIndexesMessage.RemoveIndexesResponse response;
-    int numbuckets = 0;
-    // remotely orignated removeindex
-    // IndexTask indexTask = new IndexTask(indexName);
+    int numBuckets = 0;
+    // remotely originated removeindex
-      numbuckets = removeIndex((Index) this.indexes.get(indexName), true);
+      numBuckets = removeIndex((Index) this.indexes.get(indexName), true);
-    return numbuckets;
+    return numBuckets;
-  /*
-   * @OVERRIDES
-   */
-    // bucketid 1 => "vm A", false | "vm B", false | "vm C", true | "vm D",
-    // false
+    // bucketid 1 => "vm A", false | "vm B", false | "vm C", true | "vm D", false
-   * @param bucketId
-   * Test Method: Used to debug the system when an operation fails by throwing an exception
-   * 
-   * @param key
-   * @return empty string??
-   */
-  public String getAbortedOperationReason(Object key) {
-    // Find the primary bucket info (time of creation, primary location, primary
-    // meta-data on all nodes, bucket size)
-    // using the given key.
-    return "";
-  }
-
-  /**
+    @Override
-      // if (PartitionedRegion.this.isInitialized() && hasListener()) {
-      // RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this,
-      // Operation.REGION_CREATE, null, true, id);
-      // dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CREATE,
-      // event);
-      // }
+
+    @Override
+    @Override
+    @Override
-          // @todo darrel: it would be nice to know if what actual op was done
+          // TODO: it would be nice to know if what actual op was done
-
-
-  protected boolean usesDiskStore(RegionAttributes ra) {
-    if (ra.getPartitionAttributes().getLocalMaxMemory() <= 0)
+  protected boolean usesDiskStore(RegionAttributes regionAttributes) {
+    if (regionAttributes.getPartitionAttributes().getLocalMaxMemory() <= 0) {
-    return super.usesDiskStore(ra);
+    }
+    return super.usesDiskStore(regionAttributes);
-  protected DiskStoreImpl findDiskStore(RegionAttributes ra,
+  protected DiskStoreImpl findDiskStore(RegionAttributes regionAttributes,
-    DiskStoreImpl store = super.findDiskStore(ra, internalRegionArgs);
+    DiskStoreImpl store = super.findDiskStore(regionAttributes, internalRegionArgs);
-    Set allRemoteStores = getRegionAdvisor().adviseDataStore(true);
+    Set<InternalDistributedMember> allRemoteStores = getRegionAdvisor().adviseDataStore(true);
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-    PartitionRegionConfig newConfig = new PartitionRegionConfig(prConfig.getPRId(),
-        prConfig.getFullPath(), prConfig.getPartitionAttrs(), prConfig.getScope(),
-        prConfig.getEvictionAttributes(), this.getRegionIdleTimeout(), this.getRegionTimeToLive(),
-        this.getEntryIdleTimeout(), this.getEntryTimeToLive(), prConfig.getGatewaySenderIds());
-    return newConfig;
+    return new PartitionRegionConfig(prConfig.getPRId(), prConfig.getFullPath(),
+        prConfig.getPartitionAttrs(), prConfig.getScope(), prConfig.getEvictionAttributes(),
+        this.getRegionIdleTimeout(), this.getRegionTimeToLive(), this.getEntryIdleTimeout(),
+        this.getEntryTimeToLive(), prConfig.getGatewaySenderIds());
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-      Iterator iter = this.getDataStore().getAllLocalBuckets().iterator();
-      while (iter.hasNext()) {
-        Map.Entry entry = (Map.Entry) iter.next();
-        Region bucketRegion = (BucketRegion) entry.getValue();
+      for (Object o : this.getDataStore().getAllLocalBuckets()) {
+        Map.Entry entry = (Map.Entry) o;
+        Region bucketRegion = (Region) entry.getValue();
-      Set<InternalDistributedMember> critialMembers) {
-    for (InternalDistributedMember idm : critialMembers) {
+      Set<InternalDistributedMember> criticalMembers) {
+    for (InternalDistributedMember idm : criticalMembers) {
-  private final AtomicBoolean bucketSortedOnce = new AtomicBoolean(false);
-  private final Object monitor = new Object();
+  private final AtomicBoolean bucketSortedOnce = new AtomicBoolean(false);
-    List<BucketRegion> bucketList = new ArrayList<BucketRegion>();
+    List<BucketRegion> bucketList = new ArrayList<>();
+    @Override
-          RuntimeException re = new TransactionDataRebalancedException(
+          throw new TransactionDataRebalancedException(
-                  .toLocalizedString());
-          re.initCause(pbe);
-          throw re;
+                  .toLocalizedString(),
+              pbe);
-    } catch (RegionDestroyedException rde) {
-      RuntimeException re = new TransactionDataNotColocatedException(
+    } catch (RegionDestroyedException ignore) {
+      // TODO: why is this purposely not wrapping the original cause?
+      throw new TransactionDataNotColocatedException(
-      // re.initCause(rde);
-      throw re;
-    } catch (ForceReattemptException e) {
+    } catch (ForceReattemptException ignore) {
-      int count = 0;
+      int count = 0;
-        } catch (ForceReattemptException e) {
+        } catch (ForceReattemptException ignore) {
-      RuntimeException re = new TransactionDataRebalancedException(
+      throw new TransactionDataRebalancedException(
-              .toLocalizedString());
-      re.initCause(pbe);
-      throw re;
-    } catch (RegionDestroyedException rde) {
-      RuntimeException re = new TransactionDataNotColocatedException(
+              .toLocalizedString(),
+          pbe);
+    } catch (RegionDestroyedException ignore) {
+      // TODO: why is this purposely not wrapping the original cause?
+      throw new TransactionDataNotColocatedException(
-      // re.initCause(rde);
-      throw re;
-  public DistributedMember getOwnerForKey(KeyInfo keyInfo) {
-    if (keyInfo == null) {
+  public DistributedMember getOwnerForKey(KeyInfo key) {
+    if (key == null) {
-    int bucketId = keyInfo.getBucketId();
+    int bucketId = key.getBucketId();
-      bucketId = PartitionedRegionHelper.getHashKey(this, null, keyInfo.getKey(),
-          keyInfo.getValue(), keyInfo.getCallbackArg());
-      keyInfo.setBucketId(bucketId);
+      bucketId = PartitionedRegionHelper.getHashKey(this, null, key.getKey(), key.getValue(),
+          key.getCallbackArg());
+      key.setBucketId(bucketId);
-
-
-    // public List p_list;
-
+      // TODO: equals should always check the class of other
+    @Override
-      // List list = p_list;
-      PartitionedIndex prIndex = null;
+      PartitionedIndex prIndex;
-                  .toLocalizedString(Long.valueOf(getLocalMaxMemory())));
+                  .toLocalizedString((long) getLocalMaxMemory()));
-      // List list = p_list;
-      // list = compiler.compileFromClause(fromClause);
-
+      // imports can be null
-          indexedExpression, fromClause, imports); // imports can be null
-      String modifiedFromClause;
+          indexedExpression, fromClause, imports);
+
-      // flag to false
-      // Not really an issue as a put will trigger bucket index creation which should set this the
-      // flag to true
-      // However if the region is empty, we should set this flag to true so it will be reported as
-      // used even though
-      // there is no data in the region
+      // flag to false Not really an issue as a put will trigger bucket index creation which should
+      // set this the flag to true However if the region is empty, we should set this flag to true
+      // so it will be reported as used even though there is no data in the region
+
-
-
-    int startingBucketID = 0;
+      int startingBucketID = 0;
-    Integer bucketId =
-        Integer.valueOf(PartitionedRegionHelper.getHashKey(this, null, key, null, null));
+    Integer bucketId = PartitionedRegionHelper.getHashKey(this, null, key, null, null);
-    final Integer bucketId =
-        Integer.valueOf(PartitionedRegionHelper.getHashKey(this, null, key, value, null));
+    final Integer bucketId = PartitionedRegionHelper.getHashKey(this, null, key, value, null);
-    } catch (NoSuchElementException e) { // no buckets available
+    } catch (NoSuchElementException ignore) { // no buckets available
-
-          retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
-        } catch (TimeoutException te) {
-          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
-                                                                                    // longer
-                                                                                    // exists
+          retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
+        } catch (TimeoutException ignore) {
+          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId)) {
+            // bucket no longer exists
-        retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-        getRegionAdvisor().notPrimary(bucketId.intValue(), retryNode);
-        retryNode = getOrCreateNodeForBucketWrite(bucketId.intValue(), retryTime);
+        getRegionAdvisor().notPrimary(bucketId, retryNode);
+        retryNode = getOrCreateNodeForBucketWrite(bucketId, retryTime);
-      if (count == 1) {
-        // this.prStats.incUpdateEntryVersionOpsRetried();
-      }
-      // this.prStats.incUpdateEntryVersionRetries();
+
-            .toLocalizedString(Integer.valueOf(count))); // Fix for bug 36014
+            .toLocalizedString(count)); // Fix for bug 36014
-          Integer.valueOf(count)));
+          count));
-    while (!(allBucketsClone.size() == 0)) {
+    while (allBucketsClone.size() != 0) {
-    } catch (CancelException e) {
+    } catch (CancelException ignore) {

MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 UPD40 UPD40 INS40 INS40 UPD40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS31 UPD83 UPD83 INS83 INS83 INS83 MOV44 INS83 MOV44 INS83 UPD83 UPD83 MOV29 MOV44 MOV44 MOV8 INS78 INS78 MOV8 MOV60 INS78 INS78 MOV83 MOV39 MOV42 MOV44 MOV8 INS8 INS8 INS8 INS8 INS8 INS8 UPD42 UPD42 UPD42 UPD43 UPD42 UPD42 UPD42 UPD42 MOV60 MOV25 MOV41 INS41 INS41 MOV12 INS41 MOV25 UPD43 INS83 INS42 INS42 UPD43 UPD43 MOV21 MOV60 MOV60 MOV60 INS54 INS42 INS70 INS25 MOV25 MOV60 UPD42 INS78 INS78 INS78 INS78 INS42 UPD42 UPD42 MOV60 INS25 MOV41 MOV60 INS25 MOV41 MOV60 INS25 MOV21 MOV41 MOV60 MOV25 MOV41 MOV60 MOV25 MOV21 MOV41 MOV60 MOV25 MOV41 UPD42 MOV78 UPD42 INS78 MOV32 UPD74 UPD66 INS32 INS32 UPD42 UPD42 UPD42 MOV32 UPD42 MOV43 UPD66 INS65 MOV32 INS32 INS32 MOV32 INS65 UPD66 INS32 INS32 INS66 INS65 INS66 UPD66 INS65 INS32 UPD43 UPD43 MOV22 INS8 UPD42 INS12 MOV12 MOV43 MOV43 UPD66 INS65 INS66 UPD42 UPD43 UPD43 UPD42 MOV8 MOV8 MOV12 MOV12 UPD66 INS66 INS65 UPD66 UPD66 UPD43 INS44 MOV32 MOV8 MOV27 INS8 MOV27 MOV8 INS8 MOV43 MOV74 MOV74 UPD42 INS42 INS42 INS42 INS42 MOV8 MOV74 MOV27 INS8 MOV27 INS8 MOV27 INS8 MOV14 MOV27 MOV27 MOV27 UPD42 INS12 MOV60 MOV12 MOV12 INS42 MOV43 UPD27 MOV27 INS42 INS42 INS42 INS42 MOV42 INS42 INS42 MOV42 UPD43 INS32 MOV43 MOV32 MOV22 MOV22 MOV32 MOV32 INS42 INS66 MOV42 MOV42 MOV42 MOV52 MOV42 MOV42 MOV42 MOV42 MOV52 MOV42 INS66 INS42 INS42 INS42 INS42 INS42 MOV44 INS44 UPD66 MOV66 UPD66 MOV66 MOV42 MOV42 MOV42 MOV52 MOV42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS54 MOV44 INS8 INS42 UPD66 MOV66 UPD42 UPD42 INS21 INS21 INS21 MOV8 MOV44 MOV44 INS66 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS83 MOV43 INS42 MOV25 MOV21 MOV41 MOV21 MOV41 INS41 UPD42 INS70 UPD42 UPD42 UPD42 UPD42 UPD42 INS70 INS70 INS70 INS70 INS70 INS70 INS44 INS8 MOV44 UPD42 MOV60 MOV32 MOV32 MOV32 UPD42 UPD42 MOV32 INS42 INS32 UPD42 UPD42 UPD42 UPD42 INS32 MOV42 INS12 MOV12 UPD42 UPD42 MOV43 UPD40 MOV42 MOV32 MOV32 UPD42 MOV42 INS32 UPD42 MOV43 INS42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD43 UPD42 INS8 MOV12 MOV43 INS25 MOV43 MOV43 INS59 INS32 UPD40 INS32 MOV38 INS8 INS32 UPD42 UPD42 MOV12 UPD42 INS32 UPD42 UPD42 UPD43 UPD42 INS32 MOV27 INS8 UPD42 MOV43 INS32 UPD74 UPD74 INS44 MOV32 MOV8 MOV43 MOV43 UPD42 MOV44 MOV32 INS8 INS44 MOV32 INS8 INS44 MOV32 INS8 INS44 MOV32 MOV8 INS44 MOV32 MOV8 INS44 MOV32 MOV8 UPD74 MOV43 INS42 INS53 UPD42 MOV43 UPD42 UPD42 UPD42 MOV43 UPD42 UPD42 INS42 MOV11 MOV14 UPD43 INS13 INS42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS42 INS42 MOV44 INS44 INS8 UPD42 UPD42 MOV11 MOV32 INS42 INS42 INS42 UPD42 INS51 INS21 MOV38 INS8 MOV42 MOV44 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS32 MOV60 MOV54 INS25 INS42 INS42 INS32 INS22 INS42 UPD42 UPD42 INS42 INS42 INS42 INS53 MOV44 MOV42 UPD45 MOV44 MOV43 INS42 UPD42 UPD42 UPD42 UPD42 INS60 INS60 MOV21 INS43 INS42 INS60 INS60 MOV21 INS43 INS42 INS60 INS60 MOV21 INS43 INS42 MOV21 INS43 INS42 MOV21 MOV43 INS42 MOV21 MOV14 MOV14 MOV14 UPD42 MOV42 INS42 MOV11 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 MOV43 INS42 UPD42 UPD42 MOV42 MOV42 MOV42 MOV42 MOV42 MOV42 MOV42 MOV32 INS42 UPD42 UPD42 UPD42 MOV42 MOV42 MOV43 UPD42 INS42 MOV8 INS32 MOV43 INS53 MOV42 UPD42 UPD42 MOV42 INS42 INS42 INS40 INS3 INS42 INS42 INS40 INS3 INS12 INS12 MOV27 MOV8 MOV8 INS42 INS42 INS40 MOV3 UPD42 UPD42 MOV32 INS32 INS52 INS42 MOV42 INS14 UPD42 MOV43 MOV43 INS59 INS43 INS59 INS42 MOV43 INS59 INS43 INS59 INS42 MOV43 INS59 INS43 INS59 UPD42 MOV42 MOV43 UPD42 MOV42 MOV43 MOV43 UPD42 MOV42 MOV43 INS43 INS12 INS42 MOV42 MOV43 UPD42 MOV22 MOV32 MOV32 UPD42 MOV32 MOV42 MOV14 UPD42 UPD43 INS45 INS42 INS45 INS42 MOV42 INS42 UPD42 UPD42 MOV14 UPD42 UPD42 UPD42 INS25 INS42 INS42 MOV22 MOV32 INS32 INS9 MOV42 INS14 MOV14 MOV42 MOV32 UPD42 MOV5 INS4 MOV32 MOV32 UPD42 MOV5 INS4 INS44 INS8 INS44 INS8 MOV5 UPD42 UPD42 INS42 INS42 MOV43 INS32 INS42 INS11 INS42 INS42 INS11 INS42 INS11 INS42 INS42 INS11 INS42 INS11 INS42 INS42 INS11 MOV42 INS42 MOV44 INS8 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS32 MOV14 MOV14 MOV42 INS32 INS42 MOV42 MOV42 UPD42 MOV32 INS42 UPD42 UPD42 UPD42 INS42 UPD42 MOV43 INS42 MOV42 MOV42 MOV32 INS8 INS42 MOV43 MOV32 MOV32 INS42 MOV43 INS42 UPD42 MOV32 MOV42 MOV42 MOV42 MOV32 MOV32 INS12 MOV12 MOV32 MOV32 MOV43 INS42 MOV43 INS42 INS12 MOV32 MOV42 UPD42 INS40 INS42 MOV32 INS11 UPD42 UPD42 MOV32 INS11 UPD42 MOV43 INS42 MOV43 INS42 INS43 MOV32 MOV43 INS42 INS43 MOV32 MOV43 INS42 INS43 MOV32 MOV43 INS42 UPD43 MOV43 INS42 UPD43 MOV43 INS42 MOV43 INS53 UPD42 UPD42 MOV32 MOV42 UPD42 UPD42 INS42 MOV32 MOV42 MOV42 INS42 INS42 UPD43 UPD42 UPD42 MOV42 MOV42 MOV42 INS34 MOV42 MOV42 MOV42 UPD42 UPD42 MOV21 MOV25 UPD42 MOV42 MOV42 MOV42 MOV42 MOV42 MOV14 INS44 INS8 INS44 INS8 UPD42 MOV42 UPD42 MOV42 MOV44 INS39 MOV32 UPD42 INS39 MOV32 INS42 INS42 INS42 MOV42 UPD42 INS14 INS11 MOV42 MOV42 INS22 MOV43 MOV22 UPD42 UPD42 UPD42 UPD45 INS42 UPD42 MOV42 MOV42 MOV42 UPD43 UPD43 UPD43 MOV42 UPD42 MOV42 MOV32 MOV32 MOV42 MOV32 MOV42 INS32 UPD42 MOV43 INS42 INS42 MOV32 INS42 MOV32 MOV43 INS42 UPD42 MOV43 INS42 UPD42 MOV32 UPD42 MOV43 MOV32 INS42 INS39 MOV32 MOV42 MOV32 MOV42 INS52 INS42 MOV42 MOV32 UPD42 MOV42 MOV42 MOV42 MOV42 MOV32 MOV32 INS42 MOV22 UPD42 UPD42 UPD42 MOV14 INS40 UPD42 UPD42 UPD42 INS40 INS9 INS42 INS42 INS25 MOV25 UPD42 MOV42 INS44 UPD42 UPD42 UPD42 INS40 INS9 UPD45 MOV42 MOV42 INS42 UPD42 MOV42 MOV27 INS8 MOV27 MOV43 INS42 MOV14 MOV14 INS42 MOV32 MOV60 INS25 MOV60 MOV5 INS42 INS42 MOV27 INS8 MOV8 MOV22 MOV32 INS25 MOV42 MOV38 INS8 MOV21 INS21 INS32 MOV32 INS42 INS42 INS32 UPD42 UPD42 MOV32 INS42 INS42 INS40 INS3 UPD42 UPD42 INS40 INS3 MOV5 INS4 MOV5 INS4 INS27 INS42 MOV27 INS42 INS36 INS34 INS27 INS42 INS42 DEL42 DEL32 DEL83 DEL42 DEL42 DEL42 DEL32 DEL83 DEL42 DEL43 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL52 DEL42 DEL22 DEL52 DEL42 DEL22 DEL52 DEL42 DEL22 DEL66 DEL52 DEL42 DEL22 DEL32 DEL42 DEL32 DEL52 DEL42 DEL22 DEL52 DEL42 DEL22 DEL32 DEL42 DEL32 DEL36 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL45 DEL45 DEL83 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL83 DEL40 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL4 DEL3 DEL42 DEL42 DEL32 DEL42 DEL42 DEL40 DEL9 DEL32 DEL42 DEL42 DEL32 DEL83 DEL42 DEL65 DEL83 DEL42 DEL65 DEL66 DEL65 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL65 DEL83 DEL40 DEL42 DEL44 DEL8 DEL12 DEL42 DEL32 DEL42 DEL32 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL8 DEL54 DEL8 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL45 DEL42 DEL27 DEL45 DEL42 DEL27 DEL42 DEL65 DEL42 DEL65 DEL36 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL43 DEL85 DEL5 DEL42 DEL4 DEL3 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL43 DEL85 DEL5 DEL42 DEL4 DEL3 DEL42 DEL43 DEL42 DEL32 DEL59 DEL60 DEL42 DEL41 DEL42 DEL65 DEL42 DEL65 DEL42 DEL43 DEL42 DEL32 DEL59 DEL60 DEL42 DEL41 DEL66 DEL65 DEL42 DEL65 DEL42 DEL66 DEL65 DEL42 DEL66 DEL65 DEL42 DEL43 DEL52 DEL11 DEL36 DEL42 DEL32 DEL42 DEL43 DEL52 DEL11 DEL36 DEL42 DEL32 DEL21 DEL25 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL43 DEL69 DEL68 DEL65 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL32 DEL40 DEL40 DEL42 DEL65 DEL42 DEL65 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL32 DEL40 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL44 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL32 DEL59 DEL60 DEL42 DEL41 DEL42 DEL42 DEL34 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL83 DEL83 DEL83 DEL42 DEL43 DEL42 DEL42 DEL59 DEL60 DEL42 DEL43 DEL42 DEL42 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL41 DEL42 DEL65 DEL42 DEL65 DEL42 DEL32 DEL42 DEL32 DEL42 DEL40 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL66 DEL65 DEL42 DEL65 DEL42 DEL65 DEL29 DEL33 DEL42 DEL43 DEL83 DEL42 DEL42 DEL40 DEL9 DEL32 DEL42 DEL32 DEL42 DEL8 DEL51 DEL42 DEL42 DEL52 DEL42 DEL32 DEL9 DEL32 DEL21 DEL8 DEL54 DEL8 DEL25 DEL83 DEL39 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL31 DEL83 DEL39 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL53 DEL8 DEL25 DEL8 DEL12 DEL42 DEL65 DEL42 DEL65 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL65 DEL42 DEL42 DEL32 DEL42 DEL32 DEL40 DEL83 DEL83 DEL83 DEL42 DEL65 DEL66 DEL65 DEL29 DEL42 DEL42 DEL42 DEL42 DEL32 DEL59 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL65 DEL83 DEL39 DEL42 DEL39 DEL42 DEL44 DEL42 DEL34 DEL27 DEL34 DEL41 DEL8 DEL25 DEL39 DEL42 DEL42 DEL43 DEL40 DEL42 DEL32 DEL11 DEL36 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL27 DEL41 DEL8 DEL31 DEL42 DEL65 DEL42 DEL65 DEL40 DEL42 DEL4 DEL3 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL42 DEL40 DEL42 DEL42 DEL42 DEL42 DEL27 DEL32 DEL34 DEL27 DEL42 DEL4 DEL3 DEL32 DEL32 DEL21 DEL8 DEL25 DEL8 DEL25 DEL8 DEL25 DEL83 DEL83 DEL83 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL42 DEL42 DEL40 DEL42 DEL42 DEL32 DEL4 DEL3 DEL32 DEL32 DEL21 DEL83 DEL39 DEL42 DEL42 DEL33 DEL27 DEL42 DEL42 DEL43 DEL52 DEL14 DEL7 DEL21 DEL8 DEL25 DEL8 DEL31 DEL66 DEL65 DEL66 DEL65 DEL29 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL32 DEL21 DEL42 DEL32 DEL38 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL32 DEL25 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL42 DEL52 DEL42 DEL32 DEL21 DEL9 DEL41 DEL8 DEL42 DEL42 DEL45 DEL52 DEL45 DEL42 DEL27 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL12 DEL54 DEL8 DEL61 DEL9 DEL41 DEL8 DEL31 DEL42 DEL4 DEL3 DEL42 DEL4 DEL3 DEL42 DEL44 DEL8 DEL12 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL42 DEL42 DEL40 DEL32 DEL32 DEL21 DEL25 DEL42 DEL43 DEL85 DEL5 DEL4 DEL3 DEL32 DEL54 DEL8 DEL42 DEL44 DEL8 DEL12 DEL8 DEL12 DEL42 DEL44 DEL8 DEL12 DEL42 DEL43 DEL42 DEL44 DEL42 DEL42 DEL42 DEL42 DEL32 DEL32 DEL66 DEL40 DEL42 DEL42 DEL44 DEL42 DEL42 DEL32 DEL42 DEL65 DEL66 DEL66 DEL65 DEL42 DEL65 DEL42 DEL68 DEL65 DEL29 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL43 DEL42 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL52 DEL9 DEL9 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL21 DEL52 DEL42 DEL22 DEL33 DEL27 DEL52 DEL42 DEL22 DEL42 DEL32 DEL21 DEL8 DEL25 DEL8 DEL31 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL83 DEL83 DEL66 DEL65 DEL42 DEL66 DEL65 DEL66 DEL65 DEL29 DEL83 DEL83 DEL39 DEL42 DEL42 DEL43 DEL42 DEL44 DEL52 DEL42 DEL22 DEL33 DEL27 DEL39 DEL42 DEL42 DEL42 DEL52 DEL33 DEL42 DEL33 DEL33 DEL32 DEL59 DEL60 DEL52 DEL42 DEL22 DEL42 DEL42 DEL32 DEL41 DEL8 DEL25 DEL9 DEL41 DEL8 DEL31 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL83 DEL83 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL61 DEL40 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL4 DEL3 DEL40 DEL42 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL4 DEL3 DEL32 DEL14 DEL53 DEL8 DEL8 DEL25 DEL33 DEL42 DEL44 DEL41 DEL52 DEL32 DEL36 DEL42 DEL43 DEL33 DEL33 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL43 DEL74 DEL14 DEL59 DEL60 DEL42 DEL43 DEL42 DEL65 DEL42 DEL65 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL61 DEL33 DEL33 DEL42 DEL65 DEL66 DEL65 DEL42 DEL65 DEL66 DEL65 DEL29 DEL83 DEL42 DEL43 DEL42 DEL42 DEL43 DEL42 DEL44 DEL45 DEL41 DEL8 DEL31 DEL9 DEL41 DEL31 DEL42 DEL43 DEL8 DEL8 DEL8 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL61 DEL42 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL11 DEL59 DEL60 DEL42 DEL42 DEL43 DEL11 DEL59 DEL60 DEL8 DEL61 DEL8 DEL25 DEL8 DEL42 DEL42 DEL32 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL61 DEL42 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL11 DEL59 DEL60 DEL42 DEL42 DEL43 DEL11 DEL59 DEL60 DEL8 DEL61 DEL8 DEL25 DEL8 DEL42 DEL42 DEL32 DEL42 DEL43 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL61 DEL42 DEL43 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL11 DEL59 DEL60 DEL42 DEL42 DEL43 DEL11 DEL59 DEL60 DEL8 DEL61 DEL8 DEL25 DEL8 DEL83 DEL83 DEL42 DEL14 DEL59 DEL23 DEL42 DEL43 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL43 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL43 DEL42 DEL14 DEL59 DEL60 DEL42 DEL42 DEL42 DEL32 DEL21 DEL42 DEL53 DEL8 DEL12 DEL42 DEL43 DEL42 DEL44 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL53 DEL8 DEL12 DEL33 DEL42 DEL42 DEL32 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL32 DEL42 DEL34 DEL27 DEL8 DEL25 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL36 DEL38