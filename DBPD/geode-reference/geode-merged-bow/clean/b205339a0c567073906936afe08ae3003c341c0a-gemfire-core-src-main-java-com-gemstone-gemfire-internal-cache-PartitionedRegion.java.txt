Merge branch 'feature/GEODE-8' into develop

+import com.gemstone.gemfire.cache.asyncqueue.internal.AsyncEventQueueStats;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSEntriesSet.HDFSIterator;
+import com.gemstone.gemfire.cache.hdfs.internal.HDFSStoreFactoryImpl;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.CompactionStatus;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSFlushQueueFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSForceCompactionArgs;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSForceCompactionFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSForceCompactionResultCollector;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSLastCompactionTimeFunction;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HDFSRegionDirector;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HoplogOrganizer;
+import com.gemstone.gemfire.internal.cache.control.HeapMemoryMonitor;
+import com.gemstone.gemfire.internal.cache.control.InternalResourceManager.ResourceType;
+import com.gemstone.gemfire.internal.cache.control.MemoryThresholds;
+import com.gemstone.gemfire.internal.cache.partitioned.DestroyRegionOnDataStoreMessage;
+import com.gemstone.gemfire.internal.cache.partitioned.RegionAdvisor.BucketVisitor;
+import com.gemstone.gemfire.internal.offheap.SimpleMemoryAllocatorImpl.Chunk;
+import com.gemstone.gemfire.internal.offheap.annotations.Unretained;
+  private boolean isShadowPRForHDFS = false;
+  private final ThreadLocal<Boolean> queryHDFS = new ThreadLocal<Boolean>() {
+    @Override
+    protected Boolean initialValue() {
+      return false;
+    }
+  };
+  
+    
+    // add an async queue for the region if the store name is not null. 
+    if (this.getHDFSStoreName() != null) {
+      String eventQueueName = getHDFSEventQueueName();
+      super.addAsyncEventQueueId(eventQueueName);
+    }
+      if (internalRegionArgs.isUsedForHDFSParallelGatewaySenderQueue())
+        this.isShadowPRForHDFS = true;
-  
-  public boolean isShadowPR() {
+
+  @Override
+  public final boolean isHDFSRegion() {
+    return this.getHDFSStoreName() != null;
+  }
+
+  @Override
+  public final boolean isHDFSReadWriteRegion() {
+    return isHDFSRegion() && !getHDFSWriteOnly();
+  }
+
+  @Override
+  protected final boolean isHDFSWriteOnly() {
+    return isHDFSRegion() && getHDFSWriteOnly();
+  }
+
+  public final void setQueryHDFS(boolean includeHDFS) {
+    queryHDFS.set(includeHDFS);
+  }
+
+  @Override
+  public final boolean includeHDFSResults() {
+    return queryHDFS.get();
+  }
+
+  public final boolean isShadowPR() {
+
+  public final boolean isShadowPRForHDFS() {
+    return isShadowPRForHDFS;
+  }
-      this.cache.getResourceManager().addResourceListener(this);
+      this.cache.getResourceManager().addResourceListener(ResourceType.MEMORY, this);
-          ret = this.dataStore.getEntryLocally(bucketId, key, access, allowTombstones);
+          ret = this.dataStore.getEntryLocally(bucketId, key, access, allowTombstones, true);
-        prqe.queryBuckets(null);
+        results = prqe.queryBuckets(null);
-        results = new ResultsCollectionWrapper(elementType, results.asSet(), query.getLimit(parameters));
+       // results = new ResultsCollectionWrapper(elementType, results.asSet(), query.getLimit(parameters));
-          if (event.hasDelta()) {
+          // For HDFS region, we will recover key, so allow bucket creation
+          if (!this.dataPolicy.withHDFS() && event.hasDelta()) {
+    try {
+        try {
+        } finally {
+          firstEvent.release();
+        }
-  } 
+    } finally {
+      /*
+// TODO XD OFFHEAP MERGE: do we have any events that need freeOffHeapReferences
+      for (PutAllPRMessage.PutAllResponse resp : responses) {
+        PutAllPRMessage.PRMsgResponseContext ctx = resp.getContextObject();
+        if (ctx != null) {
+          EntryEventImpl e = ctx.getEvent();
+          if (e != null) {
+            e.release();
+          }
+        }
+      }
+      */
+    }
+  }
+        try {
+        } finally {
+          firstEvent.release();
+        }
+    try {
+    } finally {
+      if (event != null) {
+        event.release();
+      }
+    }
-          // Local updates should insert a serialized (aka CacheDeserializable) object
-          // given that most manipulation of values is remote (requiring serialization to send).
-          // But... function execution always implies local manipulation of
-          // values so keeping locally updated values in Object form should be more efficient.
-          if (! DistributionManager.isFunctionExecutionThread.get().booleanValue()) {
-            event.makeSerializedNewValue();
-          }
-          try {          
+          try {   
+            final BucketRegion br = this.dataStore.getInitializedBucketForId(event.getKey(), bucketId);
+            // Local updates should insert a serialized (aka CacheDeserializable) object
+            // given that most manipulation of values is remote (requiring serialization to send).
+            // But... function execution always implies local manipulation of
+            // values so keeping locally updated values in Object form should be more efficient.
+            if (! DistributionManager.isFunctionExecutionThread.get().booleanValue()) {
+              // TODO: this condition may not help since BucketRegion.virtualPut calls forceSerialized
+              br.forceSerialized(event);
+            }
-            result = this.dataStore.createLocally(bucketId,
+            result = this.dataStore.createLocally(br,
-            result = this.dataStore.putLocally(bucketId,
+            result = this.dataStore.putLocally(br,
-    final CachedDeserializable vcd = (CachedDeserializable)eei
-        .getSerializedNewValue();
-    if (vcd != null) {
-      return vcd.getSizeInBytes();
+    @Unretained final Object v = eei.getRawNewValue();
+    if (v instanceof CachedDeserializable) {
+      return ((CachedDeserializable)v).getSizeInBytes();
-      EntryEventImpl clientEvent, boolean returnTombstones) 
+      EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) 
+            
+          
+        //For sqlf since the deserialized value is nothing but chunk
+          // before returning the found value increase its use count
+         /* if(GemFireCacheImpl.sqlfSystem() && result instanceof Chunk) {
+            if(!((Chunk)result).use()) {
+              return null;
+            }
+          }*/
-          localValue, disableCopyOnRead, preferCD, null, null, false);
+          localValue, disableCopyOnRead, preferCD, null, null, false, allowReadFromHDFS);
-      thisFuture.set(result);
+      if (result instanceof Chunk) {
+        thisFuture.set(null);
+      } else {
+        thisFuture.set(result);
+      }
-      EntryEventImpl clientEvent, boolean returnTombstones) throws TimeoutException, CacheLoaderException
+      EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) throws TimeoutException, CacheLoaderException
-                                      null /*no local value*/, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones);
+                                      null /*no local value*/, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, allowReadFromHDFS);
-    if (isTX()) {
+    if (isTX() || this.hdfsStoreName != null) {
-    if (!this.haveCacheLoader) {
+    if (!this.haveCacheLoader && (this.hdfsStoreName == null)) {
-      EntryEventImpl clientEvent, boolean returnTombstones)
+      EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS)
-      InternalDistributedMember targetNode = getNodeForBucketReadOrLoad(bucketId);
+      InternalDistributedMember targetNode = null;
+      TXStateProxy txState = getTXState();
+      boolean allowRetry;
+      if (txState != null) {
+        if (txState.isRealDealLocal()) {
+          targetNode = getMyId();
+        } else {
+          targetNode = (InternalDistributedMember) txState.getTarget();
+          assert targetNode != null;
+        }
+        allowRetry = false;
+      } else {
+        targetNode = getNodeForBucketReadOrLoad(bucketId);
+        allowRetry = true;
+      }
-      obj = getFromBucket(targetNode, bucketId, key, aCallbackArgument, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones);
+      obj = getFromBucket(targetNode, bucketId, key, aCallbackArgument, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, allowRetry, allowReadFromHDFS);
-      if (cache.getResourceManager().isMemberHeapCritical(targetNode)
-          && !InternalResourceManager.isLowMemoryExceptionDisabled()) {
+      HeapMemoryMonitor hmm = ((InternalResourceManager) cache.getResourceManager()).getHeapMonitor();
+      if (hmm.isMemberHeapCritical(targetNode)
+          && !MemoryThresholds.isLowMemoryExceptionDisabled()) {
-    if (function.optimizeForWrite() && cache.getResourceManager().
+    if (function.optimizeForWrite() && cache.getResourceManager().getHeapMonitor().
-        !InternalResourceManager.isLowMemoryExceptionDisabled()) {
-      Set<InternalDistributedMember> hcm  = cache.getResourceManager().getHeapCriticalMembers();
+        !MemoryThresholds.isLowMemoryExceptionDisabled()) {
+      Set<InternalDistributedMember> hcm  = cache.getResourceAdvisor().adviseCritialMembers();
+   * @param allowRetry if false then do not retry
-      boolean disableCopyOnRead, boolean preferCD, ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones) {
+      boolean disableCopyOnRead, boolean preferCD, ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowRetry, boolean allowReadFromHDFS) {
-              disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones);
+              disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, false, allowReadFromHDFS);
-            else if (this.haveCacheLoader) {
+            else if (this.haveCacheLoader || this.hdfsStoreName != null) {
-              if (null != ( obj = getFromLocalBucket(bucketId, key, aCallbackArgument,
-                  disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones))) {
+
+              /* MergeGemXDHDFSToGFE -readoing from local bucket was disabled in GemXD*/
+			  if (null != ( obj = getFromLocalBucket(bucketId, key, aCallbackArgument,
+                  disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, allowReadFromHDFS))) {
-          obj = getRemotely(retryNode, bucketId, key, aCallbackArgument, preferCD, requestingClient, clientEvent, returnTombstones);
+          //  Test hook
+          if (((LocalRegion)this).isTest())
+            ((LocalRegion)this).incCountNotFoundInLocal();
+          obj = getRemotely(retryNode, bucketId, key, aCallbackArgument, preferCD, requestingClient, clientEvent, returnTombstones, allowReadFromHDFS);
-        retryNode = getNodeForBucketReadOrLoad(bucketId);
+        if (allowRetry) {
+          retryNode = getNodeForBucketReadOrLoad(bucketId);
+        } else {
+          return null;
+        }
-        if (isDebugEnabled) {
-          logger.debug("getFromBucket: retry attempt: {} of {}", count, retryAttempts, prce);
-        }
-        InternalDistributedMember lastNode = retryNode;
-        retryNode = getNodeForBucketReadOrLoad(bucketId);
-        if (lastNode.equals(retryNode)) {
-          if (retryTime == null) {
-            retryTime = new RetryTimeKeeper(this.retryTimeout);
-          }
-          if (retryTime.overMaximum()) {
-            break;
-          }
+        if (allowRetry) {
+          InternalDistributedMember lastNode = retryNode;
-            logger.debug("waiting to retry node {}", retryNode);
+            logger.debug("getFromBucket: retry attempt: {} of {}", count, retryAttempts, prce);
-          retryTime.waitToRetryNode();
+          retryNode = getNodeForBucketReadOrLoad(bucketId);
+          if (lastNode.equals(retryNode)) {
+            if (retryTime == null) {
+              retryTime = new RetryTimeKeeper(this.retryTimeout);
+            }
+            if (retryTime.overMaximum()) {
+              break;
+            }
+            if (isDebugEnabled) {
+              logger.debug("waiting to retry node {}", retryNode);
+            }
+            retryTime.waitToRetryNode();
+          }
+        } else {
+          Throwable cause = prce.getCause();
+          if (cause instanceof PrimaryBucketException) {
+            throw (PrimaryBucketException)cause;
+          } else if (cause instanceof TransactionDataRebalancedException) {
+            throw (TransactionDataRebalancedException)cause;
+          } else {
+            return null;
+          }
-        if (isDebugEnabled) {
-          logger.debug("getFromBucket: {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+        if (allowRetry) {
+          if (isDebugEnabled) {
+            logger.debug("getFromBucket: {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+          }
+          getRegionAdvisor().notPrimary(bucketId, retryNode);
+          retryNode = getNodeForBucketReadOrLoad(bucketId);
+        } else {
+          throw notPrimary;
-        getRegionAdvisor().notPrimary(bucketId, retryNode);
-        retryNode = getNodeForBucketReadOrLoad(bucketId);
-
-  private Object getFromLocalBucket(int bucketId, final Object key,
+  public Object getFromLocalBucket(int bucketId, final Object key,
-		EntryEventImpl clientEvent, boolean returnTombstones)
+		EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS)
-      disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, true))) {
+      disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, true, allowReadFromHDFS))) {
-      int bucketId, final Object key, final Object aCallbackArgument, boolean preferCD, ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones) throws PrimaryBucketException,
+      int bucketId, final Object key, final Object aCallbackArgument, boolean preferCD, ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) throws PrimaryBucketException,
-        aCallbackArgument, requestingClient, returnTombstones);
+        aCallbackArgument, requestingClient, returnTombstones, allowReadFromHDFS);
+    
+    profile.isOffHeap = getOffHeap();
-          checkShutdown(); // prefer the "closed" exceptions over entry not found
-          throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+          checkEntryNotFound(event.getKey());
-          checkShutdown(); // Prefer the closed exceptions over entry not found
-          throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+          checkEntryNotFound(event.getKey());
+    return entryCount(buckets, false);
+  }
+  
+  public int entryCount(Set<Integer> buckets,
+      boolean estimate) {
+ 	if (isHDFSReadWriteRegion() && (includeHDFSResults() || estimate)) {
+      bucketSizes = getSizeForHDFS( buckets, estimate);
+	} else {
-        List<Integer> list = new ArrayList<Integer>();
+        List<Integer> list = new ArrayList<Integer>();	
-        Map<Integer, SizeEntry> remoteSizes = getSizeRemotely(recips);
+        Map<Integer, SizeEntry> remoteSizes = getSizeRemotely(recips, false);
+ 	}
+ 	
+  
+  }
+
+  @Override
+  public long getEstimatedLocalSize() {
+    final PartitionedRegionDataStore ds = this.dataStore;
+    if (ds != null) {
+      return ds.getEstimatedLocalBucketSize(false);
+    }
+    else {
+      return 0;
+    }
+  }
+  private Map<Integer, SizeEntry> getSizeForHDFS(final Set<Integer> buckets, boolean estimate) {
+    // figure out which buckets to include
+    Map<Integer, SizeEntry> bucketSizes = new HashMap<Integer, SizeEntry>();
+    getRegionAdvisor().accept(new BucketVisitor<Map<Integer, SizeEntry>>() {
+      @Override
+      public boolean visit(RegionAdvisor advisor, ProxyBucketRegion pbr,
+          Map<Integer, SizeEntry> map) {
+        if (buckets == null || buckets.contains(pbr.getBucketId())) {
+          map.put(pbr.getBucketId(), null);
+          // ensure that the bucket has been created
+          pbr.getPartitionedRegion().getOrCreateNodeForBucketWrite(pbr.getBucketId(), null);
+        }
+        return true;
+      }
+    }, bucketSizes);
+
+    RetryTimeKeeper retry = new RetryTimeKeeper(retryTimeout);
+
+    while (true) {
+      // get the size from local buckets
+      if (dataStore != null) {
+        Map<Integer, SizeEntry> localSizes;
+        if (estimate) {
+          localSizes = dataStore.getSizeEstimateForLocalPrimaryBuckets();
+        } else {
+          localSizes = dataStore.getSizeForLocalPrimaryBuckets();
+        }
+        for (Map.Entry<Integer, SizeEntry> me : localSizes.entrySet()) {
+          if (bucketSizes.containsKey(me.getKey())) {
+            bucketSizes.put(me.getKey(), me.getValue());
+          }
+        }
+      }
+      // all done
+      int count = 0;
+      Iterator it = bucketSizes.values().iterator();
+      while (it.hasNext()) {
+        if (it.next() != null) count++;
+      }
+      if (bucketSizes.size() == count) {
+        return bucketSizes;
+      }
+      
+      Set<InternalDistributedMember> remotes = getRegionAdvisor().adviseDataStore(true);
+      remotes.remove(getMyId());
+      
+      // collect remote sizes
+      if (!remotes.isEmpty()) {
+        Map<Integer, SizeEntry> remoteSizes = new HashMap<Integer, PartitionedRegion.SizeEntry>();
+        try {
+          remoteSizes = getSizeRemotely(remotes, estimate);
+        } catch (ReplyException e) {
+          // Remote member will never throw ForceReattemptException or
+          // PrimaryBucketException, so any exception on the remote member
+          // should be re-thrown
+          e.handleAsUnexpected();
+        }
+        for (Map.Entry<Integer, SizeEntry> me : remoteSizes.entrySet()) {
+          Integer k = me.getKey();
+          if (bucketSizes.containsKey(k) && me.getValue().isPrimary()) {
+            bucketSizes.put(k, me.getValue());
+          }
+        }
+      }
+      
+      if (retry.overMaximum()) {
+        checkReadiness();
+        PRHARedundancyProvider.timedOut(this, null, null, "calculate size", retry.getRetryTime());
+      }
+      
+      // throttle subsequent attempts
+      retry.waitForBucketsRecovery();
+    }
-  private Map<Integer, SizeEntry> getSizeRemotely(Set targetNodes) {
-    SizeResponse r = SizeMessage.send(targetNodes, this, null);
+  private Map<Integer, SizeEntry> getSizeRemotely(Set targetNodes, boolean estimate) {
+    SizeResponse r = SizeMessage.send(targetNodes, this, null,estimate);
+	  .append("; hdfsStoreName=").append(getHDFSStoreName())
+      .append("; hdfsWriteOnly=").append(getHDFSWriteOnly())
+      
+    //For HDFS regions, we need a data store
+    //to do the global destroy so that it can delete
+    //the data from HDFS as well.
+    if(!isDataStore() && this.dataPolicy.withHDFS()) {
+      if(destroyOnDataStore(aCallbackArgument)) {
+        //If we were able to find a data store to do the destroy,
+        //stop here.
+        //otherwise go ahead and destroy the region from this member
+        return;
+      }
+    }
+  /**Globally destroy the partitioned region by sending a message
+   * to a data store to do the destroy.
+   * @return true if the region was destroyed successfully
+   */
+  private boolean destroyOnDataStore(Object aCallbackArgument) {
+    RegionAdvisor advisor = getRegionAdvisor();
+    Set<InternalDistributedMember> attempted = new HashSet<InternalDistributedMember>();
+    
+    checkReadiness();
+    while(!isDestroyed()) {
+      Set<InternalDistributedMember> available = advisor.adviseInitializedDataStore();
+      available.removeAll(attempted);
+      if(available.isEmpty()) {
+        return false;
+      }
+      InternalDistributedMember next = available.iterator().next();
+      try {
+        DestroyRegionOnDataStoreMessage.send(next, this, aCallbackArgument);
+        return true;
+      } catch(ReplyException e) {
+        //try the next member
+        if(logger.isTraceEnabled()) {
+          logger.trace("Error destroying " + this + " on " + next, e);
+        }
+      }
+    }
+    
+    return true;
+  }
-    while(true){
+
+    AsyncEventQueueImpl hdfsQueue = getHDFSEventQueue();
+    while(true) {
-    } 
+    }
+    
+    if(hdfsQueue != null) {
+      hdfsQueue.destroy();
+      cache.removeAsyncEventQueue(hdfsQueue);
+    }
+	if(!isClose) {
+      destroyHDFSData();
+    }
+    HDFSRegionDirector.getInstance().clear(getFullPath());
+    
-    DistributedMember primary = getRegionAdvisor().getPrimaryMemberForBucket(
-        bucketId);
-    if (!primary.equals(getMyId())) {
-      throw new PrimaryBucketException("Bucket "+bucketId+" is not primary. Current primary holder is "+primary);
+    if (keyInfo.isCheckPrimary()) {
+      DistributedMember primary = getRegionAdvisor().getPrimaryMemberForBucket(
+          bucketId);
+      if (!primary.equals(getMyId())) {
+        throw new PrimaryBucketException("Bucket " + bucketId
+            + " is not primary. Current primary holder is " + primary);
+      }
-  protected void setHeapThresholdFlag(MemoryEvent event) {
-    if (event.getType().isCriticalUp()) {
+  protected void setMemoryThresholdFlag(MemoryEvent event) {
+    if (event.getState().isCritical()
+        && !event.getPreviousState().isCritical()
+        && (event.getType() == ResourceType.HEAP_MEMORY || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
-    } else if (event.getType().isCriticalDown() || event.getType().isCriticalDisabled()) {
+    } else if (!event.getState().isCritical()
+        && event.getPreviousState().isCritical()
+        && (event.getType() == ResourceType.HEAP_MEMORY || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
-  public void initialCriticalMembers(boolean localHeapIsCritical,
+  public void initialCriticalMembers(boolean localMemoryIsCritical,
-      try {
-        br.checkForPrimary();
-      } catch(PrimaryBucketException pbe) {
-         RuntimeException re = new TransactionDataRebalancedException(LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING.toLocalizedString());
-         re.initCause(pbe);
-         throw re;
+      if (keyInfo.isCheckPrimary()) {
+        try {
+          br.checkForPrimary();
+        } catch (PrimaryBucketException pbe) {
+          RuntimeException re = new TransactionDataRebalancedException(
+              LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
+                  .toLocalizedString());
+          re.initCause(pbe);
+          throw re;
+        }
-        if (!getMyId().equals(member)) {
+        if (!getMyId().equals(member) && keyInfo.isCheckPrimary()) {
-      br.checkForPrimary();
+      if (keyInfo.isCheckPrimary()) {
+        br.checkForPrimary();
+      }
-
+      //In cases where we have no data yet (creation from cache xml), it would leave the populated flag to false
+      //Not really an issue as a put will trigger bucket index creation which should set this the flag to true
+      //However if the region is empty, we should set this flag to true so it will be reported as used even though
+      //there is no data in the region
+      if (!it.hasNext()) {
+        parIndex.setPopulated(true);
+      }
-          checkShutdown(); // Prefer the closed exceptions over entry not found
-          throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+          checkEntryNotFound(event.getKey());
+  /**
+   * Clear local primary buckets.
+   * This is currently only used by gemfirexd truncate table
+   * to clear the partitioned region.
+   */
+  public void clearLocalPrimaries() {
+ // rest of it should be done only if this is a store while RecoveryLock
+    // above still required even if this is an accessor
+    if (getLocalMaxMemory() > 0) {
+      // acquire the primary bucket locks
+      // do this in a loop to handle the corner cases where a primary
+      // bucket region ceases to be so when we actually take the lock
+      // (probably not required to do this in loop after the recovery lock)
+      // [sumedh] do we need both recovery lock and bucket locks?
+      boolean done = false;
+      Set<BucketRegion> lockedRegions = null;
+      while (!done) {
+        lockedRegions = getDataStore().getAllLocalPrimaryBucketRegions();
+        done = true;
+        for (BucketRegion br : lockedRegions) {
+          try {
+            br.doLockForPrimary(false);
+          } catch (RegionDestroyedException rde) {
+            done = false;
+            break;
+          } catch (PrimaryBucketException pbe) {
+            done = false;
+            break;
+          } catch (Exception e) {
+            // ignore any other exception
+            logger.debug(
+                "GemFireContainer#clear: ignoring exception "
+                    + "in bucket lock acquire", e);
+          }
+        }
+      }
+      
+      //hoplogs - pause HDFS dispatcher while we 
+      //clear the buckets to avoid missing some files
+      //during the clear
+      pauseHDFSDispatcher();
+
+      try {
+        // now clear the bucket regions; we go through the primary bucket
+        // regions so there is distribution for every bucket but that
+        // should be performant enough
+        for (BucketRegion br : lockedRegions) {
+          try {
+            br.clear();
+          } catch (Exception e) {
+            // ignore any other exception
+            logger.debug(
+                "GemFireContainer#clear: ignoring exception "
+                    + "in bucket clear", e);
+          }
+        }
+      } finally {
+        resumeHDFSDispatcher();
+        // release the bucket locks
+        for (BucketRegion br : lockedRegions) {
+          try {
+            br.doUnlockForPrimary();
+          } catch (Exception e) {
+            // ignore all exceptions at this stage
+            logger.debug(
+                "GemFireContainer#clear: ignoring exception "
+                    + "in bucket lock release", e);
+          }
+        }
+      }
+    }
+    
+  }
+  
+  /**Destroy all data in HDFS, if this region is using HDFS persistence.*/
+  private void destroyHDFSData() {
+    if(getHDFSStoreName() == null) {
+      return;
+    }
+    
+    try {
+      hdfsManager.destroyData();
+    } catch (IOException e) {
+      logger.warn(LocalizedStrings.HOPLOG_UNABLE_TO_DELETE_HDFS_DATA, e);
+    }
+  }
+
+  private void pauseHDFSDispatcher() {
+    if(!isHDFSRegion()) {
+      return;
+    }
+    AbstractGatewaySenderEventProcessor eventProcessor = getHDFSEventProcessor();
+    if (eventProcessor == null) return;
+    eventProcessor.pauseDispatching();
+    eventProcessor.waitForDispatcherToPause();
+  }
+  
+  /**
+   * Get the statistics for the HDFS event queue associated with this region,
+   * if any
+   */
+  public AsyncEventQueueStats getHDFSEventQueueStats() {
+    AsyncEventQueueImpl asyncQ = getHDFSEventQueue();
+    if(asyncQ == null) {
+      return null;
+    }
+    return asyncQ.getStatistics();
+  }
+  
+  protected AbstractGatewaySenderEventProcessor getHDFSEventProcessor() {
+    final AsyncEventQueueImpl asyncQ = getHDFSEventQueue();
+    final AbstractGatewaySender gatewaySender = (AbstractGatewaySender)asyncQ.getSender();
+    AbstractGatewaySenderEventProcessor eventProcessor = gatewaySender.getEventProcessor();
+    return eventProcessor;
+  }
+
+  public AsyncEventQueueImpl getHDFSEventQueue() {
+    String asyncQId = getHDFSEventQueueName();
+    if(asyncQId == null) {
+      return null;
+    }
+    final AsyncEventQueueImpl asyncQ =  (AsyncEventQueueImpl)this.getCache().getAsyncEventQueue(asyncQId);
+    return asyncQ;
+  }
+  
+  private void resumeHDFSDispatcher() {
+    if(!isHDFSRegion()) {
+      return;
+    }
+    AbstractGatewaySenderEventProcessor eventProcessor = getHDFSEventProcessor();
+    if (eventProcessor == null) return;
+    eventProcessor.resumeDispatching();
+  }
+
+  protected String getHDFSEventQueueName() {
+    if (!this.getDataPolicy().withHDFS()) return null;
+    String colocatedWith = this.getPartitionAttributes().getColocatedWith();
+    String eventQueueName;
+    if (colocatedWith != null) {
+      PartitionedRegion leader = ColocationHelper.getLeaderRegionName(this);
+      eventQueueName = HDFSStoreFactoryImpl.getEventQueueName(leader
+          .getFullPath());
+    }
+    else {
+      eventQueueName = HDFSStoreFactoryImpl.getEventQueueName(getFullPath());
+    }
+    return eventQueueName;
+  }
+
+  /**
+   * schedules compaction on all members where this region is hosted.
+   * 
+   * @param isMajor
+   *          true for major compaction
+   * @param maxWaitTime
+   *          time to wait for the operation to complete, 0 will wait forever
+   */
+  @Override
+  public void forceHDFSCompaction(boolean isMajor, Integer maxWaitTime) {
+    if (!this.isHDFSReadWriteRegion()) {
+      if (this.isHDFSRegion()) {
+        throw new UnsupportedOperationException(
+            LocalizedStrings.HOPLOG_CONFIGURED_AS_WRITEONLY
+                .toLocalizedString(getName()));
+      }
+      throw new UnsupportedOperationException(
+          LocalizedStrings.HOPLOG_DOES_NOT_USE_HDFSSTORE
+              .toLocalizedString(getName()));
+    }
+    // send request to remote data stores
+    long start = System.currentTimeMillis();
+    int waitTime = maxWaitTime * 1000;
+    HDFSForceCompactionArgs args = new HDFSForceCompactionArgs(getRegionAdvisor().getBucketSet(), isMajor, waitTime);
+    HDFSForceCompactionResultCollector rc = new HDFSForceCompactionResultCollector();
+    AbstractExecution execution = (AbstractExecution) FunctionService.onRegion(this).withArgs(args).withCollector(rc);
+    execution.setWaitOnExceptionFlag(true); // wait for all exceptions
+    if (logger.isDebugEnabled()) {
+      logger.debug("HDFS: ForceCompat invoking function with arguments "+args);
+    }
+    execution.execute(HDFSForceCompactionFunction.ID);
+    List<CompactionStatus> result = rc.getResult();
+    Set<Integer> successfulBuckets = rc.getSuccessfulBucketIds();
+    if (rc.shouldRetry()) {
+      int retries = 0;
+      while (retries < HDFSForceCompactionFunction.FORCE_COMPACTION_MAX_RETRIES) {
+        waitTime -= System.currentTimeMillis() - start;
+        if (maxWaitTime > 0 && waitTime < 0) {
+          break;
+        }
+        start = System.currentTimeMillis();
+        retries++;
+        Set<Integer> retryBuckets = new HashSet<Integer>(getRegionAdvisor().getBucketSet());
+        retryBuckets.removeAll(successfulBuckets);
+        
+        for (int bucketId : retryBuckets) {
+          getNodeForBucketWrite(bucketId, new PartitionedRegion.RetryTimeKeeper(waitTime));
+          long now = System.currentTimeMillis();
+          waitTime -= now - start;
+          start = now;
+        }
+        
+        args = new HDFSForceCompactionArgs(retryBuckets, isMajor, waitTime);
+        rc = new HDFSForceCompactionResultCollector();
+        execution = (AbstractExecution) FunctionService.onRegion(this).withArgs(args).withCollector(rc);
+        execution.setWaitOnExceptionFlag(true); // wait for all exceptions
+        if (logger.isDebugEnabled()) {
+          logger.debug("HDFS: ForceCompat re-invoking function with arguments "+args+" filter:"+retryBuckets);
+        }
+        execution.execute(HDFSForceCompactionFunction.ID);
+        result = rc.getResult();
+        successfulBuckets.addAll(rc.getSuccessfulBucketIds());
+      }
+    }
+    if (successfulBuckets.size() != getRegionAdvisor().getBucketSet().size()) {
+      checkReadiness();
+      Set<Integer> uncessfulBuckets = new HashSet<Integer>(getRegionAdvisor().getBucketSet());
+      uncessfulBuckets.removeAll(successfulBuckets);
+      throw new FunctionException("Could not run compaction on following buckets:"+uncessfulBuckets);
+    }
+  }
+
+  /**
+   * Schedules compaction on local buckets
+   * @param buckets the set of buckets to compact
+   * @param isMajor true for major compaction
+   * @param time TODO use this
+   * @return a list of futures for the scheduled compaction tasks
+   */
+  public List<Future<CompactionStatus>> forceLocalHDFSCompaction(Set<Integer> buckets, boolean isMajor, long time) {
+    List<Future<CompactionStatus>> futures = new ArrayList<Future<CompactionStatus>>();
+    if (!isDataStore() || hdfsManager == null || buckets == null || buckets.isEmpty()) {
+      if (logger.isDebugEnabled()) {
+        logger.debug(
+            "HDFS: did not schedule local " + (isMajor ? "Major" : "Minor") + " compaction");
+      }
+      // nothing to do
+      return futures;
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug(
+          "HDFS: scheduling local " + (isMajor ? "Major" : "Minor") + " compaction for buckets:"+buckets);
+    }
+    Collection<HoplogOrganizer> organizers = hdfsManager.getBucketOrganizers(buckets);
+    
+    for (HoplogOrganizer hoplogOrganizer : organizers) {
+      Future<CompactionStatus> f = hoplogOrganizer.forceCompaction(isMajor);
+      futures.add(f);
+    }
+    return futures;
+  }
+  
+  @Override
+  public void flushHDFSQueue(int maxWaitTime) {
+    if (!this.isHDFSRegion()) {
+      throw new UnsupportedOperationException(
+          LocalizedStrings.HOPLOG_DOES_NOT_USE_HDFSSTORE
+              .toLocalizedString(getName()));
+    }
+    HDFSFlushQueueFunction.flushQueue(this, maxWaitTime);
+  }
+  
+  @Override
+  public long lastMajorHDFSCompaction() {
+    if (!this.isHDFSReadWriteRegion()) {
+      if (this.isHDFSRegion()) {
+        throw new UnsupportedOperationException(
+            LocalizedStrings.HOPLOG_CONFIGURED_AS_WRITEONLY
+                .toLocalizedString(getName()));
+      }
+      throw new UnsupportedOperationException(
+          LocalizedStrings.HOPLOG_DOES_NOT_USE_HDFSSTORE
+              .toLocalizedString(getName()));
+    }
+    List<Long> result = (List<Long>) FunctionService.onRegion(this)
+        .execute(HDFSLastCompactionTimeFunction.ID)
+        .getResult();
+    if (logger.isDebugEnabled()) {
+      logger.debug("HDFS: Result of LastCompactionTimeFunction "+result);
+    }
+    long min = Long.MAX_VALUE;
+    for (long ts : result) {
+      if (ts !=0 && ts < min) {
+        min = ts;
+      }
+    }
+    min = min == Long.MAX_VALUE ? 0 : min;
+    return min;
+  }
+
+  public long lastLocalMajorHDFSCompaction() {
+    if (!isDataStore() || hdfsManager == null) {
+      // nothing to do
+      return 0;
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug(
+          "HDFS: getting local Major compaction time");
+    }
+    Collection<HoplogOrganizer> organizers = hdfsManager.getBucketOrganizers();
+    long minTS = Long.MAX_VALUE;
+    for (HoplogOrganizer hoplogOrganizer : organizers) {
+      long ts = hoplogOrganizer.getLastMajorCompactionTimestamp();
+      if (ts !=0 && ts < minTS) {
+        minTS = ts;
+      }
+    }
+    minTS = minTS == Long.MAX_VALUE ? 0 : minTS;
+    if (logger.isDebugEnabled()) {
+      logger.debug(
+          "HDFS: local Major compaction time: "+minTS);
+    }
+    return minTS;
+  }
+
+

MOV26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS83 INS39 INS59 INS83 INS83 INS74 INS59 INS78 INS83 INS83 INS39 INS42 INS8 INS78 INS83 INS83 INS39 INS42 INS8 INS78 INS83 INS83 INS39 INS42 INS8 INS83 INS83 INS39 INS42 INS44 INS8 INS78 INS83 INS83 INS39 INS42 INS8 INS83 INS83 INS83 INS39 INS42 INS8 MOV29 INS83 MOV83 MOV39 MOV42 MOV44 INS8 INS44 INS44 INS44 INS44 INS44 UPD83 INS44 INS44 INS83 INS39 INS42 INS44 INS8 INS44 INS78 INS83 INS39 INS42 MOV8 INS83 INS74 INS42 INS44 INS44 INS8 INS44 INS29 INS83 INS39 INS42 INS44 INS8 UPD42 INS29 INS83 INS39 INS42 INS8 INS29 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS29 INS83 INS43 INS42 INS8 INS83 INS43 INS42 INS8 INS83 INS43 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS43 INS42 INS8 INS29 INS78 INS83 INS39 INS42 INS44 INS44 INS8 INS29 INS83 INS74 INS42 INS44 INS44 INS44 INS8 INS78 INS83 INS39 INS42 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS42 INS9 INS43 INS43 INS42 INS14 INS25 INS42 INS41 INS42 INS41 INS42 INS41 INS39 INS42 INS21 INS42 INS41 INS41 INS54 INS54 INS60 INS25 MOV41 INS39 INS42 INS39 INS42 INS39 INS42 INS65 INS39 INS42 INS39 INS42 INS39 INS42 INS39 INS42 INS21 INS74 INS42 INS41 INS39 INS42 INS25 INS42 INS43 INS43 INS43 INS83 INS74 INS42 INS39 INS42 INS60 INS21 INS60 INS61 INS39 INS42 INS25 INS65 INS65 INS43 INS42 INS60 INS60 INS21 INS61 INS41 INS60 INS25 INS25 INS21 INS25 UPD42 INS65 INS25 INS65 INS25 INS54 INS25 INS60 INS25 INS21 INS21 INS65 INS42 INS60 INS25 INS41 INS42 INS60 INS60 INS60 INS41 INS42 INS60 INS25 INS60 INS41 INS25 INS60 INS25 INS21 INS42 INS25 INS60 INS60 INS25 INS41 INS65 INS65 INS65 INS42 INS39 INS42 INS43 INS42 INS25 INS60 INS60 INS60 INS60 INS60 INS21 INS25 INS21 INS60 INS60 INS25 INS25 INS65 INS65 INS65 INS65 INS65 INS43 INS74 INS74 INS42 INS39 INS42 INS39 INS42 INS60 INS25 INS25 INS60 INS70 INS41 INS42 INS39 INS42 INS25 INS21 INS42 INS25 INS60 INS25 INS60 INS70 INS21 INS41 INS25 INS25 INS60 INS60 INS70 INS21 INS25 INS41 INS42 INS42 INS74 INS1 INS27 INS8 INS27 INS27 INS27 INS32 INS32 INS42 INS8 INS8 INS8 INS8 INS78 INS83 INS43 INS59 INS62 INS8 INS27 INS27 INS42 INS66 INS7 INS43 INS43 INS32 INS27 INS8 INS8 INS43 INS8 INS42 INS42 INS42 INS43 INS43 INS74 INS59 INS32 INS43 INS59 INS9 INS8 INS32 INS27 INS8 INS66 INS66 INS66 INS42 INS43 INS59 INS74 INS59 INS32 INS38 INS8 INS9 INS43 INS59 INS27 INS8 INS38 INS8 INS32 INS32 INS8 INS27 INS25 INS66 INS66 INS66 INS27 INS8 INS66 INS27 INS8 INS8 INS12 INS38 INS8 INS43 INS59 INS27 INS41 INS32 INS32 INS66 INS66 INS43 INS59 INS27 INS8 INS32 INS83 INS43 INS59 INS83 INS43 INS59 INS43 INS59 INS42 INS43 INS59 INS27 INS8 INS83 INS43 INS59 INS42 INS38 INS8 INS43 INS59 INS27 INS41 INS32 INS38 INS41 INS43 INS59 INS43 INS59 INS27 INS8 INS8 INS42 INS66 INS42 INS66 INS42 INS66 INS42 INS38 INS8 INS39 INS59 INS39 INS59 INS43 INS59 INS43 INS59 INS43 INS59 INS32 INS32 INS8 INS32 INS74 INS59 INS74 INS59 INS32 INS8 INS27 INS8 INS66 INS42 INS66 INS42 INS66 INS42 INS66 INS66 INS42 INS43 INS43 INS43 INS43 INS74 INS59 INS27 INS8 INS32 INS8 INS74 INS59 INS44 INS42 INS8 INS42 INS38 INS8 INS32 INS38 INS8 INS74 INS59 INS32 INS8 INS39 INS59 INS44 INS42 INS8 INS7 INS42 INS27 INS8 INS32 INS8 INS74 INS59 INS39 INS59 INS44 INS42 INS8 INS7 INS32 INS8 INS42 INS43 INS43 INS31 INS32 INS33 INS60 INS21 INS25 INS32 INS33 INS32 INS38 INS32 INS32 INS42 INS42 INS42 INS42 INS42 MOV60 MOV60 MOV60 MOV60 MOV21 MOV60 MOV61 MOV21 MOV25 MOV25 MOV60 MOV60 MOV25 MOV60 MOV60 MOV24 INS25 INS42 INS42 INS42 INS32 INS42 MOV43 INS41 INS25 MOV32 INS27 MOV38 INS36 INS60 INS60 INS25 INS60 INS40 INS32 INS42 INS42 INS42 INS42 INS9 INS32 INS36 INS21 MOV25 INS42 UPD42 INS22 UPD42 INS41 INS42 INS42 INS43 INS43 INS43 INS42 INS14 INS32 INS42 INS14 INS42 INS42 INS42 INS14 INS25 INS60 INS60 INS61 INS25 INS60 INS21 INS25 INS25 INS21 INS32 INS42 INS38 INS32 INS25 INS42 INS42 INS32 INS43 INS43 INS42 INS14 INS42 INS32 INS60 INS21 INS25 INS60 INS54 INS42 INS42 INS32 INS42 INS33 INS21 INS21 INS42 INS21 INS32 INS42 INS32 INS42 INS42 MOV60 MOV25 INS32 INS38 INS36 INS27 INS25 INS25 INS38 INS8 INS32 INS34 INS60 INS60 INS61 INS21 INS54 INS32 INS33 INS41 INS21 INS44 INS8 INS32 INS41 INS42 INS42 INS32 INS42 INS33 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS33 INS41 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS11 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS33 INS41 INS42 INS42 INS11 INS32 INS41 INS42 INS42 INS32 INS42 INS33 INS42 INS42 INS32 INS33 INS42 INS42 INS32 INS42 INS42 INS42 INS33 INS60 INS21 INS21 INS32 INS25 INS53 INS42 INS32 INS42 INS27 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS11 INS42 INS42 INS9 INS42 INS42 INS21 INS42 INS42 INS40 INS43 INS43 INS42 INS32 INS43 INS43 INS42 INS32 INS42 INS42 INS60 INS61 INS32 INS32 INS21 INS60 INS21 INS53 INS42 INS42 INS42 INS42 INS43 INS74 INS42 INS14 INS27 INS32 INS25 INS41 INS42 INS42 INS21 INS43 INS43 INS42 INS32 INS43 INS42 INS60 INS21 INS32 INS53 INS42 INS42 INS52 INS42 INS32 INS25 INS53 INS43 INS43 INS42 INS11 INS42 INS42 INS21 INS42 INS40 INS39 INS42 INS25 INS42 INS16 INS38 INS27 INS41 INS42 INS42 INS21 INS43 INS43 INS42 INS32 INS42 INS40 INS43 INS42 INS60 INS25 INS42 INS16 INS42 INS42 INS21 INS42 INS42 INS78 INS83 INS43 INS42 INS8 INS52 INS42 INS43 INS59 INS48 INS32 INS21 INS52 INS42 INS42 INS32 INS42 INS42 INS27 INS8 INS42 INS42 INS32 INS62 INS8 INS8 INS22 INS33 INS27 INS43 INS43 INS59 INS39 INS59 INS27 INS8 INS8 INS43 INS59 MOV32 INS42 INS42 MOV27 INS42 INS27 INS7 INS52 INS42 INS34 INS42 INS42 INS42 INS74 INS42 INS74 INS1 INS43 INS42 INS27 INS8 INS39 INS59 INS43 INS59 INS32 INS8 INS27 INS8 INS74 INS59 INS32 INS38 INS8 INS32 INS8 INS32 INS42 MOV32 INS42 INS45 INS32 INS22 INS42 INS32 INS8 INS42 INS42 INS42 INS74 INS42 INS74 INS59 INS32 INS32 INS8 INS43 INS59 INS8 INS12 INS42 INS32 INS32 INS32 INS42 INS42 INS42 INS32 UPD42 MOV42 INS32 MOV27 INS38 INS32 INS36 INS32 INS8 INS32 INS8 INS32 INS21 MOV27 INS42 INS39 INS59 INS74 INS59 INS38 INS8 INS32 INS8 INS8 INS42 INS32 INS43 INS42 INS21 INS42 INS42 INS42 INS33 INS42 INS43 INS32 INS42 INS42 INS42 INS33 INS43 INS32 INS42 INS42 INS32 INS42 INS32 INS42 INS43 INS59 INS7 INS7 INS52 INS42 INS32 INS8 INS14 INS42 INS42 INS42 INS34 INS43 INS32 INS42 INS42 INS43 INS43 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS39 INS59 INS27 INS8 INS42 INS42 INS32 INS42 INS32 INS74 INS59 INS32 INS14 INS42 INS43 INS43 INS74 INS27 INS27 INS42 INS42 INS32 INS8 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS74 INS59 INS32 INS52 INS42 INS14 INS52 INS42 INS32 INS8 INS14 INS42 INS42 INS74 INS32 INS32 INS27 INS8 INS27 INS34 INS42 INS32 INS42 INS33 INS34 INS32 INS42 INS42 INS42 INS42 INS42 INS39 INS59 INS27 INS8 INS27 INS34 INS42 INS32 INS42 INS42 INS41 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS7 INS42 INS40 INS42 INS33 INS21 INS36 INS42 INS42 INS43 INS21 MOV21 INS52 INS42 INS22 INS33 INS42 INS33 INS42 INS42 INS32 INS42 INS42 INS33 INS25 INS21 INS21 INS21 INS42 INS42 MOV32 INS32 UPD42 UPD42 INS32 INS8 INS8 INS32 INS42 INS42 INS32 UPD42 UPD42 INS9 INS43 INS43 INS43 INS43 INS74 INS31 INS42 INS42 INS33 INS60 INS25 INS70 INS42 INS34 INS42 INS42 INS32 INS42 INS42 INS25 INS32 INS42 INS41 INS43 INS43 INS42 INS32 INS42 INS42 INS32 INS32 INS60 INS54 INS70 INS42 INS42 INS21 INS21 INS42 INS42 INS32 INS42 MOV32 INS42 INS52 INS42 INS42 INS42 INS41 INS43 INS43 INS43 INS43 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS41 INS42 INS42 INS32 INS21 INS41 INS44 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS27 INS36 INS32 INS32 INS42 INS27 INS42 INS42 MOV54 INS42 INS42 MOV21 INS42 INS42 INS32 INS42 INS9 INS43 INS43 INS42 INS33 INS42 INS21 INS21 INS70 INS42 INS70 INS21 INS70 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS52 INS42 INS52 INS42 INS42 INS42 INS32 INS42 INS32 INS42 INS32 INS52 INS42 INS53 INS43 INS32 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS27 INS42 INS34 INS42 INS40 INS21 INS25 INS21 INS21 INS60 INS21 INS70 INS21 INS21 INS21 INS21 INS25 INS21 INS21 INS21 INS32 INS42 INS42 INS43 INS43 INS42 INS14 INS42 INS42 INS42 INS43 INS27 INS42 INS42 INS43 INS74 INS38 INS27 INS42 INS33 INS42 INS42 INS21 INS42 INS42 INS27 INS43 INS43 INS42 INS32 INS42 INS42 INS42 INS43 INS32 INS52 INS42 INS53 INS43 INS32 INS43 INS43 INS32 INS42 INS42 INS42 INS27 INS27 INS27 INS21 INS42 INS40 INS42 INS42 INS42 INS45 INS42 INS32 INS27 INS27 INS21 INS42 INS40 INS42 INS42 INS27 INS9 INS42 INS22 INS9 INS7 INS54 INS32 MOV11 INS42 INS42 INS32 INS42 INS52 INS42 INS42 INS32 INS8 INS8 INS7 INS7 INS7 INS42 INS42 INS36 UPD42 INS42 INS42 INS42 INS32 INS42 INS25 MOV21 MOV21 INS25 INS25 MOV27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS43 INS78 INS83 INS39 INS42 INS44 INS44 INS44 INS8 INS74 INS59 INS42 INS8 INS8 INS44 INS32 INS8 INS32 INS42 INS27 INS21 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS9 INS42 INS42 INS42 INS74 INS59 INS8 INS12 INS44 INS32 INS8 INS32 INS32 MOV32 UPD42 MOV42 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS9 INS32 INS42 INS32 INS9 INS43 INS42 INS25 INS42 INS42 MOV32 INS40 INS27 INS32 INS42 INS42 INS42 INS27 INS36 INS42 INS42 INS9 MOV27 INS42 INS42 INS7 INS7 INS44 INS42 INS8 INS44 INS42 INS8 INS32 INS44 INS42 INS8 INS42 INS42 INS40 INS42 INS52 INS42 INS42 INS42 INS52 INS42 INS42 INS32 INS42 INS42 INS32 INS14 INS42 INS40 INS42 INS32 INS42 INS32 INS42 INS42 INS45 INS42 INS7 INS27 INS8 INS7 INS37 INS74 INS59 INS32 INS44 INS42 INS8 INS7 INS7 INS7 INS32 INS32 INS8 INS32 INS7 INS32 INS42 INS42 INS42 INS74 INS32 INS42 INS45 INS42 INS42 INS43 INS43 INS32 INS42 INS33 INS32 INS45 INS36 INS45 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS40 INS42 INS32 INS14 INS42 INS40 INS42 INS32 INS42 INS42 INS32 INS42 INS40 INS45 INS42 INS42 INS34 INS42 INS42 INS7 INS42 INS42 INS42 INS34 INS42 INS42 INS7 INS45 INS42 INS52 INS42 INS42 MOV32 INS8 INS8 INS42 INS42 INS42 INS42 INS42 INS33 INS42 INS42 INS21 INS21 INS6 INS42 INS9 INS42 MOV32 INS42 INS9 INS11 UPD42 INS42 INS42 INS25 INS42 INS8 INS8 INS42 MOV8 MOV25 INS8 INS42 MOV8 INS8 MOV22 INS42 INS21 INS42 INS42 INS42 INS42 INS43 INS42 INS43 INS42 INS74 INS42 INS25 INS41 INS43 INS43 INS43 INS42 INS21 INS21 INS74 INS42 INS42 INS42 INS25 INS42 INS42 INS32 INS33 INS37 INS42 INS43 INS43 INS43 INS42 INS14 INS21 INS44 INS8 INS74 INS42 INS42 INS42 INS60 INS25 INS42 INS42 INS42 INS52 INS33 INS33 INS45 INS32 INS32 INS42 MOV32 INS42 INS42 INS42 INS42 INS42 INS52 INS42 INS42 INS32 INS8 INS27 MOV32 INS42 INS42 MOV32 INS40 INS27 INS42 INS32 INS42 INS9 INS43 INS42 INS54 INS43 INS42 INS54 INS42 INS43 INS42 INS54 INS42 INS42 INS42 INS43 INS32 INS42 INS42 INS42 INS52 INS42 INS27 INS27 INS27 INS10 INS42 INS32 INS42 INS43 INS43 INS42 INS14 INS42 INS42 INS42 INS39 INS42 INS21 INS60 INS21 INS21 INS42 INS14 INS42 INS14 INS42 INS11 INS42 INS42 INS9 INS42 INS42 INS21 INS42 INS42 INS40 INS42 INS32 INS42 INS42 INS32 INS43 INS43 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS16 INS42 INS43 INS32 INS42 INS42 INS42 INS52 INS42 INS42 INS42 INS42 INS27 INS54 MOV21 INS21 INS7 INS7 INS27 INS43 MOV32 INS32 INS21 MOV21 INS41 INS60 INS25 INS53 INS32 MOV32 INS42 INS42 INS43 INS43 INS43 INS27 INS8 INS9 INS42 INS42 INS42 INS7 INS7 INS43 INS43 INS43 INS32 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS74 INS7 INS43 INS42 INS21 INS43 INS43 INS43 INS43 INS59 INS27 INS8 INS42 INS42 MOV32 MOV42 UPD45 MOV45 INS42 INS42 INS21 MOV32 INS40 UPD42 INS27 INS32 MOV32 INS32 INS42 INS42 INS8 INS12 INS12 INS12 INS42 INS8 INS12 INS42 INS8 INS12 INS42 INS40 INS42 INS32 INS32 INS42 INS42 INS34 INS42 INS34 INS42 INS42 INS42 INS42 INS74 INS32 INS32 INS39 INS59 INS7 INS7 INS43 INS42 INS42 INS42 INS43 INS43 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS45 INS36 INS45 INS42 INS45 INS45 INS42 INS40 INS42 INS32 INS38 MOV32 INS8 INS8 INS32 INS60 MOV25 INS42 INS32 INS42 INS11 INS42 INS33 INS42 INS27 INS36 INS42 INS32 INS33 INS43 INS59 INS62 INS8 INS25 INS42 UPD42 MOV42 MOV32 UPD42 INS42 INS42 INS42 INS27 INS32 INS21 INS21 INS42 INS32 INS42 INS32 INS40 INS42 INS42 INS42 INS42 INS32 INS21 INS43 INS43 INS43 INS42 INS32 INS42 INS32 INS40 INS42 INS42 INS42 INS42 INS32 INS32 INS32 INS21 INS32 INS32 INS32 INS40 INS42 INS27 UPD42 INS42 INS21 INS44 INS8 INS44 INS8 INS44 INS8 INS21 INS44 INS8 INS21 INS44 INS8 INS42 INS42 INS42 INS43 INS43 INS32 INS42 INS42 INS42 INS14 INS42 INS32 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS27 INS16 INS42 INS9 INS32 MOV21 INS21 INS42 INS42 INS83 INS43 INS59 INS42 MOV43 INS32 MOV22 INS9 INS42 MOV22 INS27 INS11 INS36 INS42 INS42 INS42 INS42 INS32 INS42 INS43 INS53 INS62 INS8 INS8 INS9 INS42 INS33 INS42 INS42 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS32 UPD45 INS42 INS42 INS42 INS27 INS42 INS42 INS42 MOV38 INS32 INS32 INS43 INS42 INS21 INS10 INS43 INS42 INS21 INS10 INS43 INS42 INS21 INS32 INS43 INS42 INS21 INS32 INS43 INS42 INS21 INS42 INS42 INS42 INS43 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS45 INS42 INS45 INS42 INS42 INS45 INS45 INS22 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS22 INS33 INS43 INS52 INS11 INS42 INS42 INS42 INS11 INS42 INS43 INS53 INS41 INS42 INS42 INS42 INS42 INS32 INS33 INS32 INS42 INS32 INS33 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS45 INS52 INS45 INS42 INS42 INS42 INS42 INS42 INS9 INS42 INS7 INS42 INS7 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS40 INS42 INS42 INS52 INS52 INS42 INS42 INS42 MOV22 INS42 INS32 INS42 INS52 INS42 INS42 INS43 INS52 INS43 INS42 INS42 INS11 INS33 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD45 INS42 INS42 INS9 INS42 INS9 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS27 INS42 INS42 INS42 UPD42 UPD42 INS42 INS42 INS42 INS43 INS42 INS45 INS45 INS45 INS45 INS45 INS45 UPD42 INS22 UPD42 INS42 INS52 INS42 INS42 DEL42 DEL42 DEL43 DEL42 DEL42 DEL42 DEL32 DEL42 DEL42 DEL42 DEL32 DEL14 DEL7 DEL21 DEL42 DEL42 DEL32 DEL83 DEL31 DEL42 DEL42 DEL42 DEL32 DEL42 DEL32 DEL21 DEL42 DEL43 DEL40 DEL32 DEL14 DEL53 DEL40 DEL42 DEL32 DEL42 DEL43 DEL14 DEL53 DEL42 DEL32 DEL32 DEL40 DEL42 DEL32 DEL42 DEL43 DEL14 DEL53