Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * This class performs a rebalance on a single partitioned region. 
+ * This class performs a rebalance on a single partitioned region.
- * There are three main classes involved in the rebalance - this class,
- * the PartitionedRegionLoadModel, and the RebalanceDirector. This class
- * owns the overall rebalance process, and takes care of gathering the data
- * from all members, preventing concurrent rebalances, and forwarding operations
- * for the rebalance to the appropriate members.
+ * There are three main classes involved in the rebalance - this class, the
+ * PartitionedRegionLoadModel, and the RebalanceDirector. This class owns the overall rebalance
+ * process, and takes care of gathering the data from all members, preventing concurrent rebalances,
+ * and forwarding operations for the rebalance to the appropriate members.
- * The PartitionedRegionLoadModel model of the system that is constructed by this
- * class. It contains information about what buckets are where and how big they
- * are. It has methods to find low redundancy buckets or determine where the best
- * place to move a bucket is.
+ * The PartitionedRegionLoadModel model of the system that is constructed by this class. It contains
+ * information about what buckets are where and how big they are. It has methods to find low
+ * redundancy buckets or determine where the best place to move a bucket is.
- * The RebalanceDirector is responsible for actually deciding what to do at
- * each step of a rebalance. There are several different director implementations
- * for different types of rebalancing. The most common on is the CompositeDirector,
- * which first satisfies redundancy, moves buckets, and then moves primaries.
+ * The RebalanceDirector is responsible for actually deciding what to do at each step of a
+ * rebalance. There are several different director implementations for different types of
+ * rebalancing. The most common on is the CompositeDirector, which first satisfies redundancy, moves
+ * buckets, and then moves primaries.
- * There is also a FPRDirector that creates buckets and moves primaries for
- * fixed partititioned regions.
+ * There is also a FPRDirector that creates buckets and moves primaries for fixed partititioned
+ * regions.
-  private static final int MAX_PARALLEL_OPERATIONS = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "MAX_PARALLEL_BUCKET_RECOVERIES", 8);
-  private final boolean DEBUG = Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "LOG_REBALANCE");
-  
+  private static final int MAX_PARALLEL_OPERATIONS =
+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "MAX_PARALLEL_BUCKET_RECOVERIES", 8);
+  private final boolean DEBUG =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "LOG_REBALANCE");
+
-  
+
-  
+
-  
+
+   * 
-   * @param replaceOfflineData true to replace offline copies of buckets with new live copies of buckets
-   * @param isRebalance true if this op is a full rebalance instead of a more
-   * limited redundancy recovery
+   * @param replaceOfflineData true to replace offline copies of buckets with new live copies of
+   *        buckets
+   * @param isRebalance true if this op is a full rebalance instead of a more limited redundancy
+   *        recovery
-  public PartitionedRegionRebalanceOp(PartitionedRegion region, boolean simulate, RebalanceDirector director, boolean replaceOfflineData, boolean isRebalance) {
-    this(region, simulate, director, replaceOfflineData,
-        isRebalance, new AtomicBoolean(), null);
+  public PartitionedRegionRebalanceOp(PartitionedRegion region, boolean simulate,
+      RebalanceDirector director, boolean replaceOfflineData, boolean isRebalance) {
+    this(region, simulate, director, replaceOfflineData, isRebalance, new AtomicBoolean(), null);
-  
+
+   * 
-   * @param replaceOfflineData true to replace offline copies of buckets with new live copies of buckets
-   * @param isRebalance true if this op is a full rebalance instead of a more
-   * limited redundancy recovery
-   * @param cancelled the AtomicBoolean reference used for cancellation; if
-   * any code sets the AB value to true then the rebalance will be cancelled
+   * @param replaceOfflineData true to replace offline copies of buckets with new live copies of
+   *        buckets
+   * @param isRebalance true if this op is a full rebalance instead of a more limited redundancy
+   *        recovery
+   * @param cancelled the AtomicBoolean reference used for cancellation; if any code sets the AB
+   *        value to true then the rebalance will be cancelled
-  public PartitionedRegionRebalanceOp(PartitionedRegion region,
-      boolean simulate, RebalanceDirector director, boolean replaceOfflineData, boolean isRebalance,
+  public PartitionedRegionRebalanceOp(PartitionedRegion region, boolean simulate,
+      RebalanceDirector director, boolean replaceOfflineData, boolean isRebalance,
-    
+
-    
-    //set the region we are rebalancing to be leader of the colocation group.
+
+    // set the region we are rebalancing to be leader of the colocation group.
-  
+
+   * 
-    InternalResourceManager resourceManager = InternalResourceManager.getInternalResourceManager(leaderRegion.getCache());
+    InternalResourceManager resourceManager =
+        InternalResourceManager.getInternalResourceManager(leaderRegion.getCache());
-    if(isRebalance) {
+    if (isRebalance) {
-      if(!checkAndSetColocatedRegions()) {
+      if (!checkAndSetColocatedRegions()) {
-      
-      //Early out if this was an automatically triggered rebalance and we now 
-      //have full redundancy.
-      if (!isRebalanceNecessary()) { 
+
+      // Early out if this was an automatically triggered rebalance and we now
+      // have full redundancy.
+      if (!isRebalanceNecessary()) {
-      
+
-      
-      //Check this again after getting the lock, because someone might
-      //have fixed it already.
+
+      // Check this again after getting the lock, because someone might
+      // have fixed it already.
-      
-      //register a listener to notify us if the new members leave or join.
-      //When a membership change occurs, we want to restart the rebalancing
-      //from the beginning.
-      //TODO rebalance - we should really add a membership listener to ALL of 
-      //the colocated regions. 
+
+      // register a listener to notify us if the new members leave or join.
+      // When a membership change occurs, we want to restart the rebalancing
+      // from the beginning.
+      // TODO rebalance - we should really add a membership listener to ALL of
+      // the colocated regions.
-      ParallelBucketOperator parallelOperator = new ParallelBucketOperator(MAX_PARALLEL_OPERATIONS, cache.getDistributionManager().getWaitingThreadPool(), serialOperator);
+      ParallelBucketOperator parallelOperator = new ParallelBucketOperator(MAX_PARALLEL_OPERATIONS,
+          cache.getDistributionManager().getWaitingThreadPool(), serialOperator);
-      for(PartitionRebalanceDetailsImpl details : serialOperator.getDetailSet()) {
-        details.setPartitionMemberDetailsBefore(model.getPartitionedMemberDetails(details.getRegionPath()));
+      for (PartitionRebalanceDetailsImpl details : serialOperator.getDetailSet()) {
+        details.setPartitionMemberDetailsBefore(
+            model.getPartitionedMemberDetails(details.getRegionPath()));
-      
-      for(;;) {
-        if(cancelled.get()) {
+
+      for (;;) {
+        if (cancelled.get()) {
-        if(membershipChange) {
+        if (membershipChange) {
-          //refetch the partitioned region details after
-          //a membership change.
+          // refetch the partitioned region details after
+          // a membership change.
-          if(this.stats != null) {
+          if (this.stats != null) {
-        
+
-          //Stop when the director says we can't rebalance any more.
+          // Stop when the director says we can't rebalance any more.
-      
+
-      
-      for(PartitionRebalanceDetailsImpl details : serialOperator.getDetailSet()) {
-        if(!simulate) {
+
+      for (PartitionRebalanceDetailsImpl details : serialOperator.getDetailSet()) {
+        if (!simulate) {
-        details.setPartitionMemberDetailsAfter(model.getPartitionedMemberDetails(details.getRegionPath()));
+        details.setPartitionMemberDetailsAfter(
+            model.getPartitionedMemberDetails(details.getRegionPath()));
-      if(lock != null) {
+      if (lock != null) {
-        } catch(Exception e) {
-         logger.error(LocalizedMessage.create(LocalizedStrings.PartitionedRegionRebalanceOp_UNABLE_TO_RELEASE_RECOVERY_LOCK), e);
+        } catch (Exception e) {
+          logger.error(
+              LocalizedMessage.create(
+                  LocalizedStrings.PartitionedRegionRebalanceOp_UNABLE_TO_RELEASE_RECOVERY_LOCK),
+              e);
-        if(isRebalance) {
+        if (isRebalance) {
-      } catch(Exception e) {
-        logger.error(LocalizedMessage.create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
+      } catch (Exception e) {
+        logger.error(LocalizedMessage
+            .create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
-      
+
-      } catch(Exception e) {
-        logger.error(LocalizedMessage.create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
+      } catch (Exception e) {
+        logger.error(LocalizedMessage
+            .create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
-   * Set the list of colocated regions, and check to make sure that colocation 
-   * is complete.
+   * Set the list of colocated regions, and check to make sure that colocation is complete.
+   * 
-    //Early out of this VM doesn't have all of  the regions that are 
-    //supposed to be colocated with this one.
-    //TODO rebalance - there is a race here between this check and the 
-    //earlier acquisition of the list
-    //of colocated regions. Really we should get a list of all colocated 
-    //regions on all nodes.
-    if(!ColocationHelper.checkMembersColocation(leaderRegion, 
+    // Early out of this VM doesn't have all of the regions that are
+    // supposed to be colocated with this one.
+    // TODO rebalance - there is a race here between this check and the
+    // earlier acquisition of the list
+    // of colocated regions. Really we should get a list of all colocated
+    // regions on all nodes.
+    if (!ColocationHelper.checkMembersColocation(leaderRegion,
-    
-  //find all of the regions which are colocated with this region
-    //TODO rebalance - this should really be all of the regions which are colocated
-    //anywhere I think. We need to make sure we don't do a rebalance unless we have
-    //all of the colocated regions others do.
-    Map<String, PartitionedRegion> colocatedRegionsMap = 
+
+    // find all of the regions which are colocated with this region
+    // TODO rebalance - this should really be all of the regions which are colocated
+    // anywhere I think. We need to make sure we don't do a rebalance unless we have
+    // all of the colocated regions others do.
+    Map<String, PartitionedRegion> colocatedRegionsMap =
-    final LinkedList<PartitionedRegion> colocatedRegions =
-      new LinkedList<PartitionedRegion>();
+    final LinkedList<PartitionedRegion> colocatedRegions = new LinkedList<PartitionedRegion>();
-      
-      //Fix for 49340 - make sure all colocated regions are initialized, so
-      //that we know the region has recovered from disk
-      if(!colocatedRegion.isInitialized()) {
+
+      // Fix for 49340 - make sure all colocated regions are initialized, so
+      // that we know the region has recovered from disk
+      if (!colocatedRegion.isInitialized()) {
-      }
-      else {
+      } else {
-   * For FPR we will creatd buckets and make primaries as specified by FixedPartitionAttributes.
-   * We have to just create buckets and make primaries for the local node. 
+   * For FPR we will creatd buckets and make primaries as specified by FixedPartitionAttributes. We
+   * have to just create buckets and make primaries for the local node.
+   * 
-    
+
-    GemFireCacheImpl cache = (GemFireCacheImpl)leaderRegion.getCache();
-    InternalResourceManager resourceManager = InternalResourceManager
-        .getInternalResourceManager(cache);
+    GemFireCacheImpl cache = (GemFireCacheImpl) leaderRegion.getCache();
+    InternalResourceManager resourceManager =
+        InternalResourceManager.getInternalResourceManager(cache);
-      if(!checkAndSetColocatedRegions()) {
+      if (!checkAndSetColocatedRegions()) {
-      // If I am a datastore of a FixedPartition, I will be hosting bucket so no 
+      // If I am a datastore of a FixedPartition, I will be hosting bucket so no
-      
+
-        details.setPartitionMemberDetailsBefore(model
-            .getPartitionedMemberDetails(details.getRegionPath()));
+        details.setPartitionMemberDetailsBefore(
+            model.getPartitionedMemberDetails(details.getRegionPath()));
-       * We haen't taken the distributed recovery lock as only this node is
-       * creating bucket for itself. It will take bucket creation lock anyway.
-       * To move primary too, it has to see what all bucket it can host as
-       * primary and make them. We don't need to do all the calculation for fair
-       * balance between the nodes as this is a fixed partitioned region.
+       * We haen't taken the distributed recovery lock as only this node is creating bucket for
+       * itself. It will take bucket creation lock anyway. To move primary too, it has to see what
+       * all bucket it can host as primary and make them. We don't need to do all the calculation
+       * for fair balance between the nodes as this is a fixed partitioned region.
-      //This will perform all of the required operations.
+      // This will perform all of the required operations.
-      
+
-        details.setPartitionMemberDetailsAfter(model
-            .getPartitionedMemberDetails(details.getRegionPath()));
+        details.setPartitionMemberDetailsAfter(
+            model.getPartitionedMemberDetails(details.getRegionPath()));
-      return Collections.<PartitionRebalanceInfo> unmodifiableSet(operator
-          .getDetailSet());
+      return Collections.<PartitionRebalanceInfo>unmodifiableSet(operator.getDetailSet());
-        InternalResourceManager.getResourceObserver().recoveryFinished(
-            targetRegion);
+        InternalResourceManager.getResourceObserver().recoveryFinished(targetRegion);
-        logger.debug(LocalizedMessage.create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
+        logger.debug(LocalizedMessage
+            .create(LocalizedStrings.PartitionedRegionRebalanceOp_ERROR_IN_RESOURCE_OBSERVER), e);
-  private Map<PartitionedRegion, InternalPRInfo> fetchDetails(
-      GemFireCacheImpl cache) {
+  private Map<PartitionedRegion, InternalPRInfo> fetchDetails(GemFireCacheImpl cache) {
-    Map<PartitionedRegion, InternalPRInfo> detailsMap = 
-      new LinkedHashMap<PartitionedRegion, InternalPRInfo>(
-        colocatedRegions.size());
-    for (PartitionedRegion colocatedRegion: colocatedRegions) {
+    Map<PartitionedRegion, InternalPRInfo> detailsMap =
+        new LinkedHashMap<PartitionedRegion, InternalPRInfo>(colocatedRegions.size());
+    for (PartitionedRegion colocatedRegion : colocatedRegions) {
-        InternalPRInfo info = colocatedRegion.getRedundancyProvider().buildPartitionedRegionInfo(true, probe);
+        InternalPRInfo info =
+            colocatedRegion.getRedundancyProvider().buildPartitionedRegionInfo(true, probe);
-    Set<PartitionRebalanceDetailsImpl> rebalanceDetails = 
-      new HashSet<PartitionRebalanceDetailsImpl>(detailsMap.size());
-    for (Map.Entry<PartitionedRegion, InternalPRInfo> entry: detailsMap.entrySet()) {
+    Set<PartitionRebalanceDetailsImpl> rebalanceDetails =
+        new HashSet<PartitionRebalanceDetailsImpl>(detailsMap.size());
+    for (Map.Entry<PartitionedRegion, InternalPRInfo> entry : detailsMap.entrySet()) {
-    BucketOperator operator = simulate ? 
-        new SimulatedBucketOperator() 
-        : new BucketOperatorImpl(this);
-    BucketOperatorWrapper wrapper = new BucketOperatorWrapper(
-        operator, rebalanceDetails, stats, leaderRegion);
+    BucketOperator operator =
+        simulate ? new SimulatedBucketOperator() : new BucketOperatorImpl(this);
+    BucketOperatorWrapper wrapper =
+        new BucketOperatorWrapper(operator, rebalanceDetails, stats, leaderRegion);
-   * Build a model of the load on the partitioned region, which can determine 
-   * which buckets to move, etc.
-   * @param detailsMap 
-   * @param resourceManager 
+   * Build a model of the load on the partitioned region, which can determine which buckets to move,
+   * etc.
+   * 
+   * @param detailsMap
+   * @param resourceManager
-  private PartitionedRegionLoadModel buildModel(BucketOperator operator, 
+  private PartitionedRegionLoadModel buildModel(BucketOperator operator,
-    
+
-    
-    final DM dm = leaderRegion.getDistributionManager();    
+
+    final DM dm = leaderRegion.getDistributionManager();
-      
+
-    
-    
+
+
-    Set<InternalDistributedMember> criticalMembers = resourceManager.getResourceAdvisor().adviseCritialMembers();;
+    Set<InternalDistributedMember> criticalMembers =
+        resourceManager.getResourceAdvisor().adviseCritialMembers();;
-    
-    debug("Building Model for rebalancing " + leaderRegion
-        + ". redundantCopies=" + redundantCopies + ", totalNumBuckets="
-        + totalNumberOfBuckets + ", criticalMembers=" + criticalMembers
+
+    debug("Building Model for rebalancing " + leaderRegion + ". redundantCopies=" + redundantCopies
+        + ", totalNumBuckets=" + totalNumberOfBuckets + ", criticalMembers=" + criticalMembers
-    
-    model = new PartitionedRegionLoadModel(operator, redundantCopies, 
-        totalNumberOfBuckets, comparor, criticalMembers, leaderRegion);
+
+    model = new PartitionedRegionLoadModel(operator, redundantCopies, totalNumberOfBuckets,
+        comparor, criticalMembers, leaderRegion);
-      
+
-      if(replaceOfflineData) {
+      if (replaceOfflineData) {
-      debug("Added Region to model region=" + region + ", offlineDetails=" + offlineDetails 
+      debug("Added Region to model region=" + region + ", offlineDetails=" + offlineDetails
-      for(PartitionMemberInfo memberDetails: details.getPartitionMemberInfo()) {
-        debug(
-            "For Region: " + region + ", Member: " + memberDetails.getDistributedMember() + "LOAD="
-                + ((InternalPartitionDetails) memberDetails).getPRLoad() 
-                +", equivalentMembers=" 
-                + dm.getMembersInSameZone((InternalDistributedMember) memberDetails.getDistributedMember()));
+      for (PartitionMemberInfo memberDetails : details.getPartitionMemberInfo()) {
+        debug("For Region: " + region + ", Member: " + memberDetails.getDistributedMember()
+            + "LOAD=" + ((InternalPartitionDetails) memberDetails).getPRLoad()
+            + ", equivalentMembers=" + dm.getMembersInSameZone(
+                (InternalDistributedMember) memberDetails.getDistributedMember()));
-      Set<InternalPartitionDetails> memberDetailSet = 
-          details.getInternalPartitionDetails();
-      
+      Set<InternalPartitionDetails> memberDetailSet = details.getInternalPartitionDetails();
+
-    
+
-    
+
-    
+
-  private void debug(String message, Object ...params) {
-    if(logger.isDebugEnabled()) {
+
+  private void debug(String message, Object... params) {
+    if (logger.isDebugEnabled()) {
-    } else if(logger.isInfoEnabled() && DEBUG) {
+    } else if (logger.isInfoEnabled() && DEBUG) {
-    
+
-   * @param target
-   *          the member on which to create the redundant bucket
-   * @param bucketId
-   *          the identifier of the bucket
+   * @param target the member on which to create the redundant bucket
+   * @param bucketId the identifier of the bucket
-  public boolean createRedundantBucketForRegion(
-      InternalDistributedMember target, int bucketId) {
-    return getLeaderRegion().getRedundancyProvider().createBackupBucketOnMember(bucketId,
-        target, isRebalance, replaceOfflineData,null, true);
+  public boolean createRedundantBucketForRegion(InternalDistributedMember target, int bucketId) {
+    return getLeaderRegion().getRedundancyProvider().createBackupBucketOnMember(bucketId, target,
+        isRebalance, replaceOfflineData, null, true);
-  
+
-   * @param target
-   *          the member on which to create the redundant bucket
-   * @param bucketId
-   *          the identifier of the bucket
+   * @param target the member on which to create the redundant bucket
+   * @param bucketId the identifier of the bucket
-  public boolean removeRedundantBucketForRegion(
-      InternalDistributedMember target, int bucketId) {
+  public boolean removeRedundantBucketForRegion(InternalDistributedMember target, int bucketId) {
-    }
-    else {
+    } else {
-      RemoveBucketResponse response = RemoveBucketMessage.send(target, getLeaderRegion(),
-          bucketId, false);
+      RemoveBucketResponse response =
+          RemoveBucketMessage.send(target, getLeaderRegion(), bucketId, false);
-   * @param target
-   *          the member which should be primary
-   * @param bucketId
-   *          the identifier of the bucket
+   * @param target the member which should be primary
+   * @param bucketId the identifier of the bucket
-  public boolean movePrimaryBucketForRegion(
-      InternalDistributedMember target, int bucketId) {
+  public boolean movePrimaryBucketForRegion(InternalDistributedMember target, int bucketId) {
-      BucketAdvisor bucketAdvisor = getLeaderRegion().getRegionAdvisor().getBucketAdvisor(
-          bucketId);
+      BucketAdvisor bucketAdvisor = getLeaderRegion().getRegionAdvisor().getBucketAdvisor(bucketId);
-    }
-    else {
+    } else {
-      BecomePrimaryBucketResponse response = BecomePrimaryBucketMessage.send(
-          target, getLeaderRegion(), bucketId, isRebalance);
+      BecomePrimaryBucketResponse response =
+          BecomePrimaryBucketMessage.send(target, getLeaderRegion(), bucketId, isRebalance);
-   * @param source
-   *          member that contains the bucket
-   * @param target
-   *          member which should receive the bucket
-   * @param bucketId
-   *          the identifier of the bucket
+   * @param source member that contains the bucket
+   * @param target member which should receive the bucket
+   * @param bucketId the identifier of the bucket
-    }
-    else {
+    } else {
-      MoveBucketResponse response = MoveBucketMessage.send(target, getLeaderRegion(),
-          bucketId, source);
+      MoveBucketResponse response =
+          MoveBucketMessage.send(target, getLeaderRegion(), bucketId, source);
-  } 
-  private boolean isRebalanceNecessary() {
-    //Fixed partitions will always be rebalanced.
-    //Persistent partitions that have recovered from disk will
-    //also need to rebalance primaries
-    return isRebalance 
-        || director.isRebalanceNecessary(leaderRegion.getRedundancyProvider().isRedundancyImpaired(), 
-           leaderRegion.getDataPolicy().withPersistence());
-  
+
+  private boolean isRebalanceNecessary() {
+    // Fixed partitions will always be rebalanced.
+    // Persistent partitions that have recovered from disk will
+    // also need to rebalance primaries
+    return isRebalance || director.isRebalanceNecessary(
+        leaderRegion.getRedundancyProvider().isRedundancyImpaired(),
+        leaderRegion.getDataPolicy().withPersistence());
+  }
+
-  
+
-        logger.debug("PartitionedRegionRebalanceOP - membership changed, restarting rebalancing for region {}", targetRegion);
+        logger.debug(
+            "PartitionedRegionRebalanceOP - membership changed, restarting rebalancing for region {}",
+            targetRegion);
-        logger.debug("PartitionedRegionRebalanceOP - membership changed, restarting rebalancing for region {}", targetRegion);
+        logger.debug(
+            "PartitionedRegionRebalanceOP - membership changed, restarting rebalancing for region {}",
+            targetRegion);
-    public void memberSuspect(InternalDistributedMember id,
-        InternalDistributedMember whoSuspected, String reason) {
+    public void memberSuspect(InternalDistributedMember id, InternalDistributedMember whoSuspected,
+        String reason) {
-    
-    public void quorumLost(Set<InternalDistributedMember> failures, List<InternalDistributedMember> remaining) {
-    }
+
+    public void quorumLost(Set<InternalDistributedMember> failures,
+        List<InternalDistributedMember> remaining) {}

UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66 DEL66