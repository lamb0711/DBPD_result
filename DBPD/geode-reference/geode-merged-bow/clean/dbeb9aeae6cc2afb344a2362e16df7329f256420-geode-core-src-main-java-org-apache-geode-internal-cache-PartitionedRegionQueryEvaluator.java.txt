Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * This class sends the query on various <code>PartitionedRegion</code> data
- * store nodes and collects the results back, does the union of all the results.
+ * This class sends the query on various <code>PartitionedRegion</code> data store nodes and
+ * collects the results back, does the union of all the results.
- *   revamped with streaming of results
- *   retry logic
+ * revamped with streaming of results retry logic
-public class PartitionedRegionQueryEvaluator extends StreamingPartitionOperation
-{
+public class PartitionedRegionQueryEvaluator extends StreamingPartitionOperation {
+   * 
-    
+
+   * 
-  private static final int MAX_PR_QUERY_RETRIES = Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "MAX_PR_QUERY_RETRIES", 10).intValue();
+  private static final int MAX_PR_QUERY_RETRIES =
+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + "MAX_PR_QUERY_RETRIES", 10).intValue();
-  private volatile Map<InternalDistributedMember,List<Integer>> node2bucketIds;
+  private volatile Map<InternalDistributedMember, List<Integer>> node2bucketIds;
-  /** 
-   * Member to result map, with member as key and values are collection of query results.
-   * The value collection is collection of SelectResults (local query) or Collection of
-   * Lists (from remote queries).
+  /**
+   * Member to result map, with member as key and values are collection of query results. The value
+   * collection is collection of SelectResults (local query) or Collection of Lists (from remote
+   * queries).
-  //set of members failed to execute query
+  // set of members failed to execute query
+   * 
-  public PartitionedRegionQueryEvaluator(InternalDistributedSystem sys,
-                                         PartitionedRegion pr,
-                                         DefaultQuery query, Object[] parameters,
-                                         SelectResults cumulativeResults,
-                                         Set<Integer> bucketsToQuery) {
+  public PartitionedRegionQueryEvaluator(InternalDistributedSystem sys, PartitionedRegion pr,
+      DefaultQuery query, Object[] parameters, SelectResults cumulativeResults,
+      Set<Integer> bucketsToQuery) {
-    this.resultsPerMember = new ConcurrentHashMap<InternalDistributedMember, Collection<Collection>>();
+    this.resultsPerMember =
+        new ConcurrentHashMap<InternalDistributedMember, Collection<Collection>>();
-  
-  @Override  
+
+  @Override
-  
-  protected DistributionMessage createRequestMessage(InternalDistributedMember recipient, ReplyProcessor21 processor, List bucketIds) {
-    return new QueryMessage(recipient, this.pr.getPRId(), processor, this.query, this.parameters, bucketIds);
+
+  protected DistributionMessage createRequestMessage(InternalDistributedMember recipient,
+      ReplyProcessor21 processor, List bucketIds) {
+    return new QueryMessage(recipient, this.pr.getPRId(), processor, this.query, this.parameters,
+        bucketIds);
-  
+
-  @Override  
-  protected boolean processData(List objects, InternalDistributedMember sender,
-                                int sequenceNum, boolean lastInSequence) {
-    //check if sender is pre gfe_90. In that case the results coming from them are not sorted
+  @Override
+  protected boolean processData(List objects, InternalDistributedMember sender, int sequenceNum,
+      boolean lastInSequence) {
+    // check if sender is pre gfe_90. In that case the results coming from them are not sorted
-    if(sender.getVersionObject().compareTo(Version.GFE_90) < 0 ) {
+    if (sender.getVersionObject().compareTo(Version.GFE_90) < 0) {
-      if(cs != null && cs.isOrderBy()) {
+      if (cs != null && cs.isOrderBy()) {
-      
-      
+
+
-    
-    //We cannot do an if check for trace objects because it is possible
-    //that a remote node has system Query.VERBOSE flag on
-    //and yet the executing node does not.
-    //We have to be sure to pull all trace infos out and not pull results
+
+    // We cannot do an if check for trace objects because it is possible
+    // that a remote node has system Query.VERBOSE flag on
+    // and yet the executing node does not.
+    // We have to be sure to pull all trace infos out and not pull results
-      if (traceObject instanceof PRQueryTraceInfo ) {
+      if (traceObject instanceof PRQueryTraceInfo) {
-    //Only way objects is null is if we are a QUERY_MSG_TYPE and the msg was canceled, that is set to true if objects were dropped due to low memory
+    // Only way objects is null is if we are a QUERY_MSG_TYPE and the msg was canceled, that is set
+    // to true if objects were dropped due to low memory
-    if(sortNeeded) {
+    if (sortNeeded) {
-      if (!QueryMonitor.isLowMemory()) {        
-          results.add(objects);        
+      if (!QueryMonitor.isLowMemory()) {
+        results.add(objects);
-        String reason = LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION
-            .toLocalizedString();
+        String reason =
+            LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION
+                .toLocalizedString();
-  //TODO Asif: optimize it by creating a Sorted SelectResults Object at the time of fromData , so 
+  // TODO Asif: optimize it by creating a Sorted SelectResults Object at the time of fromData , so
-  private List sortIncomingData(List objects,
-      List<CompiledSortCriterion> orderByAttribs) {
+  private List sortIncomingData(List objects, List<CompiledSortCriterion> orderByAttribs) {
-    final SelectResults newResults; 
-    //Asif: There is a bug in the versions < 9.0, such that the struct results coming from the 
-    // bucket nodes , do not contain approrpiate ObjectTypes. All the projection fields have 
-    // have the types as ObjectType. The resultset being created here has the right more selective type.
-    // so the addition of objects throw exception due to type mismatch. To handle this problem, instead
+    final SelectResults newResults;
+    // Asif: There is a bug in the versions < 9.0, such that the struct results coming from the
+    // bucket nodes , do not contain approrpiate ObjectTypes. All the projection fields have
+    // have the types as ObjectType. The resultset being created here has the right more selective
+    // type.
+    // so the addition of objects throw exception due to type mismatch. To handle this problem,
+    // instead
-    if(resultType != null && resultType.isStructType() )  {
-      SortedStructBag sortedStructBag = new SortedStructBag(comparator, (StructType) resultType, 
-          nullAtStart);
-      for(Object o : objects) {
-        Struct s = (Struct)o;
+    if (resultType != null && resultType.isStructType()) {
+      SortedStructBag sortedStructBag =
+          new SortedStructBag(comparator, (StructType) resultType, nullAtStart);
+      for (Object o : objects) {
+        Struct s = (Struct) o;
-    }else {
-      newResults = new SortedResultsBag(comparator,resultType, nullAtStart);
-      newResults.addAll(objects) ;
+    } else {
+      newResults = new SortedResultsBag(comparator, resultType, nullAtStart);
+      newResults.addAll(objects);
-        
-   
+
+
-  
-  
+
+
-    * Returns normally if succeeded to get data, otherwise throws an exception
-    * @param th a test hook
-    * @return true if parts of the query need to be retried, otherwise false
+   * Returns normally if succeeded to get data, otherwise throws an exception
+   * 
+   * @param th a test hook
+   * @return true if parts of the query need to be retried, otherwise false
-  throws InterruptedException, QueryException {
+      throws InterruptedException, QueryException {
-    
+
-    HashMap<InternalDistributedMember,List<Integer>> n2b = new HashMap<InternalDistributedMember,List<Integer>>(this.node2bucketIds);
+    HashMap<InternalDistributedMember, List<Integer>> n2b =
+        new HashMap<InternalDistributedMember, List<Integer>>(this.node2bucketIds);
-      logger.debug("Sending query execution request to {} remote members for the query:{}", n2b.size(), this.query.getQueryString());
+      logger.debug("Sending query execution request to {} remote members for the query:{}",
+          n2b.size(), this.query.getQueryString());
-    
+
-      } 
+      }
-        // send separate message to each recipient since each one has a
-        // different list of bucket ids
-        processor = createStreamingQueryPartitionResponse(this.sys, n2b);
-        for (Iterator<Map.Entry<InternalDistributedMember,List<Integer>>> itr = n2b.entrySet().iterator(); itr.hasNext();) {
-          Map.Entry<InternalDistributedMember , List<Integer>> me =  itr.next();
-          final InternalDistributedMember rcp =  me.getKey();
-          final List<Integer> bucketIds =  me.getValue();
-          DistributionMessage m = createRequestMessage(rcp, processor, bucketIds);
-          Set notReceivedMembers = sendMessage(m);
-          if (th != null) {
-            th.hook(4);
-          }
-          if (notReceivedMembers != null && !notReceivedMembers.isEmpty()) {
-            requiresRetry = true;
-            processor.removeFailedSenders(notReceivedMembers);
-            if (isDebugEnabled) {
-              logger.debug("Failed sending to members {} retry required", notReceivedMembers);
-            }
-          }
-        }
+      // send separate message to each recipient since each one has a
+      // different list of bucket ids
+      processor = createStreamingQueryPartitionResponse(this.sys, n2b);
+      for (Iterator<Map.Entry<InternalDistributedMember, List<Integer>>> itr =
+          n2b.entrySet().iterator(); itr.hasNext();) {
+        Map.Entry<InternalDistributedMember, List<Integer>> me = itr.next();
+        final InternalDistributedMember rcp = me.getKey();
+        final List<Integer> bucketIds = me.getValue();
+        DistributionMessage m = createRequestMessage(rcp, processor, bucketIds);
+        Set notReceivedMembers = sendMessage(m);
-          th.hook(5);
+          th.hook(4);
-      
+        if (notReceivedMembers != null && !notReceivedMembers.isEmpty()) {
+          requiresRetry = true;
+          processor.removeFailedSenders(notReceivedMembers);
+          if (isDebugEnabled) {
+            logger.debug("Failed sending to members {} retry required", notReceivedMembers);
+          }
+        }
+      }
+      if (th != null) {
+        th.hook(5);
+      }
+
-    
-    //Shobhit: Check if query is only for local buckets else return.
+
+    // Shobhit: Check if query is only for local buckets else return.
-        logger.debug("Started query execution on local data for query:{}", this.query.getQueryString());
+        logger.debug("Started query execution on local data for query:{}",
+            this.query.getQueryString());
-    
+
-    
+
-        for(InternalDistributedMember member : failedMembers) {
+        for (InternalDistributedMember member : failedMembers) {
-          logger.debug("Following remote members failed {} and retry flag is set to: {}", failedMembers, requiresRetry);
+          logger.debug("Following remote members failed {} and retry flag is set to: {}",
+              failedMembers, requiresRetry);
-      } catch (org.apache.geode.cache.TimeoutException e) {  //Shobhit: Swallow remote exception if
-                                                                 //         local exception is there.
+      } catch (org.apache.geode.cache.TimeoutException e) { // Shobhit: Swallow remote exception if
+                                                            // local exception is there.
-   
-    if (query.isCanceled()){
+
+    if (query.isCanceled()) {
-        throw (QueryException)localFault;
+        throw (QueryException) localFault;
-        throw (InterruptedException)localFault;
+        throw (InterruptedException) localFault;
-        throw (Error)localFault;
+        throw (Error) localFault;
-        throw (RuntimeException)localFault;
+        throw (RuntimeException) localFault;
-  protected StreamingQueryPartitionResponse createStreamingQueryPartitionResponse(InternalDistributedSystem system,HashMap<InternalDistributedMember, List<Integer>> n2b) {
+  protected StreamingQueryPartitionResponse createStreamingQueryPartitionResponse(
+      InternalDistributedSystem system, HashMap<InternalDistributedMember, List<Integer>> n2b) {
-  
+
-   * This method will automatically retry the query on buckets on which problems
-   * where detected during query processing.
+   * This method will automatically retry the query on buckets on which problems where detected
+   * during query processing.
-   * @throws QueryException if data loss is detected during the query, when the
-   * number of retries has exceeded the system wide maximum, or when there are logic errors
-   * that cause bucket data to be omitted from the results.
+   * @throws QueryException if data loss is detected during the query, when the number of retries
+   *         has exceeded the system wide maximum, or when there are logic errors that cause bucket
+   *         data to be omitted from the results.
-    
+
-      //Shobhit: Now on if buckets to be queried are on remote as well as local node,
-      //request will be sent to remote node first to run query in parallel on local and
-      //remote node.
-      //Note: if Any Exception is thrown on local and some remote node, local exception
-      //will be given priority and will be visible to query executor and remote exception
-      //will be swallowed.
+      // Shobhit: Now on if buckets to be queried are on remote as well as local node,
+      // request will be sent to remote node first to run query in parallel on local and
+      // remote node.
+      // Note: if Any Exception is thrown on local and some remote node, local exception
+      // will be given priority and will be visible to query executor and remote exception
+      // will be swallowed.
-      
+
-        //Shobhit: Only one chance is allowed for Function queries.
+        // Shobhit: Only one chance is allowed for Function queries.
-          logger.debug("PR Query retry: {} total: {}", retry, this.pr.getCachePerfStats().getPRQueryRetries());
+          logger.debug("PR Query retry: {} total: {}", retry,
+              this.pr.getCachePerfStats().getPRQueryRetries());
-        //Shobhit: Wait for sometime as rebalancing might be happening
+        // Shobhit: Wait for sometime as rebalancing might be happening
-      String msg = "Failed to query all the partitioned region " +
-        "dataset (buckets) after " + retry + " attempts.";
-      
+      String msg = "Failed to query all the partitioned region " + "dataset (buckets) after "
+          + retry + " attempts.";
+
-        logger.debug("{} Unable to query some of the buckets from the set :{}", msg, this.calculateRetryBuckets());
+        logger.debug("{} Unable to query some of the buckets from the set :{}", msg,
+            this.calculateRetryBuckets());
-  
+
-  
+
-    Iterator<Map.Entry<InternalDistributedMember,List<Integer>>> memberToBucketList = node2bucketIds.entrySet().iterator();
+    Iterator<Map.Entry<InternalDistributedMember, List<Integer>>> memberToBucketList =
+        node2bucketIds.entrySet().iterator();
-          || (!((MemberResultsList) this.resultsPerMember.get(m))
-              .isLastChunkReceived())) {
+          || (!((MemberResultsList) this.resultsPerMember.get(m)).isLastChunkReceived())) {
-        this.resultsPerMember.remove(m);        
+        this.resultsPerMember.remove(m);
-    
+
-      .append(" needs to retry bucketsIds: [");
+          .append(" needs to retry bucketsIds: [");
-    
+
-    
+
-   
+
-    if(isGroupByResults) {
+    if (isGroupByResults) {
-      if(cgs.getOrderByAttrs() != null && !cgs.getOrderByAttrs().isEmpty()) {
-        baseResults = this.buildSortedResult(cs, limit);        
-      }else {
+      if (cgs.getOrderByAttrs() != null && !cgs.getOrderByAttrs().isEmpty()) {
+        baseResults = this.buildSortedResult(cs, limit);
+      } else {
-    }else {
+    } else {
-      if (this.cumulativeResults.getCollectionType().isOrdered()
-        && cs.getOrderByAttrs() != null) {
-      // If its a sorted result set, sort local and remote results using query.
-        return buildSortedResult(cs, limit);        
-      }else {  
+      if (this.cumulativeResults.getCollectionType().isOrdered() && cs.getOrderByAttrs() != null) {
+        // If its a sorted result set, sort local and remote results using query.
+        return buildSortedResult(cs, limit);
+      } else {
-    
+
-  
+
-    
-    List<CumulativeNonDistinctResults.Metadata> collectionsMetadata =null;
+
+    List<CumulativeNonDistinctResults.Metadata> collectionsMetadata = null;
-    
-    if(isDistinct) {
-      if(isStruct) {
-        StructType stype = (StructType)elementType;
+
+    if (isDistinct) {
+      if (isStruct) {
+        StructType stype = (StructType) elementType;
-      }else {
+      } else {
-    }else {
+    } else {
-      results =  new ArrayList<Collection>();
+      results = new ArrayList<Collection>();
-    
+
-        getDomainObjectForPdx = !(this.pr.getCache()
-            .getPdxReadSerializedByAnyGemFireServices());
+        getDomainObjectForPdx = !(this.pr.getCache().getPdxReadSerializedByAnyGemFireServices());
-        if (!getDeserializedObject
-            && !((DefaultQuery) this.query).isKeepSerialized()) {
+        if (!getDeserializedObject && !((DefaultQuery) this.query).isKeepSerialized()) {
-            .getCollectionMetadata(getDomainObjectForPdx,
-                getDeserializedObject, localResults);
-       
-          for (Collection res : e.getValue()) {
-            results.add(res);
-            collectionsMetadata.add(wrapper);    
-          }        
+            .getCollectionMetadata(getDomainObjectForPdx, getDeserializedObject, localResults);
+
+        for (Collection res : e.getValue()) {
+          results.add(res);
+          collectionsMetadata.add(wrapper);
+        }
-              logger.debug("Query Result from member :{}: {}", e.getKey(),
-                  res.size());
+              logger.debug("Query Result from member :{}: {}", e.getKey(), res.size());
-            
+
-              obj = PDXUtils.convertPDX(obj, isStruct,
-                  getDomainObjectForPdx, getDeserializedObject, localResults, objectChangedMarker, true);
-              boolean elementGotAdded = isStruct? ((StructSet)this.cumulativeResults).addFieldValues((Object[])obj):
-                this.cumulativeResults.add(obj);
+              obj = PDXUtils.convertPDX(obj, isStruct, getDomainObjectForPdx, getDeserializedObject,
+                  localResults, objectChangedMarker, true);
+              boolean elementGotAdded =
+                  isStruct ? ((StructSet) this.cumulativeResults).addFieldValues((Object[]) obj)
+                      : this.cumulativeResults.add(obj);
-    if (prQueryTraceInfoList != null && this.query.isTraced()
-        && logger.isInfoEnabled()) {
+    if (prQueryTraceInfoList != null && this.query.isTraced() && logger.isInfoEnabled()) {
-      sb.append(
-          LocalizedStrings.PartitionedRegion_QUERY_TRACE_LOG
-              .toLocalizedString(this.query.getQueryString())).append("\n");
+      sb.append(LocalizedStrings.PartitionedRegion_QUERY_TRACE_LOG
+          .toLocalizedString(this.query.getQueryString())).append("\n");
-      logger.info(sb.toString());
-      ;
+      logger.info(sb.toString());;
-      this.cumulativeResults =  new CumulativeNonDistinctResults(results, limit,
-          this.cumulativeResults.getCollectionType().getElementType(),
-          collectionsMetadata);
+      this.cumulativeResults = new CumulativeNonDistinctResults(results, limit,
+          this.cumulativeResults.getCollectionType().getElementType(), collectionsMetadata);
-    } 
+    }
-  
+
-      String reason = LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION
-          .toLocalizedString();
+      String reason =
+          LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION
+              .toLocalizedString();
-  
+
+   * 
-    for (Collection<Collection> results: this.resultsPerMember.values()) {
+    for (Collection<Collection> results : this.resultsPerMember.values()) {
-    
+
-    this.cumulativeResults.add(count);    
+    this.cumulativeResults.add(count);
-   * Applies order-by on the results returned from PR nodes and puts the results in 
-   * the cumulative result set.
-   * The order-by is applied by running a generated query on the each result returned
-   * by the remote nodes.
-   * Example generated query: SELECT DISTINCT * FROM $1 p ORDER BY p.ID
-   * Where results are passed as bind parameter.
-   * This is added as quick turn-around, this is added based on most commonly used
-   * queries, needs to be investigated further.
-   */   
+   * Applies order-by on the results returned from PR nodes and puts the results in the cumulative
+   * result set. The order-by is applied by running a generated query on the each result returned by
+   * the remote nodes. Example generated query: SELECT DISTINCT * FROM $1 p ORDER BY p.ID Where
+   * results are passed as bind parameter. This is added as quick turn-around, this is added based
+   * on most commonly used queries, needs to be investigated further.
+   */
-    
-    try {
-     ExecutionContext localContext = new QueryExecutionContext(this.parameters,
-          this.pr.cache);
-      
+    try {
+      ExecutionContext localContext = new QueryExecutionContext(this.parameters, this.pr.cache);
+
+
-      
-      this.cumulativeResults = new NWayMergeResults(allResults, cs.isDistinct(), limit, cs.getOrderByAttrs(), 
-          localContext, cs.getElementTypeForOrderByQueries());
+
+      this.cumulativeResults = new NWayMergeResults(allResults, cs.isDistinct(), limit,
+          cs.getOrderByAttrs(), localContext, cs.getElementTypeForOrderByQueries());
-      throw new QueryException("Unable to apply order-by on the partition region cumulative results.", ex);
+      throw new QueryException(
+          "Unable to apply order-by on the partition region cumulative results.", ex);
-    
+
-   * Generates a map with key as PR node and value as the list as a subset of
-   * the bucketIds hosted by the node.
+   * Generates a map with key as PR node and value as the list as a subset of the bucketIds hosted
+   * by the node.
-  
+
-  Map<InternalDistributedMember, List<Integer>> buildNodeToBucketMap() throws QueryException
-  {
+  Map<InternalDistributedMember, List<Integer>> buildNodeToBucketMap() throws QueryException {
-  private Map<InternalDistributedMember, List<Integer>> buildNodeToBucketMapForBuckets(final Set<Integer> bucketIdsToConsider) 
-  throws QueryException {
-    
-    final HashMap<InternalDistributedMember, List<Integer>> ret = new 
-    HashMap<InternalDistributedMember,List<Integer>>();
-    
+  private Map<InternalDistributedMember, List<Integer>> buildNodeToBucketMapForBuckets(
+      final Set<Integer> bucketIdsToConsider) throws QueryException {
+
+    final HashMap<InternalDistributedMember, List<Integer>> ret =
+        new HashMap<InternalDistributedMember, List<Integer>>();
+
-    
+
-    for(Map.Entry<InternalDistributedMember, Collection<Collection>> entry : resultsPerMember.entrySet()) {
-      InternalDistributedMember member = entry.getKey();
-      TaintableArrayList list = entry.getValue();
-      if(list.isTainted()) {
-        taintedMembers.add(member);
-      }
-    }*/
-     
-    //Put the failed members on the end of the list.
-    if(failedMembers != null && !failedMembers.isEmpty()) {
+     * for(Map.Entry<InternalDistributedMember, Collection<Collection>> entry :
+     * resultsPerMember.entrySet()) { InternalDistributedMember member = entry.getKey();
+     * TaintableArrayList list = entry.getValue(); if(list.isTainted()) {
+     * taintedMembers.add(member); } }
+     */
+
+    // Put the failed members on the end of the list.
+    if (failedMembers != null && !failedMembers.isEmpty()) {
-    
-    for (Iterator dsItr = allNodes.iterator(); dsItr.hasNext() && (bucketIds.size() < totalBucketsToQuery); ) {
-      InternalDistributedMember nd = (InternalDistributedMember)dsItr.next();
-      
+
+    for (Iterator dsItr = allNodes.iterator(); dsItr.hasNext()
+        && (bucketIds.size() < totalBucketsToQuery);) {
+      InternalDistributedMember nd = (InternalDistributedMember) dsItr.next();
+
-          } 
+          }
-      throw new QueryException("Data loss detected, unable to find the hosting " +
-          " node for some of the dataset. [dataset/bucket ids:" + bucketIdsToConsider + "]");
+      throw new QueryException("Data loss detected, unable to find the hosting "
+          + " node for some of the dataset. [dataset/bucket ids:" + bucketIdsToConsider + "]");
-    
+
-   * Executes query on local data store. 
+   * Executes query on local data store.
-  private boolean executeQueryOnLocalNode() throws QueryException, InterruptedException
-  {
+  private boolean executeQueryOnLocalNode() throws QueryException, InterruptedException {
-    
+
-        
+
-        
-        //Only wrap/copy results when copy on read is set and an index is used on a local query
-        //This is because when an index is used, the results are actual references to values in the cache
-        //Currently as 7.0.1 when indexes are not used, iteration uses non tx entries to retrieve the value.
-        //The non tx entry already checks copy on read and returns a copy.
-        //The rest of the pr query will be copies from their respective nodes
-        if (!this.query.isRemoteQuery()
-            && pr.getCompressor() == null
-            && pr.getCache().isCopyOnRead()
-            && (!DefaultQueryService.COPY_ON_READ_AT_ENTRY_LEVEL || (qp.isIndexUsed() && DefaultQueryService.COPY_ON_READ_AT_ENTRY_LEVEL))) {
+
+        // Only wrap/copy results when copy on read is set and an index is used on a local query
+        // This is because when an index is used, the results are actual references to values in the
+        // cache
+        // Currently as 7.0.1 when indexes are not used, iteration uses non tx entries to retrieve
+        // the value.
+        // The non tx entry already checks copy on read and returns a copy.
+        // The rest of the pr query will be copies from their respective nodes
+        if (!this.query.isRemoteQuery() && pr.getCompressor() == null
+            && pr.getCache().isCopyOnRead() && (!DefaultQueryService.COPY_ON_READ_AT_ENTRY_LEVEL
+                || (qp.isIndexUsed() && DefaultQueryService.COPY_ON_READ_AT_ENTRY_LEVEL))) {
-          for (Object o: resultCollector) {
+          for (Object o : resultCollector) {
-              for (Object collectionObject: results) {
+              for (Object collectionObject : results) {
-            }
-            else {
+            } else {
-      
-        //Adds a query trace info object to the results list
+
+        // Adds a query trace info object to the results list
-          //Due to the way trace info is populated, we will rely on the query execution logging
-          //index usage for us.
-          prQueryTraceInfoList.add(queryTraceInfo);        
+          // Due to the way trace info is populated, we will rely on the query execution logging
+          // index usage for us.
+          prQueryTraceInfoList.add(queryTraceInfo);
-        
+
-        // Add results to the results-list.  If prior successfully completed
-        //results exist from previous executions on different buckets, add (to) those results as well.
-        MemberResultsList otherResults = (MemberResultsList)this.resultsPerMember.put(me, resultCollector);
+        // Add results to the results-list. If prior successfully completed
+        // results exist from previous executions on different buckets, add (to) those results as
+        // well.
+        MemberResultsList otherResults =
+            (MemberResultsList) this.resultsPerMember.put(me, resultCollector);
-        } 
-        
+        }
+
-          logger.debug("Caught exception during local portion of query {}",this.query.getQueryString(), retryRequired);
+          logger.debug("Caught exception during local portion of query {}",
+              this.query.getQueryString(), retryRequired);
-      } 
+      }
-   * This class is used to accumulate information about indexes used
-   * in multipleThreads and results gained from buckets.
-   * In future this can be used for adding for more information to final
-   * query running info from pool threads.
+   * This class is used to accumulate information about indexes used in multipleThreads and results
+   * gained from buckets. In future this can be used for adding for more information to final query
+   * running info from pool threads.
+   * 
-      this.usedIndexInfoMap = new Object2ObjectOpenHashMap<String, IndexInfo>(); //{indexName, IndexInfo} Map
+      this.usedIndexInfoMap = new Object2ObjectOpenHashMap<String, IndexInfo>(); // {indexName,
+                                                                                 // IndexInfo} Map
-    
-    public int size(){
+
+    public int size() {
-    
-    public Object get() throws InterruptedException{
+
+    public Object get() throws InterruptedException {
-    
-    public void put(Object obj) throws InterruptedException{
+
+    public void put(Object obj) throws InterruptedException {
-  
-  public class StreamingQueryPartitionResponse extends StreamingPartitionOperation.StreamingPartitionResponse {
-    public StreamingQueryPartitionResponse(InternalDistributedSystem system,
-        Set members) {
+  public class StreamingQueryPartitionResponse
+      extends StreamingPartitionOperation.StreamingPartitionResponse {
+
+    public StreamingQueryPartitionResponse(InternalDistributedSystem system, Set members) {
-    
+
-      
+
-        StreamingReplyMessage m = (StreamingReplyMessage)msg;
+        StreamingReplyMessage m = (StreamingReplyMessage) msg;
-          String reason = LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION.toLocalizedString();
+          String reason =
+              LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION
+                  .toLocalizedString();
-        
-        //we will process null objects if it is a query msg and it is canceled.  This allows us to signal the query processor about dropped objects due to low memory
-        if (objects != null) {  // CONSTRAINT: objects should only be null if there's no data at all
+
+        // we will process null objects if it is a query msg and it is canceled. This allows us to
+        // signal the query processor about dropped objects due to low memory
+        if (objects != null) { // CONSTRAINT: objects should only be null if there's no data at all
-            isAborted = !processChunk(objects, m.getSender(),
-                m.getMessageNumber(), m.isLastMessage());
+            isAborted =
+                !processChunk(objects, m.getSender(), m.getMessageNumber(), m.isLastMessage());
-        }
-        else {
+        } else {
-       if (isLast) { //commented by Suranjan watch this out
+        if (isLast) { // commented by Suranjan watch this out
-      }
-      finally {
+      } finally {
-        checkIfDone(); // check to see if decrementing msgsBeingProcessed requires signalling to proceed
-      }          
-    }  
-    
+        checkIfDone(); // check to see if decrementing msgsBeingProcessed requires signalling to
+                       // proceed
+      }
+    }
+
-      return PartitionedRegionQueryEvaluator.this.cumulativeResults.getCollectionType().getElementType();
+      return PartitionedRegionQueryEvaluator.this.cumulativeResults.getCollectionType()
+          .getElementType();

UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66 DEL66