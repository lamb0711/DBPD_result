Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
+import org.apache.geode.cache.persistence.PartitionOfflineException;
+import org.apache.geode.cache.persistence.PersistentID;
- * A Region whose total storage is split into chunks of data (partitions) which
- * are copied up to a configurable level (for high availability) and placed on
- * multiple VMs for improved performance and increased storage capacity.
+ * A Region whose total storage is split into chunks of data (partitions) which are copied up to a
+ * configurable level (for high availability) and placed on multiple VMs for improved performance
+ * and increased storage capacity.
-public class PartitionedRegion extends LocalRegion implements 
-  CacheDistributionAdvisee, QueryExecutor {
+public class PartitionedRegion extends LocalRegion
+    implements CacheDistributionAdvisee, QueryExecutor {
-  public static final Random rand = new Random(Long.getLong(
-      DistributionConfig.GEMFIRE_PREFIX + "PartitionedRegionRandomSeed", NanoTimer.getTime()).longValue());
-  
+  public static final Random rand =
+      new Random(Long.getLong(DistributionConfig.GEMFIRE_PREFIX + "PartitionedRegionRandomSeed",
+          NanoTimer.getTime()).longValue());
+
-   * getNetworkHopType byte indicating this was the bucket owner for
-   * the last operation
+   * getNetworkHopType byte indicating this was the bucket owner for the last operation
-   * getNetworkHopType byte indicating this was not the bucket owner and
-   * a message had to be sent to a primary in the same server group
+   * getNetworkHopType byte indicating this was not the bucket owner and a message had to be sent to
+   * a primary in the same server group
-   * getNetworkHopType byte indicating this was not the bucket owner and
-   * a message had to be sent to a primary in a different server group
+   * getNetworkHopType byte indicating this was not the bucket owner and a message had to be sent to
+   * a primary in a different server group
-  
+
-  public static final boolean DISABLE_SECONDARY_BUCKET_ACK = Boolean.getBoolean(
-      DistributionConfig.GEMFIRE_PREFIX + "disablePartitionedRegionBucketAck");
-  
+  public static final boolean DISABLE_SECONDARY_BUCKET_ACK =
+      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "disablePartitionedRegionBucketAck");
+
-  
+
-   * Global Region for storing PR config ( PRName->PRConfig). This region would
-   * be used to resolve PR name conflict.*
+   * Global Region for storing PR config ( PRName->PRConfig). This region would be used to resolve
+   * PR name conflict.*
-   * PartitionedRegionDataStore class takes care of data storage for the PR.
-   * This will contain the bucket Regions to store data entries for PR*
+   * PartitionedRegionDataStore class takes care of data storage for the PR. This will contain the
+   * bucket Regions to store data entries for PR*
-  final static long VM_OWNERSHIP_WAIT_TIME = PRSystemPropertyGetter
-      .parseLong(
-          System
-              .getProperty(PartitionedRegionHelper.VM_OWNERSHIP_WAIT_TIME_PROPERTY),
-          PartitionedRegionHelper.VM_OWNERSHIP_WAIT_TIME_DEFAULT);
+  final static long VM_OWNERSHIP_WAIT_TIME = PRSystemPropertyGetter.parseLong(
+      System.getProperty(PartitionedRegionHelper.VM_OWNERSHIP_WAIT_TIME_PROPERTY),
+      PartitionedRegionHelper.VM_OWNERSHIP_WAIT_TIME_DEFAULT);
-   * Ratio of currently allocated memory to maxMemory that triggers rebalance
-   * activity.
+   * Ratio of currently allocated memory to maxMemory that triggers rebalance activity.
-  
+
-   * the thread locally destroying this pr.  not volatile,
-   * so always check isLocallyDestroyed before checking locallyDestroyingThread
+   * the thread locally destroying this pr. not volatile, so always check isLocallyDestroyed before
+   * checking locallyDestroyingThread
-   * regionMembershipListener notification requires this to be plugged into
-   * a PR's RegionAdvisor
+   * regionMembershipListener notification requires this to be plugged into a PR's RegionAdvisor
-   * Map containing <IndexTask, FutureTask<IndexTask> or Index>.
-   * IndexTask represents an index thats completely created or
-   * one thats in create phase. This is done in order to avoid
-   * synchronization on the indexes.
+   * Map containing <IndexTask, FutureTask<IndexTask> or Index>. IndexTask represents an index thats
+   * completely created or one thats in create phase. This is done in order to avoid synchronization
+   * on the indexes.
-  
+
-  
+
-  private List<BucketRegion> sortedBuckets; 
-  
+  private List<BucketRegion> sortedBuckets;
+
-  private ConcurrentMap<String, Integer[]> partitionsMap = new ConcurrentHashMap<String, Integer[]>();
+  private ConcurrentMap<String, Integer[]> partitionsMap =
+      new ConcurrentHashMap<String, Integer[]>();
+
-  * for wan shadowPR
-  */
+   * for wan shadowPR
+   */
- 
+
- 
+
-   * Byte 0 = no NWHOP Byte 1 = NWHOP to servers in same server-grp Byte 2 =
-   * NWHOP tp servers in other server-grp
+   * Byte 0 = no NWHOP Byte 1 = NWHOP to servers in same server-grp Byte 2 = NWHOP tp servers in
+   * other server-grp
-      return Byte.valueOf((byte)NETWORK_HOP_NONE);
+      return Byte.valueOf((byte) NETWORK_HOP_NONE);
-  
+
-   * If the last operation in the current thread required a one-hop to
-   * another server who held the primary bucket for the operation then
-   * this will return something other than NETWORK_HOP_NONE.
+   * If the last operation in the current thread required a one-hop to another server who held the
+   * primary bucket for the operation then this will return something other than NETWORK_HOP_NONE.
-  
+
-      
+
-   * Returns the LRUStatistics for this PR.
-   * This is needed to find the single instance of LRUStatistics
-   * created early for a PR when it is recovered from disk.
-   * This fixes bug 41938
+   * Returns the LRUStatistics for this PR. This is needed to find the single instance of
+   * LRUStatistics created early for a PR when it is recovered from disk. This fixes bug 41938
-               
-  
-  //////////////////  ConcurrentMap methods //////////////////               
-          
+
+
+  ////////////////// ConcurrentMap methods //////////////////
+
-   public boolean remove(Object key, Object value, Object callbackArg) {
-     final long startTime = PartitionedRegionStats.startTime();
-     try {
-       return super.remove(key, value, callbackArg);
-     }
-     finally {
-       this.prStats.endDestroy(startTime);
-     }
-   }
-   
-   
-               
-   //////////////////  End of ConcurrentMap methods ////////////////// 
-               
+  public boolean remove(Object key, Object value, Object callbackArg) {
+    final long startTime = PartitionedRegionStats.startTime();
+    try {
+      return super.remove(key, value, callbackArg);
+    } finally {
+      this.prStats.endDestroy(startTime);
+    }
+  }
+
+
+
+  ////////////////// End of ConcurrentMap methods //////////////////
+
-  
+
-   * @param bucketId
-   *                the bucket
+   * @param bucketId the bucket
-   * Clear the prIdMap, typically used when disconnecting from the distributed
-   * system or clearing the cache
+   * Clear the prIdMap, typically used when disconnecting from the distributed system or clearing
+   * the cache
-      return LocalizedStrings.PartitionedRegion_SHUTDOWN_LISTENER_FOR_PARTITIONEDREGION.toLocalizedString();
+      return LocalizedStrings.PartitionedRegion_SHUTDOWN_LISTENER_FOR_PARTITIONEDREGION
+          .toLocalizedString();
-      throw new UnsupportedOperationException(LocalizedStrings.PartitionedRegion_PRIDMAPGET_NOT_SUPPORTED_USE_GETREGION_INSTEAD.toLocalizedString());
+      throw new UnsupportedOperationException(
+          LocalizedStrings.PartitionedRegion_PRIDMAPGET_NOT_SUPPORTED_USE_GETREGION_INSTEAD
+              .toLocalizedString());
-        }
-        else {
+        } else {
-        throw new RegionDestroyedException(LocalizedStrings.PartitionedRegion_REGION_FOR_PRID_0_IS_DESTROYED.toLocalizedString(key), NO_PATH_FOUND);
+        throw new RegionDestroyedException(
+            LocalizedStrings.PartitionedRegion_REGION_FOR_PRID_0_IS_DESTROYED
+                .toLocalizedString(key),
+            NO_PATH_FOUND);
-        throw new PRLocallyDestroyedException(LocalizedStrings.PartitionedRegion_REGION_WITH_PRID_0_IS_LOCALLY_DESTROYED_ON_THIS_NODE.toLocalizedString(key));
+        throw new PRLocallyDestroyedException(
+            LocalizedStrings.PartitionedRegion_REGION_WITH_PRID_0_IS_LOCALLY_DESTROYED_ON_THIS_NODE
+                .toLocalizedString(key));
-        throw new PRLocallyDestroyedException(LocalizedStrings.PartitionedRegion_REGION_WITH_PRID_0_FAILED_INITIALIZATION_ON_THIS_NODE.toLocalizedString(key));
+        throw new PRLocallyDestroyedException(
+            LocalizedStrings.PartitionedRegion_REGION_WITH_PRID_0_FAILED_INITIALIZATION_ON_THIS_NODE
+                .toLocalizedString(key));
-    public Object put(final Object key, final Object value,
-        boolean sendIdentityRequestMessage) {
+    public Object put(final Object key, final Object value, boolean sendIdentityRequestMessage) {
-        throw new NullPointerException(LocalizedStrings.PartitionedRegion_NULL_KEY_NOT_ALLOWED_FOR_PRIDTOPR_MAP.toLocalizedString());
+        throw new NullPointerException(
+            LocalizedStrings.PartitionedRegion_NULL_KEY_NOT_ALLOWED_FOR_PRIDTOPR_MAP
+                .toLocalizedString());
-        throw new NullPointerException(LocalizedStrings.PartitionedRegion_NULL_VALUE_NOT_ALLOWED_FOR_PRIDTOPR_MAP.toLocalizedString());
+        throw new NullPointerException(
+            LocalizedStrings.PartitionedRegion_NULL_VALUE_NOT_ALLOWED_FOR_PRIDTOPR_MAP
+                .toLocalizedString());
-        IdentityRequestMessage.setLatestId(((Integer)key).intValue());
+        IdentityRequestMessage.setLatestId(((Integer) key).intValue());
-        PartitionedRegionException pre = new PartitionedRegionException(LocalizedStrings.PartitionedRegion_CAN_NOT_REUSE_OLD_PARTITIONED_REGION_ID_0.toLocalizedString(key));
+        PartitionedRegionException pre = new PartitionedRegionException(
+            LocalizedStrings.PartitionedRegion_CAN_NOT_REUSE_OLD_PARTITIONED_REGION_ID_0
+                .toLocalizedString(key));
-        me = (Map.Entry)i.next();
+        me = (Map.Entry) i.next();
-   * flag saying whether this VM needs cache operation notifications from other
-   * members
+   * flag saying whether this VM needs cache operation notifications from other members
-   * Constructor for a PartitionedRegion. This has an accessor (Region API)
-   * functionality and contains a datastore for actual storage. An accessor can
-   * act as a local cache by having a local storage enabled. A PartitionedRegion
-   * can be created by a factory method of RegionFactory.java and also by
-   * invoking Cache.createRegion(). (Cache.xml etc to be added)
+   * Constructor for a PartitionedRegion. This has an accessor (Region API) functionality and
+   * contains a datastore for actual storage. An accessor can act as a local cache by having a local
+   * storage enabled. A PartitionedRegion can be created by a factory method of RegionFactory.java
+   * and also by invoking Cache.createRegion(). (Cache.xml etc to be added)
-  
-  private final PartitionRegionConfigValidator validator ;
-  
+
+  private final PartitionRegionConfigValidator validator;
+
-  
+
-  
-  public List<PartitionedRegion> colocatedByList= new CopyOnWriteArrayList<PartitionedRegion>();
-  
+
+  public List<PartitionedRegion> colocatedByList = new CopyOnWriteArrayList<PartitionedRegion>();
+
-  
-  public PartitionedRegion(String regionname, RegionAttributes ra,
-      LocalRegion parentRegion, GemFireCacheImpl cache,
-      InternalRegionArguments internalRegionArgs) {
+
+  public PartitionedRegion(String regionname, RegionAttributes ra, LocalRegion parentRegion,
+      GemFireCacheImpl cache, InternalRegionArguments internalRegionArgs) {
-    
+
-    this.distAdvisor = RegionAdvisor.createRegionAdvisor(this); // Warning: potential early escape of instance
+    this.distAdvisor = RegionAdvisor.createRegionAdvisor(this); // Warning: potential early escape
+                                                                // of instance
-    
+
-    this.minimumWriteRedundancy = Integer.getInteger(
-        DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionWriteRedundancy", 0).intValue();
+    this.minimumWriteRedundancy =
+        Integer
+            .getInteger(
+                DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionWriteRedundancy", 0)
+            .intValue();
-    this.minimumReadRedundancy = Integer.getInteger(
-        DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionReadRedundancy", 0).intValue();
+    this.minimumReadRedundancy = Integer
+        .getInteger(DistributionConfig.GEMFIRE_PREFIX + "mimimumPartitionedRegionReadRedundancy", 0)
+        .intValue();
-    this.initializationLatchAfterBucketIntialization = new StoppableCountDownLatch(
-        this.getCancelCriterion(), 1);
-    
+    this.initializationLatchAfterBucketIntialization =
+        new StoppableCountDownLatch(this.getCancelCriterion(), 1);
+
-    this.partitionListeners = this.partitionAttributes.getPartitionListeners(); 
+    this.partitionListeners = this.partitionAttributes.getPartitionListeners();
-    if(colocatedWithRegion != null) {
+    if (colocatedWithRegion != null) {
-      //In a colocation chain, the child region inherits the fixed partition attributes from parent region.
+      // In a colocation chain, the child region inherits the fixed partition attributes from parent
+      // region.
-    }
-    else {
+    } else {
-      logger.debug("Partitioned Region {} constructed {}", regionname, (this.haveCacheLoader ? "with a cache loader" : ""));
+      logger.debug("Partitioned Region {} constructed {}", regionname,
+          (this.haveCacheLoader ? "with a cache loader" : ""));
-    
-    
+
+
-    if(dataPolicy.withPersistence()) {
-      startPersistenceProfileLogging();      
+    if (dataPolicy.withPersistence()) {
+      startPersistenceProfileLogging();
-      public void profileCreated(Profile profile) {
-      }
+      public void profileCreated(Profile profile) {}
-      public void profileUpdated(Profile profile) {
-      }
-      
+      public void profileUpdated(Profile profile) {}
+
-        if(isInitialized()) {
-          CacheProfile cacheProfile = ((profile instanceof CacheProfile) ? (CacheProfile) profile : null);
+        if (isInitialized()) {
+          CacheProfile cacheProfile =
+              ((profile instanceof CacheProfile) ? (CacheProfile) profile : null);
-          TransformUtils.transform(PartitionedRegion.this.distAdvisor.advisePersistentMembers().values(),onlineMembers,TransformUtils.persistentMemberIdToLogEntryTransformer);
+          TransformUtils.transform(
+              PartitionedRegion.this.distAdvisor.advisePersistentMembers().values(), onlineMembers,
+              TransformUtils.persistentMemberIdToLogEntryTransformer);
-          logger.info(LocalizedMessage.create(LocalizedStrings.PersistenceAdvisorImpl_PERSISTENT_VIEW,
-              new Object[] {PartitionedRegion.this.getName(),TransformUtils.persistentMemberIdToLogEntryTransformer.transform(cacheProfile.persistentID),onlineMembers}));                          
+          logger
+              .info(LocalizedMessage.create(LocalizedStrings.PersistenceAdvisorImpl_PERSISTENT_VIEW,
+                  new Object[] {PartitionedRegion.this.getName(),
+                      TransformUtils.persistentMemberIdToLogEntryTransformer
+                          .transform(cacheProfile.persistentID),
+                      onlineMembers}));
-      }      
+      }
-  
+
-      if (regionGatewaySenderIds.contains(sender.getId())
-          && sender.isParallel()) {
+      if (regionGatewaySenderIds.contains(sender.getId()) && sender.isParallel()) {
-  
+
-	return this.colocatedByList;
+    return this.colocatedByList;
-  } 
+  }
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_ENABLING_CONCURRENCY_CHECKS_FOR_PERSISTENT_PR, this.getFullPath()));
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_ENABLING_CONCURRENCY_CHECKS_FOR_PERSISTENT_PR,
+          this.getFullPath()));
-      String colocatedWith = colocatedWithRegion == null 
-          ? "" : colocatedWithRegion.getFullPath(); 
+      String colocatedWith = colocatedWithRegion == null ? "" : colocatedWithRegion.getFullPath();
-      if(config != null) {
+      if (config != null) {
-          Object[] prms = new Object[] { this.getFullPath(), this.getTotalNumberOfBuckets(),
-              config.getTotalNumBuckets() };
+          Object[] prms = new Object[] {this.getFullPath(), this.getTotalNumberOfBuckets(),
+              config.getTotalNumBuckets()};
-              LocalizedStrings.PartitionedRegion_FOR_REGION_0_TotalBucketNum_1_SHOULD_NOT_BE_CHANGED_Previous_Configured_2.toString(prms));
+              LocalizedStrings.PartitionedRegion_FOR_REGION_0_TotalBucketNum_1_SHOULD_NOT_BE_CHANGED_Previous_Configured_2
+                  .toString(prms));
-        //Make sure we don't change to be colocated with a different region
-        //We also can't change from colocated to not colocated without writing
-        //a record to disk, so we won't allow that right now either.
+        // Make sure we don't change to be colocated with a different region
+        // We also can't change from colocated to not colocated without writing
+        // a record to disk, so we won't allow that right now either.
-          Object[] prms = new Object[] { this.getFullPath(), colocatedWith,
-              config.getColocatedWith() };
-          DiskAccessException dae = new DiskAccessException(LocalizedStrings.LocalRegion_A_DISKACCESSEXCEPTION_HAS_OCCURED_WHILE_WRITING_TO_THE_DISK_FOR_REGION_0_THE_REGION_WILL_BE_CLOSED.toLocalizedString(this.getFullPath()), null, dsi);
+          Object[] prms =
+              new Object[] {this.getFullPath(), colocatedWith, config.getColocatedWith()};
+          DiskAccessException dae = new DiskAccessException(
+              LocalizedStrings.LocalRegion_A_DISKACCESSEXCEPTION_HAS_OCCURED_WHILE_WRITING_TO_THE_DISK_FOR_REGION_0_THE_REGION_WILL_BE_CLOSED
+                  .toLocalizedString(this.getFullPath()),
+              null, dsi);
-              LocalizedStrings.PartitionedRegion_FOR_REGION_0_ColocatedWith_1_SHOULD_NOT_BE_CHANGED_Previous_Configured_2.toString(prms));
+              LocalizedStrings.PartitionedRegion_FOR_REGION_0_ColocatedWith_1_SHOULD_NOT_BE_CHANGED_Previous_Configured_2
+                  .toString(prms));
-        
-        config= new PRPersistentConfig(this.getTotalNumberOfBuckets(), 
-            colocatedWith);
+
+        config = new PRPersistentConfig(this.getTotalNumberOfBuckets(), colocatedWith);
-        //Fix for support issue 7870 - the parent region needs to be able
-        //to discover that there is a persistent colocated child region. So
-        //if this is a child region, persist its config to the parent disk store
-        //as well.
-        if(colocatedWithRegion != null 
-            && colocatedWithRegion.getDiskStore() != null
+        // Fix for support issue 7870 - the parent region needs to be able
+        // to discover that there is a persistent colocated child region. So
+        // if this is a child region, persist its config to the parent disk store
+        // as well.
+        if (colocatedWithRegion != null && colocatedWithRegion.getDiskStore() != null
-      
+
-  
+
-   * Initializes the PartitionedRegion meta data, adding this Node and starting
-   * the service on this node (if not already started).
-   * Made this synchronized for bug 41982
+   * Initializes the PartitionedRegion meta data, adding this Node and starting the service on this
+   * node (if not already started). Made this synchronized for bug 41982
+   * 
-    
+
-    
-    //Do this after the validation, to avoid creating a persistent config
-    //for an invalid PR.
+
+    // Do this after the validation, to avoid creating a persistent config
+    // for an invalid PR.
-    
+
-    
+
-    
+
-    
+
-        sfo.flush(this.distAdvisor.adviseAllPRNodes(),
-          getDistributionManager().getId(),
-          DistributionManager.HIGH_PRIORITY_EXECUTOR, false);
+        sfo.flush(this.distAdvisor.adviseAllPRNodes(), getDistributionManager().getId(),
+            DistributionManager.HIGH_PRIORITY_EXECUTOR, false);
-    getRegionAdvisor().processProfilesQueuedDuringInitialization(); 
+    getRegionAdvisor().processProfilesQueuedDuringInitialization();
-        
+
-      if(storesData) {
-        if(this.redundancyProvider.recoverPersistentBuckets()) {
-          //Mark members as recovered from disk recursively, starting
-          //with the leader region.
+      if (storesData) {
+        if (this.redundancyProvider.recoverPersistentBuckets()) {
+          // Mark members as recovered from disk recursively, starting
+          // with the leader region.
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
-      if(storesData) {
+      if (storesData) {
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
-  
+
-    for(PartitionedRegion colocatedRegion : ColocationHelper.getColocatedChildRegions(region)) {
+    for (PartitionedRegion colocatedRegion : ColocationHelper.getColocatedChildRegions(region)) {
-          RegionMembershipListener rml = (RegionMembershipListener)listeners[i];
+          RegionMembershipListener rml = (RegionMembershipListener) listeners[i];
-            DistributedMember[] otherDms = new DistributedMember[others
-                .size()];
+            DistributedMember[] otherDms = new DistributedMember[others.size()];
-          }
-          catch (VirtualMachineError err) {
+          } catch (VirtualMachineError err) {
-            // If this ever returns, rethrow the error.  We're poisoned
+            // If this ever returns, rethrow the error. We're poisoned
-          }
-          catch (Throwable t) {
+          } catch (Throwable t) {
-            // catch VirtualMachineError (see above).  However, there is
+            // catch VirtualMachineError (see above). However, there is
-            logger.error(LocalizedMessage.create(LocalizedStrings.DistributedRegion_EXCEPTION_OCCURRED_IN_REGIONMEMBERSHIPLISTENER), t);
+            logger.error(
+                LocalizedMessage.create(
+                    LocalizedStrings.DistributedRegion_EXCEPTION_OCCURRED_IN_REGIONMEMBERSHIPLISTENER),
+                t);
-    
+
-      }     
+      }
-        if (sender.isParallel()
-            && allGatewaySenderIds.contains(sender.getId())) {
+        if (sender.isParallel() && allGatewaySenderIds.contains(sender.getId())) {
-           * get the ParallelGatewaySender to create the colocated partitioned
-           * region for this region.
+           * get the ParallelGatewaySender to create the colocated partitioned region for this
+           * region.
-          if (sender.isRunning() ) {
-            AbstractGatewaySender senderImpl = (AbstractGatewaySender)sender;
-            ((ConcurrentParallelGatewaySenderQueue)senderImpl.getQueues().toArray(new RegionQueue[1])[0])
-                .addShadowPartitionedRegionForUserPR(this);
+          if (sender.isRunning()) {
+            AbstractGatewaySender senderImpl = (AbstractGatewaySender) sender;
+            ((ConcurrentParallelGatewaySenderQueue) senderImpl.getQueues()
+                .toArray(new RegionQueue[1])[0]).addShadowPartitionedRegionForUserPR(this);
-    }   
+    }
-  protected void initialize(InputStream snapshotInputStream,
-      InternalDistributedMember imageTarget,
-      InternalRegionArguments internalRegionArgs) throws TimeoutException,
-      ClassNotFoundException {
+  protected void initialize(InputStream snapshotInputStream, InternalDistributedMember imageTarget,
+      InternalRegionArguments internalRegionArgs) throws TimeoutException, ClassNotFoundException {
-    return new Node(getDistributionManager().getId(),
-        SERIAL_NUMBER_GENERATOR.getAndIncrement());
+    return new Node(getDistributionManager().getId(), SERIAL_NUMBER_GENERATOR.getAndIncrement());
-   * receive notification that a bridge server or wan gateway has been created
-   * that requires notification of cache events from this region
+   * receive notification that a bridge server or wan gateway has been created that requires
+   * notification of cache events from this region
-    if (!this.requiresNotification
-        && !(this.isClosed || this.isLocallyDestroyed)) {
+    if (!this.requiresNotification && !(this.isClosed || this.isLocallyDestroyed)) {
-    }    
+    }
-  
+
-  void distributeUpdatedProfileOnSenderCreation()
-  {
+  void distributeUpdatedProfileOnSenderCreation() {
-      new UpdateAttributesProcessor(this).distribute(false);      
+      new UpdateAttributesProcessor(this).distribute(false);
-  
+
-    ((PartitionedRegion)this).distributeUpdatedProfileOnSenderCreation();
+    ((PartitionedRegion) this).distributeUpdatedProfileOnSenderCreation();
-    if (sender!= null && sender.isParallel() && sender.isRunning()) {
-      AbstractGatewaySender senderImpl = (AbstractGatewaySender)sender;
-      ((ConcurrentParallelGatewaySenderQueue)senderImpl.getQueues().toArray(
-          new RegionQueue[1])[0]).addShadowPartitionedRegionForUserPR(this);
+    if (sender != null && sender.isParallel() && sender.isRunning()) {
+      AbstractGatewaySender senderImpl = (AbstractGatewaySender) sender;
+      ((ConcurrentParallelGatewaySenderQueue) senderImpl.getQueues().toArray(new RegionQueue[1])[0])
+          .addShadowPartitionedRegionForUserPR(this);
-  
-  public void removeGatewaySenderId(String gatewaySenderId){
+
+  public void removeGatewaySenderId(String gatewaySenderId) {
-  
+
-    ((PartitionedRegion)this).distributeUpdatedProfileOnSenderCreation();
-    GatewaySender sender = getCache().getGatewaySender(AsyncEventQueueImpl.getSenderIdFromAsyncEventQueueId(asyncEventQueueId));
-    if (sender!= null && sender.isParallel() && sender.isRunning()) {
-      AbstractGatewaySender senderImpl = (AbstractGatewaySender)sender;
-      ((ConcurrentParallelGatewaySenderQueue)senderImpl.getQueues().toArray(
-          new RegionQueue[1])[0]).addShadowPartitionedRegionForUserPR(this);
+    ((PartitionedRegion) this).distributeUpdatedProfileOnSenderCreation();
+    GatewaySender sender = getCache()
+        .getGatewaySender(AsyncEventQueueImpl.getSenderIdFromAsyncEventQueueId(asyncEventQueueId));
+    if (sender != null && sender.isParallel() && sender.isRunning()) {
+      AbstractGatewaySender senderImpl = (AbstractGatewaySender) sender;
+      ((ConcurrentParallelGatewaySenderQueue) senderImpl.getQueues().toArray(new RegionQueue[1])[0])
+          .addShadowPartitionedRegionForUserPR(this);
-  
+
-  
+
-    List senderIds = this.getCacheDistributionAdvisor()
-        .adviseSameGatewaySenderIds(getGatewaySenderIds());
+    List senderIds =
+        this.getCacheDistributionAdvisor().adviseSameGatewaySenderIds(getGatewaySenderIds());
-              .toLocalizedString(new Object[] { this.getName(),
-                  senderIds.get(0), senderIds.get(1) }));
+              .toLocalizedString(
+                  new Object[] {this.getName(), senderIds.get(0), senderIds.get(1)}));
-    List asycnQueueIds = this.getCacheDistributionAdvisor()
-        .adviseSameAsyncEventQueueIds(getAsyncEventQueueIds());
+    List asycnQueueIds =
+        this.getCacheDistributionAdvisor().adviseSameAsyncEventQueueIds(getAsyncEventQueueIds());
-              .toLocalizedString(new Object[] { this.getName(),
-                  asycnQueueIds.get(0), asycnQueueIds.get(1) }));
+              .toLocalizedString(
+                  new Object[] {this.getName(), asycnQueueIds.get(0), asycnQueueIds.get(1)}));
-  
+
-   * Initializes the PartitionedRegion - create the Global regions for storing
-   * the PartitiotnedRegion configs.
+   * Initializes the PartitionedRegion - create the Global regions for storing the
+   * PartitiotnedRegion configs.
-      Object callback = DistributedRegion.TEST_HOOK_ADD_PROFILE? profile : null;
-      RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this,
-          Operation.REGION_CREATE, callback, true, profile.peerMemberId);
-      dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CREATE,
-            event);
+      Object callback = DistributedRegion.TEST_HOOK_ADD_PROFILE ? profile : null;
+      RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this, Operation.REGION_CREATE,
+          callback, true, profile.peerMemberId);
+      dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CREATE, event);
-   * @param ra
-   *                Region attributes
+   * @param ra Region attributes
-    this.dataStore = PartitionedRegionDataStore.createDataStore(cache, this, ra
-        .getPartitionAttributes());
+    this.dataStore =
+        PartitionedRegionDataStore.createDataStore(cache, this, ra.getPartitionAttributes());
-  
+
-   * Register this PartitionedRegion by: 1) Create a PartitionRegionConfig and
-   * 2) Bind it into the allPartitionedRegion system wide Region.
+   * Register this PartitionedRegion by: 1) Create a PartitionRegionConfig and 2) Bind it into the
+   * allPartitionedRegion system wide Region.
-   * @param storesData
-   *                which indicates whether the instance in this cache stores
-   *                data, effecting the Nodes PRType
+   * @param storesData which indicates whether the instance in this cache stores data, effecting the
+   *        Nodes PRType
-      byte loaderByte = (byte)(getAttributes().getCacheLoader() != null ? 0x01 : 0x00);
-      byte writerByte = (byte)(getAttributes().getCacheWriter() != null ? 0x02 : 0x00);
-      this.node.setLoaderWriterByte((byte)(loaderByte + writerByte));
-    }
-    else {
+      byte loaderByte = (byte) (getAttributes().getCacheLoader() != null ? 0x01 : 0x00);
+      byte writerByte = (byte) (getAttributes().getCacheWriter() != null ? 0x02 : 0x00);
+      this.node.setLoaderWriterByte((byte) (loaderByte + writerByte));
+    } else {
-      
+
-      
+
-        prConfig = new PartitionRegionConfig(this.partitionedRegionId,
-            this.getFullPath(), prAttribs, this.getScope(),
-            getAttributes().getEvictionAttributes(), 
-            getAttributes().getRegionIdleTimeout(), 
-            getAttributes().getRegionTimeToLive(), 
-            getAttributes().getEntryIdleTimeout(),
-            getAttributes().getEntryTimeToLive(),
+        prConfig = new PartitionRegionConfig(this.partitionedRegionId, this.getFullPath(),
+            prAttribs, this.getScope(), getAttributes().getEvictionAttributes(),
+            getAttributes().getRegionIdleTimeout(), getAttributes().getRegionTimeToLive(),
+            getAttributes().getEntryIdleTimeout(), getAttributes().getEntryTimeToLive(),
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_IS_BORN_WITH_PRID_1_IDENT_2,
-              new Object[] { getFullPath(), Integer.valueOf(this.partitionedRegionId), getRegionIdentifier()}));
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_IS_BORN_WITH_PRID_1_IDENT_2,
+            new Object[] {getFullPath(), Integer.valueOf(this.partitionedRegionId),
+                getRegionIdentifier()}));
-      }
-      else {
+      } else {
-        
+
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_IS_CREATED_WITH_PRID_1,
-              new Object[] { getFullPath(), Integer.valueOf(this.partitionedRegionId)}));
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_IS_CREATED_WITH_PRID_1,
+            new Object[] {getFullPath(), Integer.valueOf(this.partitionedRegionId)}));
-       * this.dataStore.grabBackupBuckets(false); } } } catch
-       * (RegionDestroyedException rde) { if (!this.isClosed) throw rde; }
+       * this.dataStore.grabBackupBuckets(false); } } } catch (RegionDestroyedException rde) { if
+       * (!this.isClosed) throw rde; }
-    }
-    catch (LockServiceDestroyedException lsde) {
+    } catch (LockServiceDestroyedException lsde) {
-              .toLocalizedString(), lsde);
-    }
-    catch (IllegalStateException ill) {
+              .toLocalizedString(),
+          lsde);
+    } catch (IllegalStateException ill) {
-    }
-    catch (VirtualMachineError err) {
+    } catch (VirtualMachineError err) {
-      // If this ever returns, rethrow the error.  We're poisoned
+      // If this ever returns, rethrow the error. We're poisoned
-    }
-    catch (Throwable t) {
+    } catch (Throwable t) {
-      // catch VirtualMachineError (see above).  However, there is
+      // catch VirtualMachineError (see above). However, there is
-      String registerErrMsg = 
-        LocalizedStrings.PartitionedRegion_AN_EXCEPTION_WAS_CAUGHT_WHILE_REGISTERING_PARTITIONEDREGION_0_DUMPPRID_1
-        .toLocalizedString(new Object[] {getFullPath(), prIdToPR.dump()});
+      String registerErrMsg =
+          LocalizedStrings.PartitionedRegion_AN_EXCEPTION_WAS_CAUGHT_WHILE_REGISTERING_PARTITIONEDREGION_0_DUMPPRID_1
+              .toLocalizedString(new Object[] {getFullPath(), prIdToPR.dump()});
-            prIdToPR.put(Integer.valueOf(this.partitionedRegionId),
-                PRIdMap.FAILED_REGISTRATION, false);
-            logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_FAILED_REGISTRATION_PRID_0_NAMED_1,
-                  new Object[] {Integer.valueOf(this.partitionedRegionId), this.getName()}));
+            prIdToPR.put(Integer.valueOf(this.partitionedRegionId), PRIdMap.FAILED_REGISTRATION,
+                false);
+            logger.info(LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_FAILED_REGISTRATION_PRID_0_NAMED_1,
+                new Object[] {Integer.valueOf(this.partitionedRegionId), this.getName()}));
-      }
-      catch (VirtualMachineError err) {
+      } catch (VirtualMachineError err) {
-        // If this ever returns, rethrow the error.  We're poisoned
+        // If this ever returns, rethrow the error. We're poisoned
-      }
-      catch (Throwable ignore) {
+      } catch (Throwable ignore) {
-        // catch VirtualMachineError (see above).  However, there is
+        // catch VirtualMachineError (see above). However, there is
-          logger.debug("Partitioned Region creation, could not clean up after caught exception", ignore);
+          logger.debug("Partitioned Region creation, could not clean up after caught exception",
+              ignore);
-    }
-    finally {
+    } finally {
-      }
-      catch (Exception es) {
+      } catch (Exception es) {
-  public void validateParalleGatewaySenderIds() throws PRLocallyDestroyedException{
+  public void validateParalleGatewaySenderIds() throws PRLocallyDestroyedException {
-          Map<String, PartitionedRegion> colocationMap = ColocationHelper
-              .getAllColocationRegions(this);
+          Map<String, PartitionedRegion> colocationMap =
+              ColocationHelper.getAllColocationRegions(this);
-            }
-            else {
+            } else {
-              PartitionedRegion colocatedPR = PartitionedRegion
-                  .getPRFromId(prID);
-              PartitionedRegion leader = ColocationHelper
-                  .getLeaderRegion(colocatedPR);
+              PartitionedRegion colocatedPR = PartitionedRegion.getPRFromId(prID);
+              PartitionedRegion leader = ColocationHelper.getLeaderRegion(colocatedPR);
-              }
-              else {
+              } else {
-                    LocalizedStrings.PartitionRegion_NON_COLOCATED_REGIONS_1_2_CANNOT_HAVE_SAME_PARALLEL_GATEWAY_SENDER_ID_2.toString(new Object[] {
-                        this.getFullPath(),
-                        config.getFullPath(),
-                        senderId.contains(AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX) ? "async event queue": "gateway sender",
-                        senderId }));
+                    LocalizedStrings.PartitionRegion_NON_COLOCATED_REGIONS_1_2_CANNOT_HAVE_SAME_PARALLEL_GATEWAY_SENDER_ID_2
+                        .toString(new Object[] {this.getFullPath(), config.getFullPath(),
+                            senderId.contains(AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX)
+                                ? "async event queue" : "gateway sender",
+                            senderId}));
-          }
-          else {
+          } else {
-                LocalizedStrings.PartitionRegion_NON_COLOCATED_REGIONS_1_2_CANNOT_HAVE_SAME_PARALLEL_GATEWAY_SENDER_ID_2.toString(new Object[] {
-                    this.getFullPath(),
-                    config.getFullPath(),
-                    senderId.contains(AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX) ? "async event queue": "gateway sender",
-                    senderId }));
+                LocalizedStrings.PartitionRegion_NON_COLOCATED_REGIONS_1_2_CANNOT_HAVE_SAME_PARALLEL_GATEWAY_SENDER_ID_2
+                    .toString(new Object[] {this.getFullPath(), config.getFullPath(),
+                        senderId.contains(AsyncEventQueueImpl.ASYNC_EVENT_QUEUE_PREFIX)
+                            ? "async event queue" : "gateway sender",
+                        senderId}));
-   * @return whether this region requires event notification for all cache
-   *         content changes from other nodes
+   * @return whether this region requires event notification for all cache content changes from
+   *         other nodes
-  
+
-  public final void updatePRConfig(PartitionRegionConfig prConfig,
-      boolean putOnlyIfUpdated) {
+  /**
+   * Throw an exception if persistent data recovery from disk is not complete for this region.
+   *
+   * @throws PartitionOfflineException
+   */
+  public void checkPROffline() throws PartitionOfflineException {
+    if (getDataPolicy().withPersistence() && !recoveredFromDisk) {
+      Set<PersistentID> persistIds =
+          new HashSet(getRegionAdvisor().advisePersistentMembers().values());
+      persistIds.removeAll(getRegionAdvisor().adviseInitializedPersistentMembers().values());
+      throw new PartitionOfflineException(persistIds,
+          LocalizedStrings.PRHARedundancyProvider_PARTITIONED_REGION_0_OFFLINE_HAS_UNRECOVERED_PERSISTENT_DATA_1
+              .toLocalizedString(new Object[] {getFullPath(), persistIds}));
+    }
+  }
+
+  public final void updatePRConfig(PartitionRegionConfig prConfig, boolean putOnlyIfUpdated) {
-    final PartitionedRegion colocatedRegion = ColocationHelper
-        .getColocatedRegion(this);
+    final PartitionedRegion colocatedRegion = ColocationHelper.getColocatedRegion(this);
-        final PartitionRegionConfig parentConf = this.prRoot
-            .get(colocatedRegion.getRegionIdentifier());
-        if (parentConf.isColocationComplete()
-            && parentConf.hasSameDataStoreMembers(prConfig)) {
+        final PartitionRegionConfig parentConf =
+            this.prRoot.get(colocatedRegion.getRegionIdentifier());
+        if (parentConf.isColocationComplete() && parentConf.hasSameDataStoreMembers(prConfig)) {
-      if(isDataStore() && !prConfig.isFirstDataStoreCreated()) {
+      if (isDataStore() && !prConfig.isFirstDataStoreCreated()) {
-   * @param access
-   *          true if caller wants last accessed time updated
+   * @param access true if caller wants last accessed time updated
-  protected Region.Entry<?, ?> nonTXGetEntry(KeyInfo keyInfo, boolean access, boolean allowTombstones) {
+  protected Region.Entry<?, ?> nonTXGetEntry(KeyInfo keyInfo, boolean access,
+      boolean allowTombstones) {
-        bucketId = PartitionedRegionHelper.getHashKey(this,
-            Operation.GET_ENTRY, key, null, null);
+        bucketId = PartitionedRegionHelper.getHashKey(this, Operation.GET_ENTRY, key, null, null);
-    }
-    finally {
+    } finally {
-  protected EntrySnapshot getEntryInBucket(
-      final DistributedMember targetNode, final int bucketId,
+  protected EntrySnapshot getEntryInBucket(final DistributedMember targetNode, final int bucketId,
-      logger.trace("getEntryInBucket: " + "Key key={} ({}) from: {} bucketId={}",
-          key, key.hashCode(), targetNode, bucketStringForLogs(bucketId));
+      logger.trace("getEntryInBucket: " + "Key key={} ({}) from: {} bucketId={}", key,
+          key.hashCode(), targetNode, bucketStringForLogs(bucketId));
-    InternalDistributedMember retryNode = (InternalDistributedMember)targetNode;
+    InternalDistributedMember retryNode = (InternalDistributedMember) targetNode;
-          if (name.startsWith("ServerConnection")
-              && !getMyId().equals(targetNode)) {
-            setNetworkHopType(bucketIdInt, (InternalDistributedMember)targetNode);
+          if (name.startsWith("ServerConnection") && !getMyId().equals(targetNode)) {
+            setNetworkHopType(bucketIdInt, (InternalDistributedMember) targetNode);
-        
+
-      }
-      catch (PRLocallyDestroyedException pde) {
+      } catch (PRLocallyDestroyedException pde) {
-      }
-      catch (EntryNotFoundException enfe) {
+      } catch (EntryNotFoundException enfe) {
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+          logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(),
+              retryNode);
-      e = new PartitionedRegionDistributionException(LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS.toLocalizedString(Integer.valueOf(count)));
+      e = new PartitionedRegionDistributionException(
+          LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS
+              .toLocalizedString(Integer.valueOf(count)));
-    logger.warn(LocalizedMessage.create(LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS, Integer.valueOf(count)), e);
+    logger.warn(LocalizedMessage.create(
+        LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GETENTRY_IN_0_ATTEMPTS,
+        Integer.valueOf(count)), e);
-   * Check for region closure, region destruction, cache closure as well as
-   * distributed system disconnect. As of 6/21/2007, there were at least four
-   * volatile variables reads and one synchonrization performed upon completion
-   * of this method.
+   * Check for region closure, region destruction, cache closure as well as distributed system
+   * disconnect. As of 6/21/2007, there were at least four volatile variables reads and one
+   * synchonrization performed upon completion of this method.
-   * @param targetNode
-   *          the node where bucket region for the key exists.
-   * @param bucketId
-   *          the bucket id for the key.
-   * @param key
-   *          the key, whose value needs to be checks
-   * @param access
-   *          true if caller wants last access time updated
+   * @param targetNode the node where bucket region for the key exists.
+   * @param bucketId the bucket id for the key.
+   * @param key the key, whose value needs to be checks
+   * @param access true if caller wants last access time updated
-   * @throws EntryNotFoundException
-   *           if the entry doesn't exist
-   * @throws ForceReattemptException
-   *           if the peer is no longer available
+   * @throws EntryNotFoundException if the entry doesn't exist
+   * @throws ForceReattemptException if the peer is no longer available
-  public EntrySnapshot getEntryRemotely(
-      InternalDistributedMember targetNode,
-      Integer bucketId, Object key, boolean access, boolean allowTombstones)
-      throws EntryNotFoundException, PrimaryBucketException,
-      ForceReattemptException {
-    FetchEntryResponse r = FetchEntryMessage
-        .send(targetNode, this, key, access);
+  public EntrySnapshot getEntryRemotely(InternalDistributedMember targetNode, Integer bucketId,
+      Object key, boolean access, boolean allowTombstones)
+      throws EntryNotFoundException, PrimaryBucketException, ForceReattemptException {
+    FetchEntryResponse r = FetchEntryMessage.send(targetNode, this, key, access);
-    if (entry != null && entry.getRawValue() == Token.TOMBSTONE){
+    if (entry != null && entry.getRawValue() == Token.TOMBSTONE) {
-  }
+      }
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-  final public Region createSubregion(String subregionName,
-      RegionAttributes regionAttributes) throws RegionExistsException,
-      TimeoutException {
+  final public Region createSubregion(String subregionName, RegionAttributes regionAttributes)
+      throws RegionExistsException, TimeoutException {
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-  public void loadSnapshot(InputStream inputStream) throws IOException,
-      ClassNotFoundException, CacheWriterException, TimeoutException {
+  public void loadSnapshot(InputStream inputStream)
+      throws IOException, ClassNotFoundException, CacheWriterException, TimeoutException {
-   * Should it destroy entry from local accessor????? 
-   * OVERRIDES
+   * Should it destroy entry from local accessor????? OVERRIDES
-  public void localDestroy(Object key, Object aCallbackArgument)
-      throws EntryNotFoundException {
+  public void localDestroy(Object key, Object aCallbackArgument) throws EntryNotFoundException {
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-  public void localInvalidate(Object key, Object aCallbackArgument)
-      throws EntryNotFoundException {
+  public void localInvalidate(Object key, Object aCallbackArgument) throws EntryNotFoundException {
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * Executes a query on this PartitionedRegion. The restrictions have already
-   * been checked. The query is a SELECT expression, and the only region it
-   * refers to is this region.
+   * Executes a query on this PartitionedRegion. The restrictions have already been checked. The
+   * query is a SELECT expression, and the only region it refers to is this region.
-  public Object executeQuery(DefaultQuery query, Object[] parameters,
-      Set buckets) throws FunctionDomainException, TypeMismatchException,
-      NameResolutionException, QueryInvocationTargetException {
+  public Object executeQuery(DefaultQuery query, Object[] parameters, Set buckets)
+      throws FunctionDomainException, TypeMismatchException, NameResolutionException,
+      QueryInvocationTargetException {
+
+   * 
-  private Object doExecuteQuery(DefaultQuery query, Object[] parameters,
-      Set buckets)
-  throws FunctionDomainException, TypeMismatchException,
-  NameResolutionException, QueryInvocationTargetException,
-  ForceReattemptException
-  {
+  private Object doExecuteQuery(DefaultQuery query, Object[] parameters, Set buckets)
+      throws FunctionDomainException, TypeMismatchException, NameResolutionException,
+      QueryInvocationTargetException, ForceReattemptException {
-    
-    if (buckets==null) { // remote buckets
+
+    if (buckets == null) { // remote buckets
-          allBuckets.add((Integer)remoteIter.next());
+          allBuckets.add((Integer) remoteIter.next());
+      } catch (NoSuchElementException stop) {
-      catch (NoSuchElementException stop) {
-      }
-    }
-    else { // local buckets
+    } else { // local buckets
-      }
-      else {
+      } else {
-          allBuckets.add((Integer)localIter.next());        
+          allBuckets.add((Integer) localIter.next());
-      }
-      catch (NoSuchElementException stop) {
+      } catch (NoSuchElementException stop) {
-          this.getValueConstraint() == null ? Object.class : this
-              .getValueConstraint()));
+          this.getValueConstraint() == null ? Object.class : this.getValueConstraint()));
-        LocalizedStrings.
-          PartitionedRegion_QUERY_MUST_BE_A_SELECT_EXPRESSION_ONLY
-            .toLocalizedString());
-    }    
+          LocalizedStrings.PartitionedRegion_QUERY_MUST_BE_A_SELECT_EXPRESSION_ONLY
+              .toLocalizedString());
+    }
-    SelectResults results = selectExpr
-        .getEmptyResultSet(parameters, getCache(), query);
+    SelectResults results = selectExpr.getEmptyResultSet(parameters, getCache(), query);
-    PartitionedRegionQueryEvaluator prqe = new PartitionedRegionQueryEvaluator(this.getSystem(), this, query,
-        parameters, results, allBuckets);
+    PartitionedRegionQueryEvaluator prqe = new PartitionedRegionQueryEvaluator(this.getSystem(),
+        this, query, parameters, results, allBuckets);
-      }
-      catch (InterruptedException e) {
+      } catch (InterruptedException e) {
-      }
-      catch (FunctionDomainException e) {
-	throw e;
-      }
-      catch (TypeMismatchException e) {
-	throw e;
-      }
-      catch (NameResolutionException e) {
-	throw e;
-      }
-      catch (QueryInvocationTargetException e) {
-	throw e;
-      }
-      catch (QueryException qe) {
-        throw new QueryInvocationTargetException(LocalizedStrings.PartitionedRegion_UNEXPECTED_QUERY_EXCEPTION_OCCURED_DURING_QUERY_EXECUTION_0.toLocalizedString(qe.getMessage()), qe);
-      }
-      finally {
+      } catch (FunctionDomainException e) {
+        throw e;
+      } catch (TypeMismatchException e) {
+        throw e;
+      } catch (NameResolutionException e) {
+        throw e;
+      } catch (QueryInvocationTargetException e) {
+        throw e;
+      } catch (QueryException qe) {
+        throw new QueryInvocationTargetException(
+            LocalizedStrings.PartitionedRegion_UNEXPECTED_QUERY_EXCEPTION_OCCURED_DURING_QUERY_EXECUTION_0
+                .toLocalizedString(qe.getMessage()),
+            qe);
+      } finally {
-    //Asif: No need to apply the limit to the SelectResults. 
+    // Asif: No need to apply the limit to the SelectResults.
-    //the results will satisfy the limit
-    // as it has been evaluated in the iteration of List to 
-    // populate the SelectsResuts     
-    //So if the results is instance of ResultsBag or is a StructSet or 
-    // a ResultsSet, if the limit exists, the data set size will 
+    // the results will satisfy the limit
+    // as it has been evaluated in the iteration of List to
+    // populate the SelectsResuts
+    // So if the results is instance of ResultsBag or is a StructSet or
+    // a ResultsSet, if the limit exists, the data set size will
-        // Set limit also, its not applied while building the final result set as order by is involved.
-       // results = new ResultsCollectionWrapper(elementType, results.asSet(), query.getLimit(parameters));
+        // Set limit also, its not applied while building the final result set as order by is
+        // involved.
+        // results = new ResultsCollectionWrapper(elementType, results.asSet(),
+        // query.getLimit(parameters));
-        SelectResults resultCount = new ResultsBag(getCachePerfStats());//Constructor with elementType not visible.
+        SelectResults resultCount = new ResultsBag(getCachePerfStats());// Constructor with
+                                                                        // elementType not visible.
-        ((ResultsBag)resultCount).addAndGetOccurence(results.size());
+        ((ResultsBag) resultCount).addAndGetOccurence(results.size());
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
-   * @throws UnsupportedOperationException
-   * OVERRIDES
+   * @throws UnsupportedOperationException OVERRIDES
- @Override
- public void clear() {
+  @Override
+  public void clear() {
-  boolean virtualPut(EntryEventImpl event,
-                     boolean ifNew,
-                     boolean ifOld,
-                     Object expectedOldValue,
-                     boolean requireOldValue,
-                     long lastModified,
-                     boolean overwriteDestroyed)
-  throws TimeoutException, CacheWriterException {
+  boolean virtualPut(EntryEventImpl event, boolean ifNew, boolean ifOld, Object expectedOldValue,
+      boolean requireOldValue, long lastModified, boolean overwriteDestroyed)
+      throws TimeoutException, CacheWriterException {
-    
+
-      InternalDistributedMember targetNode = getNodeForBucketWrite(bucketId
-          .intValue(), null);
+      InternalDistributedMember targetNode = getNodeForBucketWrite(bucketId.intValue(), null);
-          bucketStorageAssigned=false;
-          targetNode = createBucket(bucketId.intValue(), event.getNewValSizeForPR(),
-              null);
-        }
-        catch (PartitionedRegionStorageException e) {
+          bucketStorageAssigned = false;
+          targetNode = createBucket(bucketId.intValue(), event.getNewValSizeForPR(), null);
+        } catch (PartitionedRegionStorageException e) {
-        result = putInBucket(targetNode,
-                           bucketId,
-                           event,
-                           ifNew,
-                           ifOld,
-                           expectedOldValue,
-                           requireOldValue,
-                           (ifNew ? 0L : lastModified));
+        result = putInBucket(targetNode, bucketId, event, ifNew, ifOld, expectedOldValue,
+            requireOldValue, (ifNew ? 0L : lastModified));
-          logger.debug("PR.virtualPut event={} ifNew={} ifOld={} result={}", event, ifNew, ifOld, result);
+          logger.debug("PR.virtualPut event={} ifNew={} ifOld={} result={}", event, ifNew, ifOld,
+              result);
-        checkIfAboveThreshold(event);   // fix for 40502
+        checkIfAboveThreshold(event); // fix for 40502
-    	// at this time, DPAO's PutAllEntryData should be empty, we should add entry here with bucket id
-        // the message will be packed in postPutAll, include the one to local bucket, because the buckets
+        // at this time, DPAO's PutAllEntryData should be empty, we should add entry here with
+        // bucket id
+        // the message will be packed in postPutAll, include the one to local bucket, because the
+        // buckets
-    	putAllOp_save.addEntry(event, bucketId);
-    	if (logger.isDebugEnabled()) {
-    	  logger.debug("PR.virtualPut PutAll added event={} into bucket {}", event, bucketId);
-    	}
-    	result = true;
+        putAllOp_save.addEntry(event, bucketId);
+        if (logger.isDebugEnabled()) {
+          logger.debug("PR.virtualPut PutAll added event={} into bucket {}", event, bucketId);
+        }
+        result = true;
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
-//      event.setPutAllOperation(putAllOp_save); // Gester: temporary fix
+      // event.setPutAllOperation(putAllOp_save); // Gester: temporary fix
-        }
-        else {
+        } else {
-      if (!ifNew && !ifOld && !this.concurrencyChecksEnabled) { // may fail due to concurrency conflict
+      if (!ifNew && !ifOld && !this.concurrencyChecksEnabled) { // may fail due to concurrency
+                                                                // conflict
-        //throw new PartitionedRegionStorageException("unable to execute operation");
-        logger.warn(LocalizedMessage.create(
-            LocalizedStrings.PartitionedRegion_PRVIRTUALPUT_RETURNING_FALSE_WHEN_IFNEW_AND_IFOLD_ARE_BOTH_FALSE),
+        // throw new PartitionedRegionStorageException("unable to execute operation");
+        logger.warn(
+            LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_PRVIRTUALPUT_RETURNING_FALSE_WHEN_IFNEW_AND_IFOLD_ARE_BOTH_FALSE),
-  
+
-	  /*
-	   * force shared data view so that we just do the virtual op, accruing things in the put all operation for later
-	   */
+    /*
+     * force shared data view so that we just do the virtual op, accruing things in the put all
+     * operation for later
+     */
+
-    //basicDestroy(event, true, null);
+    // basicDestroy(event, true, null);
-  /* (non-Javadoc)
-   * @see org.apache.geode.internal.cache.LocalRegion#checkIfAboveThreshold(org.apache.geode.internal.cache.EntryEventImpl)
+  /*
+   * (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.LocalRegion#checkIfAboveThreshold(org.apache.geode.internal.
+   * cache.EntryEventImpl)
-  public void checkIfAboveThreshold(EntryEventImpl evi)
-      throws LowMemoryException {
+  public void checkIfAboveThreshold(EntryEventImpl evi) throws LowMemoryException {
-    List<FixedPartitionAttributesImpl> fpaList = this.getRegionAdvisor()
-        .adviseAllFixedPartitionAttributes();
-    Set<InternalDistributedMember> remoteDataStores = this.getRegionAdvisor()
-        .adviseDataStore();
-    if (!fpaList.isEmpty() 
-        || (this.fixedPAttrs != null && !this.fixedPAttrs.isEmpty()) ) {
+    List<FixedPartitionAttributesImpl> fpaList =
+        this.getRegionAdvisor().adviseAllFixedPartitionAttributes();
+    Set<InternalDistributedMember> remoteDataStores = this.getRegionAdvisor().adviseDataStore();
+    if (!fpaList.isEmpty() || (this.fixedPAttrs != null && !this.fixedPAttrs.isEmpty())) {
-    
+
-    //are any fixed PRs.
+    // are any fixed PRs.
-  
-  
+
+
-  public void postPutAllFireEvents(DistributedPutAllOperation putallOp, VersionedObjectList successfulPuts) {
+  public void postPutAllFireEvents(DistributedPutAllOperation putallOp,
+      VersionedObjectList successfulPuts) {
-  public void postRemoveAllFireEvents(DistributedRemoveAllOperation op, VersionedObjectList successfulOps) {
+  public void postRemoveAllFireEvents(DistributedRemoveAllOperation op,
+      VersionedObjectList successfulOps) {
-  
+
-   * Create PutAllPRMsgs for each bucket, and send them. 
+   * Create PutAllPRMsgs for each bucket, and send them.
-   * @param putallO
-   *                DistributedPutAllOperation object.  
-   * @param successfulPuts
-   *                not used in PartitionedRegion. 
+   * @param putallO DistributedPutAllOperation object.
+   * @param successfulPuts not used in PartitionedRegion.
-  public void postPutAllSend(DistributedPutAllOperation putallO, VersionedObjectList successfulPuts) {
+  public void postPutAllSend(DistributedPutAllOperation putallO,
+      VersionedObjectList successfulPuts) {
-    
+
-    final long startTime = PartitionedRegionStats.startTime();
-    // build all the msgs by bucketid
-    HashMap prMsgMap = putallO.createPRMessages();
-    PutAllPartialResult partialKeys = new PutAllPartialResult(putallO.putAllDataSize);
-    
-    // clear the successfulPuts list since we're actually doing the puts here
-    // and the basicPutAll work was just a way to build the DPAO object
-    Map<Object, VersionTag> keyToVersionMap = new HashMap<Object, VersionTag>(successfulPuts.size());
-    successfulPuts.clearVersions();
-    Iterator itor = prMsgMap.entrySet().iterator();
-    while (itor.hasNext()) {
-      Map.Entry mapEntry = (Map.Entry)itor.next();
-      Integer bucketId = (Integer)mapEntry.getKey();
-      PutAllPRMessage prMsg =(PutAllPRMessage)mapEntry.getValue();
-      checkReadiness();
-      long then = 0;
-      if (isDebugEnabled) {
-        then = System.currentTimeMillis();
-      }
-      try {
-        VersionedObjectList versions = sendMsgByBucket(bucketId, prMsg);
-        if (versions.size() > 0) {
-          partialKeys.addKeysAndVersions(versions);
-          versions.saveVersions(keyToVersionMap);
-        } else if (!this.concurrencyChecksEnabled) { // no keys returned if not versioned
-          Set keys = prMsg.getKeys();
-          partialKeys.addKeys(keys);
-        }
-      } catch (PutAllPartialResultException pre) {
-        // sendMsgByBucket applied partial keys 
-        if (isDebugEnabled) {
-          logger.debug("PR.postPutAll encountered PutAllPartialResultException, ",pre);
-        }
-        partialKeys.consolidate(pre.getResult());
-      } catch (Exception ex) {
-        // If failed at other exception
-        if (isDebugEnabled) {
-          logger.debug("PR.postPutAll encountered exception at sendMsgByBucket, ",ex);
-        }
-        @Released EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
-        try {
-          partialKeys.saveFailedKey(firstEvent.getKey(), ex);
-        } finally {
-          firstEvent.release();
-        }
-      }
-      if (isDebugEnabled) {
-        long now = System.currentTimeMillis();
-        if ((now - then) >= 10000) {
-          logger.debug("PR.sendMsgByBucket took "+(now-then)+" ms");
-        }
-      }
-    }
-    this.prStats.endPutAll(startTime);
-    if (!keyToVersionMap.isEmpty()) {
-      for (Iterator it=successfulPuts.getKeys().iterator(); it.hasNext(); ) {
-        successfulPuts.addVersion(keyToVersionMap.get(it.next()));
-      }
-      keyToVersionMap.clear();
-    }
+      final long startTime = PartitionedRegionStats.startTime();
+      // build all the msgs by bucketid
+      HashMap prMsgMap = putallO.createPRMessages();
+      PutAllPartialResult partialKeys = new PutAllPartialResult(putallO.putAllDataSize);
-    if (partialKeys.hasFailure()) {
-      logger.info(LocalizedMessage.create(LocalizedStrings.Region_PutAll_Applied_PartialKeys_0_1,
-          new Object[] {getFullPath(), partialKeys}));
-      if (putallO.isBridgeOperation()) {
-        if (partialKeys.getFailure() instanceof CancelException) {
-          throw (CancelException)partialKeys.getFailure(); 
-        } else {
-          throw new PutAllPartialResultException(partialKeys);
+      // clear the successfulPuts list since we're actually doing the puts here
+      // and the basicPutAll work was just a way to build the DPAO object
+      Map<Object, VersionTag> keyToVersionMap =
+          new HashMap<Object, VersionTag>(successfulPuts.size());
+      successfulPuts.clearVersions();
+      Iterator itor = prMsgMap.entrySet().iterator();
+      while (itor.hasNext()) {
+        Map.Entry mapEntry = (Map.Entry) itor.next();
+        Integer bucketId = (Integer) mapEntry.getKey();
+        PutAllPRMessage prMsg = (PutAllPRMessage) mapEntry.getValue();
+        checkReadiness();
+        long then = 0;
+        if (isDebugEnabled) {
+          then = System.currentTimeMillis();
-      } else {
-        if (partialKeys.getFailure() instanceof RuntimeException) {
-          throw (RuntimeException)partialKeys.getFailure();
-        } else {
-          throw new RuntimeException(partialKeys.getFailure());
+        try {
+          VersionedObjectList versions = sendMsgByBucket(bucketId, prMsg);
+          if (versions.size() > 0) {
+            partialKeys.addKeysAndVersions(versions);
+            versions.saveVersions(keyToVersionMap);
+          } else if (!this.concurrencyChecksEnabled) { // no keys returned if not versioned
+            Set keys = prMsg.getKeys();
+            partialKeys.addKeys(keys);
+          }
+        } catch (PutAllPartialResultException pre) {
+          // sendMsgByBucket applied partial keys
+          if (isDebugEnabled) {
+            logger.debug("PR.postPutAll encountered PutAllPartialResultException, ", pre);
+          }
+          partialKeys.consolidate(pre.getResult());
+        } catch (Exception ex) {
+          // If failed at other exception
+          if (isDebugEnabled) {
+            logger.debug("PR.postPutAll encountered exception at sendMsgByBucket, ", ex);
+          }
+          @Released
+          EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
+          try {
+            partialKeys.saveFailedKey(firstEvent.getKey(), ex);
+          } finally {
+            firstEvent.release();
+          }
-      }
-    } 
-    } finally {
-      /*
-// TODO XD OFFHEAP MERGE: do we have any events that need freeOffHeapReferences
-      for (PutAllPRMessage.PutAllResponse resp : responses) {
-        PutAllPRMessage.PRMsgResponseContext ctx = resp.getContextObject();
-        if (ctx != null) {
-          EntryEventImpl e = ctx.getEvent();
-          if (e != null) {
-            e.release();
+        if (isDebugEnabled) {
+          long now = System.currentTimeMillis();
+          if ((now - then) >= 10000) {
+            logger.debug("PR.sendMsgByBucket took " + (now - then) + " ms");
-      */
+      this.prStats.endPutAll(startTime);
+      if (!keyToVersionMap.isEmpty()) {
+        for (Iterator it = successfulPuts.getKeys().iterator(); it.hasNext();) {
+          successfulPuts.addVersion(keyToVersionMap.get(it.next()));
+        }
+        keyToVersionMap.clear();
+      }
+
+      if (partialKeys.hasFailure()) {
+        logger.info(LocalizedMessage.create(LocalizedStrings.Region_PutAll_Applied_PartialKeys_0_1,
+            new Object[] {getFullPath(), partialKeys}));
+        if (putallO.isBridgeOperation()) {
+          if (partialKeys.getFailure() instanceof CancelException) {
+            throw (CancelException) partialKeys.getFailure();
+          } else {
+            throw new PutAllPartialResultException(partialKeys);
+          }
+        } else {
+          if (partialKeys.getFailure() instanceof RuntimeException) {
+            throw (RuntimeException) partialKeys.getFailure();
+          } else {
+            throw new RuntimeException(partialKeys.getFailure());
+          }
+        }
+      }
+    } finally {
+      /*
+       * // TODO XD OFFHEAP MERGE: do we have any events that need freeOffHeapReferences for
+       * (PutAllPRMessage.PutAllResponse resp : responses) { PutAllPRMessage.PRMsgResponseContext
+       * ctx = resp.getContextObject(); if (ctx != null) { EntryEventImpl e = ctx.getEvent(); if (e
+       * != null) { e.release(); } } }
+       */
+
-  public void postRemoveAllSend(DistributedRemoveAllOperation op, VersionedObjectList successfulOps) {
+  public void postRemoveAllSend(DistributedRemoveAllOperation op,
+      VersionedObjectList successfulOps) {
-    
+
-    
+
-      Integer bucketId = (Integer)mapEntry.getKey();
+      Integer bucketId = (Integer) mapEntry.getKey();
-        // sendMsgByBucket applied partial keys 
+        // sendMsgByBucket applied partial keys
-          logger.debug("PR.postRemoveAll encountered BulkOpPartialResultException, ",pre);
+          logger.debug("PR.postRemoveAll encountered BulkOpPartialResultException, ", pre);
-          logger.debug("PR.postRemoveAll encountered exception at sendMsgByBucket, ",ex);
+          logger.debug("PR.postRemoveAll encountered exception at sendMsgByBucket, ", ex);
-        @Released EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
+        @Released
+        EntryEventImpl firstEvent = prMsg.getFirstEvent(this);
-          logger.debug("PR.sendMsgByBucket took {} ms", (now-then));
+          logger.debug("PR.sendMsgByBucket took {} ms", (now - then));
-      for (Iterator it=successfulOps.getKeys().iterator(); it.hasNext(); ) {
+      for (Iterator it = successfulOps.getKeys().iterator(); it.hasNext();) {
-          throw (CancelException)partialKeys.getFailure(); 
+          throw (CancelException) partialKeys.getFailure();
-          throw (RuntimeException)partialKeys.getFailure();
+          throw (RuntimeException) partialKeys.getFailure();
-    } 
+    }
-  /* If failed after retries, it will throw PartitionedRegionStorageException, no need for return value */
-  private VersionedObjectList sendMsgByBucket(final Integer bucketId, PutAllPRMessage prMsg)
-  {
+  /*
+   * If failed after retries, it will throw PartitionedRegionStorageException, no need for return
+   * value
+   */
+  private VersionedObjectList sendMsgByBucket(final Integer bucketId, PutAllPRMessage prMsg) {
-    
+
-    @Released EntryEventImpl event = prMsg.getFirstEvent(this);
+    @Released
+    EntryEventImpl event = prMsg.getFirstEvent(this);
-    RetryTimeKeeper retryTime = null;
-    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
-    if (isDebugEnabled) {
-      logger.debug("PR.sendMsgByBucket:bucket {}'s currentTarget is {}", bucketId, currentTarget);
-    }
-    
-    long timeOut = 0;
-    int count = 0;
-    for (;;) {
-      switch (count) {
-        case 0:
-          // Note we don't check for DM cancellation in common case.
-          // First time.  Assume success, keep going.
-          break;
-        case 1:
-          this.cache.getCancelCriterion().checkCancelInProgress(null);
-          // Second time (first failure).  Calculate timeout and keep going.
-          timeOut = System.currentTimeMillis() + this.retryTimeout;
-          break;
-        default:
-          this.cache.getCancelCriterion().checkCancelInProgress(null);
-          // test for timeout
-          long timeLeft = timeOut - System.currentTimeMillis();
-          if (timeLeft < 0) {
-            PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
-            // NOTREACHED
-          }
+      RetryTimeKeeper retryTime = null;
+      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
+      if (isDebugEnabled) {
+        logger.debug("PR.sendMsgByBucket:bucket {}'s currentTarget is {}", bucketId, currentTarget);
+      }
-          // Didn't time out.  Sleep a bit and then continue
-          boolean interrupted = Thread.interrupted();
-          try {
-            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
-          }
-          catch (InterruptedException e) {
-            interrupted = true;
-          }
-          finally {
-            if (interrupted) {
-              Thread.currentThread().interrupt();
+      long timeOut = 0;
+      int count = 0;
+      for (;;) {
+        switch (count) {
+          case 0:
+            // Note we don't check for DM cancellation in common case.
+            // First time. Assume success, keep going.
+            break;
+          case 1:
+            this.cache.getCancelCriterion().checkCancelInProgress(null);
+            // Second time (first failure). Calculate timeout and keep going.
+            timeOut = System.currentTimeMillis() + this.retryTimeout;
+            break;
+          default:
+            this.cache.getCancelCriterion().checkCancelInProgress(null);
+            // test for timeout
+            long timeLeft = timeOut - System.currentTimeMillis();
+            if (timeLeft < 0) {
+              PRHARedundancyProvider.timedOut(this, null, null, "update an entry",
+                  this.retryTimeout);
+              // NOTREACHED
+
+            // Didn't time out. Sleep a bit and then continue
+            boolean interrupted = Thread.interrupted();
+            try {
+              Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
+            } catch (InterruptedException e) {
+              interrupted = true;
+            } finally {
+              if (interrupted) {
+                Thread.currentThread().interrupt();
+              }
+            }
+            break;
+        } // switch
+        count++;
+
+        if (currentTarget == null) { // pick target
+          checkReadiness();
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
-          break;
-      } // switch
-      count ++;
-      if (currentTarget == null) { // pick target
-        checkReadiness();
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-
-        currentTarget = waitForNodeOrCreateBucket(retryTime, event, bucketId);
-        if (isDebugEnabled) {
-          logger.debug("PR.sendMsgByBucket: event size is {}, new currentTarget is {}", getEntrySize(event), currentTarget);
-        }
-
-        // It's possible this is a GemFire thread e.g. ServerConnection 
-        // which got to this point because of a distributed system shutdown or 
-        // region closure which uses interrupt to break any sleep() or wait() calls
-        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception
-        checkShutdown();
-        continue;
-      } // pick target
-
-      try {
-        return tryToSendOnePutAllMessage(prMsg,currentTarget);
-      }
-      catch (ForceReattemptException prce) {
-        checkReadiness();
-        InternalDistributedMember lastTarget = currentTarget;
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
-        if (isDebugEnabled) {
-          logger.debug("PR.sendMsgByBucket: Old target was {}, Retrying", lastTarget, currentTarget);
-        }
-        if (lastTarget.equals(currentTarget)) {
+          currentTarget = waitForNodeOrCreateBucket(retryTime, event, bucketId);
-            logger.debug("PR.sendMsgByBucket: Retrying at the same node:{} due to {}", currentTarget, prce.getMessage());
+            logger.debug("PR.sendMsgByBucket: event size is {}, new currentTarget is {}",
+                getEntrySize(event), currentTarget);
-          if (retryTime.overMaximum()) {
-            PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
-            // NOTREACHED
-          }
-          retryTime.waitToRetryNode();
-        }
-        event.setPossibleDuplicate(true);
-        if (prMsg != null) {
-          prMsg.setPossibleDuplicate(true);
-        }
-      }
-      catch (PrimaryBucketException notPrimary) {
-        if (isDebugEnabled) {
-          logger.debug("Bucket {} on Node {} not primnary", notPrimary.getLocalizedMessage(), currentTarget);
-        }
-        getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
-      }
-      catch (DataLocationException dle) {
-        if (isDebugEnabled) {
-          logger.debug("DataLocationException processing putAll", dle);
-        }
-    	throw new TransactionException(dle);
-      }
-      // It's possible this is a GemFire thread e.g. ServerConnection
-      // which got to this point because of a distributed system shutdown or
-      // region closure which uses interrupt to break any sleep() or wait()
-      // calls
-      // e.g. waitForPrimary or waitForBucketRecovery in which case throw
-      // exception
-      checkShutdown();
-      
-      // If we get here, the attempt failed...
-      if (count == 1) {
-        this.prStats.incPutAllMsgsRetried();
-      }
-      this.prStats.incPutAllRetries();
-    } // for
+          // It's possible this is a GemFire thread e.g. ServerConnection
+          // which got to this point because of a distributed system shutdown or
+          // region closure which uses interrupt to break any sleep() or wait() calls
+          // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception
+          checkShutdown();
+          continue;
+        } // pick target
+
+        try {
+          return tryToSendOnePutAllMessage(prMsg, currentTarget);
+        } catch (ForceReattemptException prce) {
+          checkReadiness();
+          InternalDistributedMember lastTarget = currentTarget;
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
+          }
+          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          if (isDebugEnabled) {
+            logger.debug("PR.sendMsgByBucket: Old target was {}, Retrying", lastTarget,
+                currentTarget);
+          }
+          if (lastTarget.equals(currentTarget)) {
+            if (isDebugEnabled) {
+              logger.debug("PR.sendMsgByBucket: Retrying at the same node:{} due to {}",
+                  currentTarget, prce.getMessage());
+            }
+            if (retryTime.overMaximum()) {
+              PRHARedundancyProvider.timedOut(this, null, null, "update an entry",
+                  this.retryTimeout);
+              // NOTREACHED
+            }
+            retryTime.waitToRetryNode();
+          }
+          event.setPossibleDuplicate(true);
+          if (prMsg != null) {
+            prMsg.setPossibleDuplicate(true);
+          }
+        } catch (PrimaryBucketException notPrimary) {
+          if (isDebugEnabled) {
+            logger.debug("Bucket {} on Node {} not primnary", notPrimary.getLocalizedMessage(),
+                currentTarget);
+          }
+          getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
+          }
+          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+        } catch (DataLocationException dle) {
+          if (isDebugEnabled) {
+            logger.debug("DataLocationException processing putAll", dle);
+          }
+          throw new TransactionException(dle);
+        }
+
+        // It's possible this is a GemFire thread e.g. ServerConnection
+        // which got to this point because of a distributed system shutdown or
+        // region closure which uses interrupt to break any sleep() or wait()
+        // calls
+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw
+        // exception
+        checkShutdown();
+
+        // If we get here, the attempt failed...
+        if (count == 1) {
+          this.prStats.incPutAllMsgsRetried();
+        }
+        this.prStats.incPutAllRetries();
+      } // for
-  /* If failed after retries, it will throw PartitionedRegionStorageException, no need for return value */
-  private VersionedObjectList sendMsgByBucket(final Integer bucketId, RemoveAllPRMessage prMsg)
-  {
+  /*
+   * If failed after retries, it will throw PartitionedRegionStorageException, no need for return
+   * value
+   */
+  private VersionedObjectList sendMsgByBucket(final Integer bucketId, RemoveAllPRMessage prMsg) {
-    @Released EntryEventImpl event = prMsg.getFirstEvent(this);
+    @Released
+    EntryEventImpl event = prMsg.getFirstEvent(this);
-    RetryTimeKeeper retryTime = null;
-    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
-    if (logger.isDebugEnabled()) {
-      logger.debug("PR.sendMsgByBucket:bucket {}'s currentTarget is {}", bucketId, currentTarget);
-    }
-    
-    long timeOut = 0;
-    int count = 0;
-    for (;;) {
-      switch (count) {
-        case 0:
-          // Note we don't check for DM cancellation in common case.
-          // First time.  Assume success, keep going.
-          break;
-        case 1:
-          this.cache.getCancelCriterion().checkCancelInProgress(null);
-          // Second time (first failure).  Calculate timeout and keep going.
-          timeOut = System.currentTimeMillis() + this.retryTimeout;
-          break;
-        default:
-          this.cache.getCancelCriterion().checkCancelInProgress(null);
-          // test for timeout
-          long timeLeft = timeOut - System.currentTimeMillis();
-          if (timeLeft < 0) {
-            PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
-            // NOTREACHED
-          }
+      RetryTimeKeeper retryTime = null;
+      InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId.intValue(), null);
+      if (logger.isDebugEnabled()) {
+        logger.debug("PR.sendMsgByBucket:bucket {}'s currentTarget is {}", bucketId, currentTarget);
+      }
-          // Didn't time out.  Sleep a bit and then continue
-          boolean interrupted = Thread.interrupted();
-          try {
-            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
-          }
-          catch (InterruptedException e) {
-            interrupted = true;
-          }
-          finally {
-            if (interrupted) {
-              Thread.currentThread().interrupt();
+      long timeOut = 0;
+      int count = 0;
+      for (;;) {
+        switch (count) {
+          case 0:
+            // Note we don't check for DM cancellation in common case.
+            // First time. Assume success, keep going.
+            break;
+          case 1:
+            this.cache.getCancelCriterion().checkCancelInProgress(null);
+            // Second time (first failure). Calculate timeout and keep going.
+            timeOut = System.currentTimeMillis() + this.retryTimeout;
+            break;
+          default:
+            this.cache.getCancelCriterion().checkCancelInProgress(null);
+            // test for timeout
+            long timeLeft = timeOut - System.currentTimeMillis();
+            if (timeLeft < 0) {
+              PRHARedundancyProvider.timedOut(this, null, null, "update an entry",
+                  this.retryTimeout);
+              // NOTREACHED
+
+            // Didn't time out. Sleep a bit and then continue
+            boolean interrupted = Thread.interrupted();
+            try {
+              Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
+            } catch (InterruptedException e) {
+              interrupted = true;
+            } finally {
+              if (interrupted) {
+                Thread.currentThread().interrupt();
+              }
+            }
+            break;
+        } // switch
+        count++;
+
+        if (currentTarget == null) { // pick target
+          checkReadiness();
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
-          break;
-      } // switch
-      count ++;
-      if (currentTarget == null) { // pick target
-        checkReadiness();
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-
-        currentTarget = waitForNodeOrCreateBucket(retryTime, event, bucketId);
-        if (logger.isDebugEnabled()) {
-          logger.debug("PR.sendMsgByBucket: event size is {}, new currentTarget is {}", getEntrySize(event), currentTarget);
-        }
-
-        // It's possible this is a GemFire thread e.g. ServerConnection 
-        // which got to this point because of a distributed system shutdown or 
-        // region closure which uses interrupt to break any sleep() or wait() calls
-        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception
-        checkShutdown();
-        continue;
-      } // pick target
-
-      try {
-        return tryToSendOneRemoveAllMessage(prMsg,currentTarget);
-      }
-      catch (ForceReattemptException prce) {
-        checkReadiness();
-        InternalDistributedMember lastTarget = currentTarget;
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
-        if (logger.isTraceEnabled()) {
-          logger.trace("PR.sendMsgByBucket: Old target was {}, Retrying {}", lastTarget, currentTarget);
-        }
-        if (lastTarget.equals(currentTarget)) {
+          currentTarget = waitForNodeOrCreateBucket(retryTime, event, bucketId);
-            logger.debug("PR.sendMsgByBucket: Retrying at the same node:{} due to {}", currentTarget, prce.getMessage());
+            logger.debug("PR.sendMsgByBucket: event size is {}, new currentTarget is {}",
+                getEntrySize(event), currentTarget);
-          if (retryTime.overMaximum()) {
-            PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
-            // NOTREACHED
-          }
-          retryTime.waitToRetryNode();
-        }
-        event.setPossibleDuplicate(true);
-        if (prMsg != null) {
-          prMsg.setPossibleDuplicate(true);
-        }
-      }
-      catch (PrimaryBucketException notPrimary) {
-        if (logger.isDebugEnabled()) {
-          logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), currentTarget);
-        }
-        getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
-        if (retryTime == null) {
-          retryTime = new RetryTimeKeeper(this.retryTimeout);
-        }
-        currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
-      }
-      catch (DataLocationException dle) {
-        if (logger.isDebugEnabled()) {
-          logger.debug("DataLocationException processing putAll",dle);
-        }
-        throw new TransactionException(dle);
-      }
-      // It's possible this is a GemFire thread e.g. ServerConnection
-      // which got to this point because of a distributed system shutdown or
-      // region closure which uses interrupt to break any sleep() or wait()
-      // calls
-      // e.g. waitForPrimary or waitForBucketRecovery in which case throw
-      // exception
-      checkShutdown();
-      
-      // If we get here, the attempt failed...
-      if (count == 1) {
-        this.prStats.incRemoveAllMsgsRetried();
-      }
-      this.prStats.incRemoveAllRetries();
-    } // for
-    // NOTREACHED
+          // It's possible this is a GemFire thread e.g. ServerConnection
+          // which got to this point because of a distributed system shutdown or
+          // region closure which uses interrupt to break any sleep() or wait() calls
+          // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception
+          checkShutdown();
+          continue;
+        } // pick target
+
+        try {
+          return tryToSendOneRemoveAllMessage(prMsg, currentTarget);
+        } catch (ForceReattemptException prce) {
+          checkReadiness();
+          InternalDistributedMember lastTarget = currentTarget;
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
+          }
+          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+          if (logger.isTraceEnabled()) {
+            logger.trace("PR.sendMsgByBucket: Old target was {}, Retrying {}", lastTarget,
+                currentTarget);
+          }
+          if (lastTarget.equals(currentTarget)) {
+            if (logger.isDebugEnabled()) {
+              logger.debug("PR.sendMsgByBucket: Retrying at the same node:{} due to {}",
+                  currentTarget, prce.getMessage());
+            }
+            if (retryTime.overMaximum()) {
+              PRHARedundancyProvider.timedOut(this, null, null, "update an entry",
+                  this.retryTimeout);
+              // NOTREACHED
+            }
+            retryTime.waitToRetryNode();
+          }
+          event.setPossibleDuplicate(true);
+          if (prMsg != null) {
+            prMsg.setPossibleDuplicate(true);
+          }
+        } catch (PrimaryBucketException notPrimary) {
+          if (logger.isDebugEnabled()) {
+            logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(),
+                currentTarget);
+          }
+          getRegionAdvisor().notPrimary(bucketId.intValue(), currentTarget);
+          if (retryTime == null) {
+            retryTime = new RetryTimeKeeper(this.retryTimeout);
+          }
+          currentTarget = getNodeForBucketWrite(bucketId.intValue(), retryTime);
+        } catch (DataLocationException dle) {
+          if (logger.isDebugEnabled()) {
+            logger.debug("DataLocationException processing putAll", dle);
+          }
+          throw new TransactionException(dle);
+        }
+
+        // It's possible this is a GemFire thread e.g. ServerConnection
+        // which got to this point because of a distributed system shutdown or
+        // region closure which uses interrupt to break any sleep() or wait()
+        // calls
+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw
+        // exception
+        checkShutdown();
+
+        // If we get here, the attempt failed...
+        if (count == 1) {
+          this.prStats.incRemoveAllMsgsRetried();
+        }
+        this.prStats.incRemoveAllRetries();
+      } // for
+      // NOTREACHED
-  public VersionedObjectList tryToSendOnePutAllMessage(PutAllPRMessage prMsg,InternalDistributedMember currentTarget) throws DataLocationException {
+  public VersionedObjectList tryToSendOnePutAllMessage(PutAllPRMessage prMsg,
+      InternalDistributedMember currentTarget) throws DataLocationException {
-      putResult = prMsg.doLocalPutAll(this, this.getDistributionManager().getDistributionManagerId(), 0L);
+      putResult =
+          prMsg.doLocalPutAll(this, this.getDistributionManager().getDistributionManagerId(), 0L);
-      PutAllPRMessage.PutAllResponse response = (PutAllPRMessage.PutAllResponse)prMsg.send(currentTarget, this); 
+      PutAllPRMessage.PutAllResponse response =
+          (PutAllPRMessage.PutAllResponse) prMsg.send(currentTarget, this);
-        }
-        catch (RegionDestroyedException rde) {
+        } catch (RegionDestroyedException rde) {
-        }
-        catch (CacheException ce) {
+        } catch (CacheException ce) {
-          throw new PartitionedRegionDistributionException("prMsg.send on "
-              + currentTarget + " failed", ce);
+          throw new PartitionedRegionDistributionException(
+              "prMsg.send on " + currentTarget + " failed", ce);
-    
+
-      // retry exception when msg failed in waitForResult()  
-      ForceReattemptException fre = new ForceReattemptException(
-          "false result in PutAllMessage.send - retrying");
+      // retry exception when msg failed in waitForResult()
+      ForceReattemptException fre =
+          new ForceReattemptException("false result in PutAllMessage.send - retrying");
-  public VersionedObjectList tryToSendOneRemoveAllMessage(RemoveAllPRMessage prMsg,InternalDistributedMember currentTarget) throws DataLocationException {
+  public VersionedObjectList tryToSendOneRemoveAllMessage(RemoveAllPRMessage prMsg,
+      InternalDistributedMember currentTarget) throws DataLocationException {
-      putResult = prMsg.doLocalRemoveAll(this, this.getDistributionManager().getDistributionManagerId(), true);
+      putResult = prMsg.doLocalRemoveAll(this,
+          this.getDistributionManager().getDistributionManagerId(), true);
-      RemoveAllPRMessage.RemoveAllResponse response = (RemoveAllPRMessage.RemoveAllResponse)prMsg.send(currentTarget, this); 
+      RemoveAllPRMessage.RemoveAllResponse response =
+          (RemoveAllPRMessage.RemoveAllResponse) prMsg.send(currentTarget, this);
-        }
-        catch (RegionDestroyedException rde) {
+        } catch (RegionDestroyedException rde) {
-        }
-        catch (CacheException ce) {
+        } catch (CacheException ce) {
-          throw new PartitionedRegionDistributionException("prMsg.send on "
-              + currentTarget + " failed", ce);
+          throw new PartitionedRegionDistributionException(
+              "prMsg.send on " + currentTarget + " failed", ce);
-    
+
-      // retry exception when msg failed in waitForResult()  
-      ForceReattemptException fre = new ForceReattemptException(
-          "false result in PutAllMessage.send - retrying");
+      // retry exception when msg failed in waitForResult()
+      ForceReattemptException fre =
+          new ForceReattemptException("false result in PutAllMessage.send - retrying");
-/**
-   * Performs the {@link Operation#UPDATE put} operation in the bucket on the
-   * remote VM and invokes "put" callbacks
+  /**
+   * Performs the {@link Operation#UPDATE put} operation in the bucket on the remote VM and invokes
+   * "put" callbacks
-   * @param targetNode
-   *          the VM in whose {@link PartitionedRegionDataStore} contains the
-   *          bucket
-   * @param bucketId
-   *                the identity of the bucket
-   * @param event
-   *                the event that contains the key and value
-   * @param lastModified
-   *                the timestamp that the entry was modified
-   * @param ifNew
-   *                true=can create a new key false=can't create a new key
-   * @param ifOld
-   *                true=can update existing entry false=can't update existing
-   *                entry
-   * @param expectedOldValue
-   *          only succeed if old value is equal to this value. If null,
-   *          then doesn't matter what old value is. If INVALID token,
-   *          must be INVALID.
-   * @see LocalRegion#virtualPut(EntryEventImpl, boolean, boolean, Object, boolean, long,
-   *      boolean)
-   * @return false if ifNew is true and there is an existing key, or ifOld is
-   *         true and there is no existing entry; otherwise return true.
+   * @param targetNode the VM in whose {@link PartitionedRegionDataStore} contains the bucket
+   * @param bucketId the identity of the bucket
+   * @param event the event that contains the key and value
+   * @param lastModified the timestamp that the entry was modified
+   * @param ifNew true=can create a new key false=can't create a new key
+   * @param ifOld true=can update existing entry false=can't update existing entry
+   * @param expectedOldValue only succeed if old value is equal to this value. If null, then doesn't
+   *        matter what old value is. If INVALID token, must be INVALID.
+   * @see LocalRegion#virtualPut(EntryEventImpl, boolean, boolean, Object, boolean, long, boolean)
+   * @return false if ifNew is true and there is an existing key, or ifOld is true and there is no
+   *         existing entry; otherwise return true.
-  private boolean putInBucket(final InternalDistributedMember targetNode, 
-                              final Integer bucketId,
-                              final EntryEventImpl event,
-                              final boolean ifNew,
-                              boolean ifOld,
-                              Object expectedOldValue,
-                              boolean requireOldValue,
-                              final long lastModified) {
+  private boolean putInBucket(final InternalDistributedMember targetNode, final Integer bucketId,
+      final EntryEventImpl event, final boolean ifNew, boolean ifOld, Object expectedOldValue,
+      boolean requireOldValue, final long lastModified) {
-      logger.debug("putInBucket: {} ({}) to {} to bucketId={} retry={} ms",
-          event.getKey(), event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId.intValue()), retryTimeout);
+      logger.debug("putInBucket: {} ({}) to {} to bucketId={} retry={} ms", event.getKey(),
+          event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId.intValue()),
+          retryTimeout);
-      case 0:
-        // Note we don't check for DM cancellation in common case.
-        // First time.  Assume success, keep going.
-        break;
-      case 1:
-        this.cache.getCancelCriterion().checkCancelInProgress(null);
-        // Second time (first failure).  Calculate timeout and keep going.
-        timeOut = System.currentTimeMillis() + this.retryTimeout;
-        break;
-      default:
-        this.cache.getCancelCriterion().checkCancelInProgress(null);
-        // test for timeout
-        long timeLeft = timeOut - System.currentTimeMillis();
-        if (timeLeft < 0) {
-          PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
-          // NOTREACHED
-        }
-
-        // Didn't time out.  Sleep a bit and then continue
-        boolean interrupted = Thread.interrupted();
-        try {
-          Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
-        }
-        catch (InterruptedException e) {
-          interrupted = true;
-        }
-        finally {
-          if (interrupted) {
-            Thread.currentThread().interrupt();
+        case 0:
+          // Note we don't check for DM cancellation in common case.
+          // First time. Assume success, keep going.
+          break;
+        case 1:
+          this.cache.getCancelCriterion().checkCancelInProgress(null);
+          // Second time (first failure). Calculate timeout and keep going.
+          timeOut = System.currentTimeMillis() + this.retryTimeout;
+          break;
+        default:
+          this.cache.getCancelCriterion().checkCancelInProgress(null);
+          // test for timeout
+          long timeLeft = timeOut - System.currentTimeMillis();
+          if (timeLeft < 0) {
+            PRHARedundancyProvider.timedOut(this, null, null, "update an entry", this.retryTimeout);
+            // NOTREACHED
-        }
-        break;
+
+          // Didn't time out. Sleep a bit and then continue
+          boolean interrupted = Thread.interrupted();
+          try {
+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
+          } catch (InterruptedException e) {
+            interrupted = true;
+          } finally {
+            if (interrupted) {
+              Thread.currentThread().interrupt();
+            }
+          }
+          break;
-      count ++;
-      
+      count++;
+
-        // It's possible this is a GemFire thread e.g. ServerConnection 
-        // which got to this point because of a distributed system shutdown or 
+        // It's possible this is a GemFire thread e.g. ServerConnection
+        // which got to this point because of a distributed system shutdown or
-      
+
-              currentTarget, ifNew, ifOld,  isLocal);
+              currentTarget, ifNew, ifOld, isLocal);
-//          final boolean cacheWrite = !event.isOriginRemote()
-//              && !event.isNetSearch();
-//          if (cacheWrite) {
-//            doCacheWriteBeforePut(event, ifNew);
-//          }
+          // final boolean cacheWrite = !event.isOriginRemote()
+          // && !event.isNetSearch();
+          // if (cacheWrite) {
+          // doCacheWriteBeforePut(event, ifNew);
+          // }
-          try {   
-            final BucketRegion br = this.dataStore.getInitializedBucketForId(event.getKey(), bucketId);
+          try {
+            final BucketRegion br =
+                this.dataStore.getInitializedBucketForId(event.getKey(), bucketId);
-            if (! DistributionManager.isFunctionExecutionThread.get().booleanValue()) {
-              // TODO: this condition may not help since BucketRegion.virtualPut calls forceSerialized
+            if (!DistributionManager.isFunctionExecutionThread.get().booleanValue()) {
+              // TODO: this condition may not help since BucketRegion.virtualPut calls
+              // forceSerialized
-          if (ifNew) {
-            result = this.dataStore.createLocally(br,
-                                                  event,
-                                                  ifNew,
-                                                  ifOld,
-                                                  requireOldValue,
-                                                  lastModified);
-          }
-          else {
-            result = this.dataStore.putLocally(br,
-                                               event,
-                                               ifNew, 
-                                               ifOld,
-                                               expectedOldValue,
-                                               requireOldValue,
-                                               lastModified);
-          }
+            if (ifNew) {
+              result = this.dataStore.createLocally(br, event, ifNew, ifOld, requireOldValue,
+                  lastModified);
+            } else {
+              result = this.dataStore.putLocally(br, event, ifNew, ifOld, expectedOldValue,
+                  requireOldValue, lastModified);
+            }
-          if (ifNew) {
-            result = createRemotely(currentTarget,
-                                    bucketId,
-                                    event,
-                                    requireOldValue);
-          }
-          else {
-            result = putRemotely(currentTarget,
-                                 event,
-                                 ifNew,
-                                 ifOld,
-                                 expectedOldValue,
-                                 requireOldValue);
-            if (!requireOldValue) {
-              // make sure old value is set to NOT_AVAILABLE token
-              event.oldValueNotAvailable();
+            if (ifNew) {
+              result = createRemotely(currentTarget, bucketId, event, requireOldValue);
+            } else {
+              result = putRemotely(currentTarget, event, ifNew, ifOld, expectedOldValue,
+                  requireOldValue);
+              if (!requireOldValue) {
+                // make sure old value is set to NOT_AVAILABLE token
+                event.oldValueNotAvailable();
+              }
-          }
-          ForceReattemptException fre = new ForceReattemptException(LocalizedStrings.PartitionedRegion_FALSE_RESULT_WHEN_IFNEW_AND_IFOLD_IS_UNACCEPTABLE_RETRYING.toLocalizedString());
+          ForceReattemptException fre = new ForceReattemptException(
+              LocalizedStrings.PartitionedRegion_FALSE_RESULT_WHEN_IFNEW_AND_IFOLD_IS_UNACCEPTABLE_RETRYING
+                  .toLocalizedString());
-          logger.trace("ConcurrentCacheModificationException received for putInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
+          logger.trace(
+              "ConcurrentCacheModificationException received for putInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-          logger.debug("putInBucket: Got ForceReattemptException for {} on VM {} for node {}{}{} for bucket = {}",
+          logger.debug(
+              "putInBucket: Got ForceReattemptException for {} on VM {} for node {}{}{} for bucket = {}",
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), currentTarget);
+          logger.debug("Bucket {} on Node {} not primary", notPrimary.getLocalizedMessage(),
+              currentTarget);
-        }
-        else {
+        } else {
-      }
-      else {
+      } else {
-        logger.debug("putInBucket for bucketId = {} failed (attempt # {} ({} ms left), retrying with node {}", 
-            bucketStringForLogs(bucketId.intValue()), count, (timeOut - System.currentTimeMillis()), currentTarget);
+        logger.debug(
+            "putInBucket for bucketId = {} failed (attempt # {} ({} ms left), retrying with node {}",
+            bucketStringForLogs(bucketId.intValue()), count, (timeOut - System.currentTimeMillis()),
+            currentTarget);
-   * Find an existing live Node that owns the bucket, or create the bucket and
-   * return one of its owners.
+   * Find an existing live Node that owns the bucket, or create the bucket and return one of its
+   * owners.
-   * @param retryTime
-   *                the RetryTimeKeeper to track retry times
-   * @param event
-   *                the event used to get the entry size in the event a new
-   *                bucket should be created
-   * @param bucketId
-   *                the identity of the bucket should it be created
+   * @param retryTime the RetryTimeKeeper to track retry times
+   * @param event the event used to get the entry size in the event a new bucket should be created
+   * @param bucketId the identity of the bucket should it be created
-  private InternalDistributedMember waitForNodeOrCreateBucket(
-      RetryTimeKeeper retryTime, EntryEventImpl event, Integer bucketId)
-  {
+  private InternalDistributedMember waitForNodeOrCreateBucket(RetryTimeKeeper retryTime,
+      EntryEventImpl event, Integer bucketId) {
-      PRHARedundancyProvider.timedOut(this, null, null, "allocate a bucket", retryTime.getRetryTime());
+      PRHARedundancyProvider.timedOut(this, null, null, "allocate a bucket",
+          retryTime.getRetryTime());
-      newNode = createBucket(bucketId.intValue(), getEntrySize(event),
-          retryTime);
+      newNode = createBucket(bucketId.intValue(), getEntrySize(event), retryTime);
-   * Serialize the key and value early (prior to creating the message) to gather
-   * the size of the entry Assumes the new value from the
-   * <code>EntryEventImpl</code> is not serialized
+   * Serialize the key and value early (prior to creating the message) to gather the size of the
+   * entry Assumes the new value from the <code>EntryEventImpl</code> is not serialized
-   * @return sum of bytes as reported by
-   *         {@link CachedDeserializable#getSizeInBytes()}
+   * @return sum of bytes as reported by {@link CachedDeserializable#getSizeInBytes()}
-   * @param eei
-   *                the entry from whcih to fetch the size
+   * @param eei the entry from whcih to fetch the size
-    @Unretained final Object v = eei.getRawNewValue();
+    @Unretained
+    final Object v = eei.getRawNewValue();
-      return ((CachedDeserializable)v).getSizeInBytes();
+      return ((CachedDeserializable) v).getSizeInBytes();
-  public InternalDistributedMember getOrCreateNodeForBucketWrite(int bucketId, final RetryTimeKeeper snoozer) {
+  public InternalDistributedMember getOrCreateNodeForBucketWrite(int bucketId,
+      final RetryTimeKeeper snoozer) {
-    if(targetNode != null) {
+    if (targetNode != null) {
-    
+
-    }
-    catch (PartitionedRegionStorageException e) {
+    } catch (PartitionedRegionStorageException e) {
+
+   * 
-  public InternalDistributedMember getNodeForBucketWrite(int bucketId, 
+  public InternalDistributedMember getNodeForBucketWrite(int bucketId,
-    
-//    InternalDistributedSystem ids = (InternalDistributedSystem)this.cache.getDistributedSystem();
+
-    while (minimumWriteRedundancy > 0 && getRegionAdvisor().getBucketRedundancy(bucketId) < this.minimumWriteRedundancy) {
+    while (minimumWriteRedundancy > 0
+        && getRegionAdvisor().getBucketRedundancy(bucketId) < this.minimumWriteRedundancy) {
-      // First check to see if there is any storage assigned TODO: redundant check to while condition
-      if ( ! getRegionAdvisor().isStorageAssignedForBucket(bucketId, this.minimumWriteRedundancy, false)) {
+      // First check to see if there is any storage assigned TODO: redundant check to while
+      // condition
+      if (!getRegionAdvisor().isStorageAssignedForBucket(bucketId, this.minimumWriteRedundancy,
+          false)) {
-          logger.debug("No storage assigned for bucket ({}{}{}) writer", getPRId(), BUCKET_ID_SEPARATOR, bucketId);
+          logger.debug("No storage assigned for bucket ({}{}{}) writer", getPRId(),
+              BUCKET_ID_SEPARATOR, bucketId);
-        return null;  // No bucket for this key
+        return null; // No bucket for this key
-      }
-      else {
+      } else {
-                .toLocalizedString(new Object[] { bucketStringForLogs(bucketId), Integer.valueOf(localSnoozer.getRetryTime()),
-                    Integer.valueOf(red), Integer.valueOf(this.minimumWriteRedundancy) }));
+                .toLocalizedString(new Object[] {bucketStringForLogs(bucketId),
+                    Integer.valueOf(localSnoozer.getRetryTime()), Integer.valueOf(red),
+                    Integer.valueOf(this.minimumWriteRedundancy)}));
-  
-  
+
+
+   * 
-   private InternalDistributedMember waitForNoStorageOrPrimary(int bucketId,
-      String readOrWrite) {
-     boolean isInterrupted = false;
-     try {
-       for (;;) {
-         isInterrupted = Thread.interrupted() || isInterrupted;
-         InternalDistributedMember d = getBucketPrimary(bucketId);
-         if (d != null) {
-           return d; // success!
-         } 
-         else {
-           // go around the loop again
-           if (logger.isDebugEnabled()) {
-             logger.debug("No primary node found for bucket ({}{}{}) {}", getPRId(), BUCKET_ID_SEPARATOR, bucketId, readOrWrite);
-           }
-         }
-         if (!getRegionAdvisor().isStorageAssignedForBucket(bucketId)) {
-           if (logger.isDebugEnabled()) {
-             logger.debug("No storage while waiting for primary for bucket ({}{}{}) {}", getPRId(), BUCKET_ID_SEPARATOR, bucketId, readOrWrite);
-           }
-           return null; // No bucket for this key
-         }
-         checkShutdown();
-       }
-     }
-     finally {
-       if (isInterrupted) {
-         Thread.currentThread().interrupt();
-       }
-     }
+  private InternalDistributedMember waitForNoStorageOrPrimary(int bucketId, String readOrWrite) {
+    boolean isInterrupted = false;
+    try {
+      for (;;) {
+        isInterrupted = Thread.interrupted() || isInterrupted;
+        InternalDistributedMember d = getBucketPrimary(bucketId);
+        if (d != null) {
+          return d; // success!
+        } else {
+          // go around the loop again
+          if (logger.isDebugEnabled()) {
+            logger.debug("No primary node found for bucket ({}{}{}) {}", getPRId(),
+                BUCKET_ID_SEPARATOR, bucketId, readOrWrite);
+          }
+        }
+        if (!getRegionAdvisor().isStorageAssignedForBucket(bucketId)) {
+          if (logger.isDebugEnabled()) {
+            logger.debug("No storage while waiting for primary for bucket ({}{}{}) {}", getPRId(),
+                BUCKET_ID_SEPARATOR, bucketId, readOrWrite);
+          }
+          return null; // No bucket for this key
+        }
+        checkShutdown();
+      }
+    } finally {
+      if (isInterrupted) {
+        Thread.currentThread().interrupt();
+      }
+    }
-   @Override
-  public Object get(Object key, Object aCallbackArgument,
-                    boolean generateCallbacks, boolean disableCopyOnRead, boolean preferCD,
-                    ClientProxyMembershipID requestingClient,
-                    EntryEventImpl clientEvent, boolean returnTombstones) throws TimeoutException, CacheLoaderException
-  {
+  @Override
+  public Object get(Object key, Object aCallbackArgument, boolean generateCallbacks,
+      boolean disableCopyOnRead, boolean preferCD, ClientProxyMembershipID requestingClient,
+      EntryEventImpl clientEvent, boolean returnTombstones)
+      throws TimeoutException, CacheLoaderException {
-      Object value = getDataView().findObject(getKeyInfo(key, aCallbackArgument), this, true/*isCreate*/, generateCallbacks,
-                                      null /*no local value*/, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones);
+      Object value = getDataView().findObject(getKeyInfo(key, aCallbackArgument), this,
+          true/* isCreate */, generateCallbacks, null /* no local value */, disableCopyOnRead,
+          preferCD, requestingClient, clientEvent, returnTombstones);
-    }
-    finally {
+    } finally {
-   
-   public InternalDistributedMember getOrCreateNodeForBucketRead(int bucketId) {
-     InternalDistributedMember targetNode = getNodeForBucketRead(bucketId);
-     if(targetNode != null) {
-       return targetNode;
-     }
-     try {
-       return createBucket(bucketId, 0, null);
-     }
-     catch (PartitionedRegionStorageException e) {
-       // try not to throw a PRSE if the cache is closing or this region was
-       // destroyed during createBucket() (bug 36574)
-       this.checkReadiness();
-       if (this.cache.isClosed()) {
-         throw new RegionDestroyedException(toString(), getFullPath());
-       }
-       throw e;
-     }
-   }
+
+  public InternalDistributedMember getOrCreateNodeForBucketRead(int bucketId) {
+    InternalDistributedMember targetNode = getNodeForBucketRead(bucketId);
+    if (targetNode != null) {
+      return targetNode;
+    }
+    try {
+      return createBucket(bucketId, 0, null);
+    } catch (PartitionedRegionStorageException e) {
+      // try not to throw a PRSE if the cache is closing or this region was
+      // destroyed during createBucket() (bug 36574)
+      this.checkReadiness();
+      if (this.cache.isClosed()) {
+        throw new RegionDestroyedException(toString(), getFullPath());
+      }
+      throw e;
+    }
+  }
-   * Gets the Node for reading a specific bucketId. This method gives
-   * priority to local node to speed up operation and avoid remote calls.
+   * Gets the Node for reading a specific bucketId. This method gives priority to local node to
+   * speed up operation and avoid remote calls.
-   * @param bucketId
-   *                identifier for bucket
+   * @param bucketId identifier for bucket
-    InternalDistributedMember primary = waitForNoStorageOrPrimary(bucketId, 
-        "read");
+    InternalDistributedMember primary = waitForNoStorageOrPrimary(bucketId, "read");
-    InternalDistributedMember result =  getRegionAdvisor().getPreferredNode(bucketId);
+    InternalDistributedMember result = getRegionAdvisor().getPreferredNode(bucketId);
+   * 
-    }
-    else {
+    } else {
-   * Puts the key/value pair into the remote target that is managing the key's
-   * bucket.
+   * Puts the key/value pair into the remote target that is managing the key's bucket.
-   * @param recipient
-   *                the member to receive the message
-   * @param event
-   *                the event prompting this action
-   * @param ifNew
-   *                the mysterious ifNew parameter
-   * @param ifOld
-   *                the mysterious ifOld parameter
+   * @param recipient the member to receive the message
+   * @param event the event prompting this action
+   * @param ifNew the mysterious ifNew parameter
+   * @param ifOld the mysterious ifOld parameter
-   * @throws PrimaryBucketException
-   *                 if the remote bucket was not the primary
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @throws PrimaryBucketException if the remote bucket was not the primary
+   * @throws ForceReattemptException if the peer is no longer available
-  public boolean putRemotely(final DistributedMember recipient,
-                              final EntryEventImpl event,
-                              boolean ifNew,
-                              boolean ifOld,
-                              Object expectedOldValue,
-                              boolean requireOldValue)  
-  throws PrimaryBucketException, ForceReattemptException {
+  public boolean putRemotely(final DistributedMember recipient, final EntryEventImpl event,
+      boolean ifNew, boolean ifOld, Object expectedOldValue, boolean requireOldValue)
+      throws PrimaryBucketException, ForceReattemptException {
-    PutMessage.PutResponse response =
-      (PutMessage.PutResponse)PutMessage.send(recipient,
-                                              this,
-                                              event,
-                                              eventTime,
-                                              ifNew,
-                                              ifOld,
-                                              expectedOldValue,
-                                              requireOldValue);
+    PutMessage.PutResponse response = (PutMessage.PutResponse) PutMessage.send(recipient, this,
+        event, eventTime, ifNew, ifOld, expectedOldValue, requireOldValue);
-      }
-      catch (RegionDestroyedException rde) {
+      } catch (RegionDestroyedException rde) {
-      } catch(TransactionException te) {
+      } catch (TransactionException te) {
-      } 
-      catch (CacheException ce) {
+      } catch (CacheException ce) {
-        throw new PartitionedRegionDistributionException(LocalizedStrings.PartitionedRegion_PUTTING_ENTRY_ON_0_FAILED.toLocalizedString(recipient), ce);
+        throw new PartitionedRegionDistributionException(
+            LocalizedStrings.PartitionedRegion_PUTTING_ENTRY_ON_0_FAILED
+                .toLocalizedString(recipient),
+            ce);
-   * @param bucketId
-   *                the bucket identifier for the bucket that needs creation
-   * @param snoozer
-   *                tracking object used to determine length of time t for
-   *                bucket creation
+   * @param bucketId the bucket identifier for the bucket that needs creation
+   * @param snoozer tracking object used to determine length of time t for bucket creation
-    final PartitionedRegion colocatedWith = ColocationHelper
-        .getColocatedRegion(this);
+    final PartitionedRegion colocatedWith = ColocationHelper.getColocatedRegion(this);
-    
+
-      FixedPartitionAttributesImpl fpa = PartitionedRegionHelper
-          .getFixedPartitionAttributesForBucket(this, bucketId);
+      FixedPartitionAttributesImpl fpa =
+          PartitionedRegionHelper.getFixedPartitionAttributesForBucket(this, bucketId);
-      if(startBucketId == -1){
+      if (startBucketId == -1) {
-                .toString(new Object[]{getName(),partitionName}));
+                .toString(new Object[] {getName(), partitionName}));
-    if(isDataStore()) {
-      ret = this.redundancyProvider.createBucketAtomically(bucketId, size,
-          startTime, false, partitionName);
+    if (isDataStore()) {
+      ret = this.redundancyProvider.createBucketAtomically(bucketId, size, startTime, false,
+          partitionName);
-  protected Object findObjectInSystem(KeyInfo keyInfo,
-                                      boolean isCreate,
-                                      TXStateInterface tx,
-                                      boolean generateCallbacks,
-                                      Object localValue,
-                                      boolean disableCopyOnRead,
-                                      boolean preferCD,
-                                      ClientProxyMembershipID requestingClient,
-                                      EntryEventImpl clientEvent,
-                                      boolean returnTombstones)
-      throws CacheLoaderException, TimeoutException
-  {
+  protected Object findObjectInSystem(KeyInfo keyInfo, boolean isCreate, TXStateInterface tx,
+      boolean generateCallbacks, Object localValue, boolean disableCopyOnRead, boolean preferCD,
+      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent,
+      boolean returnTombstones) throws CacheLoaderException, TimeoutException {
-        bucketId = PartitionedRegionHelper.getHashKey(this,
-            isCreate ? Operation.CREATE : null, key, null, aCallbackArgument);
+        bucketId = PartitionedRegionHelper.getHashKey(this, isCreate ? Operation.CREATE : null, key,
+            null, aCallbackArgument);
-      
-      obj = getFromBucket(targetNode, bucketId, key, aCallbackArgument, disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, allowRetry);
-    }
-    finally {
+
+      obj = getFromBucket(targetNode, bucketId, key, aCallbackArgument, disableCopyOnRead, preferCD,
+          requestingClient, clientEvent, returnTombstones, allowRetry);
+    } finally {
-  
+
-   * Execute the provided named function in all locations that contain the given
-   * keys. So function can be executed on just one fabric node, executed in
-   * parallel on a subset of nodes in parallel across all the nodes.
+   * Execute the provided named function in all locations that contain the given keys. So function
+   * can be executed on just one fabric node, executed in parallel on a subset of nodes in parallel
+   * across all the nodes.
-              logger.debug("Executing Function: (Single Hop) {} on multiple nodes.", function.getId());
+              logger.debug("Executing Function: (Single Hop) {} on multiple nodes.",
+                  function.getId());
-      }
-      else {
+      } else {
-          logger.debug("Executing Function: (Single Hop) {} on a set of buckets nodes.", function.getId());
+          logger.debug("Executing Function: (Single Hop) {} on a set of buckets nodes.",
+              function.getId());
-        return executeOnBucketSet(function, execution, rc, execution
-            .getFilter());
+        return executeOnBucketSet(function, execution, rc, execution.getFilter());
-    }
-    else {
+    } else {
-            logger.debug("Executing Function: {} withArgs={} on all buckets.", function.getId(), execution.getArguments());
+            logger.debug("Executing Function: {} withArgs={} on all buckets.", function.getId(),
+                execution.getArguments());
-            logger.debug("Executing Function: {} withArgs={} on single node.", function.getId(), execution.getArguments());
+            logger.debug("Executing Function: {} withArgs={} on single node.", function.getId(),
+                execution.getArguments());
-            logger.debug("Executing Function: {} withArgs={} on multiple nodes.", function.getId(), execution.getArguments());
+            logger.debug("Executing Function: {} withArgs={} on multiple nodes.", function.getId(),
+                execution.getArguments());
-    HashMap<Integer, HashSet> bucketToKeysMap = FunctionExecutionNodePruner
-        .groupByBucket(this, routingKeys, primaryMembersNeeded, false, isBucketSetAsFilter);
-    HashMap<InternalDistributedMember, HashSet> memberToKeysMap = new HashMap<InternalDistributedMember, HashSet>();
-    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets = FunctionExecutionNodePruner
-    .groupByMemberToBuckets(this, bucketToKeysMap.keySet(), primaryMembersNeeded);    
-    
+    HashMap<Integer, HashSet> bucketToKeysMap = FunctionExecutionNodePruner.groupByBucket(this,
+        routingKeys, primaryMembersNeeded, false, isBucketSetAsFilter);
+    HashMap<InternalDistributedMember, HashSet> memberToKeysMap =
+        new HashMap<InternalDistributedMember, HashSet>();
+    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets =
+        FunctionExecutionNodePruner.groupByMemberToBuckets(this, bucketToKeysMap.keySet(),
+            primaryMembersNeeded);
+
-            Set<ServerBucketProfile> profiles = this.getRegionAdvisor()
-                .getClientBucketProfiles(bucketId);
+            Set<ServerBucketProfile> profiles =
+                this.getRegionAdvisor().getClientBucketProfiles(bucketId);
-    
-    while(!execution.getFailedNodes().isEmpty()) {
+
+    while (!execution.getFailedNodes().isEmpty()) {
-      
+
-      
-      while (iterator.hasNext()){
-        if(execution.getFailedNodes().contains(((InternalDistributedMember)iterator.next()).getId())){
+
+      while (iterator.hasNext()) {
+        if (execution.getFailedNodes()
+            .contains(((InternalDistributedMember) iterator.next()).getId())) {
-      
-      if(hasRemovedNode){
+
+      if (hasRemovedNode) {
-          PRHARedundancyProvider.timedOut(this, null, null, "doing function execution", this.retryTimeout);
+          PRHARedundancyProvider.timedOut(this, null, null, "doing function execution",
+              this.retryTimeout);
-        memberToBuckets = FunctionExecutionNodePruner.groupByMemberToBuckets(
-            this, bucketToKeysMap.keySet(), primaryMembersNeeded);     
-        
-      }else{
+        memberToBuckets = FunctionExecutionNodePruner.groupByMemberToBuckets(this,
+            bucketToKeysMap.keySet(), primaryMembersNeeded);
+
+      } else {
-      }    
+      }
-    
+
-      InternalDistributedMember member = (InternalDistributedMember)entry
-          .getKey();
-      HashSet<Integer> buckets = (HashSet)entry.getValue();
+      InternalDistributedMember member = (InternalDistributedMember) entry.getKey();
+      HashSet<Integer> buckets = (HashSet) entry.getValue();
-    //memberToKeysMap.keySet().retainAll(memberToBuckets.keySet());
+    // memberToKeysMap.keySet().retainAll(memberToBuckets.keySet());
-      throw new FunctionException(
-          LocalizedStrings.PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0
-              .toLocalizedString(routingKeys));
+      throw new FunctionException(LocalizedStrings.PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0
+          .toLocalizedString(routingKeys));
-    //added for the data aware procedure.
+    // added for the data aware procedure.
-    //end
+    // end
-    }
-    else {
-      localBucketSet = FunctionExecutionNodePruner
-      .getBucketSet(PartitionedRegion.this, localKeys,
-                    false, isBucketSetAsFilter);
-      
+    } else {
+      localBucketSet = FunctionExecutionNodePruner.getBucketSet(PartitionedRegion.this, localKeys,
+          false, isBucketSetAsFilter);
+
-    final LocalResultCollector<?, ?> localResultCollector = execution
-        .getLocalResultCollector(function, rc);
+    final LocalResultCollector<?, ?> localResultCollector =
+        execution.getLocalResultCollector(function, rc);
-    final PartitionedRegionFunctionResultSender resultSender = new PartitionedRegionFunctionResultSender(
-        dm, this, 0L, localResultCollector, execution
-            .getServerResultSender(), memberToKeysMap.isEmpty(), remoteOnly,
-        execution.isForwardExceptions(), function, localBucketSet);
+    final PartitionedRegionFunctionResultSender resultSender =
+        new PartitionedRegionFunctionResultSender(dm, this, 0L, localResultCollector,
+            execution.getServerResultSender(), memberToKeysMap.isEmpty(), remoteOnly,
+            execution.isForwardExceptions(), function, localBucketSet);
-      final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(
-          function.getId(),
-          PartitionedRegion.this,
-          execution.getArgumentsForMember(getMyId().getId()),
-                                          localKeys,
-              ColocationHelper.constructAndGetAllColocatedLocalDataSet(
-                               PartitionedRegion.this, localBucketSet), 
-                                          localBucketSet,
-                                          resultSender,
-                                          execution.isReExecute());
+      final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(function.getId(),
+          PartitionedRegion.this, execution.getArgumentsForMember(getMyId().getId()),
+          localKeys, ColocationHelper
+              .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this, localBucketSet),
+          localBucketSet, resultSender, execution.isReExecute());
-        logger.debug("FunctionService: Executing on local node with keys.{}"+  localKeys);
+        logger.debug("FunctionService: Executing on local node with keys.{}" + localKeys);
-    if (!memberToKeysMap.isEmpty()) {    
-      HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap = 
-        new HashMap<InternalDistributedMember, FunctionRemoteContext>();
+    if (!memberToKeysMap.isEmpty()) {
+      HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap =
+          new HashMap<InternalDistributedMember, FunctionRemoteContext>();
-        InternalDistributedMember recip = (InternalDistributedMember)me
-            .getKey();
-        HashSet memKeys = (HashSet)me.getValue();
+        InternalDistributedMember recip = (InternalDistributedMember) me.getKey();
+        HashSet memKeys = (HashSet) me.getValue();
-            FunctionExecutionNodePruner.getBucketSet(this, memKeys,
-                false, isBucketSetAsFilter), execution.isReExecute(),
-                execution.isFnSerializationReqd());
+            FunctionExecutionNodePruner.getBucketSet(this, memKeys, false, isBucketSetAsFilter),
+            execution.isReExecute(), execution.isFnSerializationReqd());
-        logger.debug("FunctionService: Executing on remote nodes with member to keys map.{}" + memberToKeysMap);
+        logger.debug("FunctionService: Executing on remote nodes with member to keys map.{}"
+            + memberToKeysMap);
-      PartitionedRegionFunctionResultWaiter resultReciever = new PartitionedRegionFunctionResultWaiter(
-          getSystem(), this.getPRId(), localResultCollector, function,
-          resultSender);
+      PartitionedRegionFunctionResultWaiter resultReciever =
+          new PartitionedRegionFunctionResultWaiter(getSystem(), this.getPRId(),
+              localResultCollector, function, resultSender);
-  
+
-      final PartitionedRegionFunctionExecutor execution, ResultCollector rc, 
-      boolean isPRSingleHop, boolean isBucketSetAsFilter){  
+      final PartitionedRegionFunctionExecutor execution, ResultCollector rc, boolean isPRSingleHop,
+      boolean isBucketSetAsFilter) {
-      bucketId = Integer.valueOf(PartitionedRegionHelper.getHashKey(this,
-            Operation.FUNCTION_EXECUTION, key, null, null));
+      bucketId = Integer.valueOf(
+          PartitionedRegionHelper.getHashKey(this, Operation.FUNCTION_EXECUTION, key, null, null));
-      HeapMemoryMonitor hmm = ((InternalResourceManager) cache.getResourceManager()).getHeapMonitor();
+      HeapMemoryMonitor hmm =
+          ((InternalResourceManager) cache.getResourceManager()).getHeapMonitor();
-        throw new LowMemoryException(LocalizedStrings.ResourceManager_LOW_MEMORY_FOR_0_FUNCEXEC_MEMBERS_1.toLocalizedString(
-                new Object[] {function.getId(), sm}), sm);
+        throw new LowMemoryException(
+            LocalizedStrings.ResourceManager_LOW_MEMORY_FOR_0_FUNCEXEC_MEMBERS_1
+                .toLocalizedString(new Object[] {function.getId(), sm}),
+            sm);
-    }
-    else {
+    } else {
-    final DistributedMember localVm = getMyId(); 
-    if (targetNode!= null && isPRSingleHop && !localVm.equals(targetNode)) {
-      Set<ServerBucketProfile> profiles = this.getRegionAdvisor()
-          .getClientBucketProfiles(bucketId);
+    final DistributedMember localVm = getMyId();
+    if (targetNode != null && isPRSingleHop && !localVm.equals(targetNode)) {
+      Set<ServerBucketProfile> profiles = this.getRegionAdvisor().getClientBucketProfiles(bucketId);
-          LocalizedStrings.PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0
-              .toLocalizedString(key));
+          LocalizedStrings.PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0.toLocalizedString(key));
-    
+
-      logger.debug("Executing Function: {} withArgs={} on {}", function.getId(), execution.getArguments(), targetNode);
+      logger.debug("Executing Function: {} withArgs={} on {}", function.getId(),
+          execution.getArguments(), targetNode);
-        /*if (retryTime.overMaximum()) {
-          PRHARedundancyProvider.timedOut(this, null, null,
-              "doing function execution", this.retryTimeout);
-          // NOTREACHED
-        }*/
-	//Asif: Fix for Bug # 40083
+        /*
+         * if (retryTime.overMaximum()) { PRHARedundancyProvider.timedOut(this, null, null,
+         * "doing function execution", this.retryTimeout); // NOTREACHED }
+         */
+        // Asif: Fix for Bug # 40083
-            PRHARedundancyProvider.timedOut(this, null, null,
-                "doing function execution", this.retryTimeout);
+            PRHARedundancyProvider.timedOut(this, null, null, "doing function execution",
+                this.retryTimeout);
-          retryTime.waitToRetryNode();          
+          retryTime.waitToRetryNode();
-          }
-          else {
+          } else {
-      }
-      else {
+      } else {
-    final HashSet<Integer> buckets = new HashSet<Integer>(); 
+    final HashSet<Integer> buckets = new HashSet<Integer>();
-    final Set<InternalDistributedMember> singleMember = Collections
-        .singleton(targetNode);
+    final Set<InternalDistributedMember> singleMember = Collections.singleton(targetNode);
-    LocalResultCollector<?, ?> localRC = execution
-          .getLocalResultCollector(function, rc);
+    LocalResultCollector<?, ?> localRC = execution.getLocalResultCollector(function, rc);
-      PartitionedRegionFunctionResultSender resultSender = new PartitionedRegionFunctionResultSender(
-          dm, PartitionedRegion.this, 0, localRC, execution.getServerResultSender(), true, false, execution.isForwardExceptions(), function, buckets);
-      final FunctionContext context = new RegionFunctionContextImpl(function
-          .getId(), PartitionedRegion.this, execution
-          .getArgumentsForMember(localVm.getId()), routingKeys,
-          ColocationHelper.constructAndGetAllColocatedLocalDataSet(
-              PartitionedRegion.this, buckets), buckets, resultSender, execution.isReExecute()); 
-      execution.executeFunctionOnLocalPRNode(function, context, resultSender, dm, isTX()); 
-      return localRC;      
-    }
-    else {
-      return executeFunctionOnRemoteNode(targetNode, function, execution
-          .getArgumentsForMember(targetNode.getId()), routingKeys, function.isHA()? rc :localRC, buckets,
-          execution.getServerResultSender(), execution);
+      PartitionedRegionFunctionResultSender resultSender =
+          new PartitionedRegionFunctionResultSender(dm, PartitionedRegion.this, 0, localRC,
+              execution.getServerResultSender(), true, false, execution.isForwardExceptions(),
+              function, buckets);
+      final FunctionContext context =
+          new RegionFunctionContextImpl(function.getId(), PartitionedRegion.this,
+              execution.getArgumentsForMember(localVm.getId()), routingKeys, ColocationHelper
+                  .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this, buckets),
+              buckets, resultSender, execution.isReExecute());
+      execution.executeFunctionOnLocalPRNode(function, context, resultSender, dm, isTX());
+      return localRC;
+    } else {
+      return executeFunctionOnRemoteNode(targetNode, function,
+          execution.getArgumentsForMember(targetNode.getId()), routingKeys,
+          function.isHA() ? rc : localRC, buckets, execution.getServerResultSender(), execution);
-  
+
+    } catch (NoSuchElementException done) {
-    catch (NoSuchElementException done) {
-    }
-    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets = FunctionExecutionNodePruner
-        .groupByMemberToBuckets(this, bucketSet, function.optimizeForWrite());
+    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets =
+        FunctionExecutionNodePruner.groupByMemberToBuckets(this, bucketSet,
+            function.optimizeForWrite());
-        logger.debug("Executing on bucketset : {} executeOnBucketSet Member to buckets map is : {} bucketSet is empty",
+        logger.debug(
+            "Executing on bucketset : {} executeOnBucketSet Member to buckets map is : {} bucketSet is empty",
-    }
-    else {
+    } else {
-    
+
-    
+
-            Set<ServerBucketProfile> profiles = this.getRegionAdvisor()
-                .getClientBucketProfiles(bucketId);
+            Set<ServerBucketProfile> profiles =
+                this.getRegionAdvisor().getClientBucketProfiles(bucketId);
-                    logger.debug("FunctionServiceSingleHop: Found multiple nodes for executing on bucket set.{}", getMyId());
+                    logger.debug(
+                        "FunctionServiceSingleHop: Found multiple nodes for executing on bucket set.{}",
+                        getMyId());
-    
-    execution = (PartitionedRegionFunctionExecutor)execution.withFilter(new HashSet());
+
+    execution = (PartitionedRegionFunctionExecutor) execution.withFilter(new HashSet());
-        if (execution.getFailedNodes().contains(
-            ((InternalDistributedMember)iterator.next()).getId())) {
+        if (execution.getFailedNodes()
+            .contains(((InternalDistributedMember) iterator.next()).getId())) {
-          PRHARedundancyProvider.timedOut(this, null, null,
-              "doing function execution", this.retryTimeout);
+          PRHARedundancyProvider.timedOut(this, null, null, "doing function execution",
+              this.retryTimeout);
-        memberToBuckets = FunctionExecutionNodePruner.groupByMemberToBuckets(
-            this, bucketSet, function.optimizeForWrite());
-      }
-      else {
+        memberToBuckets = FunctionExecutionNodePruner.groupByMemberToBuckets(this, bucketSet,
+            function.optimizeForWrite());
+      } else {
-    
+
-    if (function.optimizeForWrite() && cache.getResourceManager().getHeapMonitor().
-        containsHeapCriticalMembers(dest) &&
-        !MemoryThresholds.isLowMemoryExceptionDisabled()) {
-      Set<InternalDistributedMember> hcm  = cache.getResourceAdvisor().adviseCritialMembers();
+    if (function.optimizeForWrite()
+        && cache.getResourceManager().getHeapMonitor().containsHeapCriticalMembers(dest)
+        && !MemoryThresholds.isLowMemoryExceptionDisabled()) {
+      Set<InternalDistributedMember> hcm = cache.getResourceAdvisor().adviseCritialMembers();
-      throw new LowMemoryException(LocalizedStrings.ResourceManager_LOW_MEMORY_FOR_0_FUNCEXEC_MEMBERS_1.toLocalizedString(
-          new Object[] {function.getId(), sm}), sm);
+      throw new LowMemoryException(
+          LocalizedStrings.ResourceManager_LOW_MEMORY_FOR_0_FUNCEXEC_MEMBERS_1
+              .toLocalizedString(new Object[] {function.getId(), sm}),
+          sm);
-    final HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap = new HashMap<InternalDistributedMember, FunctionRemoteContext>();
+    final HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap =
+        new HashMap<InternalDistributedMember, FunctionRemoteContext>();
-          execution.getArgumentsForMember(recip.getId()), null, memberToBuckets
-              .get(recip), execution.isReExecute(), execution.isFnSerializationReqd() );
+          execution.getArgumentsForMember(recip.getId()), null, memberToBuckets.get(recip),
+          execution.isReExecute(), execution.isFnSerializationReqd());
-    //final LocalResultCollector localResultCollector = new LocalResultCollector(function, rc, execution);
-    final LocalResultCollector<?, ?> localRC = execution
-    .getLocalResultCollector(function, rc);
-    
+    // final LocalResultCollector localResultCollector = new LocalResultCollector(function, rc,
+    // execution);
+    final LocalResultCollector<?, ?> localRC = execution.getLocalResultCollector(function, rc);
+
-    final PartitionedRegionFunctionResultSender resultSender = new PartitionedRegionFunctionResultSender(
-        dm, this, 0L, localRC, execution
-            .getServerResultSender(), recipMap.isEmpty(), !isSelf, execution.isForwardExceptions(), function, localBucketSet);
+    final PartitionedRegionFunctionResultSender resultSender =
+        new PartitionedRegionFunctionResultSender(dm, this, 0L, localRC,
+            execution.getServerResultSender(), recipMap.isEmpty(), !isSelf,
+            execution.isForwardExceptions(), function, localBucketSet);
-      final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(function.getId(), PartitionedRegion.this,
-          execution.getArgumentsForMember(getMyId().getId()), null,
-          ColocationHelper.constructAndGetAllColocatedLocalDataSet(
-              PartitionedRegion.this, localBucketSet), localBucketSet,
-          resultSender, execution.isReExecute());
-//      final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(
-//          function.getId(), PartitionedRegion.this, execution
-//              .getArgumentsForMember(getMyId().getId()), null, ColocationHelper
-//              .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this,
-//                  localBucketSet), resultSender, execution.isReExecute());
-      execution.executeFunctionOnLocalNode(function, prContext, resultSender,
-          dm, isTX());
+      final RegionFunctionContextImpl prContext =
+          new RegionFunctionContextImpl(function.getId(), PartitionedRegion.this,
+              execution.getArgumentsForMember(getMyId().getId()), null, ColocationHelper
+                  .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this, localBucketSet),
+              localBucketSet, resultSender, execution.isReExecute());
+      // final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(
+      // function.getId(), PartitionedRegion.this, execution
+      // .getArgumentsForMember(getMyId().getId()), null, ColocationHelper
+      // .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this,
+      // localBucketSet), resultSender, execution.isReExecute());
+      execution.executeFunctionOnLocalNode(function, prContext, resultSender, dm, isTX());
-    PartitionedRegionFunctionResultWaiter resultReciever = new PartitionedRegionFunctionResultWaiter(
-        getSystem(), this.getPRId(), localRC, function, resultSender);
+    PartitionedRegionFunctionResultWaiter resultReciever =
+        new PartitionedRegionFunctionResultWaiter(getSystem(), this.getPRId(), localRC, function,
+            resultSender);
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap,
-        this, execution);
+    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
-  
+
-  
+
-      final PartitionedRegionFunctionExecutor execution, ResultCollector rc, boolean isPRSingleHop) {
+      final PartitionedRegionFunctionExecutor execution, ResultCollector rc,
+      boolean isPRSingleHop) {
-      }
-      catch (NoSuchElementException ex) {
+      } catch (NoSuchElementException ex) {
-    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets = FunctionExecutionNodePruner
-        .groupByMemberToBuckets(this, bucketSet, function.optimizeForWrite());
+    HashMap<InternalDistributedMember, HashSet<Integer>> memberToBuckets =
+        FunctionExecutionNodePruner.groupByMemberToBuckets(this, bucketSet,
+            function.optimizeForWrite());
-      throw new EmptyRegionFunctionException(LocalizedStrings.PartitionedRegion_FUNCTION_NOT_EXECUTED_AS_REGION_IS_EMPTY.toLocalizedString()
-          );
+      throw new EmptyRegionFunctionException(
+          LocalizedStrings.PartitionedRegion_FUNCTION_NOT_EXECUTED_AS_REGION_IS_EMPTY
+              .toLocalizedString());
-    
-    while(!execution.getFailedNodes().isEmpty()){
+
+    while (!execution.getFailedNodes().isEmpty()) {
-      
-     Iterator iterator = memberKeySet.iterator();
-      
+
+      Iterator iterator = memberKeySet.iterator();
+
-      
-      while (iterator.hasNext()){
-        if(execution.getFailedNodes().contains(((InternalDistributedMember)iterator.next()).getId())){
+
+      while (iterator.hasNext()) {
+        if (execution.getFailedNodes()
+            .contains(((InternalDistributedMember) iterator.next()).getId())) {
-      
-      if(hasRemovedNode){
+
+      if (hasRemovedNode) {
-          PRHARedundancyProvider.timedOut(this, null, null, "doing function execution", this.retryTimeout);
+          PRHARedundancyProvider.timedOut(this, null, null, "doing function execution",
+              this.retryTimeout);
-        memberToBuckets = FunctionExecutionNodePruner
-        .groupByMemberToBuckets(this, bucketSet, function.optimizeForWrite());
-      }else{
+        memberToBuckets = FunctionExecutionNodePruner.groupByMemberToBuckets(this, bucketSet,
+            function.optimizeForWrite());
+      } else {
-      }    
+      }
-    final HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap = new HashMap<InternalDistributedMember, FunctionRemoteContext>();
+    final HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap =
+        new HashMap<InternalDistributedMember, FunctionRemoteContext>();
-          execution.getArgumentsForMember(recip.getId()), null, memberToBuckets
-              .get(recip), execution.isReExecute(), execution.isFnSerializationReqd() );
+          execution.getArgumentsForMember(recip.getId()), null, memberToBuckets.get(recip),
+          execution.isReExecute(), execution.isFnSerializationReqd());
-    final LocalResultCollector<?, ?> localResultCollector = execution
-        .getLocalResultCollector(function, rc);
+    final LocalResultCollector<?, ?> localResultCollector =
+        execution.getLocalResultCollector(function, rc);
-    final PartitionedRegionFunctionResultSender resultSender = new PartitionedRegionFunctionResultSender(
-        dm, this, 0L, localResultCollector, execution
-            .getServerResultSender(), recipMap.isEmpty(), !isSelf, execution.isForwardExceptions(), function, localBucketSet);
+    final PartitionedRegionFunctionResultSender resultSender =
+        new PartitionedRegionFunctionResultSender(dm, this, 0L, localResultCollector,
+            execution.getServerResultSender(), recipMap.isEmpty(), !isSelf,
+            execution.isForwardExceptions(), function, localBucketSet);
-      final RegionFunctionContextImpl prContext = new RegionFunctionContextImpl(
-          function.getId(), PartitionedRegion.this, execution
-              .getArgumentsForMember(getMyId().getId()), null,
-          ColocationHelper.constructAndGetAllColocatedLocalDataSet(
-              PartitionedRegion.this, localBucketSet), localBucketSet,
-              resultSender, execution.isReExecute());
+      final RegionFunctionContextImpl prContext =
+          new RegionFunctionContextImpl(function.getId(), PartitionedRegion.this,
+              execution.getArgumentsForMember(getMyId().getId()), null, ColocationHelper
+                  .constructAndGetAllColocatedLocalDataSet(PartitionedRegion.this, localBucketSet),
+              localBucketSet, resultSender, execution.isReExecute());
-    PartitionedRegionFunctionResultWaiter resultReciever = new PartitionedRegionFunctionResultWaiter(
-        getSystem(), this.getPRId(), localResultCollector, function, resultSender);
+    PartitionedRegionFunctionResultWaiter resultReciever =
+        new PartitionedRegionFunctionResultWaiter(getSystem(), this.getPRId(), localResultCollector,
+            function, resultSender);
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap,
-        this, execution);
+    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
+   * 
-  private Object getFromBucket(final InternalDistributedMember targetNode,
-                               int bucketId,
-                               final Object key,
-                               final Object aCallbackArgument,
-                               boolean disableCopyOnRead,
-                               boolean preferCD,
-                               ClientProxyMembershipID requestingClient,
-                               EntryEventImpl clientEvent,
-                               boolean returnTombstones,
-                               boolean allowRetry) {
+  private Object getFromBucket(final InternalDistributedMember targetNode, int bucketId,
+      final Object key, final Object aCallbackArgument, boolean disableCopyOnRead, boolean preferCD,
+      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent,
+      boolean returnTombstones, boolean allowRetry) {
-    
+
-      
+
-          obj = this.dataStore.getLocally(bucketId, key, aCallbackArgument,
-              disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, false);
-        }
-        else {
-            if (localCacheEnabled && null != (obj = localCacheGet(key))) { // OFFHEAP: copy into heap cd; TODO optimize for preferCD case
-              if (logger.isTraceEnabled()) {
-                logger.trace("getFromBucket: Getting key {} ({}) from local cache", key, key.hashCode());
-              }
+          obj = this.dataStore.getLocally(bucketId, key, aCallbackArgument, disableCopyOnRead,
+              preferCD, requestingClient, clientEvent, returnTombstones, false);
+        } else {
+          if (localCacheEnabled && null != (obj = localCacheGet(key))) { // OFFHEAP: copy into heap
+                                                                         // cd; TODO optimize for
+                                                                         // preferCD case
+            if (logger.isTraceEnabled()) {
+              logger.trace("getFromBucket: Getting key {} ({}) from local cache", key,
+                  key.hashCode());
+            }
+            return obj;
+          } else if (this.haveCacheLoader) {
+            // If the region has a cache loader,
+            // the target node is the primary server of the bucket. But, if the
+            // value can be found in a local bucket, we should first try there.
+
+            /* MergeGemXDHDFSToGFE -readoing from local bucket was disabled in GemXD */
+            if (null != (obj = getFromLocalBucket(bucketId, key, aCallbackArgument,
+                disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones))) {
-            else if (this.haveCacheLoader) {
-              // If the region has a cache loader, 
-              // the target node is the primary server of the bucket. But, if the 
-              // value can be found in a local bucket, we should first try there. 
+          }
-              /* MergeGemXDHDFSToGFE -readoing from local bucket was disabled in GemXD*/
-			  if (null != ( obj = getFromLocalBucket(bucketId, key, aCallbackArgument,
-                  disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones))) {
-                return obj;
-              } 
-            }
-          
-          //  Test hook
-          if (((LocalRegion)this).isTest())
-            ((LocalRegion)this).incCountNotFoundInLocal();
-          obj = getRemotely(retryNode, bucketId, key, aCallbackArgument, preferCD, requestingClient, clientEvent, returnTombstones);
- 
+          // Test hook
+          if (((LocalRegion) this).isTest())
+            ((LocalRegion) this).incCountNotFoundInLocal();
+          obj = getRemotely(retryNode, bucketId, key, aCallbackArgument, preferCD, requestingClient,
+              clientEvent, returnTombstones);
+
-          if (name.startsWith("ServerConnection")
-              && !getMyId().equals(retryNode)) {
-            setNetworkHopType(bucketId, (InternalDistributedMember)retryNode);
+          if (name.startsWith("ServerConnection") && !getMyId().equals(retryNode)) {
+            setNetworkHopType(bucketId, (InternalDistributedMember) retryNode);
-      }
-      catch (PRLocallyDestroyedException pde) {
+      } catch (PRLocallyDestroyedException pde) {
-          return null;
+          // Only transactions set allowRetry to false,
+          // fail the transaction here as region is destroyed.
+          Throwable cause = pde.getCause();
+          if (cause != null && cause instanceof RegionDestroyedException) {
+            throw (RegionDestroyedException) cause;
+          } else {
+            // Should not see it currently, all current constructors of PRLocallyDestroyedException
+            // set the cause to RegionDestroyedException.
+            throw new RegionDestroyedException(toString(), getFullPath());
+          }
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
+          // with transaction
+          if (prce instanceof BucketNotFoundException) {
+            TransactionException ex = new TransactionDataRebalancedException(
+                LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
+                    .toLocalizedString(key));
+            ex.initCause(prce);
+            throw ex;
+          }
-            throw (PrimaryBucketException)cause;
+            throw (PrimaryBucketException) cause;
-            throw (TransactionDataRebalancedException)cause;
+            throw (TransactionDataRebalancedException) cause;
+          } else if (cause instanceof RegionDestroyedException) {
+            TransactionException ex = new TransactionDataRebalancedException(
+                LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
+                    .toLocalizedString(key));
+            ex.initCause(cause);
+            throw ex;
-            return null;
+            // Make transaction fail so client could retry
+            // instead of returning null if ForceReattemptException is thrown.
+            // Should not see it currently, added to be protected against future changes.
+            TransactionException ex = new TransactionException("Failed to get key: " + key, prce);
+            throw ex;
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-            logger.debug("getFromBucket: {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+            logger.debug("getFromBucket: {} on Node {} not primary",
+                notPrimary.getLocalizedMessage(), retryNode);
-        logger.debug("getFromBucket: Attempting to resend get to node {} after {} failed attempts", retryNode, count);
+        logger.debug("getFromBucket: Attempting to resend get to node {} after {} failed attempts",
+            retryNode, count);
-    
+
-      e = new PartitionedRegionDistributionException(LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS.toLocalizedString(Integer.valueOf(count)));
+      e = new PartitionedRegionDistributionException(
+          LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS
+              .toLocalizedString(Integer.valueOf(count)));
-    logger.warn(LocalizedMessage.create(LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS, Integer.valueOf(count)), e);
+    logger.warn(LocalizedMessage.create(
+        LocalizedStrings.PartitionRegion_NO_VM_AVAILABLE_FOR_GET_IN_0_ATTEMPTS,
+        Integer.valueOf(count)), e);
-   * If a bucket is local, try to fetch the value 
-   * from it
-   *   
+   * If a bucket is local, try to fetch the value from it
+   * 
-  public Object getFromLocalBucket(int bucketId, final Object key,
-                                   final Object aCallbackArgument, boolean disableCopyOnRead,
-                                   boolean preferCD, ClientProxyMembershipID requestingClient,
-                                   EntryEventImpl clientEvent, boolean returnTombstones)
-		throws ForceReattemptException, PRLocallyDestroyedException {
+  public Object getFromLocalBucket(int bucketId, final Object key, final Object aCallbackArgument,
+      boolean disableCopyOnRead, boolean preferCD, ClientProxyMembershipID requestingClient,
+      EntryEventImpl clientEvent, boolean returnTombstones)
+      throws ForceReattemptException, PRLocallyDestroyedException {
-    // try reading locally. 
+    // try reading locally.
-    if (readNode.equals(getMyId()) && null != ( obj = this.dataStore.getLocally(bucketId, key, aCallbackArgument,
-      disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, true))) {
-	  if (logger.isTraceEnabled()) {
-            logger.trace("getFromBucket: Getting key {} ({}) locally - success", key, key.hashCode());
-	  }
-      return obj;  
+    if (readNode.equals(getMyId())
+        && null != (obj = this.dataStore.getLocally(bucketId, key, aCallbackArgument,
+            disableCopyOnRead, preferCD, requestingClient, clientEvent, returnTombstones, true))) {
+      if (logger.isTraceEnabled()) {
+        logger.trace("getFromBucket: Getting key {} ({}) locally - success", key, key.hashCode());
+      }
+      return obj;
-  
-  
+
+
-   * This invokes a cache writer before a destroy operation. Although it has the
-   * same method signature as the method in LocalRegion, it is invoked in a
-   * different code path. LocalRegion invokes this method via its "entries"
-   * member, while PartitionedRegion invokes this method in its region operation
-   * methods and messages.
+   * This invokes a cache writer before a destroy operation. Although it has the same method
+   * signature as the method in LocalRegion, it is invoked in a different code path. LocalRegion
+   * invokes this method via its "entries" member, while PartitionedRegion invokes this method in
+   * its region operation methods and messages.
-      Set netWriteRecipients = localWriter == null ? this.distAdvisor
-          .adviseNetWrite() : null;
+      Set netWriteRecipients = localWriter == null ? this.distAdvisor.adviseNetWrite() : null;
-      if (localWriter == null
-          && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
+      if (localWriter == null && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
-        SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor
-            .getProcessor();
+        SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();
-      }
-      finally {
+      } finally {
-   * Test Method: Get the DistributedMember identifier for the vm containing a
-   * key
+   * Test Method: Get the DistributedMember identifier for the vm containing a key
-   * @param key
-   *                the key to look for
-   * @return The ID of the DistributedMember holding the key, or null if there
-   *         is no current mapping for the key
+   * @param key the key to look for
+   * @return The ID of the DistributedMember holding the key, or null if there is no current mapping
+   *         for the key
-   * Test Method: Investigate the local cache to determine if it contains a the
-   * key
+   * Test Method: Investigate the local cache to determine if it contains a the key
-   * @param key
-   *                The key
+   * @param key The key
-   * @param key
-   *                The kye
+   * @param key The kye
-    // TODO:KIRK:OK if (re == null || Token.isRemoved(re.getValueInVM(this))) {
+      // TODO:KIRK:OK if (re == null || Token.isRemoved(re.getValueInVM(this))) {
-   * Test Method: Get a random set of keys from a randomly selected bucket using
-   * the provided <code>Random</code> number generator.
+   * Test Method: Get a random set of keys from a randomly selected bucket using the provided
+   * <code>Random</code> number generator.
-   * @return A set of keys from a randomly chosen bucket or
-   *         {@link Collections#EMPTY_SET}
+   * @return A set of keys from a randomly chosen bucket or {@link Collections#EMPTY_SET}
-  public Set getSomeKeys(Random rnd) throws IOException,
-  ClassNotFoundException {
+  public Set getSomeKeys(Random rnd) throws IOException, ClassNotFoundException {
-          buck = (Integer)buksA[ind];
+          buck = (Integer) buksA[ind];
-              ret = dataStore.handleRemoteGetKeys(buck,
-                  InterestType.REGULAR_EXPRESSION, ".*", false);
-            }
-            else {
+              ret =
+                  dataStore.handleRemoteGetKeys(buck, InterestType.REGULAR_EXPRESSION, ".*", false);
+            } else {
-          logger.debug("Test hook getSomeKeys caught a ForceReattemptException for bucketId={}{}{}. Moving on to another bucket",
+          logger.debug(
+              "Test hook getSomeKeys caught a ForceReattemptException for bucketId={}{}{}. Moving on to another bucket",
-   * This method will not work correctly if membership in the distributed
-   * system changes while the result is being calculated.
+   * This method will not work correctly if membership in the distributed system changes while the
+   * result is being calculated.
-   * @return a List of HashMaps, each map being a copy of the entries in a
-   *         bucket
+   * @return a List of HashMaps, each map being a copy of the entries in a bucket
-  public List<BucketDump> getAllBucketEntries(final int bucketId)
-      throws ForceReattemptException {
+  public List<BucketDump> getAllBucketEntries(final int bucketId) throws ForceReattemptException {
-      
+
-      InternalDistributedMember owner = (InternalDistributedMember)
-          ownersI.next();
+      InternalDistributedMember owner = (InternalDistributedMember) ownersI.next();
-      
+
-                + getDistributionManager().getDistributionManagerId() + ": "
-                + super.toString();
+                + getDistributionManager().getDistributionManagerId() + ": " + super.toString();
-        
+
-        for (Iterator<Map.Entry> it=br.entrySet().iterator(); it.hasNext(); ) {
-          LocalRegion.NonTXEntry entry = (LocalRegion.NonTXEntry)it.next();
+        for (Iterator<Map.Entry> it = br.entrySet().iterator(); it.hasNext();) {
+          LocalRegion.NonTXEntry entry = (LocalRegion.NonTXEntry) it.next();
-          if(versionTag != null) {
+          if (versionTag != null) {
-          }
-          else if (Token.isInvalid(value)) {
+          } else if (Token.isInvalid(value)) {
-          }
-          else if (value instanceof CachedDeserializable) { 
-            value = ((CachedDeserializable)value).getDeserializedForReading();
+          } else if (value instanceof CachedDeserializable) {
+            value = ((CachedDeserializable) value).getDeserializedForReading();
-      
+
-        r = FetchEntriesMessage.send(owner,
-            this, bucketId);
+        r = FetchEntriesMessage.send(owner, this, bucketId);
-      }
-      catch (ForceReattemptException e) {
-        // node has departed?  Ignore.
+      } catch (ForceReattemptException e) {
+        // node has departed? Ignore.
-    
+
-  
-  
+
+
-   * Fetch the keys for the given bucket identifier, if the bucket is local or
-   * remote.
+   * Fetch the keys for the given bucket identifier, if the bucket is local or remote.
-   * @return A set of keys from bucketNum or {@link Collections#EMPTY_SET}if no
-   *         keys can be found.
+   * @return A set of keys from bucketNum or {@link Collections#EMPTY_SET}if no keys can be found.
-   * Fetch the keys for the given bucket identifier, if the bucket is local or
-   * remote.  This version of the method allows you to retrieve Tombstone entries
-   * as well as undestroyed entries.
+   * Fetch the keys for the given bucket identifier, if the bucket is local or remote. This version
+   * of the method allows you to retrieve Tombstone entries as well as undestroyed entries.
-   * @return A set of keys from bucketNum or {@link Collections#EMPTY_SET}if no
-   *         keys can be found.
+   * @return A set of keys from bucketNum or {@link Collections#EMPTY_SET}if no keys can be found.
-        }
-        else {
+        } else {
-      }
-      catch (PRLocallyDestroyedException pde) {
+      } catch (PRLocallyDestroyedException pde) {
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-            throw new TimeoutException(LocalizedStrings.PartitionedRegion_ATTEMPT_TO_ACQUIRE_PRIMARY_NODE_FOR_READ_ON_BUCKET_0_TIMED_OUT_IN_1_MS.toLocalizedString(new Object[] {getBucketName(buck.intValue()), Integer.valueOf(snoozer.getRetryTime())}));
+            throw new TimeoutException(
+                LocalizedStrings.PartitionedRegion_ATTEMPT_TO_ACQUIRE_PRIMARY_NODE_FOR_READ_ON_BUCKET_0_TIMED_OUT_IN_1_MS
+                    .toLocalizedString(new Object[] {getBucketName(buck.intValue()),
+                        Integer.valueOf(snoozer.getRetryTime())}));
-   * Fetches entries from local and remote nodes and appends these to
-   * register-interest response.
+   * Fetches entries from local and remote nodes and appends these to register-interest response.
-  public void fetchEntries(HashMap<Integer, HashSet> bucketKeys,
-      VersionedObjectList values, ServerConnection servConn) throws IOException {
+  public void fetchEntries(HashMap<Integer, HashSet> bucketKeys, VersionedObjectList values,
+      ServerConnection servConn) throws IOException {
-    HashMap<InternalDistributedMember, HashMap<Integer, HashSet>> nodeToBuckets = new HashMap<InternalDistributedMember, HashMap<Integer, HashSet>>();
+    HashMap<InternalDistributedMember, HashMap<Integer, HashSet>> nodeToBuckets =
+        new HashMap<InternalDistributedMember, HashMap<Integer, HashSet>>();
-          BaseCommand.appendNewRegisterInterestResponseChunkFromLocal(this, values, "keyList", keys, servConn);
+          BaseCommand.appendNewRegisterInterestResponseChunkFromLocal(this, values, "keyList", keys,
+              servConn);
-      throw new InternalGemFireException("Failed to fetch entries from " + failures.size() + " buckets of region " + getName() + " for register interest.");
+      throw new InternalGemFireException("Failed to fetch entries from " + failures.size()
+          + " buckets of region " + getName() + " for register interest.");
-  private Set<Integer> handleOldNodes(HashMap nodeToBuckets,
-      VersionedObjectList values, ServerConnection servConn) throws IOException {
+  private Set<Integer> handleOldNodes(HashMap nodeToBuckets, VersionedObjectList values,
+      ServerConnection servConn) throws IOException {
-            BaseCommand.sendNewRegisterInterestResponseChunk(this, "keyList", values, false, servConn);
+            BaseCommand.sendNewRegisterInterestResponseChunk(this, "keyList", values, false,
+                servConn);
-   * @param nodeToBuckets
-   *          A map with InternalDistributedSystem as key and either HashSet or
-   *          HashMap<Integer, HashSet> as value.
+   * @param nodeToBuckets A map with InternalDistributedSystem as key and either HashSet or
+   *        HashMap<Integer, HashSet> as value.
-    DistributionManager dm = (DistributionManager)getDistributionManager();
+    DistributionManager dm = (DistributionManager) getDistributionManager();
-    Set<InternalDistributedMember> oldMembers = new HashSet<InternalDistributedMember>(nodeToBuckets.keySet());
+    Set<InternalDistributedMember> oldMembers =
+        new HashSet<InternalDistributedMember>(nodeToBuckets.keySet());
-    
+
-   * Fetches entries from local and remote nodes and appends these to
-   * register-interest response.
+   * Fetches entries from local and remote nodes and appends these to register-interest response.
-  public void fetchEntries(String regex, VersionedObjectList values,
-      ServerConnection servConn) throws IOException {
+  public void fetchEntries(String regex, VersionedObjectList values, ServerConnection servConn)
+      throws IOException {
-    HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets = new HashMap<InternalDistributedMember, HashSet<Integer>>();
+    HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets =
+        new HashMap<InternalDistributedMember, HashSet<Integer>>();
-        Set keys = fetchAllLocalKeys(id, failures, regex);
-        if (!keys.isEmpty()) {
-          BaseCommand.appendNewRegisterInterestResponseChunkFromLocal(this, values, regex != null ? regex : "ALL_KEYS", keys, servConn);
-        }
+          Set keys = fetchAllLocalKeys(id, failures, regex);
+          if (!keys.isEmpty()) {
+            BaseCommand.appendNewRegisterInterestResponseChunkFromLocal(this, values,
+                regex != null ? regex : "ALL_KEYS", keys, servConn);
+          }
-//        updateNodeToBucketMap(nodeToBuckets, failures);
-//        failures.clear();
+        // updateNodeToBucketMap(nodeToBuckets, failures);
+        // failures.clear();
-      throw new InternalGemFireException("Failed to fetch entries from " + failures.size() + " buckets of region " + getName() + " for register interest.");
+      throw new InternalGemFireException("Failed to fetch entries from " + failures.size()
+          + " buckets of region " + getName() + " for register interest.");
-      HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets,
-      Set<Integer> buckets) {
+      HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets, Set<Integer> buckets) {
-      try {
-        Set keys = null;
-        if (regex != null) {
-          keys = this.dataStore.handleRemoteGetKeys(id,
-              InterestType.REGULAR_EXPRESSION, regex, true);
-        } else {
-          keys = this.dataStore.getKeysLocally(id, true);
-        }
-        result.addAll(keys);
-      } catch (ForceReattemptException fre) {
-        failures.add(id);
-      } catch (PRLocallyDestroyedException prlde) {
-        failures.add(id);
+    try {
+      Set keys = null;
+      if (regex != null) {
+        keys = this.dataStore.handleRemoteGetKeys(id, InterestType.REGULAR_EXPRESSION, regex, true);
+      } else {
+        keys = this.dataStore.getKeysLocally(id, true);
+      result.addAll(keys);
+    } catch (ForceReattemptException fre) {
+      failures.add(id);
+    } catch (PRLocallyDestroyedException prlde) {
+      failures.add(id);
+    }
-   * Sends FetchBulkEntriesMessage to each of the nodes hosting the buckets,
-   * unless the nodes are older than 8.0
+   * Sends FetchBulkEntriesMessage to each of the nodes hosting the buckets, unless the nodes are
+   * older than 8.0
-      HashMap<Integer, HashSet> failures, VersionedObjectList values,
-      ServerConnection servConn) throws IOException {
+      HashMap<Integer, HashSet> failures, VersionedObjectList values, ServerConnection servConn)
+      throws IOException {
-    for(Iterator<Map.Entry<InternalDistributedMember, HashMap<Integer, HashSet>>> itr = nodeToBuckets.entrySet().iterator(); itr.hasNext();) {
+    for (Iterator<Map.Entry<InternalDistributedMember, HashMap<Integer, HashSet>>> itr =
+        nodeToBuckets.entrySet().iterator(); itr.hasNext();) {
-      try {
-        if (entry.getKey().getVersionObject().compareTo(Version.GFE_80) < 0) {
-          failures.putAll(nodeToBuckets.get(entry.getKey()));
-          continue;
-        }
-        fber = FetchBulkEntriesMessage.send(entry.getKey(), this, oneBucketKeys, null, null, true);
-
-        BucketDump[] bds =  fber.waitForEntries();
-        if (fber.getFailedBucketIds() != null && !fber.getFailedBucketIds().isEmpty()) {
-          for (int id : fber.getFailedBucketIds()) {
-            failures.put(id, nodeToBuckets.get(entry.getKey()).get(id));
+        try {
+          if (entry.getKey().getVersionObject().compareTo(Version.GFE_80) < 0) {
+            failures.putAll(nodeToBuckets.get(entry.getKey()));
+            continue;
-        }
-        for (BucketDump bd : bds) {
-          result.addAll(bd.getValuesWithVersions().entrySet());
-        }
+          fber =
+              FetchBulkEntriesMessage.send(entry.getKey(), this, oneBucketKeys, null, null, true);
-        BaseCommand.appendNewRegisterInterestResponseChunk(this, values, "keyList", result, servConn);
+          BucketDump[] bds = fber.waitForEntries();
+          if (fber.getFailedBucketIds() != null && !fber.getFailedBucketIds().isEmpty()) {
+            for (int id : fber.getFailedBucketIds()) {
+              failures.put(id, nodeToBuckets.get(entry.getKey()).get(id));
+            }
+          }
+          for (BucketDump bd : bds) {
+            result.addAll(bd.getValuesWithVersions().entrySet());
+          }
-      } catch (ForceReattemptException fre) {
-        // failures.putAll(nodeToBuckets.get(entry.getKey()));
-        failures.put(e.getKey(), e.getValue());
-      }
+          BaseCommand.appendNewRegisterInterestResponseChunk(this, values, "keyList", result,
+              servConn);
+
+        } catch (ForceReattemptException fre) {
+          // failures.putAll(nodeToBuckets.get(entry.getKey()));
+          failures.put(e.getKey(), e.getValue());
+        }
-   * Sends FetchBulkEntriesMessage to each of the nodes hosting the buckets,
-   * unless the nodes are older than 8.0
+   * Sends FetchBulkEntriesMessage to each of the nodes hosting the buckets, unless the nodes are
+   * older than 8.0
-      HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets,
-      HashSet<Integer> failures, String regex, VersionedObjectList values,
-      ServerConnection servConn) throws IOException {
+      HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBuckets, HashSet<Integer> failures,
+      String regex, VersionedObjectList values, ServerConnection servConn) throws IOException {
-    for(Iterator<Map.Entry<InternalDistributedMember, HashSet<Integer>>> itr = nodeToBuckets.entrySet().iterator(); itr.hasNext();) {
+    for (Iterator<Map.Entry<InternalDistributedMember, HashSet<Integer>>> itr =
+        nodeToBuckets.entrySet().iterator(); itr.hasNext();) {
-      HashSet<Integer> buckets = new HashSet<Integer>(entry.getValue()); // Is it needed to copy the set here?
+      HashSet<Integer> buckets = new HashSet<Integer>(entry.getValue()); // Is it needed to copy the
+                                                                         // set here?
-      try {
-        if (entry.getKey().getVersionObject().compareTo(Version.GFE_80) < 0) {
-          failures.addAll(nodeToBuckets.get(entry.getKey()));
-          continue;
-        }
-        fber = FetchBulkEntriesMessage.send(entry.getKey(), this, null, bucketId, regex, true);
+        try {
+          if (entry.getKey().getVersionObject().compareTo(Version.GFE_80) < 0) {
+            failures.addAll(nodeToBuckets.get(entry.getKey()));
+            continue;
+          }
+          fber = FetchBulkEntriesMessage.send(entry.getKey(), this, null, bucketId, regex, true);
-        BucketDump[] bds = fber.waitForEntries();
-        if (fber.getFailedBucketIds() != null) {
-          failures.addAll(fber.getFailedBucketIds());
-        }
-        for (BucketDump bd : bds) {
-          result.addAll(bd.getValuesWithVersions().entrySet());
-        }
-        BaseCommand.appendNewRegisterInterestResponseChunk(this, values, regex != null ? regex : "ALL_KEYS", result, servConn);
+          BucketDump[] bds = fber.waitForEntries();
+          if (fber.getFailedBucketIds() != null) {
+            failures.addAll(fber.getFailedBucketIds());
+          }
+          for (BucketDump bd : bds) {
+            result.addAll(bd.getValuesWithVersions().entrySet());
+          }
+          BaseCommand.appendNewRegisterInterestResponseChunk(this, values,
+              regex != null ? regex : "ALL_KEYS", result, servConn);
-      } catch (ForceReattemptException fre) {
-        // failures.addAll(nodeToBuckets.get(entry.getKey()));
-        failures.add(bucket);
-      }
+        } catch (ForceReattemptException fre) {
+          // failures.addAll(nodeToBuckets.get(entry.getKey()));
+          failures.add(bucket);
+        }
-   * Test Method: Get all {@link InternalDistributedMember}s known by this
-   * instance of the PartitionedRegion. Note: A member is recognized as such
-   * when it partiticpates as a "data store".
+   * Test Method: Get all {@link InternalDistributedMember}s known by this instance of the
+   * PartitionedRegion. Note: A member is recognized as such when it partiticpates as a "data
+   * store".
-   * @return a <code>HashSet</code> of {@link InternalDistributedMember}s or
-   *         an empty <code>HashSet</code>
+   * @return a <code>HashSet</code> of {@link InternalDistributedMember}s or an empty
+   *         <code>HashSet</code>
-    if(this.isDataStore()) {
+    if (this.isDataStore()) {
-    for (Iterator si = this.dataStore.getSizeLocally().values().iterator(); si
-        .hasNext();) {
-     i = (Integer)si.next(); 
-     ret += i.intValue();
+    for (Iterator si = this.dataStore.getSizeLocally().values().iterator(); si.hasNext();) {
+      i = (Integer) si.next();
+      ret += i.intValue();
-   * @param targetNode
-   *                the Node hosting the key
-   * @param bucketId
-   *                the id of the bucket the key hashed into
-   * @param key
-   *                the key
+   * @param targetNode the Node hosting the key
+   * @param bucketId the id of the bucket the key hashed into
+   * @param key the key
-   * @param clientEvent client event for carrying version information.  Null if not a client operation
+   * @param clientEvent client event for carrying version information. Null if not a client
+   *        operation
-   * @throws PrimaryBucketException
-   *                 if the peer is no longer the primary
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @throws PrimaryBucketException if the peer is no longer the primary
+   * @throws ForceReattemptException if the peer is no longer available
-  public Object getRemotely(InternalDistributedMember targetNode,
-                            int bucketId,
-                            final Object key,
-                            final Object aCallbackArgument,
-                            boolean preferCD,
-                            ClientProxyMembershipID requestingClient,
-                            EntryEventImpl clientEvent,
-                            boolean returnTombstones) throws PrimaryBucketException,
-      ForceReattemptException {
+  public Object getRemotely(InternalDistributedMember targetNode, int bucketId, final Object key,
+      final Object aCallbackArgument, boolean preferCD, ClientProxyMembershipID requestingClient,
+      EntryEventImpl clientEvent, boolean returnTombstones)
+      throws PrimaryBucketException, ForceReattemptException {
-    GetResponse response = GetMessage.send(targetNode, this, key,
-        aCallbackArgument, requestingClient, returnTombstones);
+    GetResponse response = GetMessage.send(targetNode, this, key, aCallbackArgument,
+        requestingClient, returnTombstones);
-    }
-    catch (Exception e) {
+    } catch (Exception e) {
-        logger.debug("getRemotely: Can not cache value = {} for key = {} in local cache", value, key, e);
+        logger.debug("getRemotely: Can not cache value = {} for key = {} in local cache", value,
+            key, e);
-  
-  private ResultCollector executeFunctionOnRemoteNode(
-      InternalDistributedMember targetNode, final Function function,
-      final Object object, final Set routingKeys, ResultCollector rc,
-      Set bucketSet, ServerToClientFunctionResultSender sender,
-      AbstractExecution execution) {
-    PartitionedRegionFunctionResultSender resultSender = new PartitionedRegionFunctionResultSender(
-        null, this, 0, rc, sender, false, true, execution.isForwardExceptions(), function, bucketSet);
-    PartitionedRegionFunctionResultWaiter resultReciever = new PartitionedRegionFunctionResultWaiter(
-        getSystem(), this.getPRId(), rc, function, resultSender);
+  private ResultCollector executeFunctionOnRemoteNode(InternalDistributedMember targetNode,
+      final Function function, final Object object, final Set routingKeys, ResultCollector rc,
+      Set bucketSet, ServerToClientFunctionResultSender sender, AbstractExecution execution) {
+    PartitionedRegionFunctionResultSender resultSender =
+        new PartitionedRegionFunctionResultSender(null, this, 0, rc, sender, false, true,
+            execution.isForwardExceptions(), function, bucketSet);
-    FunctionRemoteContext context = new FunctionRemoteContext(function, object,
-        routingKeys, bucketSet, execution.isReExecute(), execution.isFnSerializationReqd());
+    PartitionedRegionFunctionResultWaiter resultReciever =
+        new PartitionedRegionFunctionResultWaiter(getSystem(), this.getPRId(), rc, function,
+            resultSender);
-    HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap = 
-      new HashMap<InternalDistributedMember, FunctionRemoteContext>();
+    FunctionRemoteContext context = new FunctionRemoteContext(function, object, routingKeys,
+        bucketSet, execution.isReExecute(), execution.isFnSerializationReqd());
+
+    HashMap<InternalDistributedMember, FunctionRemoteContext> recipMap =
+        new HashMap<InternalDistributedMember, FunctionRemoteContext>();
-    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap,
-        this, execution);
-    
+    ResultCollector reply = resultReciever.getPartitionedDataFrom(recipMap, this, execution);
+
-  
+
-   * This method returns Partitioned Region data store associated with this
-   * Partitioned Region
+   * This method returns Partitioned Region data store associated with this Partitioned Region
-   * Grab the PartitionedRegionID Lock, this MUST be done in a try block since
-   * it may throw an exception
+   * Grab the PartitionedRegionID Lock, this MUST be done in a try block since it may throw an
+   * exception
-    
+
-//      try {
-        ownership = lockService.lock(
-            PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID,
-            VM_OWNERSHIP_WAIT_TIME, -1);
-//      }
-//      catch (InterruptedException ie) {
-//        Thread.currentThread().interrupt();
-//        if (ownership) {
-//          lockService.unlock(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID);
-//        }
-//        throw new PartitionedRegionException(LocalizedStrings.PartitionedRegion_INTERRUPTEDEXCEPTION_ENCOUNTERED_GETTING_THE_MAX_PARTITIONED_REGION_ID.toLocalizedString(), ie);
-//      }
+      // try {
+      ownership = lockService.lock(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID,
+          VM_OWNERSHIP_WAIT_TIME, -1);
+      // }
+      // catch (InterruptedException ie) {
+      // Thread.currentThread().interrupt();
+      // if (ownership) {
+      // lockService.unlock(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID);
+      // }
+      // throw new
+      // PartitionedRegionException(LocalizedStrings.PartitionedRegion_INTERRUPTEDEXCEPTION_ENCOUNTERED_GETTING_THE_MAX_PARTITIONED_REGION_ID.toLocalizedString(),
+      // ie);
+      // }
-    }
-    catch (Exception es) {
+    } catch (Exception es) {
-         Integer.valueOf(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID)), es);
+          Integer.valueOf(PartitionedRegionHelper.MAX_PARTITIONED_REGION_ID)), es);
-  
-  private static int _generatePRId(InternalDistributedSystem sys, DistributedLockService lockService) {
+
+  private static int _generatePRId(InternalDistributedSystem sys,
+      DistributedLockService lockService) {
-        
-        Set parMembers = sys.getDistributionManager()
-            .getOtherDistributionManagerIds();
+
+        Set parMembers = sys.getDistributionManager().getOtherDistributionManagerIds();
-            IdentityUpdateMessage.send(parMembers,
-                                       sys,
-                                       currentPRID.intValue());
+              IdentityUpdateMessage.send(parMembers, sys, currentPRID.intValue());
-        }
-        catch (ReplyException ignore) {
+        } catch (ReplyException ignore) {
-    }
-    finally {
+    } finally {
-  public final CacheDistributionAdvisor getCacheDistributionAdvisor()
-  {
+  public final CacheDistributionAdvisor getCacheDistributionAdvisor() {
-    CacheProfile profile = (CacheProfile)p;
+    CacheProfile profile = (CacheProfile) p;
-    
-    //TODO - prpersist - this is a bit of a hack, but we're 
-    //reusing this boolean to indicate that this member has finished disk recovery.
+
+    // TODO - prpersist - this is a bit of a hack, but we're
+    // reusing this boolean to indicate that this member has finished disk recovery.
-    
-    profile.hasCacheServer = ((this.cache.getCacheServers().size() > 0)?true:false);
+
+    profile.hasCacheServer = ((this.cache.getCacheServers().size() > 0) ? true : false);
-    
-    if(dataPolicy.withPersistence()) {
+
+    if (dataPolicy.withPersistence()) {
-    
+
-    // initialization.  It is not currently needed by other members
+    // initialization. It is not currently needed by other members
-   * This method returns PartitionedRegion associated with a PartitionedRegion
-   * ID from prIdToPR map.
+   * This method returns PartitionedRegion associated with a PartitionedRegion ID from prIdToPR map.
-   * @param prid
-   *                Partitioned Region ID
+   * @param prid Partitioned Region ID
-  public static PartitionedRegion getPRFromId(int prid)
-      throws PRLocallyDestroyedException {
+  public static PartitionedRegion getPRFromId(int prid) throws PRLocallyDestroyedException {
-    return (PartitionedRegion)o;
+    return (PartitionedRegion) o;
-   * @param sender
-   *                the member requesting validation
-   * @param prId
-   *                the ID being used for the pr by the sender
-   * @param regionId
-   *                the regionIdentifier used for prId by the sender
+   * @param sender the member requesting validation
+   * @param prId the ID being used for the pr by the sender
+   * @param regionId the regionIdentifier used for prId by the sender
-  public static void validatePRID(InternalDistributedMember sender, int prId,
-      String regionId) {
+  public static void validatePRID(InternalDistributedMember sender, int prId, String regionId) {
-        pr = (PartitionedRegion)prIdToPR.getRegion(Integer.valueOf(prId));
+        pr = (PartitionedRegion) prIdToPR.getRegion(Integer.valueOf(prId));
-      if (pr != null && !pr.isLocallyDestroyed && 
-          pr.getRegionIdentifier().equals(regionId)) {
+      if (pr != null && !pr.isLocallyDestroyed && pr.getRegionIdentifier().equals(regionId)) {
-    }
-    catch (RegionDestroyedException e) {
+    } catch (RegionDestroyedException e) {
-    }
-    catch (PartitionedRegionException e) {
+    } catch (PartitionedRegionException e) {
-    }
-    catch (PRLocallyDestroyedException e) {
+    } catch (PRLocallyDestroyedException e) {
-    synchronized(prIdToPR) {
+    synchronized (prIdToPR) {
-        PartitionedRegion pr = (PartitionedRegion)o;
+        PartitionedRegion pr = (PartitionedRegion) o;
-        }
-        else if (pr.getRegionIdentifier().equals(regionId)) {
+        } else if (pr.getRegionIdentifier().equals(regionId)) {
-              new Object[] {sender, Integer.valueOf(prId), pr.getRegionIdentifier(), Integer.valueOf(pr.getPRId())}));
+              new Object[] {sender, Integer.valueOf(prId), pr.getRegionIdentifier(),
+                  Integer.valueOf(pr.getPRId())}));
-    
+
-   * @param key
-   *                the key
-   * @param value
-   *                the value
-   * @param newVersion
-   *                the new version of the key
+   * @param key the key
+   * @param value the value
+   * @param newVersion the new version of the key
-  void basicDestroy(final EntryEventImpl event,
-                       final boolean cacheWrite,
-                       final Object expectedOldValue)
-  throws TimeoutException, EntryNotFoundException, CacheWriterException {
-    
+  void basicDestroy(final EntryEventImpl event, final boolean cacheWrite,
+      final Object expectedOldValue)
+      throws TimeoutException, EntryNotFoundException, CacheWriterException {
+
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
-    }
-    finally {
+    } finally {
-   * @throws EntryNotFoundException if entry not found or if expectedOldValue
-   *         not null and current value was not equal to expectedOldValue
+   * @throws EntryNotFoundException if entry not found or if expectedOldValue not null and current
+   *         value was not equal to expectedOldValue
-    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(
-        bucketId, null);
+    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(bucketId, null);
-          event.getKey(), event.getKey().hashCode(), targetNode, bucketStringForLogs(bucketId.intValue()), retryTimeout);
+          event.getKey(), event.getKey().hashCode(), targetNode,
+          bucketStringForLogs(bucketId.intValue()), retryTimeout);
-      case 0:
-        // Note we don't check for DM cancellation in common case.
-        // First time, keep going
-        break;
-      case 1:
-        // First failure
-        this.cache.getCancelCriterion().checkCancelInProgress(null);
-        timeOut = System.currentTimeMillis() + this.retryTimeout;
-        break;
-      default:
-        this.cache.getCancelCriterion().checkCancelInProgress(null);
-        // test for timeout
-        long timeLeft = timeOut - System.currentTimeMillis();
-        if (timeLeft < 0) {
-          PRHARedundancyProvider.timedOut(this, null, null, "destroy an entry", this.retryTimeout);
-          // NOTREACHED
-        }
-        
-        // Didn't time out.  Sleep a bit and then continue
-        boolean interrupted = Thread.interrupted();
-        try {
-          Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
-        }
-        catch (InterruptedException e) {
-          interrupted = true;
-        }
-        finally {
-          if (interrupted) {
-            Thread.currentThread().interrupt();
+        case 0:
+          // Note we don't check for DM cancellation in common case.
+          // First time, keep going
+          break;
+        case 1:
+          // First failure
+          this.cache.getCancelCriterion().checkCancelInProgress(null);
+          timeOut = System.currentTimeMillis() + this.retryTimeout;
+          break;
+        default:
+          this.cache.getCancelCriterion().checkCancelInProgress(null);
+          // test for timeout
+          long timeLeft = timeOut - System.currentTimeMillis();
+          if (timeLeft < 0) {
+            PRHARedundancyProvider.timedOut(this, null, null, "destroy an entry",
+                this.retryTimeout);
+            // NOTREACHED
-        }
-      break;
+
+          // Didn't time out. Sleep a bit and then continue
+          boolean interrupted = Thread.interrupted();
+          try {
+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
+          } catch (InterruptedException e) {
+            interrupted = true;
+          } finally {
+            if (interrupted) {
+              Thread.currentThread().interrupt();
+            }
+          }
+          break;
-      count ++;
-      
+      count++;
+
-          if (getRegionAdvisor().getBucket(bucketId.intValue())
-              .getBucketAdvisor().basicGetPrimaryMember() == null) {
-            throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+          if (getRegionAdvisor().getBucket(bucketId.intValue()).getBucketAdvisor()
+              .basicGetPrimaryMember() == null) {
+            throw new EntryNotFoundException(
+                LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0
+                    .toLocalizedString(event.getKey()));
-          TimeoutException e = new TimeoutException(LocalizedStrings.PartitionedRegion_TIME_OUT_LOOKING_FOR_TARGET_NODE_FOR_DESTROY_WAITED_0_MS.toLocalizedString(
-                  Integer.valueOf(retryTime.getRetryTime())));
+          TimeoutException e = new TimeoutException(
+              LocalizedStrings.PartitionedRegion_TIME_OUT_LOOKING_FOR_TARGET_NODE_FOR_DESTROY_WAITED_0_MS
+                  .toLocalizedString(Integer.valueOf(retryTime.getRetryTime())));
-        
+
-//          doCacheWriteBeforeDestroy(event);
+          // doCacheWriteBeforeDestroy(event);
-          this.dataStore.destroyLocally(bucketId,
-              event, expectedOldValue);
-        }
-        else {
+          this.dataStore.destroyLocally(bucketId, event, expectedOldValue);
+        } else {
-          destroyRemotely(currentTarget,
-                          bucketId,
-                          event,
-                          expectedOldValue);
+          destroyRemotely(currentTarget, bucketId, event, expectedOldValue);
-              super.basicDestroy(event,
-                                 cacheWrite,
-                                 null);  // pass null as expectedOldValue,
-                                         // since if successfully destroyed
-                                         // remotely we always want to succeed
-                                         // locally
-            }
-            catch (EntryNotFoundException enf) {
+              super.basicDestroy(event, cacheWrite, null); // pass null as expectedOldValue,
+                                                           // since if successfully destroyed
+                                                           // remotely we always want to succeed
+                                                           // locally
+            } catch (EntryNotFoundException enf) {
-                logger.debug("destroyInBucket: Failed to invalidate from local cache because of EntryNotFoundException.", enf);
+                logger.debug(
+                    "destroyInBucket: Failed to invalidate from local cache because of EntryNotFoundException.",
+                    enf);
-        
+
-      }
-      catch (ConcurrentCacheModificationException e) {
+      } catch (ConcurrentCacheModificationException e) {
-          logger.trace("ConcurrentCacheModificationException received for destroyInBucket for bucketId: {}{}{} for event: {} No reattempt is done, returning from here",
+          logger.trace(
+              "ConcurrentCacheModificationException received for destroyInBucket for bucketId: {}{}{} for event: {} No reattempt is done, returning from here",
-      }
-      catch (ForceReattemptException e) {
+      } catch (ForceReattemptException e) {
-            PRHARedundancyProvider.timedOut(this, null, null, "destroy an entry", retryTime.getRetryTime());
+            PRHARedundancyProvider.timedOut(this, null, null, "destroy an entry",
+                retryTime.getRetryTime());
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("destroyInBucket: {} on Node {} not primary", notPrimary.getLocalizedMessage(), currentTarget);
+          logger.debug("destroyInBucket: {} on Node {} not primary",
+              notPrimary.getLocalizedMessage(), currentTarget);
-        logger.debug("destroyInBucket: Attempting to resend destroy to node {} after {} failed attempts", currentTarget, count);
+        logger.debug(
+            "destroyInBucket: Attempting to resend destroy to node {} after {} failed attempts",
+            currentTarget, count);
-                                 final InternalDistributedMember targetNode) {
+      final InternalDistributedMember targetNode) {
-      Set<ServerBucketProfile> profiles = this.getRegionAdvisor()
-          .getClientBucketProfiles(bucketId);
-      
+      Set<ServerBucketProfile> profiles = this.getRegionAdvisor().getClientBucketProfiles(bucketId);
+
-              if (this.getNetworkHopType() != NETWORK_HOP_TO_SAME_GROUP && logger.isDebugEnabled()) {
-                logger.debug("one-hop: cache op meta data staleness observed.  Message is in same server group (byte 1)");
+              if (this.getNetworkHopType() != NETWORK_HOP_TO_SAME_GROUP
+                  && logger.isDebugEnabled()) {
+                logger.debug(
+                    "one-hop: cache op meta data staleness observed.  Message is in same server group (byte 1)");
-              this.setNetworkHopType((byte)NETWORK_HOP_TO_SAME_GROUP);
+              this.setNetworkHopType((byte) NETWORK_HOP_TO_SAME_GROUP);
-              if (this.getNetworkHopType() != NETWORK_HOP_TO_DIFFERENT_GROUP && logger.isDebugEnabled()) {
-                logger.debug("one-hop: cache op meta data staleness observed.  Message is to different server group (byte 2)");
+              if (this.getNetworkHopType() != NETWORK_HOP_TO_DIFFERENT_GROUP
+                  && logger.isDebugEnabled()) {
+                logger.debug(
+                    "one-hop: cache op meta data staleness observed.  Message is to different server group (byte 2)");
-              this.setNetworkHopType((byte)NETWORK_HOP_TO_DIFFERENT_GROUP);
+              this.setNetworkHopType((byte) NETWORK_HOP_TO_DIFFERENT_GROUP);
-            this.setMetadataVersion((byte)profile.getVersion());
+            this.setMetadataVersion((byte) profile.getVersion());
-    Collections.addAll(localServerGroups, MemberAttributes.parseGroups(null, c.getSystem().getConfig().getGroups()));
-    
+    Collections.addAll(localServerGroups,
+        MemberAttributes.parseGroups(null, c.getSystem().getConfig().getGroups()));
+
-      CacheServerImpl server = (CacheServerImpl)object;
+      CacheServerImpl server = (CacheServerImpl) object;
+
-   * @param recipient
-   *                the member id of the receiver of the message
-   * @param bucketId
-   *                the idenity of the bucket
-   * @param event
-   *                the event prompting this request
-   * @param expectedOldValue
-   *        if not null, then destroy only if entry exists and current value
-   *        is equal to expectedOldValue
-   * @throws EntryNotFoundException if entry not found OR if expectedOldValue
-   *         is non-null and doesn't equal the current value
-   * @throws PrimaryBucketException
-   *                 if the bucket on that node is not the primary copy
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @param recipient the member id of the receiver of the message
+   * @param bucketId the idenity of the bucket
+   * @param event the event prompting this request
+   * @param expectedOldValue if not null, then destroy only if entry exists and current value is
+   *        equal to expectedOldValue
+   * @throws EntryNotFoundException if entry not found OR if expectedOldValue is non-null and
+   *         doesn't equal the current value
+   * @throws PrimaryBucketException if the bucket on that node is not the primary copy
+   * @throws ForceReattemptException if the peer is no longer available
-  public void destroyRemotely(DistributedMember recipient,
-                                  Integer bucketId,
-                                  EntryEventImpl event,
-                                  Object expectedOldValue)
-      throws EntryNotFoundException,
-             PrimaryBucketException,
-             ForceReattemptException {
-    DestroyResponse response = DestroyMessage.send(recipient,
-                                                     this,
-                                                     event,
-                                                     expectedOldValue);
+  public void destroyRemotely(DistributedMember recipient, Integer bucketId, EntryEventImpl event,
+      Object expectedOldValue)
+      throws EntryNotFoundException, PrimaryBucketException, ForceReattemptException {
+    DestroyResponse response = DestroyMessage.send(recipient, this, event, expectedOldValue);
-      }
-      catch (EntryNotFoundException enfe) {
+      } catch (EntryNotFoundException enfe) {
-      }
-      catch (CacheException ce) {
-        throw new PartitionedRegionException(LocalizedStrings.PartitionedRegion_DESTROY_OF_ENTRY_ON_0_FAILED.toLocalizedString(recipient), ce);
-      }
-      catch (RegionDestroyedException rde) {
+      } catch (CacheException ce) {
+        throw new PartitionedRegionException(
+            LocalizedStrings.PartitionedRegion_DESTROY_OF_ENTRY_ON_0_FAILED
+                .toLocalizedString(recipient),
+            ce);
+      } catch (RegionDestroyedException rde) {
-    // PR buckets maintain their own trackers.  None is needed at this level
+    // PR buckets maintain their own trackers. None is needed at this level
-      for (Map.Entry<Integer, BucketRegion> entry: bucketMap) {
+      for (Map.Entry<Integer, BucketRegion> entry : bucketMap) {
-  
+
-      for (Map.Entry<Integer, BucketRegion> entry: bucketMap) {
+      for (Map.Entry<Integer, BucketRegion> entry : bucketMap) {
-  
+
-   * This method cleans the Partioned region structures if the the creation of
-   * Partition region fails
-   * OVERRIDES
+   * This method cleans the Partioned region structures if the the creation of Partition region
+   * fails OVERRIDES
-    //Fix for 44551 - make sure persistent buckets
-    //are done recoverying from disk before sending the 
-    //destroy region message.
+    // Fix for 44551 - make sure persistent buckets
+    // are done recoverying from disk before sending the
+    // destroy region message.
-    RegionEventImpl event = new RegionEventImpl(this, Operation.REGION_CLOSE,
-        null, false, getMyId(), generateEventID()/* generate EventID */);
+    RegionEventImpl event = new RegionEventImpl(this, Operation.REGION_CLOSE, null, false,
+        getMyId(), generateEventID()/* generate EventID */);
-    }
-    catch (Exception ex) {
-      logger.warn(LocalizedMessage.create(
-          LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_DATA_STORE), ex);
+    } catch (Exception ex) {
+      logger.warn(
+          LocalizedMessage.create(
+              LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_DATA_STORE),
+          ex);
-      }
-      catch (Exception ex) {
-        logger.warn(LocalizedMessage.create(
-            LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_DATA_STORE), ex);
+      } catch (Exception ex) {
+        logger.warn(
+            LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_DATA_STORE),
+            ex);
-    
+
-            prIdToPR.put(Integer.valueOf(this.partitionedRegionId),
-                PRIdMap.FAILED_REGISTRATION, false);
+            prIdToPR.put(Integer.valueOf(this.partitionedRegionId), PRIdMap.FAILED_REGISTRATION,
+                false);
-              logger.debug("cleanupFailedInitialization: set failed for prId={} named {}", this.partitionedRegionId, this.getName());
+              logger.debug("cleanupFailedInitialization: set failed for prId={} named {}",
+                  this.partitionedRegionId, this.getName());
-        
+
-      }
-      catch (Exception ex) {
-        logger.warn(LocalizedMessage.create(
-            LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_ALLPARTITIONEDREGIONS), ex);
+      } catch (Exception ex) {
+        logger.warn(
+            LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_CLEANUPFAILEDINITIALIZATION_FAILED_TO_CLEAN_THE_PARTIONREGION_ALLPARTITIONEDREGIONS),
+            ex);
-    if(getDiskStore() != null && getDiskStore().getOwnedByRegion()) {
+    if (getDiskStore() != null && getDiskStore().getOwnedByRegion()) {
+
-   * Called after the cache close has closed all regions. This clean up static
-   * pr resources.
+   * Called after the cache close has closed all regions. This clean up static pr resources.
-    
+
-  protected void invalidateAllEntries(RegionEvent rgnEvent) {
-  }
-  
+  protected void invalidateAllEntries(RegionEvent rgnEvent) {}
+
-        ReplyProcessor21 response = InvalidatePartitionedRegionMessage.send(
-            recipients, this, event);
+        ReplyProcessor21 response =
+            InvalidatePartitionedRegionMessage.send(recipients, this, event);
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
-    }
-    finally {
+    } finally {
-   * We yet don't have any stats for this operation.
-   * (non-Javadoc)
-   * @see org.apache.geode.internal.cache.LocalRegion#basicUpdateEntryVersion(org.apache.geode.internal.cache.EntryEventImpl)
+   * We yet don't have any stats for this operation. (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.LocalRegion#basicUpdateEntryVersion(org.apache.geode.internal.
+   * cache.EntryEventImpl)
-  void basicUpdateEntryVersion(EntryEventImpl event)
-      throws EntryNotFoundException {
+  void basicUpdateEntryVersion(EntryEventImpl event) throws EntryNotFoundException {
-    }
-    catch (RegionDestroyedException rde) {
+    } catch (RegionDestroyedException rde) {
+   * 
-  void invalidateInBucket(final EntryEventImpl event)
-      throws EntryNotFoundException {
+  void invalidateInBucket(final EntryEventImpl event) throws EntryNotFoundException {
-    
+
-    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(
-        bucketId, null);
+    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(bucketId, null);
-        }
-        catch (TimeoutException te) {
-          if (getRegionAdvisor()
-              .isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
-                                                                  // longer
-                                                                  // exists
-            throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+        } catch (TimeoutException te) {
+          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
+                                                                                    // longer
+                                                                                    // exists
+            throw new EntryNotFoundException(
+                LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0
+                    .toLocalizedString(event.getKey()));
-        }
-        else {
+        } else {
-            }
-            catch (EntryNotFoundException enf) {
+            } catch (EntryNotFoundException enf) {
-                logger.debug("invalidateInBucket: Failed to invalidate from local cache because of EntryNotFoundException.", enf);
+                logger.debug(
+                    "invalidateInBucket: Failed to invalidate from local cache because of EntryNotFoundException.",
+                    enf);
-          logger.debug("ConcurrentCacheModificationException received for invalidateInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
+          logger.debug(
+              "ConcurrentCacheModificationException received for invalidateInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("invalidateInBucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+          logger.debug("invalidateInBucket {} on Node {} not primary",
+              notPrimary.getLocalizedMessage(), retryNode);
-        logger.debug("invalidateInBucket: Attempting to resend invalidate to node {} after {} failed attempts", retryNode, count);
+        logger.debug(
+            "invalidateInBucket: Attempting to resend invalidate to node {} after {} failed attempts",
+            retryNode, count);
-    PartitionedRegionDistributionException e 
-      = new PartitionedRegionDistributionException(LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS
-          .toLocalizedString(Integer.valueOf(count)));  // Fix for bug 36014
+    PartitionedRegionDistributionException e = new PartitionedRegionDistributionException(
+        LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS
+            .toLocalizedString(Integer.valueOf(count))); // Fix for bug 36014
-      logger.warn(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS, Integer.valueOf(count)));
-    }
-    else {
+      logger.warn(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_INVALIDATE_IN_0_ATTEMPTS,
+          Integer.valueOf(count)));
+    } else {
-   * @param recipient
-   *                the member id of the recipient of the operation
-   * @param bucketId
-   *                the id of the bucket the key hashed into
-   * @throws EntryNotFoundException
-   *                 if the entry does not exist in this region
-   * @throws PrimaryBucketException
-   *                 if the bucket on that node is not the primary copy
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @param recipient the member id of the recipient of the operation
+   * @param bucketId the id of the bucket the key hashed into
+   * @throws EntryNotFoundException if the entry does not exist in this region
+   * @throws PrimaryBucketException if the bucket on that node is not the primary copy
+   * @throws ForceReattemptException if the peer is no longer available
-  public void invalidateRemotely(DistributedMember recipient,
-      Integer bucketId, EntryEventImpl event)
-      throws EntryNotFoundException, PrimaryBucketException,
-      ForceReattemptException {
+  public void invalidateRemotely(DistributedMember recipient, Integer bucketId,
+      EntryEventImpl event)
+      throws EntryNotFoundException, PrimaryBucketException, ForceReattemptException {
-      }
-      catch (EntryNotFoundException ex) {
+      } catch (EntryNotFoundException ex) {
-        throw new PartitionedRegionException(LocalizedStrings.PartitionedRegion_INVALIDATION_OF_ENTRY_ON_0_FAILED.toLocalizedString(recipient), ce);
+        throw new PartitionedRegionException(
+            LocalizedStrings.PartitionedRegion_INVALIDATION_OF_ENTRY_ON_0_FAILED
+                .toLocalizedString(recipient),
+            ce);
-   * Calculate the number of times we attempt to commumnicate with a data store.
-   * Beware that this method is called very frequently so it absolutely must
-   * perform well.
+   * Calculate the number of times we attempt to commumnicate with a data store. Beware that this
+   * method is called very frequently so it absolutely must perform well.
-    return (this.retryTimeout / 
-        PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION) + 1;
+    return (this.retryTimeout / PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION) + 1;
-   * Creates the key/value pair into the remote target that is managing the
-   * key's bucket.
+   * Creates the key/value pair into the remote target that is managing the key's bucket.
-   * @param recipient
-   *                member id of the recipient of the operation
-   * @param bucketId
-   *                the id of the bucket that the key hashed to
-   * @param event
-   *                the event prompting this request
-   * @throws PrimaryBucketException
-   *                 if the bucket on that node is not the primary copy
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @param recipient member id of the recipient of the operation
+   * @param bucketId the id of the bucket that the key hashed to
+   * @param event the event prompting this request
+   * @throws PrimaryBucketException if the bucket on that node is not the primary copy
+   * @throws ForceReattemptException if the peer is no longer available
-  private boolean createRemotely(DistributedMember recipient,
-                                 Integer bucketId,
-                                 EntryEventImpl event,
-                                 boolean requireOldValue)
+  private boolean createRemotely(DistributedMember recipient, Integer bucketId,
+      EntryEventImpl event, boolean requireOldValue)
-    PutMessage.PutResponse reply =
-        (PutMessage.PutResponse)PutMessage.send(recipient,
-                                                this,
-                                                event,
-                                                eventTime,
-                                                true,
-                                                false,
-                                                null, // expectedOldValue
-                                                requireOldValue);
+    PutMessage.PutResponse reply = (PutMessage.PutResponse) PutMessage.send(recipient, this, event,
+        eventTime, true, false, null, // expectedOldValue
+        requireOldValue);
-      }
-      catch (EntryExistsException eee) {
+      } catch (EntryExistsException eee) {
-        throw new PartitionedRegionException(LocalizedStrings.PartitionedRegion_CREATE_OF_ENTRY_ON_0_FAILED.toLocalizedString(recipient), ce);
-      }
-      catch (RegionDestroyedException rde) {
+        throw new PartitionedRegionException(
+            LocalizedStrings.PartitionedRegion_CREATE_OF_ENTRY_ON_0_FAILED
+                .toLocalizedString(recipient),
+            ce);
+      } catch (RegionDestroyedException rde) {
-   * This method returns set of all the entries of this
-   * PartitionedRegion(locally or remotely). Currently, it throws
-   * UnsupportedOperationException
+   * This method returns set of all the entries of this PartitionedRegion(locally or remotely).
+   * Currently, it throws UnsupportedOperationException
-   * @param recursive
-   *                boolean flag to indicate whether subregions should be
-   *                considered or not.
+   * @param recursive boolean flag to indicate whether subregions should be considered or not.
-   * OVERRIDES
+   *         OVERRIDES
-   * Set view of entries. This currently extends the keySet iterator and
-   * performs individual getEntry() operations using the keys
+   * Set view of entries. This currently extends the keySet iterator and performs individual
+   * getEntry() operations using the keys
-    
+
-        
-        Object entry = view.getEntryForIterator(this.key, PartitionedRegion.this, true, allowTombstones);
+
+        Object entry =
+            view.getEntryForIterator(this.key, PartitionedRegion.this, true, allowTombstones);
+
-   * This method returns set of all the keys of this PartitionedRegion(locally
-   * or remotely).
+   * This method returns set of all the keys of this PartitionedRegion(locally or remotely).
-   * OVERRIDES
+   *         OVERRIDES
-  
+
-  
+
-    for(int i =0; i < getTotalNumberOfBuckets(); i++) {
-      if(distAdvisor.isStorageAssignedForBucket(i)) {
+    for (int i = 0; i < getTotalNumberOfBuckets(); i++) {
+      if (distAdvisor.isStorageAssignedForBucket(i)) {
-    
+
-         return this.bucketSet.iterator(); 
-        } 
+          return this.bucketSet.iterator();
+        }
-    
+
-        }
-        else {
+        } else {
-        }
-        else {
+        } else {
-          return view.getBucketKeys(PartitionedRegion.this,
-              this.currentBucketId, this.allowTombstones).iterator();
-        }
-        catch (NoSuchElementException endOfTheLine) {
+          return view
+              .getBucketKeys(PartitionedRegion.this, this.currentBucketId, this.allowTombstones)
+              .iterator();
+        } catch (NoSuchElementException endOfTheLine) {
-          }
-          else {
+          } else {
-    
+
-        }
-        catch (EntryNotFoundException ignore) {
-         if (logger.isDebugEnabled()) {
-           logger.debug("Caught exception during KeySetIterator remove", ignore);
-         }
-        }
-        finally {
+        } catch (EntryNotFoundException ignore) {
+          if (logger.isDebugEnabled()) {
+            logger.debug("Caught exception during KeySetIterator remove", ignore);
+          }
+        } finally {
-      
+
-    
+
+
+
-      this.bucketSet = bucketSet ;
-    }    
+      this.bucketSet = bucketSet;
+    }
+
-     return PartitionedRegion.this.entryCount(this.bucketSet);
+      return PartitionedRegion.this.entryCount(this.bucketSet);
-      }
-      else {
+      } else {
-    /**
-   * This method returns collection of all the values of this
-   * PartitionedRegion(locally or remotely).
+  /**
+   * This method returns collection of all the values of this PartitionedRegion(locally or
+   * remotely).
-   * Set view of values. This currently extends the keySet iterator and performs
-   * individual get() operations using the keys
+   * Set view of values. This currently extends the keySet iterator and performs individual get()
+   * operations using the keys
-  protected class ValuesSet extends KeysSet  {
+  protected class ValuesSet extends KeysSet {
-          Region.Entry re = (Region.Entry) view.getEntryForIterator(key, PartitionedRegion.this, rememberReads, allowTombstones);
+          Region.Entry re = (Region.Entry) view.getEntryForIterator(key, PartitionedRegion.this,
+              rememberReads, allowTombstones);
-    
+
-    
+
+
-    /**
+  /**
-      throw new NullPointerException(LocalizedStrings.LocalRegion_VALUE_FOR_CONTAINSVALUEVALUE_CANNOT_BE_NULL.toLocalizedString());
+      throw new NullPointerException(
+          LocalizedStrings.LocalRegion_VALUE_FOR_CONTAINSVALUEVALUE_CANNOT_BE_NULL
+              .toLocalizedString());
-      ValuesSet vSet = new ValuesSet(this.getDataStore()
-          .getAllLocalPrimaryBucketIds());
+      ValuesSet vSet = new ValuesSet(this.getDataStore().getAllLocalPrimaryBucketIds());
-    
+
-      rc = FunctionService.onRegion(this).withArgs((Serializable)value)
+      rc = FunctionService.onRegion(this).withArgs((Serializable) value)
-      List<Boolean> results = ((List<Boolean>)rc.getResult());
-      for(Boolean r: results){
-        if(r){
+      List<Boolean> results = ((List<Boolean>) rc.getResult());
+      for (Boolean r : results) {
+        if (r) {
-    }
-    catch (FunctionException fe) {
+    } catch (FunctionException fe) {
-      logger.warn(LocalizedMessage.create(LocalizedStrings.PR_CONTAINSVALUE_WARNING), fe.getCause());  
+      logger.warn(LocalizedMessage.create(LocalizedStrings.PR_CONTAINSVALUE_WARNING),
+          fe.getCause());
-        bucketId = PartitionedRegionHelper.getHashKey(this,
-            Operation.CONTAINS_KEY, keyInfo.getKey(), keyInfo.getValue(),
-            keyInfo.getCallbackArg());
+        bucketId = PartitionedRegionHelper.getHashKey(this, Operation.CONTAINS_KEY,
+            keyInfo.getKey(), keyInfo.getValue(), keyInfo.getCallbackArg());
-    }
-    finally {
+    } finally {
-  boolean containsKeyInBucket(final InternalDistributedMember targetNode,
-      final Integer bucketIdInt, final Object key, boolean valueCheck) {
+  boolean containsKeyInBucket(final InternalDistributedMember targetNode, final Integer bucketIdInt,
+      final Object key, boolean valueCheck) {
-          (valueCheck ? "ValueForKey key=" : "Key key="), key, key.hashCode(), targetNode, bucketStringForLogs(bucketIdInt.intValue()));
+          (valueCheck ? "ValueForKey key=" : "Key key="), key, key.hashCode(), targetNode,
+          bucketStringForLogs(bucketIdInt.intValue()));
-          }
-          else {
+          } else {
-        }
-        else {
+        } else {
-          }
-          else {
+          } else {
-      }
-      catch (PRLocallyDestroyedException pde) {
+      } catch (PRLocallyDestroyedException pde) {
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("containsKeyInBucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+          logger.debug("containsKeyInBucket {} on Node {} not primary",
+              notPrimary.getLocalizedMessage(), retryNode);
-      }
-      catch (RegionDestroyedException rde) {
+      } catch (RegionDestroyedException rde) {
-      msg = LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_CONTAINS_VALUE_FOR_KEY_IN_1_ATTEMPTS;
+      msg =
+          LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_CONTAINS_VALUE_FOR_KEY_IN_1_ATTEMPTS;
-    
+
-   * @param targetNode
-   *                the node where bucket region for the key exists.
-   * @param bucketId
-   *                the bucket id for the key.
-   * @param key
-   *                the key, whose value needs to be checks
+   * @param targetNode the node where bucket region for the key exists.
+   * @param bucketId the bucket id for the key.
+   * @param key the key, whose value needs to be checks
-   * @throws PrimaryBucketException
-   *                 if the remote bucket was not the primary
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @throws PrimaryBucketException if the remote bucket was not the primary
+   * @throws ForceReattemptException if the peer is no longer available
-  public boolean containsKeyRemotely(InternalDistributedMember targetNode,
-      Integer bucketId, Object key) throws PrimaryBucketException,
-      ForceReattemptException {
-    ContainsKeyValueResponse r = ContainsKeyValueMessage.send(targetNode, this,
-        key, bucketId, false);
+  public boolean containsKeyRemotely(InternalDistributedMember targetNode, Integer bucketId,
+      Object key) throws PrimaryBucketException, ForceReattemptException {
+    ContainsKeyValueResponse r =
+        ContainsKeyValueMessage.send(targetNode, this, key, bucketId, false);
-   * Returns whether there is a valid (non-null) value present for the specified
-   * key, locally or remotely. This method is equivalent to:
+   * Returns whether there is a valid (non-null) value present for the specified key, locally or
+   * remotely. This method is equivalent to:
-   * @param key
-   *                the key to check for a valid value
-   * @return true if there is an entry in this region for the specified key and
-   *         it has a valid value 
-   * OVERRIDES
+   * @param key the key to check for a valid value
+   * @return true if there is an entry in this region for the specified key and it has a valid value
+   *         OVERRIDES
-    }
-    finally {
+    } finally {
-      bucketId = PartitionedRegionHelper.getHashKey(this,
-          Operation.CONTAINS_VALUE_FOR_KEY, keyInfo.getKey(),
-          keyInfo.getValue(), keyInfo.getCallbackArg());
+      bucketId = PartitionedRegionHelper.getHashKey(this, Operation.CONTAINS_VALUE_FOR_KEY,
+          keyInfo.getKey(), keyInfo.getValue(), keyInfo.getCallbackArg());
-      containsValueForKey = containsKeyInBucket(targetNode, bucketId, keyInfo.getKey(),
-          true);
+      containsValueForKey = containsKeyInBucket(targetNode, bucketId, keyInfo.getKey(), true);
-  
+
-   * @param targetNode
-   *                the node where bucket region for the key exists.
-   * @param bucketId
-   *                the bucket id for the key.
-   * @param key
-   *                the key, whose value needs to be checks
+   * @param targetNode the node where bucket region for the key exists.
+   * @param bucketId the bucket id for the key.
+   * @param key the key, whose value needs to be checks
-   * @throws PrimaryBucketException
-   *                 if the remote bucket was not the primary
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @throws PrimaryBucketException if the remote bucket was not the primary
+   * @throws ForceReattemptException if the peer is no longer available
-  public boolean containsValueForKeyRemotely(
-      InternalDistributedMember targetNode, Integer bucketId, Object key)
-      throws PrimaryBucketException, ForceReattemptException {
+  public boolean containsValueForKeyRemotely(InternalDistributedMember targetNode, Integer bucketId,
+      Object key) throws PrimaryBucketException, ForceReattemptException {
-    ContainsKeyValueResponse r = ContainsKeyValueMessage.send(targetNode, this,
-        key, bucketId, true);
+    ContainsKeyValueResponse r =
+        ContainsKeyValueMessage.send(targetNode, this, key, bucketId, true);
-//  @Override
-//  public int entryCount() {
-//    return entryCount(null);
-//  }
+  // @Override
+  // public int entryCount() {
+  // return entryCount(null);
+  // }
-  
+
-      }
-      else {
+      } else {
-    }
-    else {
+    } else {
-  
-  public int entryCount(Set<Integer> buckets,
-      boolean estimate) {
+
+  public int entryCount(Set<Integer> buckets, boolean estimate) {
-        List<Integer> list = new ArrayList<Integer>();	
+        List<Integer> list = new ArrayList<Integer>();
-    }
-    else {
+    } else {
-      HashSet recips = (HashSet)getRegionAdvisor().adviseDataStore(true);
+      HashSet recips = (HashSet) getRegionAdvisor().adviseDataStore(true);
-        }
-        else {
+        } else {
-      for(SizeEntry entry : bucketSizes.values()) {
+      for (SizeEntry entry : bucketSizes.values()) {
- 	
-  
+
+
-    }
-    else {
+    } else {
-   * This method gets a PartitionServerSocketConnection to targetNode and sends
-   * size request to the node. It returns size of all the buckets "primarily"
-   * hosted on that node. Here "primarily" means that for a given bucketID that
-   * node comes first in the node list. This selective counting ensures that
-   * redundant bucket size is added only once.
+   * This method gets a PartitionServerSocketConnection to targetNode and sends size request to the
+   * node. It returns size of all the buckets "primarily" hosted on that node. Here "primarily"
+   * means that for a given bucketID that node comes first in the node list. This selective counting
+   * ensures that redundant bucket size is added only once.
-    SizeResponse r = SizeMessage.send(targetNodes, this, null,estimate);
+    SizeResponse r = SizeMessage.send(targetNodes, this, null, estimate);
-    int ti = ((Integer)PartitionedRegion.threadRandom.get()).intValue();
+    int ti = ((Integer) PartitionedRegion.threadRandom.get()).intValue();
-   * Returns the lockname used by Distributed Lock service to clean the
-   * <code> allPartitionedRegions<code>
+   * Returns the lockname used by Distributed Lock service to clean the <code>
+   * allPartitionedRegions<code>
-   * A simple container class that holds the lock name and the service that
-   * created the lock, typically used for locking buckets, but not restricted to
-   * that usage.
+   * A simple container class that holds the lock name and the service that created the lock,
+   * typically used for locking buckets, but not restricted to that usage.
-    
+
-      this.lockService = (DLockService)
-          cache.getPartitionedRegionLockService();
+      this.lockService = (DLockService) cache.getPartitionedRegionLockService();
-     * Locks the given name (provided during construction) uninterruptibly or
-     * throws an exception.
+     * Locks the given name (provided during construction) uninterruptibly or throws an exception.
-      }
-      catch (LockServiceDestroyedException e) {
+      } catch (LockServiceDestroyedException e) {
-     * Attempts to lock the given name (provided during construction)
-     * uninterruptibly
+     * Attempts to lock the given name (provided during construction) uninterruptibly
-        basicTryLock(
-            PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
-      }
-      catch (LockServiceDestroyedException e) {
+        basicTryLock(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);
+      } catch (LockServiceDestroyedException e) {
-    
-    
+
+
-      if(enableAlerts) {
+      if (enableAlerts) {
-  
-        long ackWaitThreshold = 0; 
+
+        long ackWaitThreshold = 0;
-        
+
-  
-        if(!enableAlerts) {
-          //Make sure we only attempt the lock long enough not to
-          //get a 15 second warning from the reply processor.
+
+        if (!enableAlerts) {
+          // Make sure we only attempt the lock long enough not to
+          // get a 15 second warning from the reply processor.
-        }
-        else if (ackSAThreshold > 0) {
+        } else if (ackSAThreshold > 0) {
-        }
-        else {
+        } else {
-  
+
-          this.lockOwned = this.lockService.lock(this.lockName,
-              waitInterval, -1, false, false, !enableAlerts);
+          this.lockOwned =
+              this.lockService.lock(this.lockName, waitInterval, -1, false, false, !enableAlerts);
-                  dm.getMembershipManager()
-                    .suspectMember(lockHolder,
+                  dm.getMembershipManager().suspectMember(lockHolder,
-                      + ackWaitThreshold / 1000 + " sec");
+                          + ackWaitThreshold / 1000 + " sec");
-              }
-              else if (elapsed > ackSAThreshold  && enableAlerts) {
+              } else if (elapsed > ackSAThreshold && enableAlerts) {
-                      LocalizedStrings.PartitionedRegion_0_SECONDS_HAVE_ELAPSED_WAITING_FOR_THE_PARTITIONED_REGION_LOCK_HELD_BY_1,
-                      new Object[] {Long.valueOf((ackWaitThreshold+ackSAThreshold)/1000), lockHolder}));     
+                        LocalizedStrings.PartitionedRegion_0_SECONDS_HAVE_ELAPSED_WAITING_FOR_THE_PARTITIONED_REGION_LOCK_HELD_BY_1,
+                        new Object[] {Long.valueOf((ackWaitThreshold + ackSAThreshold) / 1000),
+                            lockHolder}));
-                }
-                else {
+                } else {
-      }
-      finally {
-        if(enableAlerts) {
+      } finally {
+        if (enableAlerts) {
-    
-    
-    
-    private void basicTryLock(long time)
-    {
-      
+
+
+
+    private void basicTryLock(long time) {
+
-      }
-      else {
+      } else {
-      long ackSAThreshold = cache.getDistributedSystem().getConfig().getAckSevereAlertThreshold() * 1000;
+      long ackSAThreshold =
+          cache.getDistributedSystem().getConfig().getAckSevereAlertThreshold() * 1000;
-      }
-      else {
+      } else {
-          waitInterval = Math.min(end-System.currentTimeMillis(), waitInterval);
+          waitInterval = Math.min(end - System.currentTimeMillis(), waitInterval);
-          this.lockOwned = this.lockService.lock(key,
-                waitInterval, -1, true, false);
+          this.lockOwned = this.lockService.lock(key, waitInterval, -1, true, false);
-                DLockRemoteToken remoteToken =
-                  this.lockService.queryLock(key);
+                DLockRemoteToken remoteToken = this.lockService.queryLock(key);
-                  dm.getMembershipManager()
-                  .suspectMember(lockHolder,
+                  dm.getMembershipManager().suspectMember(lockHolder,
-                      + ackWaitThreshold / 1000 + " sec");
+                          + ackWaitThreshold / 1000 + " sec");
-              }
-              else if (elapsed > ackSAThreshold) {
-                DLockRemoteToken remoteToken =
-                  this.lockService.queryLock(key);
+              } else if (elapsed > ackSAThreshold) {
+                DLockRemoteToken remoteToken = this.lockService.queryLock(key);
-                        new Object[] {Long.valueOf(ackWaitThreshold+ackSAThreshold)/1000 /* fix for bug 44757*/, lockHolder}));
+                        new Object[] {Long.valueOf(ackWaitThreshold + ackSAThreshold)
+                            / 1000 /* fix for bug 44757 */, lockHolder}));
-                }
-                else {
+                } else {
-        }
-        catch (IllegalStateException ex) {
+        } catch (IllegalStateException ex) {
-        }
-        finally {
+        } finally {
+     * 
-      }
-      catch (LockServiceDestroyedException e) {
+      } catch (LockServiceDestroyedException e) {
-        }
-        catch (LockServiceDestroyedException ignore) {
+        } catch (LockServiceDestroyedException ignore) {
-            logger.debug("BucketLock#unlock: Lock service {} was destroyed", this.lockService, ignore);
+            logger.debug("BucketLock#unlock: Lock service {} was destroyed", this.lockService,
+                ignore);
-        }
-        finally {
+        } finally {
-      BucketLock other = (BucketLock)obj;
+      BucketLock other = (BucketLock) obj;
-      return "BucketLock@" + System.identityHashCode(this) + "lockName="
-          + this.lockName + " lockService=" + this.lockService;
+      return "BucketLock@" + System.identityHashCode(this) + "lockName=" + this.lockName
+          + " lockService=" + this.lockService;
-      return "RegionLock@" + System.identityHashCode(this) + "lockName="
-          + super.lockName + " lockService=" + super.lockService;
+      return "RegionLock@" + System.identityHashCode(this) + "lockName=" + super.lockName
+          + " lockService=" + super.lockService;
-      return "RecoveryLock@" + System.identityHashCode(this) + "lockName="
-          + super.lockName + " lockService=" + super.lockService;
+      return "RecoveryLock@" + System.identityHashCode(this) + "lockName=" + super.lockName
+          + " lockService=" + super.lockService;
-    return new StringBuffer()
-      .append("Partitioned Region ")
-      .append("@").append(Integer.toHexString(hashCode()))
-      .append(" [")
-      .append("path='").append(getFullPath())
-      .append("'; dataPolicy=").append(this.dataPolicy)
-      .append("; prId=").append(this.partitionedRegionId)
-      .append("; isDestroyed=").append(this.isDestroyed) 
-      .append("; isClosed=").append(this.isClosed)
-      .append("; retryTimeout=").append(this.retryTimeout)
-      .append("; serialNumber=").append(getSerialNumber())
+    return new StringBuffer().append("Partitioned Region ").append("@")
+        .append(Integer.toHexString(hashCode())).append(" [").append("path='").append(getFullPath())
+        .append("'; dataPolicy=").append(this.dataPolicy).append("; prId=")
+        .append(this.partitionedRegionId).append("; isDestroyed=").append(this.isDestroyed)
+        .append("; isClosed=").append(this.isClosed).append("; retryTimeout=")
+        .append(this.retryTimeout).append("; serialNumber=").append(getSerialNumber())
-      .append("; partition attributes=").append(getPartitionAttributes().toString())
-      .append("; on VM ").append(getMyId())
-      .append("]")
-      .toString();
+        .append("; partition attributes=").append(getPartitionAttributes().toString())
+        .append("; on VM ").append(getMyId()).append("]").toString();
-  
+
-  
+
-      boolean netSearchAllowed, boolean netLoadAllowed,
-      SearchLoadAndWriteProcessor searcher) {
-    return new LoaderHelperImpl(this, key, callbackArgument, netSearchAllowed,
-        netLoadAllowed, searcher);
+      boolean netSearchAllowed, boolean netLoadAllowed, SearchLoadAndWriteProcessor searcher) {
+    return new LoaderHelperImpl(this, key, callbackArgument, netSearchAllowed, netLoadAllowed,
+        searcher);
-      throw new RegionDestroyedException(LocalizedStrings.PartitionedRegion_PR_0_IS_LOCALLY_CLOSED.toLocalizedString(this), getFullPath());
+      throw new RegionDestroyedException(
+          LocalizedStrings.PartitionedRegion_PR_0_IS_LOCALLY_CLOSED.toLocalizedString(this),
+          getFullPath());
-   * This method closes the partitioned region locally. It is invoked from the
-   * postDestroyRegion method of LocalRegion {@link LocalRegion}, which is
-   * overridden in PartitionedRegion This method <br>
+   * This method closes the partitioned region locally. It is invoked from the postDestroyRegion
+   * method of LocalRegion {@link LocalRegion}, which is overridden in PartitionedRegion This method
+   * <br>
-   * Cleanups the data store (Removes the bucket mapping from b2n region,
-   * locally destroys b2n and destroys the bucket regions. <br>
-   * sends destroyPartitionedRegionMessage to other VMs so that they update
-   * their RegionAdvisor <br>
+   * Cleanups the data store (Removes the bucket mapping from b2n region, locally destroys b2n and
+   * destroys the bucket regions. <br>
+   * sends destroyPartitionedRegionMessage to other VMs so that they update their RegionAdvisor <br>
-   * @param event
-   *                the region event
+   * @param event the region event
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_CLOSING,
-            new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
-      if(!checkIfAlreadyDestroyedOrOldReference()) {
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_CLOSING,
+          new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+      if (!checkIfAlreadyDestroyedOrOldReference()) {
-      if(!event.getOperation().isClose() && getDiskStore() != null && getDataStore() != null) {
-        for(BucketRegion bucketRegion : getDataStore().getAllLocalBucketRegions()) {
+      if (!event.getOperation().isClose() && getDiskStore() != null && getDataStore() != null) {
+        for (BucketRegion bucketRegion : getDataStore().getAllLocalBucketRegions()) {
-      // Must clean up pridToPR map so that messages do not get access to buckets 
+      // Must clean up pridToPR map so that messages do not get access to buckets
-      synchronized (prIdToPR) { 
-        prIdToPR.put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED,
-            false);
+      synchronized (prIdToPR) {
+        prIdToPR.put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED, false);
-    }
-    finally {
+    } finally {
-        prIdToPR
-        .put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED, false);
+        prIdToPR.put(Integer.valueOf(getPRId()), PRIdMap.LOCALLY_DESTROYED, false);
-    logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_CLOSED,
-          new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
+    logger.info(LocalizedMessage.create(
+        LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_CLOSED,
+        new Object[] {getFullPath(), Integer.valueOf(getPRId())}));
-    List<PartitionedRegion> listOfChildRegions = ColocationHelper
-        .getColocatedChildRegions(this);
+    List<PartitionedRegion> listOfChildRegions = ColocationHelper.getColocatedChildRegions(this);
-        if (!childRegion.getName().contains(
-            ParallelGatewaySenderQueue.QSTRING)) {
+        if (!childRegion.getName().contains(ParallelGatewaySenderQueue.QSTRING)) {
-    RegionEventImpl event = new RegionEventImpl(this, Operation.REGION_DESTROY,
-        aCallbackArgument, false, getMyId(), generateEventID());
+    RegionEventImpl event = new RegionEventImpl(this, Operation.REGION_DESTROY, aCallbackArgument,
+        false, getMyId(), generateEventID());
-  /**Globally destroy the partitioned region by sending a message
-   * to a data store to do the destroy.
+  /**
+   * Globally destroy the partitioned region by sending a message to a data store to do the destroy.
+   * 
-    
+
-    while(!isDestroyed()) {
+    while (!isDestroyed()) {
-      if(available.isEmpty()) {
+      if (available.isEmpty()) {
-      } catch(ReplyException e) {
-        //try the next member
-        if(logger.isTraceEnabled()) {
+      } catch (ReplyException e) {
+        // try the next member
+        if (logger.isTraceEnabled()) {
-    
+
-  public void destroyParallelGatewaySenderRegion(Operation op, boolean cacheWrite,
-      boolean lock, boolean callbackEvents) {
+
+  public void destroyParallelGatewaySenderRegion(Operation op, boolean cacheWrite, boolean lock,
+      boolean callbackEvents) {
-      logger.debug("Destoying parallel queue region for senders: {}", this.getParallelGatewaySenderIds());
+      logger.debug("Destoying parallel queue region for senders: {}",
+          this.getParallelGatewaySenderIds());
-    while(true) {
+    while (true) {
-      List<ConcurrentParallelGatewaySenderQueue> parallelQueues = new ArrayList<ConcurrentParallelGatewaySenderQueue>();
+      List<ConcurrentParallelGatewaySenderQueue> parallelQueues =
+          new ArrayList<ConcurrentParallelGatewaySenderQueue>();
-        AbstractGatewaySender sender = (AbstractGatewaySender)this.cache
-            .getGatewaySender(senderId);
+        AbstractGatewaySender sender =
+            (AbstractGatewaySender) this.cache.getGatewaySender(senderId);
-          if (ep == null) continue;
-          ConcurrentParallelGatewaySenderQueue parallelQueue = (ConcurrentParallelGatewaySenderQueue)ep.getQueue();
-          PartitionedRegion parallelQueueRegion = parallelQueue.getRegion(this
-              .getFullPath());
-          
+          if (ep == null)
+            continue;
+          ConcurrentParallelGatewaySenderQueue parallelQueue =
+              (ConcurrentParallelGatewaySenderQueue) ep.getQueue();
+          PartitionedRegion parallelQueueRegion = parallelQueue.getRegion(this.getFullPath());
+
-          
+
-          exception = LocalizedStrings.PartitionedRegion_GATEWAYSENDER_0_IS_PAUSED_RESUME_IT_BEFORE_DESTROYING_USER_REGION_1
-              .toLocalizedString(new Object[] { pausedSenders, this.getName() });
-        }
-        else {
-          exception = LocalizedStrings.PartitionedRegion_GATEWAYSENDERS_0_ARE_PAUSED_RESUME_THEM_BEFORE_DESTROYING_USER_REGION_1
-              .toLocalizedString(new Object[] { pausedSenders, this.getName() });
+          exception =
+              LocalizedStrings.PartitionedRegion_GATEWAYSENDER_0_IS_PAUSED_RESUME_IT_BEFORE_DESTROYING_USER_REGION_1
+                  .toLocalizedString(new Object[] {pausedSenders, this.getName()});
+        } else {
+          exception =
+              LocalizedStrings.PartitionedRegion_GATEWAYSENDERS_0_ARE_PAUSED_RESUME_THEM_BEFORE_DESTROYING_USER_REGION_1
+                  .toLocalizedString(new Object[] {pausedSenders, this.getName()});
-      
+
-        PartitionedRegion parallelQueueRegion = parallelQueue.getRegion(this
-            .getFullPath());
+        PartitionedRegion parallelQueueRegion = parallelQueue.getRegion(this.getFullPath());
-        }
-        else {// In any case, destroy shadow PR locally. distributed destroy of
-              // userPR will take care of detsroying shadowPR locally on other
-              // nodes.
+        } else {// In any case, destroy shadow PR locally. distributed destroy of
+                // userPR will take care of detsroying shadowPR locally on other
+                // nodes.
-          if (op.isClose()) { // In case of cache close operation, we want SPR's basic destroy to go through CACHE_CLOSE condition of postDestroyRegion not closePartitionedRegion code
-            event = new RegionEventImpl(parallelQueueRegion,
-                op, null, false, getMyId(),
+          if (op.isClose()) { // In case of cache close operation, we want SPR's basic destroy to go
+                              // through CACHE_CLOSE condition of postDestroyRegion not
+                              // closePartitionedRegion code
+            event = new RegionEventImpl(parallelQueueRegion, op, null, false, getMyId(),
+          } else {
+            event = new RegionEventImpl(parallelQueueRegion, Operation.REGION_LOCAL_DESTROY, null,
+                false, getMyId(), generateEventID());
-          else {
-            event = new RegionEventImpl(parallelQueueRegion,
-                Operation.REGION_LOCAL_DESTROY, null, false, getMyId(),
-                generateEventID());
-          }
-          parallelQueueRegion.basicDestroyRegion(event, false, lock,
-              callbackEvents);
+          parallelQueueRegion.basicDestroyRegion(event, false, lock, callbackEvents);
-      if(countOfQueueRegionsToBeDestroyed == 0){
+      if (countOfQueueRegionsToBeDestroyed == 0) {
-          }
-          catch (InterruptedException e) {
+          } catch (InterruptedException e) {
-        }
-        else {
+        } else {
-            Thread
-                .sleep(AbstractGatewaySender.MAXIMUM_SHUTDOWN_WAIT_TIME * 1000);
-          }
-          catch (InterruptedException e) {/* ignore */
+            Thread.sleep(AbstractGatewaySender.MAXIMUM_SHUTDOWN_WAIT_TIME * 1000);
+          } catch (InterruptedException e) {/* ignore */
-        
+
-  public void localDestroyRegion(Object aCallbackArgument)
-  {
+  public void localDestroyRegion(Object aCallbackArgument) {
-    List<PartitionedRegion> listOfChildRegions = ColocationHelper
-        .getColocatedChildRegions(this);
+    List<PartitionedRegion> listOfChildRegions = ColocationHelper.getColocatedChildRegions(this);
-    if ((prName != null)
-        || (!childRegionsWithoutSendersList.isEmpty())) {
+    if ((prName != null) || (!childRegionsWithoutSendersList.isEmpty())) {
-    
-    RegionEventImpl event = new RegionEventImpl(this,
-        Operation.REGION_LOCAL_DESTROY, aCallbackArgument, false, getMyId(),
-        generateEventID()/* generate EventID */);
+
+    RegionEventImpl event = new RegionEventImpl(this, Operation.REGION_LOCAL_DESTROY,
+        aCallbackArgument, false, getMyId(), generateEventID()/* generate EventID */);
-    }
-    catch (CacheWriterException e) {
+    } catch (CacheWriterException e) {
-      throw new Error(
-          "CacheWriterException should not be thrown in localDestroyRegion", e);
-    }
-    catch (TimeoutException e) {
+      throw new Error("CacheWriterException should not be thrown in localDestroyRegion", e);
+    } catch (TimeoutException e) {
-      throw new Error(
-          "TimeoutException should not be thrown in localDestroyRegion", e);
+      throw new Error("TimeoutException should not be thrown in localDestroyRegion", e);
-   * This method actually destroys the local accessor and data store. This
-   * method is invoked from the postDestroyRegion method of LocalRegion
-   * {@link LocalRegion}, which is overridden in PartitionedRegion This method
-   * is invoked from postDestroyRegion method. If origin is local: <br>
+   * This method actually destroys the local accessor and data store. This method is invoked from
+   * the postDestroyRegion method of LocalRegion {@link LocalRegion}, which is overridden in
+   * PartitionedRegion This method is invoked from postDestroyRegion method. If origin is local:
+   * <br>
-   * @param event
-   *                the RegionEvent that triggered this operation
+   * @param event the RegionEvent that triggered this operation
-    
+
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_IS_BEING_DESTROYED,
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_IS_BEING_DESTROYED,
-        }
-        catch (CancelException e) {
+        } catch (CancelException e) {
-      }
-      else {
+      } else {
-          prConfig = this.prRoot
-            .get(getRegionIdentifier());
-        }
-        catch (CancelException e) {
+          prConfig = this.prRoot.get(getRegionIdentifier());
+        } catch (CancelException e) {
-        if (!checkIfAlreadyDestroyedOrOldReference() && null != prConfig && !prConfig.getIsDestroying()) {
+        if (!checkIfAlreadyDestroyedOrOldReference() && null != prConfig
+            && !prConfig.getIsDestroying()) {
-          }
-          catch (CancelException e) {
+          } catch (CancelException e) {
-        }
-        else {
+        } else {
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_IS_DESTROYED,
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_PARTITIONED_REGION_0_WITH_PRID_1_IS_DESTROYED,
-    }
-    finally {
+    } finally {
-      }
-      catch (Exception es) {
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_CAUGHT_EXCEPTION_WHILE_TRYING_TO_UNLOCK_DURING_REGION_DESTRUCTION), es);
+      } catch (Exception es) {
+        logger.info(
+            LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_CAUGHT_EXCEPTION_WHILE_TRYING_TO_UNLOCK_DURING_REGION_DESTRUCTION),
+            es);
-   * This method destroys the PartitionedRegion globally. It sends destroyRegion
-   * message to other nodes and handles cleaning up of the data stores and
-   * meta-data.
+   * This method destroys the PartitionedRegion globally. It sends destroyRegion message to other
+   * nodes and handles cleaning up of the data stores and meta-data.
-   * @param event
-   *                the RegionEvent which triggered this global destroy
-   *                operation
+   * @param event the RegionEvent which triggered this global destroy operation
-      prConfig = prRoot.get(
-          this.getRegionIdentifier());
-    }
-    catch (CancelException e) {
+      prConfig = prRoot.get(this.getRegionIdentifier());
+    } catch (CancelException e) {
-    
+
-    }
-    catch (CancelException e) {
+    } catch (CancelException e) {
-    RegionEventImpl eventForLocalDestroy = (RegionEventImpl)event.clone();
+    RegionEventImpl eventForLocalDestroy = (RegionEventImpl) event.clone();
-   * @param event
-   *                the RegionEvent that triggered the region clean up
+   * @param event the RegionEvent that triggered the region clean up
-  private void destroyCleanUp(RegionEventImpl event, int serials[])
-  {
+  private void destroyCleanUp(RegionEventImpl event, int serials[]) {
-      }
-      catch (EntryNotFoundException ex) {
+      } catch (EntryNotFoundException ex) {
-      }
-      catch (CancelException e) {
+      } catch (CancelException e) {
-    }
-    finally {
+    } finally {
-   * Sends the partitioned region specific destroy region message and waits for
-   * any responses. This message is also sent in close/localDestroyRegion
-   * operation. When it is sent in Cache close/Region close/localDestroyRegion
-   * operations, it results in updating of RegionAdvisor on recipient nodes.
+   * Sends the partitioned region specific destroy region message and waits for any responses. This
+   * message is also sent in close/localDestroyRegion operation. When it is sent in Cache
+   * close/Region close/localDestroyRegion operations, it results in updating of RegionAdvisor on
+   * recipient nodes.
-   * @param event
-   *                the destruction event
+   * @param event the destruction event
-  private void sendDestroyRegionMessage(RegionEventImpl event, int serials[])
-  {
+  private void sendDestroyRegionMessage(RegionEventImpl event, int serials[]) {
-        logger.debug("Partition region {} failed to initialize. Remove its profile from remote members.", this);
+        logger.debug(
+            "Partition region {} failed to initialize. Remove its profile from remote members.",
+            this);
-    final HashSet configRecipients = new HashSet(getRegionAdvisor()
-        .adviseAllPRNodes());
-    
+    final HashSet configRecipients = new HashSet(getRegionAdvisor().adviseAllPRNodes());
+
-          InternalDistributedMember idm = ((Node)itr.next()).getMemberId();
+          InternalDistributedMember idm = ((Node) itr.next()).getMemberId();
-    }
-    catch (CancelException e) {
+    } catch (CancelException e) {
-      DestroyPartitionedRegionResponse resp = DestroyPartitionedRegionMessage
-          .send(configRecipients, this, event, serials);
+      DestroyPartitionedRegionResponse resp =
+          DestroyPartitionedRegionMessage.send(configRecipients, this, event, serials);
-    }
-    catch (ReplyException ignore) {
-      logger.warn(LocalizedMessage.create(
-          LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_SENDDESTROYREGIONMESSAGE_CAUGHT_EXCEPTION_DURING_DESTROYREGIONMESSAGE_SEND_AND_WAITING_FOR_RESPONSE),
+    } catch (ReplyException ignore) {
+      logger.warn(
+          LocalizedMessage.create(
+              LocalizedStrings.PartitionedRegion_PARTITIONEDREGION_SENDDESTROYREGIONMESSAGE_CAUGHT_EXCEPTION_DURING_DESTROYREGIONMESSAGE_SEND_AND_WAITING_FOR_RESPONSE),
-   * This method is used to destroy this partitioned region data and its
-   * associated store and removal of its PartitionedRegionID from local prIdToPR
-   * map. This method is called from destroyPartitionedRegion Method and removes
-   * the entry from prIdMap and cleans the data store buckets. It first checks
-   * whether this PartitionedRegion is already locally destroyed. If it is, this
-   * call returns, else if process with the removal from prIdMap and dataStore
-   * cleanup.
+   * This method is used to destroy this partitioned region data and its associated store and
+   * removal of its PartitionedRegionID from local prIdToPR map. This method is called from
+   * destroyPartitionedRegion Method and removes the entry from prIdMap and cleans the data store
+   * buckets. It first checks whether this PartitionedRegion is already locally destroyed. If it is,
+   * this call returns, else if process with the removal from prIdMap and dataStore cleanup.
+   * 
-    }
-    finally {
+    } finally {
-   * This method is invoked from recursiveDestroyRegion method of LocalRegion.
-   * This method checks the region type and invokes the relevant method.
+   * This method is invoked from recursiveDestroyRegion method of LocalRegion. This method checks
+   * the region type and invokes the relevant method.
-   * @param event
-   *                the RegionEvent <br>
-   * OVERRIDES
+   * @param event the RegionEvent <br>
+   *        OVERRIDES
-    //Fixes 44551 - wait for persistent buckets to finish
-    //recovering before sending the destroy region message
-    //any GII or wait for persistent recoveery will be aborted by the destroy
-    //flag being set to true, so this shouldn't take long.
+    // Fixes 44551 - wait for persistent buckets to finish
+    // recovering before sending the destroy region message
+    // any GII or wait for persistent recoveery will be aborted by the destroy
+    // flag being set to true, so this shouldn't take long.
-    
+
-        if (Operation.CACHE_CLOSE.equals(op) || 
-            Operation.FORCED_DISCONNECT.equals(op)) {
+        if (Operation.CACHE_CLOSE.equals(op) || Operation.FORCED_DISCONNECT.equals(op)) {
-            
-            //Because this code path never cleans up the real buckets, we need
-            //to log the fact that those buckets are destroyed here
-            if(RegionLogger.isEnabled()) {
+
+            // Because this code path never cleans up the real buckets, we need
+            // to log the fact that those buckets are destroyed here
+            if (RegionLogger.isEnabled()) {
-              if(store != null) {
-                for(BucketRegion bucket: store.getAllLocalBucketRegions()) {
-                  RegionLogger.logDestroy(bucket.getFullPath(), getMyId(), bucket.getPersistentID(), true);
+              if (store != null) {
+                for (BucketRegion bucket : store.getAllLocalBucketRegions()) {
+                  RegionLogger.logDestroy(bucket.getFullPath(), getMyId(), bucket.getPersistentID(),
+                      true);
-          }
-          catch (CancelException e) {
+          } catch (CancelException e) {
-              logger.debug("postDestroyRegion: failed sending DestroyRegionMessage due to cache closure");
+              logger.debug(
+                  "postDestroyRegion: failed sending DestroyRegionMessage due to cache closure");
-            //Instead of closing it, we need to register it to be closed later
-            //Otherwise, when the cache close tries to close all of the bucket regions,
-            //they'll fail because their disk store is already closed.
+            // Instead of closing it, we need to register it to be closed later
+            // Otherwise, when the cache close tries to close all of the bucket regions,
+            // they'll fail because their disk store is already closed.
-        }
-        else {
+        } else {
-            logger.debug("Making closePartitionedRegion call for {} with origin = {} op= {}", this, event.isOriginRemote(), op);
+            logger.debug("Making closePartitionedRegion call for {} with origin = {} op= {}", this,
+                event.isOriginRemote(), op);
-      } 
-      finally {
+      } finally {
-    }
-    else if (Operation.REGION_DESTROY.equals(op) || Operation.REGION_EXPIRE_DESTROY.equals(op)) {
+    } else if (Operation.REGION_DESTROY.equals(op) || Operation.REGION_EXPIRE_DESTROY.equals(op)) {
-        logger.debug("PartitionedRegion#postDestroyRegion: Making destroyPartitionedRegion call for {} with originRemote = {}", this, event.isOriginRemote());
+        logger.debug(
+            "PartitionedRegion#postDestroyRegion: Making destroyPartitionedRegion call for {} with originRemote = {}",
+            this, event.isOriginRemote());
+    } else {
+      Assert.assertTrue(false, "Unknown op" + op);
-    else {
-      Assert.assertTrue(false, "Unknown op" + op); 
-    }
-    
+
-        && !isUsedForPartitionedRegionBucket()
-        && !isUsedForParallelGatewaySenderQueue()) {
-      FilterRoutingInfo localCqFrInfo = getFilterProfile().getFilterRoutingInfoPart1(event, FilterProfile.NO_PROFILES, Collections.EMPTY_SET);
-      FilterRoutingInfo localCqInterestFrInfo = getFilterProfile().getFilterRoutingInfoPart2(localCqFrInfo, event);
-      if (localCqInterestFrInfo != null){
+        && !isUsedForPartitionedRegionBucket() && !isUsedForParallelGatewaySenderQueue()) {
+      FilterRoutingInfo localCqFrInfo = getFilterProfile().getFilterRoutingInfoPart1(event,
+          FilterProfile.NO_PROFILES, Collections.EMPTY_SET);
+      FilterRoutingInfo localCqInterestFrInfo =
+          getFilterProfile().getFilterRoutingInfoPart2(localCqFrInfo, event);
+      if (localCqInterestFrInfo != null) {
-    
-    if(destroyDiskRegion) {
+
+    if (destroyDiskRegion) {
-      if(dsi != null && getDataPolicy().withPersistence()) {
+      if (dsi != null && getDataPolicy().withPersistence()) {
-        //Fix for support issue 7870 - remove this regions
-        //config from the parent disk store, if we are removing the region.
-        if (colocatedWithRegion != null
-            && colocatedWithRegion.getDiskStore() != null
+        // Fix for support issue 7870 - remove this regions
+        // config from the parent disk store, if we are removing the region.
+        if (colocatedWithRegion != null && colocatedWithRegion.getDiskStore() != null
-          
+
-    
+
-   * This method checks whether this PartitionedRegion is eligible for the
-   * destruction or not. It first gets the prConfig for this region, and if it
-   * NULL, it sends a destroyPartitionedRegionLocally call as a pure
-   * precautionary measure. If it is not null, we check if this call is intended
-   * for this region only and there is no new PartitionedRegion creation with
-   * the same name. This check fixes, bug # 34621.
+   * This method checks whether this PartitionedRegion is eligible for the destruction or not. It
+   * first gets the prConfig for this region, and if it NULL, it sends a
+   * destroyPartitionedRegionLocally call as a pure precautionary measure. If it is not null, we
+   * check if this call is intended for this region only and there is no new PartitionedRegion
+   * creation with the same name. This check fixes, bug # 34621.
-      prConfig = prRoot.get(this
-          .getRegionIdentifier());
-    }
-    catch (CancelException e) {
+      prConfig = prRoot.get(this.getRegionIdentifier());
+    } catch (CancelException e) {
-    }
-    else {
+    } else {
-        EntryEventImpl ev = (EntryEventImpl)event;
+        EntryEventImpl ev = (EntryEventImpl) event;
-          if (this.getSubscriptionAttributes().getInterestPolicy() == 
-              InterestPolicy.CACHE_CONTENT) {
+          if (this.getSubscriptionAttributes()
+              .getInterestPolicy() == InterestPolicy.CACHE_CONTENT) {
-              logger.trace(LogMarker.DM_BRIDGE_SERVER, "not dispatching PR event in this member as there is no interest in it");
+              logger.trace(LogMarker.DM_BRIDGE_SERVER,
+                  "not dispatching PR event in this member as there is no interest in it");
-  
+
-   * Invoke the cache writer before a put is performed. Each
-   * BucketRegion delegates to the CacheWriter on the PartitionedRegion
-   * meaning that CacheWriters on a BucketRegion should only be used for internal
-   * purposes.
+   * Invoke the cache writer before a put is performed. Each BucketRegion delegates to the
+   * CacheWriter on the PartitionedRegion meaning that CacheWriters on a BucketRegion should only be
+   * used for internal purposes.
-      CacheWriter localWriter, 
-      boolean requireOldValue,
-      Object expectedOldValue)
+      CacheWriter localWriter, boolean requireOldValue, Object expectedOldValue)
-    
+
-      
+
-    if (localWriter == null
-        && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
+    if (localWriter == null && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
-        logger.debug("cacheWriteBeforePut: beforePut empty set returned by advisor.adviseNetWrite in netWrite");
+        logger.debug(
+            "cacheWriteBeforePut: beforePut empty set returned by advisor.adviseNetWrite in netWrite");
-      SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor
-          .getProcessor();
+      SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();
-        }
-        else {
+        } else {
-      }
-      finally {
+      } finally {
-    }
-    finally {
+    } finally {
-   * Invoke the CacheWriter before the detroy operation occurs.  Each
-   * BucketRegion delegates to the CacheWriter on the PartitionedRegion
-   * meaning that CacheWriters on a BucketRegion should only be used for internal
-   * purposes.
+   * Invoke the CacheWriter before the detroy operation occurs. Each BucketRegion delegates to the
+   * CacheWriter on the PartitionedRegion meaning that CacheWriters on a BucketRegion should only be
+   * used for internal purposes.
+   * 
-      Set netWriteRecipients = localWriter == null ? this.distAdvisor
-          .adviseNetWrite() : null;
+      Set netWriteRecipients = localWriter == null ? this.distAdvisor.adviseNetWrite() : null;
-      if (localWriter == null
-          && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
+      if (localWriter == null && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {
-        SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor
-            .getProcessor();
+        SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();
-      }
-      finally {
+      } finally {
-   * Send a message to all PartitionedRegion participants, telling each member
-   * of the PartitionedRegion with a datastore to dump the contents of the
-   * buckets to the system.log and validate that the meta-data for buckets
-   * agrees with the data store's perspective
+   * Send a message to all PartitionedRegion participants, telling each member of the
+   * PartitionedRegion with a datastore to dump the contents of the buckets to the system.log and
+   * validate that the meta-data for buckets agrees with the data store's perspective
-      PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor()
-          .adviseAllPRNodes(), this, false /* only validate */, false);
+      PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor().adviseAllPRNodes(),
+          this, false /* only validate */, false);
-  
-  /* (non-Javadoc)
+
+  /*
+   * (non-Javadoc)
+   * 
-   * Send a message to all PartitionedRegion participants, telling each member
-   * of the PartitionedRegion with a datastore to dump just the bucket names to
-   * the system.log
+   * Send a message to all PartitionedRegion participants, telling each member of the
+   * PartitionedRegion with a datastore to dump just the bucket names to the system.log
-    PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor()
-        .adviseDataStore(), this, false /* only validate */, true);
+    PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor().adviseDataStore(), this,
+        false /* only validate */, true);
-   * Send a message to all PartitionedRegion participants, telling each member
-   * of the PartitionedRegion with a datastore to validate that the meta-data
-   * for buckets agrees with the data store's perspective
+   * Send a message to all PartitionedRegion participants, telling each member of the
+   * PartitionedRegion with a datastore to validate that the meta-data for buckets agrees with the
+   * data store's perspective
-    PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor()
-        .adviseAllPRNodes(), this, true /* only validate */, false);
+    PartitionResponse response = DumpBucketsMessage.send(getRegionAdvisor().adviseAllPRNodes(),
+        this, true /* only validate */, false);
-   * Sends a message to all the <code>PartitionedRegion</code> participants,
-   * telling each member of the PartitionedRegion to dump the nodelist in
-   * bucket2node metadata for specified bucketId.
+   * Sends a message to all the <code>PartitionedRegion</code> participants, telling each member of
+   * the PartitionedRegion to dump the nodelist in bucket2node metadata for specified bucketId.
-      PartitionResponse response = DumpB2NRegion.send(this.getRegionAdvisor()
-          .adviseAllPRNodes(), this, bucketId, false);
+      PartitionResponse response =
+          DumpB2NRegion.send(this.getRegionAdvisor().adviseAllPRNodes(), this, bucketId, false);
-    }
-    catch (ReplyException re) {
+    } catch (ReplyException re) {
-    }
-    catch (CancelException e) {
+    } catch (CancelException e) {
-    }
-    catch (RegionDestroyedException e) {
+    } catch (RegionDestroyedException e) {
-    getRegionAdvisor().getBucket(bId).getBucketAdvisor().dumpProfiles(
-        "Dumping advisor bucket meta-data for bId=" + bucketStringForLogs(bId)
+    getRegionAdvisor().getBucket(bId).getBucketAdvisor()
+        .dumpProfiles("Dumping advisor bucket meta-data for bId=" + bucketStringForLogs(bId)
-   * Send a message to all PartitionedRegion participants, telling each member
-   * of the PartitionedRegion with a datastore to dump the contents of the
-   * allPartitionedRegions for this PartitionedRegion.
+   * Send a message to all PartitionedRegion participants, telling each member of the
+   * PartitionedRegion with a datastore to dump the contents of the allPartitionedRegions for this
+   * PartitionedRegion.
-    PartitionResponse response = DumpAllPRConfigMessage.send(getRegionAdvisor()
-        .adviseAllPRNodes(), this);
+    PartitionResponse response =
+        DumpAllPRConfigMessage.send(getRegionAdvisor().adviseAllPRNodes(), this);
-   * This method prints the content of the allPartitionedRegion's contents for
-   * this PartitionedRegion.
+   * This method prints the content of the allPartitionedRegion's contents for this
+   * PartitionedRegion.
-  
+
-   * A test method to get the list of all the bucket ids for the partitioned
-   * region in the data Store.
+   * A test method to get the list of all the bucket ids for the partitioned region in the data
+   * Store.
-  
+
-   * A test method to get the list of all the primary bucket ids for the partitioned
-   * region in the data Store.
+   * A test method to get the list of all the primary bucket ids for the partitioned region in the
+   * data Store.
-   * A Simple class used to track retry time for Region operations Does not
-   * provide any synchronization or concurrent safety
+   * A Simple class used to track retry time for Region operations Does not provide any
+   * synchronization or concurrent safety
-     * wait for {@link PartitionedRegionHelper#DEFAULT_WAIT_PER_RETRY_ITERATION},
-     * updating the total wait time. Use this method when the same node has been
-     * selected for consecutive attempts with an operation.
+     * wait for {@link PartitionedRegionHelper#DEFAULT_WAIT_PER_RETRY_ITERATION}, updating the total
+     * wait time. Use this method when the same node has been selected for consecutive attempts with
+     * an operation.
-     * Wait for {@link PartitionedRegionHelper#DEFAULT_WAIT_PER_RETRY_ITERATION}
-     * time and update the total wait time.
+     * Wait for {@link PartitionedRegionHelper#DEFAULT_WAIT_PER_RETRY_ITERATION} time and update the
+     * total wait time.
-       * Unfortunately, due to interrupts plus the vagaries of thread
-       * scheduling, we can't assume that our sleep is for exactly the amount of
-       * time that we specify. Thus, we need to measure the before/after times
-       * and increment the counter accordingly.
+       * Unfortunately, due to interrupts plus the vagaries of thread scheduling, we can't assume
+       * that our sleep is for exactly the amount of time that we specify. Thus, we need to measure
+       * the before/after times and increment the counter accordingly.
-      }
-      catch (InterruptedException intEx) {
+      } catch (InterruptedException intEx) {
-      }
-      finally {
+      } finally {
-   * Test to determine if the data store is managing the bucket appropriate for
-   * the given key
+   * Test to determine if the data store is managing the bucket appropriate for the given key
-   * @param key
-   *                the cache key
+   * @param key the cache key
-  
+
-    if(supportsConcurrencyChecks()) {
+    if (supportsConcurrencyChecks()) {
-   * finds all the keys matching the given regular expression (or all keys if
-   * regex is ".*")
+   * finds all the keys matching the given regular expression (or all keys if regex is ".*")
-   * @param regex
-   *                the regular expression
+   * @param regex the regular expression
-   * @param collector
-   *                object that will receive the keys as they arrive
+   * @param collector object that will receive the keys as they arrive
-   * @param         allowTombstones whether to return destroyed entries
-   * @param collector  object that will receive the keys as they arrive
+   * @param allowTombstones whether to return destroyed entries
+   * @param collector object that will receive the keys as they arrive
-   * finds all the keys matching the given interest type and passes them to the
-   * given collector
+   * finds all the keys matching the given interest type and passes them to the given collector
-  private void _getKeysWithInterest(int interestType, Object interestArg,
-      boolean allowTombstones, SetCollector collector) throws IOException {
+  private void _getKeysWithInterest(int interestType, Object interestArg, boolean allowTombstones,
+      SetCollector collector) throws IOException {
-      InternalDistributedMember bucketNode = getOrCreateNodeForBucketRead(lbucket
-          .intValue());
+      InternalDistributedMember bucketNode = getOrCreateNodeForBucketRead(lbucket.intValue());
-              bucketSet = this.dataStore.handleRemoteGetKeys(lbucket,
+              bucketSet = this.dataStore.handleRemoteGetKeys(lbucket, interestType, interestArg,
+                  allowTombstones);
+            } else {
+              FetchKeysResponse r = FetchKeysMessage.sendInterestQuery(bucketNode, this, lbucket,
-            }
-            else {
-              FetchKeysResponse r = FetchKeysMessage.sendInterestQuery(
-                  bucketNode, this, lbucket, interestType, interestArg, allowTombstones);
-        }
-        catch (PRLocallyDestroyedException pde) {
+        } catch (PRLocallyDestroyedException pde) {
-        }
-        catch (ForceReattemptException prce) {
+        } catch (ForceReattemptException prce) {
-   * SetCollector is implemented by classes that want to receive chunked results
-   * from queries like getKeysWithRegEx. The implementor creates a method,
-   * receiveSet, that consumes the chunks.
+   * SetCollector is implemented by classes that want to receive chunked results from queries like
+   * getKeysWithRegEx. The implementor creates a method, receiveSet, that consumes the chunks.
-  
+
-    while (iter.hasNext()){
+    while (iter.hasNext()) {
-      if (ind instanceof Index){
-        availableIndexes.put(((Index)ind).getName(), ind);
+      if (ind instanceof Index) {
+        availableIndexes.put(((Index) ind).getName(), ind);
-    while (iter.hasNext()){
+    while (iter.hasNext()) {
-      if (ind instanceof PartitionedIndex && ((Index) ind).getName().equals(indexName)){
-        return (PartitionedIndex)ind;
+      if (ind instanceof PartitionedIndex && ((Index) ind).getName().equals(indexName)) {
+        return (PartitionedIndex) ind;
-      if (ind instanceof Index){
+      if (ind instanceof Index) {
+
-   * @param remotelyOriginated
-   *                true if the index is created because of a remote index
-   *                creation call
-   * @param indexType
-   *                the type of index created.
-   * @param indexName
-   *                the name for the index to be created
-   * @param indexedExpression
-   *                expression for index creation.
-   * @param fromClause
-   *                the from clause for index creation
-   * @param imports
-   *                class to be imported for fromClause.
+   * @param remotelyOriginated true if the index is created because of a remote index creation call
+   * @param indexType the type of index created.
+   * @param indexName the name for the index to be created
+   * @param indexedExpression expression for index creation.
+   * @param fromClause the from clause for index creation
+   * @param imports class to be imported for fromClause.
-   * @throws ForceReattemptException
-   *                 indicating the operation failed to create a remote index
-   * @throws IndexCreationException
-   *                 if the index is not created properly
-   * @throws IndexNameConflictException
-   *                 if an index exists with this name on this region
-   * @throws IndexExistsException
-   *                 if and index already exists with the same properties as the
-   *                 one created
+   * @throws ForceReattemptException indicating the operation failed to create a remote index
+   * @throws IndexCreationException if the index is not created properly
+   * @throws IndexNameConflictException if an index exists with this name on this region
+   * @throws IndexExistsException if and index already exists with the same properties as the one
+   *         created
-  public Index createIndex(boolean remotelyOriginated, IndexType indexType,
-      String indexName, String indexedExpression, String fromClause, 
-      String imports, boolean loadEntries) throws ForceReattemptException, IndexCreationException,
-      IndexNameConflictException, IndexExistsException {
-    return createIndex(remotelyOriginated, indexType, indexName, indexedExpression, fromClause, imports, loadEntries, true);
+  public Index createIndex(boolean remotelyOriginated, IndexType indexType, String indexName,
+      String indexedExpression, String fromClause, String imports, boolean loadEntries)
+      throws ForceReattemptException, IndexCreationException, IndexNameConflictException,
+      IndexExistsException {
+    return createIndex(remotelyOriginated, indexType, indexName, indexedExpression, fromClause,
+        imports, loadEntries, true);
-  
-  public Index createIndex(boolean remotelyOriginated, IndexType indexType,
-      String indexName, String indexedExpression, String fromClause, 
-      String imports, boolean loadEntries, boolean sendMessage) throws ForceReattemptException, IndexCreationException,
+
+  public Index createIndex(boolean remotelyOriginated, IndexType indexType, String indexName,
+      String indexedExpression, String fromClause, String imports, boolean loadEntries,
+      boolean sendMessage) throws ForceReattemptException, IndexCreationException,
-        throw new IndexCreationException(LocalizedStrings.
-            PartitionedRegion_DATA_STORE_ON_THIS_VM_IS_NULL_AND_THE_LOCAL_MAX_MEMORY_IS_NOT_ZERO_THE_DATA_POLICY_IS_0_AND_THE_LOCALMAXMEMEORY_IS_1.
-            toLocalizedString(new Object[] {getDataPolicy(), Long.valueOf(getLocalMaxMemory())}));
+        throw new IndexCreationException(
+            LocalizedStrings.PartitionedRegion_DATA_STORE_ON_THIS_VM_IS_NULL_AND_THE_LOCAL_MAX_MEMORY_IS_NOT_ZERO_THE_DATA_POLICY_IS_0_AND_THE_LOCALMAXMEMEORY_IS_1
+                .toLocalizedString(
+                    new Object[] {getDataPolicy(), Long.valueOf(getLocalMaxMemory())}));
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA));
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA));
-      this.indexManager = IndexUtils.getIndexManager(this, true); 
+      this.indexManager = IndexUtils.getIndexManager(this, true);
-    
+
-      logger.debug("Started creating index with Index Name :{} On PartitionedRegion {}, Indexfrom caluse={}, Remote Request: {}",
-         indexName, this.getFullPath(), fromClause, remotelyOriginated);
+      logger.debug(
+          "Started creating index with Index Name :{} On PartitionedRegion {}, Indexfrom caluse={}, Remote Request: {}",
+          indexName, this.getFullPath(), fromClause, remotelyOriginated);
-    IndexTask indexTask = new IndexTask(remotelyOriginated, indexType, indexName,
-        indexedExpression, fromClause,  imports, loadEntries);
+    IndexTask indexTask = new IndexTask(remotelyOriginated, indexType, indexName, indexedExpression,
+        fromClause, imports, loadEntries);
-    if (ind instanceof Index){
+    if (ind instanceof Index) {
-        return (Index)ind;
+        return (Index) ind;
-      throw new IndexNameConflictException(LocalizedStrings.IndexManager_INDEX_NAMED_0_ALREADY_EXISTS
-          .toLocalizedString(indexName));
+      throw new IndexNameConflictException(
+          LocalizedStrings.IndexManager_INDEX_NAMED_0_ALREADY_EXISTS.toLocalizedString(indexName));
-    FutureTask<Index> oldIndexFutureTask = (FutureTask<Index>)ind;
+    FutureTask<Index> oldIndexFutureTask = (FutureTask<Index>) ind;
-        
+
-        if (index != null){
+        if (index != null) {
-          PartitionedIndex prIndex = (PartitionedIndex)index;      
+          PartitionedIndex prIndex = (PartitionedIndex) index;
-          
+
-          if (!remotelyOriginated && sendMessage){
-            logger.info(LocalizedMessage.create(LocalizedStrings.
-                PartitionedRegion_CREATED_INDEX_LOCALLY_SENDING_INDEX_CREATION_MESSAGE_TO_ALL_MEMBERS_AND_WILL_BE_WAITING_FOR_RESPONSE_0,
+          if (!remotelyOriginated && sendMessage) {
+            logger.info(LocalizedMessage.create(
+                LocalizedStrings.PartitionedRegion_CREATED_INDEX_LOCALLY_SENDING_INDEX_CREATION_MESSAGE_TO_ALL_MEMBERS_AND_WILL_BE_WAITING_FOR_RESPONSE_0,
-            
+
-              response = (IndexCreationMsg.IndexCreationResponse)IndexCreationMsg.send(null, PartitionedRegion.this, singleIndexDefinition);            
+              response = (IndexCreationMsg.IndexCreationResponse) IndexCreationMsg.send(null,
+                  PartitionedRegion.this, singleIndexDefinition);
-                if(indexBucketsMap != null && indexBucketsMap.size() > 0) {
+                if (indexBucketsMap != null && indexBucketsMap.size() > 0) {
-            } catch(UnsupportedOperationException ex) {
-              // if remote nodes are of older versions indexes will not be created there, so remove index on this node as well.
+            } catch (UnsupportedOperationException ex) {
+              // if remote nodes are of older versions indexes will not be created there, so remove
+              // index on this node as well.
-              throw new IndexCreationException(LocalizedStrings.PartitionedRegion_INDEX_CREATION_FAILED_ROLLING_UPGRADE.toLocalizedString());
+              throw new IndexCreationException(
+                  LocalizedStrings.PartitionedRegion_INDEX_CREATION_FAILED_ROLLING_UPGRADE
+                      .toLocalizedString());
-        
+
-           return index;
+          return index;
-        
-        throw new IndexNameConflictException(LocalizedStrings.IndexManager_INDEX_NAMED_0_ALREADY_EXISTS.toLocalizedString(indexName));
+
+        throw new IndexNameConflictException(
+            LocalizedStrings.IndexManager_INDEX_NAMED_0_ALREADY_EXISTS
+                .toLocalizedString(indexName));
-      if(!remotelyOriginated) {
+      if (!remotelyOriginated) {
-          throw (IndexNameConflictException)c;
-        } else if (c instanceof IndexExistsException){
-          throw (IndexExistsException)c;
+          throw (IndexNameConflictException) c;
+        } else if (c instanceof IndexExistsException) {
+          throw (IndexExistsException) c;
-      //If the index is not successfully created, remove IndexTask from the map.
-      if (index == null){
+      // If the index is not successfully created, remove IndexTask from the map.
+      if (index == null) {
-        if (index != null && !(index instanceof Index)){
+        if (index != null && !(index instanceof Index)) {
-      } 
+      }
-      logger.debug("Completed creating index with Index Name :{} On PartitionedRegion {}, Remote Request: {}",
+      logger.debug(
+          "Completed creating index with Index Name :{} On PartitionedRegion {}, Remote Request: {}",
-  public List<Index> createIndexes(boolean remotelyOriginated, HashSet<IndexCreationData> indexDefinitions)
-      throws MultiIndexCreationException, CacheException,
-      ForceReattemptException, IndexCreationException {
+  public List<Index> createIndexes(boolean remotelyOriginated,
+      HashSet<IndexCreationData> indexDefinitions) throws MultiIndexCreationException,
+      CacheException, ForceReattemptException, IndexCreationException {
-                .toLocalizedString(new Object[] { getDataPolicy(),
-                    Long.valueOf(getLocalMaxMemory()) }));
+                .toLocalizedString(
+                    new Object[] {getDataPolicy(), Long.valueOf(getLocalMaxMemory())}));
-      logger.info(LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA);
+      logger
+          .info(LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA);
-    
+
-    throwException = createEmptyIndexes(indexDefinitions, remotelyOriginated, indexes, exceptionsMap);
+    throwException |=
+        createEmptyIndexes(indexDefinitions, remotelyOriginated, indexes, exceptionsMap);
-    
-    if(indexes.size() > 0) {
+
+    if (indexes.size() > 0) {
-    if(unpopulatedIndexes != null && unpopulatedIndexes.size() > 0) {
-      throwException = populateEmptyIndexes(unpopulatedIndexes, exceptionsMap);
+    if (unpopulatedIndexes != null && unpopulatedIndexes.size() > 0) {
+      throwException |= populateEmptyIndexes(unpopulatedIndexes, exceptionsMap);
- 
+
-    throwException = sendCreateIndexesMessage(remotelyOriginated, indexDefinitions, indexes, exceptionsMap);
-    
-    //If exception is throw in any of the above steps
+    throwException |=
+        sendCreateIndexesMessage(remotelyOriginated, indexDefinitions, indexes, exceptionsMap);
+
+    // If exception is throw in any of the above steps
-     ((AbstractIndex) ind).setPopulated(true);
+      ((AbstractIndex) ind).setPopulated(true);
-    
-    return new ArrayList<Index>(indexes);
-  }  
-  private boolean createEmptyIndexes(
-      HashSet<IndexCreationData> indexDefinitions, boolean remotelyOriginated,
-      Set<Index> indexes, HashMap<String, Exception> exceptionsMap) {
+    return new ArrayList<Index>(indexes);
+  }
+
+  private boolean createEmptyIndexes(HashSet<IndexCreationData> indexDefinitions,
+      boolean remotelyOriginated, Set<Index> indexes, HashMap<String, Exception> exceptionsMap) {
-        Index ind = this.createIndex(remotelyOriginated, icd.getIndexType(),
-            icd.getIndexName(), icd.getIndexExpression(),
-            icd.getIndexFromClause(), icd.getIndexImportString(), false, false);
+        Index ind = this.createIndex(remotelyOriginated, icd.getIndexType(), icd.getIndexName(),
+            icd.getIndexExpression(), icd.getIndexFromClause(), icd.getIndexImportString(), false,
+            false);
-          logger.debug("Creation failed for index: {}, {}", icd.getIndexName(), ex.getMessage(), ex);
+          logger.debug("Creation failed for index: {}, {}", icd.getIndexName(), ex.getMessage(),
+              ex);
- 
+
-    synchronized(indexLock) {
+    synchronized (indexLock) {
-      for(Index ind : indexSet) {
-        PartitionedIndex prIndex = (PartitionedIndex)ind;
-        if(!prIndex.isPopulateInProgress()) {
+      for (Index ind : indexSet) {
+        PartitionedIndex prIndex = (PartitionedIndex) ind;
+        if (!prIndex.isPopulateInProgress()) {
- 
+
- }
-  
+  }
+
-    for(Index ind : indexes) {
-      bucketIndexes.addAll(((PartitionedIndex)ind).getBucketIndexes(bucket));
+    for (Index ind : indexes) {
+      bucketIndexes.addAll(((PartitionedIndex) ind).getBucketIndexes(bucket));
-  
-  
+
+
-      HashSet<IndexCreationData> indexDefinitions, Set<Index> indexes, HashMap<String, Exception> exceptionsMap)
-      throws CacheException, ForceReattemptException {
+      HashSet<IndexCreationData> indexDefinitions, Set<Index> indexes,
+      HashMap<String, Exception> exceptionsMap) throws CacheException, ForceReattemptException {
-      logger
-          .info(LocalizedStrings.PartitionedRegion_CREATED_INDEX_LOCALLY_SENDING_INDEX_CREATION_MESSAGE_TO_ALL_MEMBERS_AND_WILL_BE_WAITING_FOR_RESPONSE_0);
+      logger.info(
+          LocalizedStrings.PartitionedRegion_CREATED_INDEX_LOCALLY_SENDING_INDEX_CREATION_MESSAGE_TO_ALL_MEMBERS_AND_WILL_BE_WAITING_FOR_RESPONSE_0);
-        response = (IndexCreationMsg.IndexCreationResponse) IndexCreationMsg
-            .send(null, this, indexDefinitions);
+        response = (IndexCreationMsg.IndexCreationResponse) IndexCreationMsg.send(null, this,
+            indexDefinitions);
-          IndexCreationMsg.IndexCreationResult result = response
-              .waitForResult();
+          IndexCreationMsg.IndexCreationResult result = response.waitForResult();
-                .setRemoteBucketesIndexed(remoteIndexBucketsMap.get(ind.getName()));
+                    .setRemoteBucketesIndexed(remoteIndexBucketsMap.get(ind.getName()));
-          exceptionsMap.put(ind.getName(), new IndexCreationException(
-            LocalizedStrings.PartitionedRegion_INDEX_CREATION_FAILED_ROLLING_UPGRADE
-                .toLocalizedString()));
+          exceptionsMap.put(ind.getName(),
+              new IndexCreationException(
+                  LocalizedStrings.PartitionedRegion_INDEX_CREATION_FAILED_ROLLING_UPGRADE
+                      .toLocalizedString()));
-  
+
-   * Explicitly sends an index creation message to a newly added node to the
-   * system on prs.
+   * Explicitly sends an index creation message to a newly added node to the system on prs.
-   * @param idM
-   *                id on the newly added node.
+   * @param idM id on the newly added node.
-    RegionAdvisor advisor = (RegionAdvisor)(this.getCacheDistributionAdvisor());
-    final Set recipients  = advisor.adviseDataStore();
-    if(!recipients.contains(idM)){
+    RegionAdvisor advisor = (RegionAdvisor) (this.getCacheDistributionAdvisor());
+    final Set recipients = advisor.adviseDataStore();
+    if (!recipients.contains(idM)) {
-          LocalizedStrings.PartitionedRegion_NEWLY_ADDED_MEMBER_TO_THE_PR_IS_AN_ACCESSOR_AND_WILL_NOT_RECEIVE_INDEX_INFORMATION_0,  idM));
+          LocalizedStrings.PartitionedRegion_NEWLY_ADDED_MEMBER_TO_THE_PR_IS_AN_ACCESSOR_AND_WILL_NOT_RECEIVE_INDEX_INFORMATION_0,
+          idM));
-    
+
-      if (!(ind instanceof Index)){
+      if (!(ind instanceof Index)) {
-      PartitionedIndex prIndex = (PartitionedIndex)ind;
+      PartitionedIndex prIndex = (PartitionedIndex) ind;
-      icd.setIndexData(prIndex.getType(), prIndex.getFromClause(), prIndex.getIndexedExpression(), prIndex.getImports(), true);
+      icd.setIndexData(prIndex.getType(), prIndex.getFromClause(), prIndex.getIndexedExpression(),
+          prIndex.getImports(), true);
-    response = (IndexCreationMsg.IndexCreationResponse)IndexCreationMsg.send(
-          idM, this, indexDefinitions);
+    response =
+        (IndexCreationMsg.IndexCreationResponse) IndexCreationMsg.send(idM, this, indexDefinitions);
-          ((PartitionedIndex)ind).setRemoteBucketesIndexed(remoteIndexBucketsMap.get(ind.getName()));
+          ((PartitionedIndex) ind)
+              .setRemoteBucketesIndexed(remoteIndexBucketsMap.get(ind.getName()));
-      
-   
+
+
-   * Removes all the indexes on this partitioned regions instance and send
-   * remove index message
+   * Removes all the indexes on this partitioned regions instance and send remove index message
-  public int removeIndexes(boolean remotelyOriginated) throws CacheException,
-      ForceReattemptException {
+  public int removeIndexes(boolean remotelyOriginated)
+      throws CacheException, ForceReattemptException {
-    
+
-    logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_REMOVING_ALL_THE_INDEXES_ON_THIS_PARITITION_REGION__0, this));
+    logger.info(LocalizedMessage.create(
+        LocalizedStrings.PartitionedRegion_REMOVING_ALL_THE_INDEXES_ON_THIS_PARITITION_REGION__0,
+        this));
-        Map.Entry bucketEntry = (Map.Entry)bucketIterator.next();
-        bucket = (LocalRegion)bucketEntry.getValue();
+        Map.Entry bucketEntry = (Map.Entry) bucketIterator.next();
+        bucket = (LocalRegion) bucketEntry.getValue();
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_SENDING_REMOVEINDEX_MESSAGE_TO_ALL_THE_PARTICIPATING_PRS));
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.PartitionedRegion_SENDING_REMOVEINDEX_MESSAGE_TO_ALL_THE_PARTICIPATING_PRS));
-        response = (RemoveIndexesMessage.RemoveIndexesResponse)
-            RemoveIndexesMessage.send(this, null, true);
-        
+        response = (RemoveIndexesMessage.RemoveIndexesResponse) RemoveIndexesMessage.send(this,
+            null, true);
+
-          logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_DONE_WATING_FOR_REMOVE_INDEX));
+          logger.info(LocalizedMessage
+              .create(LocalizedStrings.PartitionedRegion_DONE_WATING_FOR_REMOVE_INDEX));
-            logger.debug("Total number of buckets which removed indexes , locally : {} and remotely removed : {} and the total number of remote buckets : {}",
+            logger.debug(
+                "Total number of buckets which removed indexes , locally : {} and remotely removed : {} and the total number of remote buckets : {}",
-      //this.indexes = null;
+      // this.indexes = null;
-    
+
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_THIS_INDEX__0_IS_NOT_ON_THIS_PARTITONED_REGION___1,
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_THIS_INDEX__0_IS_NOT_ON_THIS_PARTITONED_REGION___1,
-      logger.debug("Remove index called, IndexName: {} Index: {}  Will be removing all the bucket indexes.", ind.getName(), ind);
+      logger.debug(
+          "Remove index called, IndexName: {} Index: {}  Will be removing all the bucket indexes.",
+          ind.getName(), ind);
-    try {  
+    try {
-        List allBucketIndex = ((PartitionedIndex)prIndex).getBucketIndexes();
+        List allBucketIndex = ((PartitionedIndex) prIndex).getBucketIndexes();
-          
+
-          
+
-          Index in = (Index)it.next();
-          LocalRegion region = ((LocalRegion)in.getRegion());
+          Index in = (Index) it.next();
+          LocalRegion region = ((LocalRegion) in.getRegion());
-          
+
-          ((PartitionedIndex)prIndex).removeFromBucketIndexes(region, in);
+          ((PartitionedIndex) prIndex).removeFromBucketIndexes(region, in);
-      ((PartitionedIndex)prIndex).releaseIndexWriteLockForRemove();
+      ((PartitionedIndex) prIndex).releaseIndexWriteLockForRemove();
-      logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_SENDING_REMOVEINDEX_MESSAGE_TO_ALL_THE_PARTICIPATING_PRS));
-      response = (RemoveIndexesMessage.RemoveIndexesResponse)RemoveIndexesMessage.send(this, ind, false);
+      logger.info(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_SENDING_REMOVEINDEX_MESSAGE_TO_ALL_THE_PARTICIPATING_PRS));
+      response =
+          (RemoveIndexesMessage.RemoveIndexesResponse) RemoveIndexesMessage.send(this, ind, false);
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_DONE_WATING_FOR_REMOVE_INDEX));
+        logger.info(LocalizedMessage
+            .create(LocalizedStrings.PartitionedRegion_DONE_WATING_FOR_REMOVE_INDEX));
-          logger.debug("Total number of buckets which removed indexs , locally : {} and remotely removed : {} and the total number of remote buckets : {}",
-               numBuckets, response.getRemoteRemovedIndexes(), response.getTotalRemoteBuckets());
+          logger.debug(
+              "Total number of buckets which removed indexs , locally : {} and remotely removed : {} and the total number of remote buckets : {}",
+              numBuckets, response.getRemoteRemovedIndexes(), response.getTotalRemoteBuckets());
-   * @param indexName
-   *                name of the index to be removed.
+   * @param indexName name of the index to be removed.
-  public int removeIndex(String indexName) throws CacheException,
-  ForceReattemptException {
+  public int removeIndex(String indexName) throws CacheException, ForceReattemptException {
-    //IndexTask indexTask = new IndexTask(indexName);
+    // IndexTask indexTask = new IndexTask(indexName);
-      numbuckets = removeIndex((Index)this.indexes.get(indexName), true);
+      numbuckets = removeIndex((Index) this.indexes.get(indexName), true);
-  public Object getValueInVM(EntryEventImpl event)
-      throws EntryNotFoundException {
+  public Object getValueInVM(EntryEventImpl event) throws EntryNotFoundException {
-  
+
-   * Test Method: Fetch the given bucket's meta-data from each member hosting
-   * buckets
+   * Test Method: Fetch the given bucket's meta-data from each member hosting buckets
-   * @param bucketId
-   *                the identity of the bucket
-   * @return list of arrays, each array element containing a
-   *         {@link DistributedMember} and a {@link Boolean} the boolean denotes
-   *         if the member is hosting the bucket and believes it is the primary
-   * @throws ForceReattemptException
-   *                 if the caller should reattempt this request
+   * @param bucketId the identity of the bucket
+   * @return list of arrays, each array element containing a {@link DistributedMember} and a
+   *         {@link Boolean} the boolean denotes if the member is hosting the bucket and believes it
+   *         is the primary
+   * @throws ForceReattemptException if the caller should reattempt this request
-  public List getBucketOwnersForValidation(int bucketId)
-      throws ForceReattemptException {
+  public List getBucketOwnersForValidation(int bucketId) throws ForceReattemptException {
-    for (int i=0; i<3; i++) {
+    for (int i = 0; i < 3; i++) {
-      DumpB2NResponse response = DumpB2NRegion.send(getRegionAdvisor()
-          .adviseDataStore(), this, bucketId, true);
+      DumpB2NResponse response =
+          DumpB2NRegion.send(getRegionAdvisor().adviseDataStore(), this, bucketId, true);
-        logger.info("DumpB2NRegion failed to get PR {}, bucket id {}'s info due to {}, retrying...", this.getFullPath(), bucketId, e.getMessage());
+        logger.info("DumpB2NRegion failed to get PR {}, bucket id {}'s info due to {}, retrying...",
+            this.getFullPath(), bucketId, e.getMessage());
-        remoteInfos.add(new Object[] { getSystem().getDM().getId(),
-            Boolean.TRUE, "" });
-      }
-      else {
-        remoteInfos.add(new Object[] { getSystem().getDM().getId(),
-            Boolean.FALSE, "" });
+        remoteInfos.add(new Object[] {getSystem().getDM().getId(), Boolean.TRUE, ""});
+      } else {
+        remoteInfos.add(new Object[] {getSystem().getDM().getId(), Boolean.FALSE, ""});
-   * Return the primary for the local bucket. Returns null if no primary
-   * can be found within {@link DistributionConfig#getMemberTimeout}.
+   * Return the primary for the local bucket. Returns null if no primary can be found within
+   * {@link DistributionConfig#getMemberTimeout}.
+   * 
-   * Test Method: Used to debug the system when an operation fails by throwing
-   * an exception
+   * Test Method: Used to debug the system when an operation fails by throwing an exception
-   * Wait until the bucket meta-data has been built and is ready to receive
-   * messages and/or updates
+   * Wait until the bucket meta-data has been built and is ready to receive messages and/or updates
-   * get the total retry interval, in milliseconds, for operations concerning
-   * this partitioned region
+   * get the total retry interval, in milliseconds, for operations concerning this partitioned
+   * region
-  
-  public long getBirthTime() { 
+
+  public long getBirthTime() {
-   * Used to get membership events from our advisor to implement
-   * RegionMembershipListener invocations. This is copied almost in whole from
-   * DistributedRegion
+   * Used to get membership events from our advisor to implement RegionMembershipListener
+   * invocations. This is copied almost in whole from DistributedRegion
-  protected class AdvisorListener implements MembershipListener
-  {
+  protected class AdvisorListener implements MembershipListener {
-//      if (PartitionedRegion.this.isInitialized() && hasListener()) {
-//        RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this,
-//            Operation.REGION_CREATE, null, true, id);
-//        dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CREATE,
-//            event);
-//      }
+      // if (PartitionedRegion.this.isInitialized() && hasListener()) {
+      // RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this,
+      // Operation.REGION_CREATE, null, true, id);
+      // dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CREATE,
+      // event);
+      // }
-    public void quorumLost(Set<InternalDistributedMember> failures, List<InternalDistributedMember> remaining) {
-    }
+    public void quorumLost(Set<InternalDistributedMember> failures,
+        List<InternalDistributedMember> remaining) {}
-    public void memberSuspect(InternalDistributedMember id,
-        InternalDistributedMember whoSuspected, String reason) {
-    }
-    
-    public synchronized void memberDeparted(InternalDistributedMember id,
-        boolean crashed) {
+    public void memberSuspect(InternalDistributedMember id, InternalDistributedMember whoSuspected,
+        String reason) {}
+
+    public synchronized void memberDeparted(InternalDistributedMember id, boolean crashed) {
-        RegionEventImpl event = new RegionEventImpl(PartitionedRegion.this,
-            Operation.REGION_CLOSE, null, true, id);
+        RegionEventImpl event =
+            new RegionEventImpl(PartitionedRegion.this, Operation.REGION_CLOSE, null, true, id);
-          dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CRASH,
-              event);
-        }
-        else {
+          dispatchListenerEvent(EnumListenerEvent.AFTER_REMOTE_REGION_CRASH, event);
+        } else {
-          //               could be close, local destroy, or destroy (or load snap?)
+          // could be close, local destroy, or destroy (or load snap?)
-  
+
-      bucketId = PartitionedRegionHelper.getHashKey(this, null,
-          keyInfo.getKey(), keyInfo.getValue(), keyInfo.getCallbackArg());
+      bucketId = PartitionedRegionHelper.getHashKey(this, null, keyInfo.getKey(),
+          keyInfo.getValue(), keyInfo.getCallbackArg());
-      DistributedMember primary = getRegionAdvisor().getPrimaryMemberForBucket(
-          bucketId);
+      DistributedMember primary = getRegionAdvisor().getPrimaryMemberForBucket(bucketId);
-        throw new PrimaryBucketException("Bucket " + bucketId
-            + " is not primary. Current primary holder is " + primary);
+        throw new PrimaryBucketException(
+            "Bucket " + bucketId + " is not primary. Current primary holder is " + primary);
-  
-  
+
+
-    if (ra.getPartitionAttributes().getLocalMaxMemory() <= 0) return false; // see bug 42055
+    if (ra.getPartitionAttributes().getLocalMaxMemory() <= 0)
+      return false; // see bug 42055
-                                        InternalRegionArguments internalRegionArgs) {
+      InternalRegionArguments internalRegionArgs) {
-    if(store != null && store.getOwnedByRegion()) {
+    if (store != null && store.getOwnedByRegion()) {
-  protected DiskRegion createDiskRegion(InternalRegionArguments internalRegionArgs) throws DiskAccessException {
+  protected DiskRegion createDiskRegion(InternalRegionArguments internalRegionArgs)
+      throws DiskAccessException {
-  
+
-      logger.debug("PartitionedRegion {} sending InterestEvent message to:{}", getFullPath(), allRemoteStores);
+      logger.debug("PartitionedRegion {} sending InterestEvent message to:{}", getFullPath(),
+          allRemoteStores);
-      }
-      catch (ForceReattemptException e) {
+      } catch (ForceReattemptException e) {
-          logger.debug("PartitionedRegion {} waiting for response from {}", getFullPath(), allRemoteStores);
+          logger.debug("PartitionedRegion {} waiting for response from {}", getFullPath(),
+              allRemoteStores);
-      }
-      catch (ForceReattemptException e) {
+      } catch (ForceReattemptException e) {
-  
+
-   * Changes the timeToLive expiration attributes for the partitioned region as
-   * a whole
+   * Changes the timeToLive expiration attributes for the partitioned region as a whole
-   * @param timeToLive
-   *                the expiration attributes for the region timeToLive
+   * @param timeToLive the expiration attributes for the region timeToLive
-   * @throws IllegalArgumentException
-   *                 if timeToLive is null or if the ExpirationAction is
-   *                 LOCAL_INVALIDATE and the region is
-   *                 {@link DataPolicy#withReplication replicated}
-   * @throws IllegalStateException
-   *                 if statistics are disabled for this region.
+   * @throws IllegalArgumentException if timeToLive is null or if the ExpirationAction is
+   *         LOCAL_INVALIDATE and the region is {@link DataPolicy#withReplication replicated}
+   * @throws IllegalStateException if statistics are disabled for this region.
-  public ExpirationAttributes setRegionTimeToLive(
-      ExpirationAttributes timeToLive) {
+  public ExpirationAttributes setRegionTimeToLive(ExpirationAttributes timeToLive) {
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-   * Changes the idleTimeout expiration attributes for the region as a whole.
-   * Resets the {@link CacheStatistics#getLastAccessedTime} for the region.
+   * Changes the idleTimeout expiration attributes for the region as a whole. Resets the
+   * {@link CacheStatistics#getLastAccessedTime} for the region.
-   * @param idleTimeout
-   *                the ExpirationAttributes for this region idleTimeout
+   * @param idleTimeout the ExpirationAttributes for this region idleTimeout
-   * @throws IllegalArgumentException
-   *                 if idleTimeout is null or if the ExpirationAction is
-   *                 LOCAL_INVALIDATE and the region is
-   *                 {@link DataPolicy#withReplication replicated}
-   * @throws IllegalStateException
-   *                 if statistics are disabled for this region.
+   * @throws IllegalArgumentException if idleTimeout is null or if the ExpirationAction is
+   *         LOCAL_INVALIDATE and the region is {@link DataPolicy#withReplication replicated}
+   * @throws IllegalStateException if statistics are disabled for this region.
-  public ExpirationAttributes setRegionIdleTimeout(
-      ExpirationAttributes idleTimeout) {
+  public ExpirationAttributes setRegionIdleTimeout(ExpirationAttributes idleTimeout) {
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-   * @param timeToLive
-   *                the timeToLive expiration attributes for entries
+   * @param timeToLive the timeToLive expiration attributes for entries
-   * @throws IllegalArgumentException
-   *                 if timeToLive is null or if the ExpirationAction is
-   *                 LOCAL_DESTROY and the region is
-   *                 {@link DataPolicy#withReplication replicated} or if the
-   *                 ExpirationAction is LOCAL_INVALIDATE and the region is
-   *                 {@link DataPolicy#withReplication replicated}
-   * @throws IllegalStateException
-   *                 if statistics are disabled for this region.
+   * @throws IllegalArgumentException if timeToLive is null or if the ExpirationAction is
+   *         LOCAL_DESTROY and the region is {@link DataPolicy#withReplication replicated} or if the
+   *         ExpirationAction is LOCAL_INVALIDATE and the region is
+   *         {@link DataPolicy#withReplication replicated}
+   * @throws IllegalStateException if statistics are disabled for this region.
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-  private PartitionRegionConfig getPRConfigWithLatestExpirationAttributes(){
+  private PartitionRegionConfig getPRConfigWithLatestExpirationAttributes() {
-    PartitionRegionConfig newConfig = new PartitionRegionConfig(
-        prConfig.getPRId(),
-        prConfig.getFullPath(),
-        prConfig.getPartitionAttrs(),
-        prConfig.getScope(),
-        prConfig.getEvictionAttributes(),
-        this.getRegionIdleTimeout(),
-        this.getRegionTimeToLive(),
-        this.getEntryIdleTimeout(),
-        this.getEntryTimeToLive(),
-        prConfig.getGatewaySenderIds());
+    PartitionRegionConfig newConfig = new PartitionRegionConfig(prConfig.getPRId(),
+        prConfig.getFullPath(), prConfig.getPartitionAttrs(), prConfig.getScope(),
+        prConfig.getEvictionAttributes(), this.getRegionIdleTimeout(), this.getRegionTimeToLive(),
+        this.getEntryIdleTimeout(), this.getEntryTimeToLive(), prConfig.getGatewaySenderIds());
-   * @param custom
-   *                the new CustomExpiry
+   * @param custom the new CustomExpiry
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-   * @param idleTimeout
-   *                the idleTimeout expiration attributes for entries
+   * @param idleTimeout the idleTimeout expiration attributes for entries
-   * @throws IllegalArgumentException
-   *                 if idleTimeout is null or if the ExpirationAction is
-   *                 LOCAL_DESTROY and the region is
-   *                 {@link DataPolicy#withReplication replicated} or if the the
-   *                 ExpirationAction is LOCAL_INVALIDATE and the region is
-   *                 {@link DataPolicy#withReplication replicated}
+   * @throws IllegalArgumentException if idleTimeout is null or if the ExpirationAction is
+   *         LOCAL_DESTROY and the region is {@link DataPolicy#withReplication replicated} or if the
+   *         the ExpirationAction is LOCAL_INVALIDATE and the region is
+   *         {@link DataPolicy#withReplication replicated}
-   * @throws IllegalStateException
-   *                 if statistics are disabled for this region.
+   * @throws IllegalStateException if statistics are disabled for this region.
-  public ExpirationAttributes setEntryIdleTimeout(
-      ExpirationAttributes idleTimeout) {
+  public ExpirationAttributes setEntryIdleTimeout(ExpirationAttributes idleTimeout) {
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-   * @param custom
-   *                the new CustomExpiry
+   * @param custom the new CustomExpiry
-        Map.Entry entry = (Map.Entry)iter.next();
-        Region bucketRegion = (BucketRegion)entry.getValue();
+        Map.Entry entry = (Map.Entry) iter.next();
+        Region bucketRegion = (BucketRegion) entry.getValue();
-    if (event.getState().isCritical()
-        && !event.getPreviousState().isCritical()
-        && (event.getType() == ResourceType.HEAP_MEMORY || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
+    if (event.getState().isCritical() && !event.getPreviousState().isCritical()
+        && (event.getType() == ResourceType.HEAP_MEMORY
+            || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
-      getRegionAdvisor().markBucketsOnMember(event.getMember(), true/*sick*/);
-    } else if (!event.getState().isCritical()
-        && event.getPreviousState().isCritical()
-        && (event.getType() == ResourceType.HEAP_MEMORY || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
-      getRegionAdvisor().markBucketsOnMember(event.getMember(), false/*not sick*/);
+      getRegionAdvisor().markBucketsOnMember(event.getMember(), true/* sick */);
+    } else if (!event.getState().isCritical() && event.getPreviousState().isCritical()
+        && (event.getType() == ResourceType.HEAP_MEMORY
+            || (event.getType() == ResourceType.OFFHEAP_MEMORY && getOffHeap()))) {
+      getRegionAdvisor().markBucketsOnMember(event.getMember(), false/* not sick */);
-    for (InternalDistributedMember idm: critialMembers) {
-      getRegionAdvisor().markBucketsOnMember(idm, true/*sick*/);
+    for (InternalDistributedMember idm : critialMembers) {
+      getRegionAdvisor().markBucketsOnMember(idm, true/* sick */);
-    getRegionAdvisor().markBucketsOnMember(member, false/*sick*/);
+    getRegionAdvisor().markBucketsOnMember(member, false/* sick */);
-  public PartitionedRegion getColocatedWithRegion() { 
+  public PartitionedRegion getColocatedWithRegion() {
-        logger.debug("Started BucketSorter to sort the buckets according to numver of entries in each bucket for every {} milliseconds",
-            HeapEvictor.BUCKET_SORTING_INTERVAL);     
+        logger.debug(
+            "Started BucketSorter to sort the buckets according to numver of entries in each bucket for every {} milliseconds",
+            HeapEvictor.BUCKET_SORTING_INTERVAL);
-    if(!bucketSortedOnce.get()){
-      while(bucketSortedOnce.get() == false);
+    if (!bucketSortedOnce.get()) {
+      while (bucketSortedOnce.get() == false);
-              }
-              else if (buk1NumEntries < buk2NumEntries) {
+              } else if (buk1NumEntries < buk2NumEntries) {
-        if(!bucketSortedOnce.get()){
+        if (!bucketSortedOnce.get()) {
-      }
-      catch (Exception e) {
+      } catch (Exception e) {
-  
+
-        throw new TransactionException(LocalizedStrings.PartitionedRegion_TX_ON_DATASTORE.toLocalizedString());
+        throw new TransactionException(
+            LocalizedStrings.PartitionedRegion_TX_ON_DATASTORE.toLocalizedString());
-        bucketId = PartitionedRegionHelper.getHashKey(this, null, entryKey,
-            keyInfo.getValue(), keyInfo.getCallbackArg());
+        bucketId = PartitionedRegionHelper.getHashKey(this, null, entryKey, keyInfo.getValue(),
+            keyInfo.getCallbackArg());
-    } catch(RegionDestroyedException rde) {
-      RuntimeException re = new TransactionDataNotColocatedException(LocalizedStrings.PartitionedRegion_KEY_0_NOT_COLOCATED_WITH_TRANSACTION.toLocalizedString(entryKey));
-      //re.initCause(rde);
+    } catch (RegionDestroyedException rde) {
+      RuntimeException re = new TransactionDataNotColocatedException(
+          LocalizedStrings.PartitionedRegion_KEY_0_NOT_COLOCATED_WITH_TRANSACTION
+              .toLocalizedString(entryKey));
+      // re.initCause(rde);
-    int count = 0;
-    final int retryAttempts = calcRetry();
-    // TODO provide appropriate Operation and arg
-    int bucketId = keyInfo.getBucketId();
-    if (bucketId == KeyInfo.UNKNOWN_BUCKET) {
-      bucketId = PartitionedRegionHelper.getHashKey(this, null, entryKey,
-          keyInfo.getValue(), keyInfo.getCallbackArg());
-      keyInfo.setBucketId(bucketId);
-    }
-    while (count <= retryAttempts) {
-      try {
-        PartitionedRegionDataStore ds = getDataStore();
-        if (ds == null) {
-          throw new TransactionException(LocalizedStrings.PartitionedRegion_TX_ON_DATASTORE.toLocalizedString());
-        }
-        br = ds.getInitializedBucketWithKnownPrimaryForId(entryKey, bucketId);
-        break;
-      } catch (ForceReattemptException e) {
-        // create a new bucket
-        InternalDistributedMember member = createBucket(bucketId, 0, null);
-        if (!getMyId().equals(member) && keyInfo.isCheckPrimary()) {
-          throw new PrimaryBucketException("Bucket "+bucketId+" is not primary. Current primary holder is "+member);
-        }
-        count++;
+      int count = 0;
+      final int retryAttempts = calcRetry();
+      // TODO provide appropriate Operation and arg
+      int bucketId = keyInfo.getBucketId();
+      if (bucketId == KeyInfo.UNKNOWN_BUCKET) {
+        bucketId = PartitionedRegionHelper.getHashKey(this, null, entryKey, keyInfo.getValue(),
+            keyInfo.getCallbackArg());
+        keyInfo.setBucketId(bucketId);
-    }
-    Assert.assertTrue(br != null, "Could not create storage for Entry");
+      while (count <= retryAttempts) {
+        try {
+          PartitionedRegionDataStore ds = getDataStore();
+          if (ds == null) {
+            throw new TransactionException(
+                LocalizedStrings.PartitionedRegion_TX_ON_DATASTORE.toLocalizedString());
+          }
+          br = ds.getInitializedBucketWithKnownPrimaryForId(entryKey, bucketId);
+          break;
+        } catch (ForceReattemptException e) {
+          // create a new bucket
+          InternalDistributedMember member = createBucket(bucketId, 0, null);
+          if (!getMyId().equals(member) && keyInfo.isCheckPrimary()) {
+            throw new PrimaryBucketException(
+                "Bucket " + bucketId + " is not primary. Current primary holder is " + member);
+          }
+          count++;
+        }
+      }
+      Assert.assertTrue(br != null, "Could not create storage for Entry");
-    } catch(PrimaryBucketException pbe) {
-      RuntimeException re = new TransactionDataRebalancedException(LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING.toLocalizedString());
+    } catch (PrimaryBucketException pbe) {
+      RuntimeException re = new TransactionDataRebalancedException(
+          LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
+              .toLocalizedString());
-    } catch(RegionDestroyedException rde) {
-      RuntimeException re = new TransactionDataNotColocatedException(LocalizedStrings.PartitionedRegion_KEY_0_NOT_COLOCATED_WITH_TRANSACTION.toLocalizedString(entryKey));
-      //re.initCause(rde);
+    } catch (RegionDestroyedException rde) {
+      RuntimeException re = new TransactionDataNotColocatedException(
+          LocalizedStrings.PartitionedRegion_KEY_0_NOT_COLOCATED_WITH_TRANSACTION
+              .toLocalizedString(entryKey));
+      // re.initCause(rde);
-    } 
+    }
-      bucketId = PartitionedRegionHelper.getHashKey(this, null,
-          keyInfo.getKey(), keyInfo.getValue(), keyInfo.getCallbackArg());
+      bucketId = PartitionedRegionHelper.getHashKey(this, null, keyInfo.getKey(),
+          keyInfo.getValue(), keyInfo.getCallbackArg());
+
-  
+
-  public KeyInfo getKeyInfo(Object key, Object callbackArg){
+  public KeyInfo getKeyInfo(Object key, Object callbackArg) {
+
-    if (key == null){
+    if (key == null) {
-  
+
-    
+
-    
+
-      return "SizeEntry("+size+", primary="+isPrimary+")";
+      return "SizeEntry(" + size + ", primary=" + isPrimary + ")";
-    
-    
+
+
-  
+
-   * Index Task used to create the index. This is used along with the
-   * FutureTask to take care of, same index creation request from multiple
-   * threads. At any time only one thread succeeds and other threads waits
-   * for the completion of the index creation. This avoids usage of
+   * Index Task used to create the index. This is used along with the FutureTask to take care of,
+   * same index creation request from multiple threads. At any time only one thread succeeds and
+   * other threads waits for the completion of the index creation. This avoids usage of
-    //public List p_list;
+    // public List p_list;
-    
-    IndexTask (boolean remotelyOriginated, IndexType indexType, String indexName
-        ,
-        String indexedExpression, String fromClaus,  String imports, boolean loadEntries
-    ){
+
+    IndexTask(boolean remotelyOriginated, IndexType indexType, String indexName,
+        String indexedExpression, String fromClaus, String imports, boolean loadEntries) {
-     //this.p_list = p_list;
+      // this.p_list = p_list;
-      
+
-    IndexTask (String indexName) {
+
+    IndexTask(String indexName) {
-    public boolean equals (Object other){
+    public boolean equals(Object other) {
-      if (this.indexName.equals(otherIndexTask.indexName)){
+      if (this.indexName.equals(otherIndexTask.indexName)) {
-    public int hashCode(){
+    public int hashCode() {
-    IndexExistsException, ForceReattemptException {
-     // List list = p_list;
+        IndexExistsException, ForceReattemptException {
+      // List list = p_list;
-      if (dataStore != null){
+      if (dataStore != null) {
-        if (getLocalMaxMemory() != 0 ) {
-          throw new IndexCreationException(LocalizedStrings.
-              PartitionedRegion_DATA_STORE_ON_THIS_VM_IS_NULL_AND_THE_LOCAL_MAX_MEMORY_IS_NOT_ZERO_0.toLocalizedString(
-                  Long.valueOf(getLocalMaxMemory())));
+        if (getLocalMaxMemory() != 0) {
+          throw new IndexCreationException(
+              LocalizedStrings.PartitionedRegion_DATA_STORE_ON_THIS_VM_IS_NULL_AND_THE_LOCAL_MAX_MEMORY_IS_NOT_ZERO_0
+                  .toLocalizedString(Long.valueOf(getLocalMaxMemory())));
-        logger.info(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA));
-         
+        logger.info(LocalizedMessage.create(
+            LocalizedStrings.PartitionedRegion_THIS_IS_AN_ACCESSOR_VM_AND_DOESNT_CONTAIN_DATA));
+
-    private PartitionedIndex createIndexOnPRBuckets() throws IndexNameConflictException, IndexExistsException, IndexCreationException {
+    private PartitionedIndex createIndexOnPRBuckets()
+        throws IndexNameConflictException, IndexExistsException, IndexCreationException {
-      //list = compiler.compileFromClause(fromClause);
+      // list = compiler.compileFromClause(fromClause);
-          indexedExpression, fromClause,  imports); // imports can be null
+          indexedExpression, fromClause, imports); // imports can be null
-      //In cases where we have no data yet (creation from cache xml), it would leave the populated flag to false
-      //Not really an issue as a put will trigger bucket index creation which should set this the flag to true
-      //However if the region is empty, we should set this flag to true so it will be reported as used even though
-      //there is no data in the region
+      // In cases where we have no data yet (creation from cache xml), it would leave the populated
+      // flag to false
+      // Not really an issue as a put will trigger bucket index creation which should set this the
+      // flag to true
+      // However if the region is empty, we should set this flag to true so it will be reported as
+      // used even though
+      // there is no data in the region
-        
+
-        externalContext.setBucketRegion(PartitionedRegion.this,
-            (BucketRegion) bucket);
+        externalContext.setBucketRegion(PartitionedRegion.this, (BucketRegion) bucket);
-          Index bucketIndex = indMng
-              .createIndex(indexName, indexType, indexedExpression, fromClause,
-                  imports, externalContext, parIndex, loadEntries);
-          //parIndex.addToBucketIndexes(bucketIndex);
+          Index bucketIndex = indMng.createIndex(indexName, indexType, indexedExpression,
+              fromClause, imports, externalContext, parIndex, loadEntries);
+          // parIndex.addToBucketIndexes(bucketIndex);
-      }// End of bucket list
+      } // End of bucket list
-  
+
-  
+
-    List<FixedPartitionAttributesImpl> primaryFixedPAttrs = new LinkedList<FixedPartitionAttributesImpl>();
+    List<FixedPartitionAttributesImpl> primaryFixedPAttrs =
+        new LinkedList<FixedPartitionAttributesImpl>();
-    List<FixedPartitionAttributesImpl> secondaryFixedPAttrs = new LinkedList<FixedPartitionAttributesImpl>();
+    List<FixedPartitionAttributesImpl> secondaryFixedPAttrs =
+        new LinkedList<FixedPartitionAttributesImpl>();
-  
+
-   * For the very first member, FPR's first partition has starting bucket id as
-   * 0 and other partitions have starting bucket id as the sum of previous
-   * partition's starting bucket id and previous partition's num-buckets.
+   * For the very first member, FPR's first partition has starting bucket id as 0 and other
+   * partitions have starting bucket id as the sum of previous partition's starting bucket id and
+   * previous partition's num-buckets.
-   * For other members, all partitions defined previously with assigned starting
-   * bucket ids are fetched from the metadata PartitionRegionConfig. Now for
-   * each partition defined for this member, if this partition is already
-   * available in the list of the previously defined partitions then starting
-   * bucket id is directly assigned from the same previously defined partition.
+   * For other members, all partitions defined previously with assigned starting bucket ids are
+   * fetched from the metadata PartitionRegionConfig. Now for each partition defined for this
+   * member, if this partition is already available in the list of the previously defined partitions
+   * then starting bucket id is directly assigned from the same previously defined partition.
-   * And if the partition on this member is not available in the previously
-   * defined partitions then new starting bucket id is calculated as the sum of
-   * the largest starting bucket id from previously defined partitions and
-   * corresponding num-buckets of the partition.
+   * And if the partition on this member is not available in the previously defined partitions then
+   * new starting bucket id is calculated as the sum of the largest starting bucket id from
+   * previously defined partitions and corresponding num-buckets of the partition.
-   * This data of the partitions (FixedPartitionAttributes with starting bucket
-   * id for the Fixed Partitioned Region) is stored in metadata for each member.
+   * This data of the partitions (FixedPartitionAttributes with starting bucket id for the Fixed
+   * Partitioned Region) is stored in metadata for each member.
-  
+
-    
+
-      Set<FixedPartitionAttributesImpl> elderFPAs = prConfig
-          .getElderFPAs();
+      Set<FixedPartitionAttributesImpl> elderFPAs = prConfig.getElderFPAs();
-        }
-        else {
+        } else {
-      this.partitionsMap.put(
-          fxPrAttr.getPartitionName(),
-          new Integer[] { fxPrAttr.getStartingBucketID(),
-              fxPrAttr.getNumBuckets() });
+      this.partitionsMap.put(fxPrAttr.getPartitionName(),
+          new Integer[] {fxPrAttr.getStartingBucketID(), fxPrAttr.getNumBuckets()});
-  
+
-   * Returns the local BucketRegion given the key.
-   * Returns null if no BucketRegion exists.
+   * Returns the local BucketRegion given the key. Returns null if no BucketRegion exists.
+   * 
-    Integer bucketId = Integer.valueOf(PartitionedRegionHelper.getHashKey(this,
-        null, key, null, null));
+    Integer bucketId =
+        Integer.valueOf(PartitionedRegionHelper.getHashKey(this, null, key, null, null));
-   * Returns the local BucketRegion given the key and value.
-   * Returns null if no BucketRegion exists.
+   * Returns the local BucketRegion given the key and value. Returns null if no BucketRegion exists.
-    final Integer bucketId = Integer.valueOf(PartitionedRegionHelper
-        .getHashKey(this, null, key, value, null));
+    final Integer bucketId =
+        Integer.valueOf(PartitionedRegionHelper.getHashKey(this, null, key, value, null));
-   * Test hook to return the per entry overhead for a bucket region.
-   * Returns -1 if no buckets exist in this vm. 
+   * Test hook to return the per entry overhead for a bucket region. Returns -1 if no buckets exist
+   * in this vm.
+   * 
-  
+
-  
+
-    
+
-    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(
-        bucketId, null);
+    final InternalDistributedMember targetNode = getOrCreateNodeForBucketWrite(bucketId, null);
-        }
-        catch (TimeoutException te) {
-          if (getRegionAdvisor()
-              .isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
-                                                                  // longer
-                                                                  // exists
-            throw new EntryNotFoundException(LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0.toLocalizedString(event.getKey()));
+        } catch (TimeoutException te) {
+          if (getRegionAdvisor().isStorageAssignedForBucket(bucketId.intValue())) { // bucket no
+                                                                                    // longer
+                                                                                    // exists
+            throw new EntryNotFoundException(
+                LocalizedStrings.PartitionedRegion_ENTRY_NOT_FOUND_FOR_KEY_0
+                    .toLocalizedString(event.getKey()));
-        }
-        else {
+        } else {
-            }
-            catch (EntryNotFoundException enf) {
+            } catch (EntryNotFoundException enf) {
-                logger.debug("updateEntryVersionInBucket: Failed to update entry version timestamp from local cache because of EntryNotFoundException.", enf);
+                logger.debug(
+                    "updateEntryVersionInBucket: Failed to update entry version timestamp from local cache because of EntryNotFoundException.",
+                    enf);
-          logger.debug("updateEntryVersionInBucket: caught concurrent cache modification exception", e);
+          logger.debug("updateEntryVersionInBucket: caught concurrent cache modification exception",
+              e);
-          logger.debug("ConcurrentCacheModificationException received for updateEntryVersionInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
+          logger.debug(
+              "ConcurrentCacheModificationException received for updateEntryVersionInBucket for bucketId: {}{}{} for event: {}  No reattampt is done, returning from here",
-      }
-      catch (ForceReattemptException prce) {
+      } catch (ForceReattemptException prce) {
-          logger.debug("updateEntryVersionInBucket: retry attempt:{} of {}", count, retryAttempts, prce);
+          logger.debug("updateEntryVersionInBucket: retry attempt:{} of {}", count, retryAttempts,
+              prce);
-      }
-      catch (PrimaryBucketException notPrimary) {
+      } catch (PrimaryBucketException notPrimary) {
-          logger.debug("updateEntryVersionInBucket {} on Node {} not primary", notPrimary.getLocalizedMessage(), retryNode);
+          logger.debug("updateEntryVersionInBucket {} on Node {} not primary",
+              notPrimary.getLocalizedMessage(), retryNode);
-        //this.prStats.incUpdateEntryVersionOpsRetried();
+        // this.prStats.incUpdateEntryVersionOpsRetried();
-      //this.prStats.incUpdateEntryVersionRetries();
+      // this.prStats.incUpdateEntryVersionRetries();
-        logger.debug("updateEntryVersionInBucket: Attempting to resend update version to node {} after {} failed attempts", retryNode, count);
+        logger.debug(
+            "updateEntryVersionInBucket: Attempting to resend update version to node {} after {} failed attempts",
+            retryNode, count);
-    PartitionedRegionDistributionException e 
-      = new PartitionedRegionDistributionException(LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_UPDATE_ENTRY_VERSION_IN_0_ATTEMPTS
-          .toLocalizedString(Integer.valueOf(count)));  // Fix for bug 36014
+    PartitionedRegionDistributionException e = new PartitionedRegionDistributionException(
+        LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_UPDATE_ENTRY_VERSION_IN_0_ATTEMPTS
+            .toLocalizedString(Integer.valueOf(count))); // Fix for bug 36014
-      logger.warn(LocalizedMessage.create(LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_UPDATE_ENTRY_VERSION_IN_0_ATTEMPTS, Integer.valueOf(count)));
-    }
-    else {
+      logger.warn(LocalizedMessage.create(
+          LocalizedStrings.PartitionedRegion_NO_VM_AVAILABLE_FOR_UPDATE_ENTRY_VERSION_IN_0_ATTEMPTS,
+          Integer.valueOf(count)));
+    } else {
-   * @param recipient
-   *                the member id of the recipient of the operation
-   * @param bucketId
-   *                the id of the bucket the key hashed into
-   * @throws EntryNotFoundException
-   *                 if the entry does not exist in this region
-   * @throws PrimaryBucketException
-   *                 if the bucket on that node is not the primary copy
-   * @throws ForceReattemptException
-   *                 if the peer is no longer available
+   * @param recipient the member id of the recipient of the operation
+   * @param bucketId the id of the bucket the key hashed into
+   * @throws EntryNotFoundException if the entry does not exist in this region
+   * @throws PrimaryBucketException if the bucket on that node is not the primary copy
+   * @throws ForceReattemptException if the peer is no longer available
-  private void updateEntryVersionRemotely(InternalDistributedMember recipient,
-      Integer bucketId, EntryEventImpl event) throws EntryNotFoundException,
-      PrimaryBucketException, ForceReattemptException {
+  private void updateEntryVersionRemotely(InternalDistributedMember recipient, Integer bucketId,
+      EntryEventImpl event)
+      throws EntryNotFoundException, PrimaryBucketException, ForceReattemptException {
-      }
-      catch (EntryNotFoundException ex) {
+      } catch (EntryNotFoundException ex) {
-        throw new PartitionedRegionException(LocalizedStrings.PartitionedRegion_UPDATE_VERSION_OF_ENTRY_ON_0_FAILED.toLocalizedString(recipient), ce);
+        throw new PartitionedRegionException(
+            LocalizedStrings.PartitionedRegion_UPDATE_VERSION_OF_ENTRY_ON_0_FAILED
+                .toLocalizedString(recipient),
+            ce);
-    }  
+    }
-    
+
-    Set<Integer> allBuckets = userPR.getDataStore()
-        .getAllLocalBucketIds();
+    Set<Integer> allBuckets = userPR.getDataStore().getAllLocalBucketIds();
-      logger.debug("Need to wait until partitionedRegionQueue <<{}>> is loaded with all the buckets", this.getName());
+      logger.debug(
+          "Need to wait until partitionedRegionQueue <<{}>> is loaded with all the buckets",
+          this.getName());
-        InternalDistributedMember node = this
-            .getNodeForBucketWrite(itr.next(), null);
+        InternalDistributedMember node = this.getNodeForBucketWrite(itr.next(), null);
-  
+
-      // If cache is being closed, ignore and go 
+      // If cache is being closed, ignore and go
-  
+
-  
+
-  
+
-	return logger;
+    return logger;

INS26 INS26 MOV31 INS40 INS40 INS31 INS29 INS83 INS39 INS42 INS43 INS8 MOV78 MOV78 MOV43 MOV44 MOV78 MOV43 UPD42 MOV78 UPD42 MOV44 MOV78 MOV8 MOV78 MOV8 INS29 MOV29 UPD66 UPD66 UPD66 INS65 INS65 INS42 INS25 MOV65 INS65 MOV65 MOV65 UPD65 MOV65 UPD65 MOV65 MOV65 MOV65 INS65 MOV65 INS65 MOV65 MOV65 MOV29 MOV29 INS65 MOV65 MOV65 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 INS42 INS27 INS8 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS42 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 INS66 MOV65 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 MOV65 UPD66 UPD66 UPD66 MOV65 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD7 UPD7 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS65 UPD66 UPD66 UPD66 UPD66 UPD66 MOV65 UPD66 UPD66 UPD66 UPD66 MOV65 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 MOV66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS32 INS38 INS60 INS21 INS53 UPD66 UPD66 UPD66 UPD66 INS66 INS66 UPD66 UPD66 UPD66 INS67 INS66 MOV67 INS32 INS42 INS42 INS74 INS59 INS32 INS14 UPD7 INS42 INS42 INS42 INS43 INS43 INS42 INS14 INS42 INS42 INS32 INS43 INS42 INS32 INS42 INS42 INS43 INS32 INS32 INS42 INS42 INS40 INS42 INS3 INS42 INS32 INS42 INS32 INS42 INS5 INS4 INS32 INS42 INS42 INS43 INS85 INS32 INS42 INS60 INS25 INS25 INS42 INS42 INS42 INS43 INS59 INS27 INS8 INS8 INS62 INS8 INS25 INS42 INS42 INS32 INS27 INS62 INS53 INS53 INS42 INS43 INS60 INS21 INS53 MOV62 MOV8 MOV25 INS42 INS42 INS42 INS33 INS42 INS43 INS11 INS14 INS42 INS43 INS59 INS32 INS42 INS62 INS8 INS42 INS43 INS42 INS43 INS32 INS32 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS43 INS60 INS21 INS53 INS60 INS53 INS42 INS42 INS42 INS42 INS43 INS32 INS42 INS43 INS59 INS32 INS42 INS43 INS59 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS14 INS43 INS32 INS43 INS27 INS42 INS42 INS40 INS42 INS42 INS42 INS45 INS42 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL42 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL33 DEL41 DEL33 DEL41 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL65 DEL66 DEL66 DEL66 DEL65 DEL29 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL65 DEL66