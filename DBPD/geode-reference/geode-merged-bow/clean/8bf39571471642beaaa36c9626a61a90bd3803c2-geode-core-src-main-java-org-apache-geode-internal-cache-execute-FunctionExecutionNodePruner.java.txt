Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
+
-  
+
-    
+
-    HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBucketsMap = new HashMap<InternalDistributedMember, HashSet<Integer>>();
-    HashMap<InternalDistributedMember, HashSet<Integer>> prunedNodeToBucketsMap = new HashMap<InternalDistributedMember, HashSet<Integer>>();
+    HashMap<InternalDistributedMember, HashSet<Integer>> nodeToBucketsMap =
+        new HashMap<InternalDistributedMember, HashSet<Integer>>();
+    HashMap<InternalDistributedMember, HashSet<Integer>> prunedNodeToBucketsMap =
+        new HashMap<InternalDistributedMember, HashSet<Integer>>();
-        Set<InternalDistributedMember> nodes = pr.getRegionAdvisor()
-            .getBucketOwners(bucketId);
+        Set<InternalDistributedMember> nodes = pr.getRegionAdvisor().getBucketOwners(bucketId);
-          logger.debug("FunctionExecutionNodePruner: The buckets owners of the bucket: {} are: {}", bucketId , nodes);
+          logger.debug("FunctionExecutionNodePruner: The buckets owners of the bucket: {} are: {}",
+              bucketId, nodes);
-          }
-          else {
+          } else {
+    } catch (NoSuchElementException e) {
-    catch (NoSuchElementException e) {}
-    
+
-     * First Logic:
-     *  Just implement the Greedy algorithm where you keep adding nodes which has the biggest set of 
-     *  non-currentBucketSet.
-     *  // Deterministic but it (almost)always chooses minimum no of nodes to execute the function on.
-     *  
-     * Second Logic:
-     *  Give highest preference to the local node and after that use First Logic.
-     *  // Local Node gets preference but still its deterministic for all the execution taking
-     *  // place at that node which require same set of buckets.
-     *  
-     * Third Logic:
-     *  After including local node, choose random nodes among the remaining nodes in step 
-     *  until your curentBucketSet has all the required buckets. 
-     *  // No optimization for number of nodes to execute the function  
+     * First Logic: Just implement the Greedy algorithm where you keep adding nodes which has the
+     * biggest set of non-currentBucketSet. // Deterministic but it (almost)always chooses minimum
+     * no of nodes to execute the function on.
+     * 
+     * Second Logic: Give highest preference to the local node and after that use First Logic. //
+     * Local Node gets preference but still its deterministic for all the execution taking // place
+     * at that node which require same set of buckets.
+     * 
+     * Third Logic: After including local node, choose random nodes among the remaining nodes in
+     * step until your curentBucketSet has all the required buckets. // No optimization for number
+     * of nodes to execute the function
-    
-    
+
+
-    if(nodeToBucketsMap.get(localNode) != null){
+    if (nodeToBucketsMap.get(localNode) != null) {
-        logger.debug("FunctionExecutionNodePruner: Adding the node: {} which is lcoal and buckets {} to prunedMap",
+        logger.debug(
+            "FunctionExecutionNodePruner: Adding the node: {} which is lcoal and buckets {} to prunedMap",
-      if(nodeToBucketsMap.size() ==  0){
+      if (nodeToBucketsMap.size() == 0) {
-      InternalDistributedMember node = findNextNode(
-          nodeToBucketsMap.entrySet(), currentBucketSet);
+      InternalDistributedMember node = findNextNode(nodeToBucketsMap.entrySet(), currentBucketSet);
-          logger.debug("FunctionExecutionNodePruner: Breaking out of prunedMap calculation due to no available nodes for remaining buckets");
+          logger.debug(
+              "FunctionExecutionNodePruner: Breaking out of prunedMap calculation due to no available nodes for remaining buckets");
-          logger.debug("FunctionExecutionNodePruner: Adding the node: {} and buckets {} to prunedMap",
-              node, bucketSet);
+          logger.debug(
+              "FunctionExecutionNodePruner: Adding the node: {} and buckets {} to prunedMap", node,
+              bucketSet);
-      logger.debug("FunctionExecutionNodePruner: The final prunedNodeToBucket calculated is: {}", prunedNodeToBucketsMap);
+      logger.debug("FunctionExecutionNodePruner: The final prunedNodeToBucket calculated is: {}",
+          prunedNodeToBucketsMap);
-  
-  
+
+
-   
+
-    ArrayList<InternalDistributedMember> nodesOfEqualSize = new ArrayList<InternalDistributedMember>(); 
+    ArrayList<InternalDistributedMember> nodesOfEqualSize =
+        new ArrayList<InternalDistributedMember>();
-      }
-      else if (max == buckets.size()){
+      } else if (max == buckets.size()) {
-    
-    //return node;
-    return (nodesOfEqualSize.size() > 0 ? nodesOfEqualSize
-        .get(PartitionedRegion.rand.nextInt(nodesOfEqualSize.size())) : null);
+
+    // return node;
+    return (nodesOfEqualSize.size() > 0
+        ? nodesOfEqualSize.get(PartitionedRegion.rand.nextInt(nodesOfEqualSize.size())) : null);
-  public static HashMap<Integer, HashSet> groupByBucket(PartitionedRegion pr,
-      Set routingKeys, final boolean primaryMembersNeeded,
-      final boolean hasRoutingObjects, final boolean isBucketSetAsFilter) {
+  public static HashMap<Integer, HashSet> groupByBucket(PartitionedRegion pr, Set routingKeys,
+      final boolean primaryMembersNeeded, final boolean hasRoutingObjects,
+      final boolean isBucketSetAsFilter) {
-    
+
-          bucketId = Integer.valueOf(PartitionedRegionHelper
-              .getHashKey(pr, key));
+          bucketId = Integer.valueOf(PartitionedRegionHelper.getHashKey(pr, key));
-      }
-      else {
+      } else {
-        throw new FunctionException(LocalizedStrings.
-          PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0
-            .toLocalizedString(key));
+        throw new FunctionException(
+            LocalizedStrings.PartitionedRegion_NO_TARGET_NODE_FOUND_FOR_KEY_0
+                .toLocalizedString(key));
-      HashSet bucketKeys = (HashSet)bucketToKeysMap.get(bucketId);
+      HashSet bucketKeys = (HashSet) bucketToKeysMap.get(bucketId);
-    }   
+    }
-  public static HashSet<Integer> getBucketSet(PartitionedRegion pr,
-      Set routingKeys, final boolean hasRoutingObjects,
-      boolean isBucketSetAsFilter) {
+  public static HashSet<Integer> getBucketSet(PartitionedRegion pr, Set routingKeys,
+      final boolean hasRoutingObjects, boolean isBucketSetAsFilter) {
-          bucketId = Integer.valueOf(PartitionedRegionHelper
-              .getHashKey(pr, key));
+          bucketId = Integer.valueOf(PartitionedRegionHelper.getHashKey(pr, key));
-    if (primaryOnly) {      
+    if (primaryOnly) {
-          InternalDistributedMember mem = pr.getOrCreateNodeForBucketWrite(
-              bucketId, null);
+          InternalDistributedMember mem = pr.getOrCreateNodeForBucketWrite(bucketId, null);
-    }
-    else {
-      return pruneNodes(pr,bucketSet);
+    } else {
+      return pruneNodes(pr, bucketSet);

