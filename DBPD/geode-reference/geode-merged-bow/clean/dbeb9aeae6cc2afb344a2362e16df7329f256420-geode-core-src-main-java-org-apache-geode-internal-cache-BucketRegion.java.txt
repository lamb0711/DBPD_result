Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * The storage used for a Partitioned Region.
- * This class asserts distributed scope as well as a replicate data policy
- * It does not support transactions
+ * The storage used for a Partitioned Region. This class asserts distributed scope as well as a
+ * replicate data policy It does not support transactions
- * Primary election for a BucketRegion can be found in the 
+ * Primary election for a BucketRegion can be found in the
-public class BucketRegion extends DistributedRegion
-implements Bucket
-{
+public class BucketRegion extends DistributedRegion implements Bucket {
-  
+
-   * A special value for the bucket size indicating that this bucket
-   * has been destroyed.
+   * A special value for the bucket size indicating that this bucket has been destroyed.
-  
+
-   * Contains size in bytes of the values stored
-   * in theRealMap. Sizes are tallied during put and remove operations.
+   * Contains size in bytes of the values stored in theRealMap. Sizes are tallied during put and
+   * remove operations.
-  
+
+
-    
+
-        ((CachedDeserializable)this.rawValue).writeValueAsByteArray(out);
+        ((CachedDeserializable) this.rawValue).writeValueAsByteArray(out);
-      } else if (this.rawValue == Token.TOMBSTONE) { 
+      } else if (this.rawValue == Token.TOMBSTONE) {
-    
+
-      return "RawValue("+this.rawValue+")";
+      return "RawValue(" + this.rawValue + ")";
-     * Return the de-serialized value without changing the stored form
-     * in the heap.  This causes local access to create a de-serialized copy (extra work)
-     * in favor of keeping values in serialized form which is important because
-     * it makes remote access more efficient.  This assumption is that remote
-     * access is much more frequent.
-     * TODO Unused, but keeping for potential performance boost when local Bucket 
-     * access de-serializes the entry (which could hurt perf.)
+     * Return the de-serialized value without changing the stored form in the heap. This causes
+     * local access to create a de-serialized copy (extra work) in favor of keeping values in
+     * serialized form which is important because it makes remote access more efficient. This
+     * assumption is that remote access is much more frequent. TODO Unused, but keeping for
+     * potential performance boost when local Bucket access de-serializes the entry (which could
+     * hurt perf.)
-          byte[] src = (byte[])this.rawValue;
+          byte[] src = (byte[]) this.rawValue;
-          return ((CachedDeserializable)this.rawValue).getDeserializedWritableCopy(null, null);
+          return ((CachedDeserializable) this.rawValue).getDeserializedWritableCopy(null, null);
-          return ((CachedDeserializable)this.rawValue).getDeserializedForReading();
+          return ((CachedDeserializable) this.rawValue).getDeserializedForReading();
-  
+
-  private final Map<Object, ExpiryTask> pendingSecondaryExpires = new HashMap<Object, ExpiryTask>(); 
- 
+  private final Map<Object, ExpiryTask> pendingSecondaryExpires = new HashMap<Object, ExpiryTask>();
+
-  static final boolean FORCE_LOCAL_LISTENERS_INVOCATION =
-      Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + "BucketRegion.alwaysFireLocalListeners");
+  static final boolean FORCE_LOCAL_LISTENERS_INVOCATION = Boolean
+      .getBoolean(DistributionConfig.GEMFIRE_PREFIX + "BucketRegion.alwaysFireLocalListeners");
-  
+
-  
+
-  public BucketRegion(String regionName, RegionAttributes attrs,
-      LocalRegion parentRegion, GemFireCacheImpl cache,
-      InternalRegionArguments internalRegionArgs) {
+  public BucketRegion(String regionName, RegionAttributes attrs, LocalRegion parentRegion,
+      GemFireCacheImpl cache, InternalRegionArguments internalRegionArgs) {
-    if(PartitionedRegion.DISABLE_SECONDARY_BUCKET_ACK) {
+    if (PartitionedRegion.DISABLE_SECONDARY_BUCKET_ACK) {
-    } 
-    else {
+    } else {
-    Assert.assertTrue( ! attrs.getEarlyAck());
+    Assert.assertTrue(!attrs.getEarlyAck());
-    Assert.assertTrue( ! isUsedForPartitionedRegionAdmin());
+    Assert.assertTrue(!isUsedForPartitionedRegionAdmin());
-  
+
-  protected void initialize(InputStream snapshotInputStream,
-      InternalDistributedMember imageTarget,
-      InternalRegionArguments internalRegionArgs) 
-    throws TimeoutException, IOException, ClassNotFoundException
-  {
+  protected void initialize(InputStream snapshotInputStream, InternalDistributedMember imageTarget,
+      InternalRegionArguments internalRegionArgs)
+      throws TimeoutException, IOException, ClassNotFoundException {
-        PartitionedRegion parentPR = ColocationHelper
-            .getLeaderRegion(this.partitionedRegion);
-        BucketRegion parentBucket = parentPR.getDataStore().getLocalBucketById(
-            getId());
+        PartitionedRegion parentPR = ColocationHelper.getLeaderRegion(this.partitionedRegion);
+        BucketRegion parentBucket = parentPR.getDataStore().getLocalBucketById(getId());
-        PartitionedRegion parentPR = ColocationHelper
-            .getLeaderRegion(this.partitionedRegion);
-        BucketRegion parentBucket = parentPR.getDataStore().getLocalBucketById(
-            getId());
+        PartitionedRegion parentPR = ColocationHelper.getLeaderRegion(this.partitionedRegion);
+        BucketRegion parentBucket = parentPR.getDataStore().getLocalBucketById(getId());
-          logger.debug("The parentBucket of region {} bucketId {} is NULL", this.partitionedRegion.getFullPath(), getId());
+          logger.debug("The parentBucket of region {} bucketId {} is NULL",
+              this.partitionedRegion.getFullPath(), getId());
-      
-      final InternalDistributedMember primaryHolder = 
-        getBucketAdvisor().basicGetPrimaryMember();
-      if (primaryHolder != null && ! primaryHolder.equals(getMyId())) {
+
+      final InternalDistributedMember primaryHolder = getBucketAdvisor().basicGetPrimaryMember();
+      if (primaryHolder != null && !primaryHolder.equals(getMyId())) {
-      
+
-      if(!success) {
+      if (!success) {
-  
-  
+
+
-    //announce that the bucket is ready
-    //setHosting performs a profile exchange, so there
-    //is no need to call super.initialized() here.
+    // announce that the bucket is ready
+    // setHosting performs a profile exchange, so there
+    // is no need to call super.initialized() here.
-  
+
-  protected DiskStoreImpl findDiskStore(RegionAttributes ra, InternalRegionArguments internalRegionArgs) {
+  protected DiskStoreImpl findDiskStore(RegionAttributes ra,
+      InternalRegionArguments internalRegionArgs) {
-  
+
-      InternalRegionArguments internalRegionArgs){
+      InternalRegionArguments internalRegionArgs) {
-  
+
-  
+
-  
+
+
-  protected void notifyClientsOfTombstoneGC(Map<VersionSource, Long> regionGCVersions, Set<Object>removedKeys, EventID eventID, FilterInfo routing) {
+  protected void notifyClientsOfTombstoneGC(Map<VersionSource, Long> regionGCVersions,
+      Set<Object> removedKeys, EventID eventID, FilterInfo routing) {
-          && (routing != null || fp != null)) { // fix for bug #46309 - don't send null/empty key set to clients
-        RegionEventImpl regionEvent = new RegionEventImpl(getPartitionedRegion(), Operation.REGION_DESTROY, null, true, getMyId()); 
+          && (routing != null || fp != null)) { // fix for bug #46309 - don't send null/empty key
+                                                // set to clients
+        RegionEventImpl regionEvent = new RegionEventImpl(getPartitionedRegion(),
+            Operation.REGION_DESTROY, null, true, getMyId());
-        regionEvent.setLocalFilterInfo(clientRouting); 
-          
-        ClientUpdateMessage clientMessage = ClientTombstoneMessage.gc(getPartitionedRegion(), removedKeys,
-            eventID);
+        regionEvent.setLocalFilterInfo(clientRouting);
+
+        ClientUpdateMessage clientMessage =
+            ClientTombstoneMessage.gc(getPartitionedRegion(), removedKeys, eventID);
-   * Search the CM for keys. If found any, return the first found one
-   * Otherwise, save the keys into the CM, and return null
-   * The thread will acquire the lock before searching.
+   * Search the CM for keys. If found any, return the first found one Otherwise, save the keys into
+   * the CM, and return null The thread will acquire the lock before searching.
-   * @return first key found in CM
-   *         null means not found
+   * @return first key found in CM null means not found
-    
+
-    
-    synchronized(allKeysMap) {
+
+    synchronized (allKeysMap) {
-      for (int i=0; i<keys.length; i++) {
+      for (int i = 0; i < keys.length; i++) {
-          foundLock = (LockObject)allKeysMap.get(keys[i]);
+          foundLock = (LockObject) allKeysMap.get(keys[i]);
-      
+
-        for (int i=0; i<keys.length; i++) {
-          LockObject lockValue = new LockObject(keys[i], isDebugEnabled?System.currentTimeMillis():0);
+        for (int i = 0; i < keys.length; i++) {
+          LockObject lockValue =
+              new LockObject(keys[i], isDebugEnabled ? System.currentTimeMillis() : 0);
-    } 
-    
+    }
+
-   * After processed the keys, this method will remove them from CM. 
-   * And notifyAll for each key. 
-   * The thread needs to acquire lock of CM first.
+   * After processed the keys, this method will remove them from CM. And notifyAll for each key. The
+   * thread needs to acquire lock of CM first.
-    
-    synchronized(allKeysMap) {
-      for (int i=0; i<keys.length; i++) {
-        LockObject lockValue = (LockObject)allKeysMap.remove(keys[i]);
+
+    synchronized (allKeysMap) {
+      for (int i = 0; i < keys.length; i++) {
+        LockObject lockValue = (LockObject) allKeysMap.remove(keys[i]);
-              long waitTime = System.currentTimeMillis()-lockValue.lockedTimeStamp;
-              logger.trace("LockKeys: remove key {}, notifyAll for {}. It waited", keys[i], lockValue, waitTime);
+              long waitTime = System.currentTimeMillis() - lockValue.lockedTimeStamp;
+              logger.trace("LockKeys: remove key {}, notifyAll for {}. It waited", keys[i],
+                  lockValue, waitTime);
-    } 
+    }
-  
+
-   * Keep checking if CM has contained any key in keys. If yes, wait for notify,
-   * then retry again. This method will block current thread for long time. 
-   * It only exits when current thread successfully save its keys into CM. 
+   * Keep checking if CM has contained any key in keys. If yes, wait for notify, then retry again.
+   * This method will block current thread for long time. It only exits when current thread
+   * successfully save its keys into CM.
-    
+
-        synchronized(foundLock) {
+        synchronized (foundLock) {
-          }
-          catch (InterruptedException e) {
+          } catch (InterruptedException e) {
-            long waitTime = System.currentTimeMillis()-foundLock.lockedTimeStamp;
+            long waitTime = System.currentTimeMillis() - foundLock.lockedTimeStamp;
-  
+
-  //  1) apply op locally, aka update or create entry
-  //  2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
-  //  3) cache listener with synchrony on entry
+  // 1) apply op locally, aka update or create entry
+  // 2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
+  // 3) cache listener with synchrony on entry
-  //  1) apply op locally
-  //  2) update local bs, gateway
+  // 1) apply op locally
+  // 2) update local bs, gateway
-  protected
-  boolean virtualPut(EntryEventImpl event,
-                     boolean ifNew,
-                     boolean ifOld,
-                     Object expectedOldValue,
-                     boolean requireOldValue,
-                     long lastModified,
-                     boolean overwriteDestroyed)
- throws TimeoutException,
-      CacheWriterException {
+  protected boolean virtualPut(EntryEventImpl event, boolean ifNew, boolean ifOld,
+      Object expectedOldValue, boolean requireOldValue, long lastModified,
+      boolean overwriteDestroyed) throws TimeoutException, CacheWriterException {
-    
+
-        RegionEntry oldEntry = this.entries
-            .basicPut(event, lastModified, ifNew, ifOld, expectedOldValue,
-                requireOldValue, overwriteDestroyed);
+        RegionEntry oldEntry = this.entries.basicPut(event, lastModified, ifNew, ifOld,
+            expectedOldValue, requireOldValue, overwriteDestroyed);
-            "Cache encountered replay of event containing delta bytes for key "
-                + event.getKey());
+            "Cache encountered replay of event containing delta bytes for key " + event.getKey());
-        logger.trace(LogMarker.DM, "BR.virtualPut: this cache has already seen this event {}", event);
+        logger.trace(LogMarker.DM, "BR.virtualPut: this cache has already seen this event {}",
+            event);
-  
+
-    long key = this.eventSeqNum.addAndGet(this.partitionedRegion
-        .getTotalNumberOfBuckets());
-    if (key < 0
-        || key % getPartitionedRegion().getTotalNumberOfBuckets() != getId()) {
-      logger
-          .error(LocalizedMessage
-              .create(
-                  LocalizedStrings.GatewaySender_SEQUENCENUMBER_GENERATED_FOR_EVENT_IS_INVALID,
-                  new Object[] { key, getId() }));
+    long key = this.eventSeqNum.addAndGet(this.partitionedRegion.getTotalNumberOfBuckets());
+    if (key < 0 || key % getPartitionedRegion().getTotalNumberOfBuckets() != getId()) {
+      logger.error(LocalizedMessage.create(
+          LocalizedStrings.GatewaySender_SEQUENCENUMBER_GENERATED_FOR_EVENT_IS_INVALID,
+          new Object[] {key, getId()}));
-      logger.debug("WAN: On primary bucket {}, setting the seq number as {}",
-          getId(), this.eventSeqNum.get());
+      logger.debug("WAN: On primary bucket {}, setting the seq number as {}", getId(),
+          this.eventSeqNum.get());
-  
+
-        logger.debug("The bucket corresponding to this user bucket is not created yet. This event will not go to remote wan site. Event: {}", event);
+        logger.debug(
+            "The bucket corresponding to this user bucket is not created yet. This event will not go to remote wan site. Event: {}",
+            event);
-    
+
-        if (key < 0
-            || key % getPartitionedRegion().getTotalNumberOfBuckets() != getId()) {
-          logger.error(LocalizedMessage.create(LocalizedStrings.GatewaySender_SEQUENCENUMBER_GENERATED_FOR_EVENT_IS_INVALID,
-                  new Object[] { key, getId() }));
+        if (key < 0 || key % getPartitionedRegion().getTotalNumberOfBuckets() != getId()) {
+          logger.error(LocalizedMessage.create(
+              LocalizedStrings.GatewaySender_SEQUENCENUMBER_GENERATED_FOR_EVENT_IS_INVALID,
+              new Object[] {key, getId()}));
-          logger.debug("WAN: On primary bucket {}, setting the seq number as {}", getId(), this.eventSeqNum.get());
+          logger.debug("WAN: On primary bucket {}, setting the seq number as {}", getId(),
+              this.eventSeqNum.get());
-          logger.debug("WAN: On secondary bucket {}, setting the seq number as {}", getId(), event.getTailKey());
+          logger.debug("WAN: On secondary bucket {}, setting the seq number as {}", getId(),
+              event.getTailKey());
+
-   * Fix for Bug#45917
-   * We are updating the seqNumber so that new seqNumbers are 
-   * generated starting from the latest in the system.
+   * Fix for Bug#45917 We are updating the seqNumber so that new seqNumbers are generated starting
+   * from the latest in the system.
+   * 
-  
+
-    if (!event.isOriginRemote()
-        && !event.isNetSearch()
-        && getBucketAdvisor().isPrimary()) {
+    if (!event.isOriginRemote() && !event.isNetSearch() && getBucketAdvisor().isPrimary()) {
-          logger.debug("sent update operation : for region  : {}: with event: {}", this.getName(), event);
+          logger.debug("sent update operation : for region  : {}: with event: {}", this.getName(),
+              event);
-    if (!event.getOperation().isPutAll()) {  // putAll will invoke listeners later
+    if (!event.getOperation().isPutAll()) { // putAll will invoke listeners later
-  
+
-   * distribute the operation in basicPutPart2 so the region entry lock is
-   * held
+   * distribute the operation in basicPutPart2 so the region entry lock is held
-  protected long basicPutPart2(EntryEventImpl event, RegionEntry entry, boolean isInitialized, 
-      long lastModified, boolean clearConflict)  {
+  protected long basicPutPart2(EntryEventImpl event, RegionEntry entry, boolean isInitialized,
+      long lastModified, boolean clearConflict) {
-    // Update the get stats if necessary. 
+    // Update the get stats if necessary.
-      // This code assumes it is safe ignore token mode (GII in progress) 
+      // This code assumes it is safe ignore token mode (GII in progress)
-  protected void notifyGatewaySender(EnumListenerEvent operation,
-      EntryEventImpl event) {
+  protected void notifyGatewaySender(EnumListenerEvent operation, EntryEventImpl event) {
-    }
-    finally {
+    } finally {
-    if (! isp){
+    if (!isp) {
-      InternalDistributedMember primaryHolder = getBucketAdvisor().basicGetPrimaryMember();    
-      throw new PrimaryBucketException("Bucket " + getName()
-          + " is not primary. Current primary holder is "+primaryHolder);
+      InternalDistributedMember primaryHolder = getBucketAdvisor().basicGetPrimaryMember();
+      throw new PrimaryBucketException(
+          "Bucket " + getName() + " is not primary. Current primary holder is " + primaryHolder);
-  
+
-   * Checks to make sure that this node is primary, and locks the bucket
-   * to make sure the bucket stays the primary bucket while the write
-   * is in progress. Any call to this method must be followed with a call
-   * to endLocalWrite().
+   * Checks to make sure that this node is primary, and locks the bucket to make sure the bucket
+   * stays the primary bucket while the write is in progress. Any call to this method must be
+   * followed with a call to endLocalWrite().
+   * 
-    if(!needWriteLock(event)) {
+    if (!needWriteLock(event)) {
+   * 
-    if(!locked) {
+    if (!locked) {
-    
+
-      if(!isPrimary) {
+      if (!isPrimary) {
-    
+
-        //Get the lock. If we have to wait here, it's because
-        //this VM is actively becoming "not primary". We don't want
-        //to throw an exception until this VM is actually no longer
-        //primary, so we wait here for not primary to complete. See bug #39963
+        // Get the lock. If we have to wait here, it's because
+        // this VM is actively becoming "not primary". We don't want
+        // to throw an exception until this VM is actually no longer
+        // primary, so we wait here for not primary to complete. See bug #39963
-        }
-        else {
+        } else {
-    
+
-    if(parentLock!= null){
+    if (parentLock != null) {
-   * Release the lock on the bucket that makes the bucket
-   * stay the primary during a write.
+   * Release the lock on the bucket that makes the bucket stay the primary during a write.
-    if(!needWriteLock(event)) {
+    if (!needWriteLock(event)) {
-    
-    
+
+
-    return !(event.isOriginRemote()
-        || event.isNetSearch()
-        || event.getOperation().isLocal() 
-        || event.getOperation().isPutAll()
-        || event.getOperation().isRemoveAll()
-        || (event.isExpiration() && isEntryEvictDestroyEnabled() 
+    return !(event.isOriginRemote() || event.isNetSearch() || event.getOperation().isLocal()
+        || event.getOperation().isPutAll() || event.getOperation().isRemoveAll()
+        || (event.isExpiration() && isEntryEvictDestroyEnabled()
-  protected void distributeUpdate(EntryEventImpl event, long lastModified, boolean ifNew, boolean ifOld, Object expectedOldValue, boolean requireOldValue) {
-  }
+  protected void distributeUpdate(EntryEventImpl event, long lastModified, boolean ifNew,
+      boolean ifOld, Object expectedOldValue, boolean requireOldValue) {}
-  //  1) apply op locally, aka update entry
-  //  2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
-  //  3) cache listener with synchrony on entry
-  //  4) update local bs, gateway
+  // 1) apply op locally, aka update entry
+  // 2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
+  // 3) cache listener with synchrony on entry
+  // 4) update local bs, gateway
-  //  1) apply op locally
-  //  2) update local bs, gateway
+  // 1) apply op locally
+  // 2) update local bs, gateway
-  void basicInvalidate(EntryEventImpl event) throws EntryNotFoundException
-  {
+  void basicInvalidate(EntryEventImpl event) throws EntryNotFoundException {
-  
+
-  void basicInvalidate(final EntryEventImpl event, boolean invokeCallbacks,
-      boolean forceNewEntry)
+  void basicInvalidate(final EntryEventImpl event, boolean invokeCallbacks, boolean forceNewEntry)
-    Assert.assertTrue(! event.isLocalInvalid());
+    Assert.assertTrue(!event.isLocalInvalid());
-      if ( !hasSeenEvent(event) ) {
+      if (!hasSeenEvent(event)) {
-          DistributedSystem sys =   cache.getDistributedSystem(); 
-          EventID newID = new EventID(sys); 
+          DistributedSystem sys = cache.getDistributedSystem();
+          EventID newID = new EventID(sys);
-        boolean forceCallbacks = isEntryEvictDestroyEnabled(); 
-        boolean done = this.entries.invalidate(event, invokeCallbacks, forceNewEntry, forceCallbacks); 
+        boolean forceCallbacks = isEntryEvictDestroyEnabled();
+        boolean done =
+            this.entries.invalidate(event, invokeCallbacks, forceNewEntry, forceCallbacks);
-          synchronized(pendingSecondaryExpires) {
+          synchronized (pendingSecondaryExpires) {
-      }
-      else {
+      } else {
-          logger.trace(LogMarker.DM, "LR.basicInvalidate: this cache has already seen this event {}", event);
+          logger.trace(LogMarker.DM,
+              "LR.basicInvalidate: this cache has already seen this event {}", event);
-    if (!event.isOriginRemote()
-        && getBucketAdvisor().isPrimary()) {
+    if (!event.isOriginRemote() && getBucketAdvisor().isPrimary()) {
-    event.invokeCallbacks(this,true, false);
+    event.invokeCallbacks(this, true, false);
-  
+
-  void basicInvalidatePart2(final RegionEntry re, final EntryEventImpl event,
-      boolean clearConflict, boolean invokeCallbacks)
-  {
+  void basicInvalidatePart2(final RegionEntry re, final EntryEventImpl event, boolean clearConflict,
+      boolean invokeCallbacks) {
-      // This code assumes it is safe ignore token mode (GII in progress) 
+      // This code assumes it is safe ignore token mode (GII in progress)
-      
+
-    super.basicInvalidatePart2(re, event, clearConflict /*Clear conflict occurred */, invokeCallbacks);
+    super.basicInvalidatePart2(re, event, clearConflict /* Clear conflict occurred */,
+        invokeCallbacks);
-  void distributeInvalidate(EntryEventImpl event) {
-  }
+  void distributeInvalidate(EntryEventImpl event) {}
-  
+
-    return this.concurrencyChecksEnabled && ((event.getVersionTag() == null) || event.getVersionTag().isGatewayTag());
+    return this.concurrencyChecksEnabled
+        && ((event.getVersionTag() == null) || event.getVersionTag().isGatewayTag());
-  
+
-    
+
-    if(needWriteLock(event) && !getBucketAdvisor().isPrimary()) {
+    if (needWriteLock(event) && !getBucketAdvisor().isPrimary()) {
-    } catch(PrimaryBucketException e) {
-      //must have concurrently removed the primary
+    } catch (PrimaryBucketException e) {
+      // must have concurrently removed the primary
-  
+
-    if(!getBucketAdvisor().isPrimary()) {
+    if (!getBucketAdvisor().isPrimary()) {
-      //must have concurrently removed the primary
+      // must have concurrently removed the primary
-  final void performExpiryTimeout(ExpiryTask p_task) throws CacheException
-  {
+  final void performExpiryTimeout(ExpiryTask p_task) throws CacheException {
-    //Fix for bug 43805 - get the primary lock before
-    //synchronizing on pendingSecondaryExpires, to match the lock
-    //ordering in other place (like acquiredPrimaryLock)
+    // Fix for bug 43805 - get the primary lock before
+    // synchronizing on pendingSecondaryExpires, to match the lock
+    // ordering in other place (like acquiredPrimaryLock)
-      if(!getBucketAdvisor().isPrimary() && !isEvictDestroy) {
+      if (!getBucketAdvisor().isPrimary() && !isEvictDestroy) {
-    return getEvictionAttributes() != null && EvictionAction.LOCAL_DESTROY.equals(getEvictionAttributes().getAction());
+    return getEvictionAttributes() != null
+        && EvictionAction.LOCAL_DESTROY.equals(getEvictionAttributes().getAction());
-  
-  protected final void processPendingSecondaryExpires()
-  {
+
+  protected final void processPendingSecondaryExpires() {
-          }
-          catch (EntryNotFoundException ignore) {
+          } catch (EntryNotFoundException ignore) {
-      }
-      catch (RegionDestroyedException re) {
+      } catch (RegionDestroyedException re) {
-      }
-      catch (CancelException ex) {
+      } catch (CancelException ex) {
-      }
-      catch (VirtualMachineError err) {
+      } catch (VirtualMachineError err) {
-        // If this ever returns, rethrow the error.  We're poisoned
+        // If this ever returns, rethrow the error. We're poisoned
-      }
-      catch (Throwable ex) {
+      } catch (Throwable ex) {
-        // catch VirtualMachineError (see above).  However, there is
+        // catch VirtualMachineError (see above). However, there is
-        logger.fatal(LocalizedMessage.create(LocalizedStrings.LocalRegion_EXCEPTION_IN_EXPIRATION_TASK), ex);
+        logger.fatal(
+            LocalizedMessage.create(LocalizedStrings.LocalRegion_EXCEPTION_IN_EXPIRATION_TASK), ex);
-  
+
-   * Creates an event for the EVICT_DESTROY operation so that events will fire
-   * for Partitioned Regions.
+   * Creates an event for the EVICT_DESTROY operation so that events will fire for Partitioned
+   * Regions.
+   * 
-    event.setInvokePRCallbacks(true);   //see bug 40797
+    event.setInvokePRCallbacks(true); // see bug 40797
-    
+
-  //  1) apply op locally, aka destroy entry (REMOVED token)
-  //  2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
-  //  3) cache listener with synchrony on local entry
-  //  4) update local bs, gateway
+  // 1) apply op locally, aka destroy entry (REMOVED token)
+  // 2) distribute op to bucket secondaries and bridge servers with synchrony on local entry
+  // 3) cache listener with synchrony on local entry
+  // 4) update local bs, gateway
-  //  1) apply op locally
-  //  2) update local bs, gateway
+  // 1) apply op locally
+  // 2) update local bs, gateway
-  protected
-  void basicDestroy(final EntryEventImpl event,
-                       final boolean cacheWrite,
-                       Object expectedOldValue)
-  throws EntryNotFoundException, CacheWriterException, TimeoutException {
+  protected void basicDestroy(final EntryEventImpl event, final boolean cacheWrite,
+      Object expectedOldValue)
+      throws EntryNotFoundException, CacheWriterException, TimeoutException {
-      if ( !hasSeenEvent(event) ) {
+      if (!hasSeenEvent(event)) {
-          DistributedSystem sys =   cache.getDistributedSystem(); 
+          DistributedSystem sys = cache.getDistributedSystem();
-        boolean done = mapDestroy(event,
-                          cacheWrite,
-                          false, // isEviction //merge44610: In cheetah instead of false event.getOperation().isEviction() is used. We kept the cedar change as it is.
-                          expectedOldValue);
-        if(done && !getBucketAdvisor().isPrimary() && isEntryExpiryPossible()) {
-          synchronized(pendingSecondaryExpires) {
+        boolean done = mapDestroy(event, cacheWrite, false, // isEviction //merge44610: In cheetah
+                                                            // instead of false
+                                                            // event.getOperation().isEviction() is
+                                                            // used. We kept the cedar change as it
+                                                            // is.
+            expectedOldValue);
+        if (done && !getBucketAdvisor().isPrimary() && isEntryExpiryPossible()) {
+          synchronized (pendingSecondaryExpires) {
-      }
-      else {
-    	if (!getConcurrencyChecksEnabled() || event.hasValidVersionTag()) {
+      } else {
+        if (!getConcurrencyChecksEnabled() || event.hasValidVersionTag()) {
-    	}
+        }
-  
-  protected void distributeDestroyOperation (EntryEventImpl event) {
+
+  protected void distributeDestroyOperation(EntryEventImpl event) {
-      logger.trace(LogMarker.DM, "BR.basicDestroy: this cache has already seen this event {}", event);
+      logger.trace(LogMarker.DM, "BR.basicDestroy: this cache has already seen this event {}",
+          event);
-    if (!event.isOriginRemote()
-        && getBucketAdvisor().isPrimary()) {
+    if (!event.isOriginRemote() && getBucketAdvisor().isPrimary()) {
-    if (!event.getOperation().isRemoveAll()) {  // removeAll will invoke listeners later
-      event.invokeCallbacks(this,true, false);    
+    if (!event.getOperation().isRemoveAll()) { // removeAll will invoke listeners later
+      event.invokeCallbacks(this, true, false);
-    if (!event.isOriginRemote()
-        && !event.isBulkOpInProgress()
-        && !event.getOperation().isLocal()
+    if (!event.isOriginRemote() && !event.isBulkOpInProgress() && !event.getOperation().isLocal()
-  void distributeDestroy(EntryEventImpl event, Object expectedOldValue) {
-  }
-  
-  
-// impl removed - not needed for listener invocation alterations
-//  void basicDestroyPart2(RegionEntry re, EntryEventImpl event, boolean inTokenMode, boolean invokeCallbacks)
+  void distributeDestroy(EntryEventImpl event, Object expectedOldValue) {}
+
+
+  // impl removed - not needed for listener invocation alterations
+  // void basicDestroyPart2(RegionEntry re, EntryEventImpl event, boolean inTokenMode, boolean
+  // invokeCallbacks)
-  protected void validateArguments(Object key, Object value, Object aCallbackArgument)
-  {
+  protected void validateArguments(Object key, Object value, Object aCallbackArgument) {
-//    Object obj = event.getRawNewValue();
-//    if (obj instanceof byte[]
-//                            || obj == null
-//                            || obj instanceof CachedDeserializable
-//                            || obj == NotAvailable.NOT_AVAILABLE
-//                            || Token.isInvalidOrRemoved(obj)) {
-//                          // already serialized
-//                          return;
-//                        }
-//    throw new InternalGemFireError("event did not force serialized: " + event);
+    // Object obj = event.getRawNewValue();
+    // if (obj instanceof byte[]
+    // || obj == null
+    // || obj instanceof CachedDeserializable
+    // || obj == NotAvailable.NOT_AVAILABLE
+    // || Token.isInvalidOrRemoved(obj)) {
+    // // already serialized
+    // return;
+    // }
+    // throw new InternalGemFireError("event did not force serialized: " + event);
-  
+
-   * This method is called when a miss from a get ends up
-   * finding an object through a cache loader or from a server.
-   * In that case we want to make sure that we don't move
-   * this bucket while putting the value in the ache.
-   * @see LocalRegion#basicPutEntry(EntryEventImpl, long) 
+   * This method is called when a miss from a get ends up finding an object through a cache loader
+   * or from a server. In that case we want to make sure that we don't move this bucket while
+   * putting the value in the ache.
+   * 
+   * @see LocalRegion#basicPutEntry(EntryEventImpl, long)
-  protected RegionEntry basicPutEntry(final EntryEventImpl event,
-      final long lastModified) throws TimeoutException,
-      CacheWriterException {
+  protected RegionEntry basicPutEntry(final EntryEventImpl event, final long lastModified)
+      throws TimeoutException, CacheWriterException {
-  void basicUpdateEntryVersion(EntryEventImpl event)
-      throws EntryNotFoundException {
-    
+  void basicUpdateEntryVersion(EntryEventImpl event) throws EntryNotFoundException {
+
-      try {      
+      try {
-            logger.trace(LogMarker.DM, "BR.basicUpdateEntryVersion: this cache has already seen this event {}", event);
+            logger.trace(LogMarker.DM,
+                "BR.basicUpdateEntryVersion: this cache has already seen this event {}", event);
-  
-  public int getRedundancyLevel()
-  {
+
+  public int getRedundancyLevel() {
-    throw new UnsupportedOperationException(LocalizedStrings.BucketRegion_THIS_SHOULD_NEVER_BE_CALLED_ON_0.toLocalizedString(getClass()));
+    throw new UnsupportedOperationException(
+        LocalizedStrings.BucketRegion_THIS_SHOULD_NEVER_BE_CALLED_ON_0
+            .toLocalizedString(getClass()));
-  
+
-    //TODO prpersist - Added this if null check for the partitioned region
+    // TODO prpersist - Added this if null check for the partitioned region
-    return isBucketDestroyed()
-        || (this.partitionedRegion != null
-            && this.partitionedRegion.isLocallyDestroyed && !isInDestroyingThread()); 
+    return isBucketDestroyed() || (this.partitionedRegion != null
+        && this.partitionedRegion.isLocallyDestroyed && !isInDestroyingThread());
-   * Return true if this bucket has been destroyed.
-   * Don't bother checking to see if the PR that owns this bucket was destroyed;
-   * that has already been checked.
+   * Return true if this bucket has been destroyed. Don't bother checking to see if the PR that owns
+   * this bucket was destroyed; that has already been checked.
+   * 
-  public void checkReadiness()
-  {
+  public void checkReadiness() {
-  public PartitionedRegion getPartitionedRegion(){
+  public PartitionedRegion getPartitionedRegion() {
-  
+
-   * is the current thread involved in destroying the PR that
-   * owns this region?
+   * is the current thread involved in destroying the PR that owns this region?
-    return this.partitionedRegion.locallyDestroyingThread
-      == Thread.currentThread();
+    return this.partitionedRegion.locallyDestroyingThread == Thread.currentThread();
-//  public int getSerialNumber() {
-//    String s = "This should never be called on " + getClass();
-//    throw new UnsupportedOperationException(s);
-//  }
+  // public int getSerialNumber() {
+  // String s = "This should never be called on " + getClass();
+  // throw new UnsupportedOperationException(s);
+  // }
-  
+
-    return !this.partitionedRegion.isLocallyDestroyed &&
-      !this.partitionedRegion.isClosed && !this.partitionedRegion.isDestroyed();
+    return !this.partitionedRegion.isLocallyDestroyed && !this.partitionedRegion.isClosed
+        && !this.partitionedRegion.isDestroyed();
-  
+
-   * @return serialized form if present, null if the entry is not in the cache,
-   *         or INVALID or LOCAL_INVALID re is a miss (invalid)
-   * @throws IOException
-   *                 if there is a serialization problem
-   * see LocalRegion#getDeserializedValue(RegionEntry, KeyInfo, boolean, boolean,  boolean, EntryEventImpl, boolean, boolean, boolean)
+   * @return serialized form if present, null if the entry is not in the cache, or INVALID or
+   *         LOCAL_INVALID re is a miss (invalid)
+   * @throws IOException if there is a serialization problem see
+   *         LocalRegion#getDeserializedValue(RegionEntry, KeyInfo, boolean, boolean, boolean,
+   *         EntryEventImpl, boolean, boolean, boolean)
-  private RawValue getSerialized(Object key,
-                                 boolean updateStats,
-                                 boolean doNotLockEntry,
-                                 EntryEventImpl clientEvent,
-                                 boolean returnTombstones)
+  private RawValue getSerialized(Object key, boolean updateStats, boolean doNotLockEntry,
+      EntryEventImpl clientEvent, boolean returnTombstones)
-    
+
-      v =re.getValue(this);
-      if(doNotLockEntry) {
-        if(v == Token.NOT_AVAILABLE || v == null) {
+      v = re.getValue(this);
+      if (doNotLockEntry) {
+        if (v == Token.NOT_AVAILABLE || v == null) {
-    }catch(DiskAccessException dae) {
-      this.handleDiskAccessException(dae);     
+    } catch (DiskAccessException dae) {
+      this.handleDiskAccessException(dae);
-    
+
-    } else { 
+    } else {
-  public RawValue getSerialized(KeyInfo keyInfo,
-                                boolean generateCallbacks,
-                                boolean doNotLockEntry,
-                                ClientProxyMembershipID requestingClient,
-                                EntryEventImpl clientEvent,
-                                boolean returnTombstones) throws IOException {
+  public RawValue getSerialized(KeyInfo keyInfo, boolean generateCallbacks, boolean doNotLockEntry,
+      ClientProxyMembershipID requestingClient, EntryEventImpl clientEvent,
+      boolean returnTombstones) throws IOException {
-    
+
-      RawValue result = getSerialized(keyInfo.getKey(), true, doNotLockEntry, clientEvent, returnTombstones);
-      isCreate = result == NULLVALUE || (result.getRawValue() == Token.TOMBSTONE && !returnTombstones);
+      RawValue result =
+          getSerialized(keyInfo.getKey(), true, doNotLockEntry, clientEvent, returnTombstones);
+      isCreate =
+          result == NULLVALUE || (result.getRawValue() == Token.TOMBSTONE && !returnTombstones);
-        if (hasServerProxy() || 
-            basicGetLoader() != null) {
-          if(doNotLockEntry) {
+        if (hasServerProxy() || basicGetLoader() != null) {
+          if (doNotLockEntry) {
-          Object value = nonTxnFindObject(keyInfo, isCreate,
-              generateCallbacks, result.getRawValue(), true, true, requestingClient, clientEvent, false);
+          Object value = nonTxnFindObject(keyInfo, isCreate, generateCallbacks,
+              result.getRawValue(), true, true, requestingClient, clientEvent, false);
-        }
-        else { // local scope with no loader, still might need to update stats
+        } else { // local scope with no loader, still might need to update stats
-      return result;  // changed in 7.0 to return RawValue(Token.INVALID) if the entry is invalid
-    }
-    finally {
+      return result; // changed in 7.0 to return RawValue(Token.INVALID) if the entry is invalid
+    } finally {
-    
+
-  public String toString()
-  {
-    return new StringBuilder()
-    .append("BucketRegion")
-    .append("[path='").append(getFullPath())
-    .append(";serial=").append(getSerialNumber())
-    .append(";primary=").append(getBucketAdvisor().getProxyBucketRegion().isPrimary())
-    .append("]")
-    .toString();
+  public String toString() {
+    return new StringBuilder().append("BucketRegion").append("[path='").append(getFullPath())
+        .append(";serial=").append(getSerialNumber()).append(";primary=")
+        .append(getBucketAdvisor().getProxyBucketRegion().isPrimary()).append("]").toString();
-  protected void distributedRegionCleanup(RegionEventImpl event)
-  {
-    // No need to close advisor, assume its already closed 
+  protected void distributedRegionCleanup(RegionEventImpl event) {
+    // No need to close advisor, assume its already closed
-  
+
-   * Also marks the local disk files as to be deleted before 
-   * sending the message to peers.
+   * Also marks the local disk files as to be deleted before sending the message to peers.
-    if(getPersistenceAdvisor() != null) {
+    if (getPersistenceAdvisor() != null) {
-    
+
-    
-    //Tell our peers whether we are destroying this region
-    //or just closing it.
-    boolean shouldDestroy = rebalance || diskRegion == null
-        || !diskRegion.isRecreated();
-    Operation op = shouldDestroy ? Operation.REGION_LOCAL_DESTROY
-        : Operation.REGION_CLOSE;
-    
-    RegionEventImpl event = new RegionEventImpl(this, op, null, false,
-        getMyId(), generateEventID()/* generate EventID */);
+
+    // Tell our peers whether we are destroying this region
+    // or just closing it.
+    boolean shouldDestroy = rebalance || diskRegion == null || !diskRegion.isRecreated();
+    Operation op = shouldDestroy ? Operation.REGION_LOCAL_DESTROY : Operation.REGION_CLOSE;
+
+    RegionEventImpl event = new RegionEventImpl(this, op, null, false, getMyId(),
+        generateEventID()/* generate EventID */);
-    // distribute the region closure/destruction, the PR RegionAdvisor.close() 
+    // distribute the region closure/destruction, the PR RegionAdvisor.close()
-      
-      
-      //Only delete the files on the local disk if
-      //this is a rebalance, or we are creating the bucket
-      //for the first time
-      if (diskRegion != null && shouldDestroy) { 
+
+
+      // Only delete the files on the local disk if
+      // this is a rebalance, or we are creating the bucket
+      // for the first time
+      if (diskRegion != null && shouldDestroy) {
-      
-      //Send out the destroy op to peers
+
+      // Send out the destroy op to peers
-  protected void distributeDestroyRegion(RegionEventImpl event,
-                                         boolean notifyOfRegionDeparture) {
-    //No need to do this when we actually destroy the region,
-    //we already distributed this info.
+  protected void distributeDestroyRegion(RegionEventImpl event, boolean notifyOfRegionDeparture) {
+    // No need to do this when we actually destroy the region,
+    // we already distributed this info.
-  
+
-    e2.setRegion(this.partitionedRegion);
-    if (FORCE_LOCAL_LISTENERS_INVOCATION) {
-      e2.setInvokePRCallbacks(true);
-    }
-    else {
-      e2.setInvokePRCallbacks(sourceEvent.getInvokePRCallbacks());
-    }
-    DistributedMember dm = this.getDistributionManager().getDistributionManagerId();
-    e2.setOriginRemote(!e2.getDistributedMember().equals(dm));
-    returned = true;
-    return e2;
+      e2.setRegion(this.partitionedRegion);
+      if (FORCE_LOCAL_LISTENERS_INVOCATION) {
+        e2.setInvokePRCallbacks(true);
+      } else {
+        e2.setInvokePRCallbacks(sourceEvent.getInvokePRCallbacks());
+      }
+      DistributedMember dm = this.getDistributionManager().getDistributionManagerId();
+      e2.setOriginRemote(!e2.getDistributedMember().equals(dm));
+      returned = true;
+      return e2;
-  
-  
+
+
-  public void invokeTXCallbacks(
-      final EnumListenerEvent eventType, final EntryEventImpl event,
-      final boolean callDispatchListenerEvent)
-  {
+  public void invokeTXCallbacks(final EnumListenerEvent eventType, final EntryEventImpl event,
+      final boolean callDispatchListenerEvent) {
-    // initializing.  We can't block while initializing or a GII state flush
+    // initializing. We can't block while initializing or a GII state flush
-    @Released final EntryEventImpl prevent = createEventForPR(event);
+    @Released
+    final EntryEventImpl prevent = createEventForPR(event);
-      this.partitionedRegion.invokeTXCallbacks(eventType, prevent, this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false);
+      this.partitionedRegion.invokeTXCallbacks(eventType, prevent,
+          this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false);
-  
-  
-  /* (non-Javadoc)
-   * @see org.apache.geode.internal.cache.LocalRegion#invokeDestroyCallbacks(org.apache.geode.internal.cache.EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
+
+
+  /*
+   * (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.LocalRegion#invokeDestroyCallbacks(org.apache.geode.internal.
+   * cache.EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
-  public void invokeDestroyCallbacks(
-      final EnumListenerEvent eventType, final EntryEventImpl event,
-      final boolean callDispatchListenerEvent, boolean notifyGateways)
-  {
+  public void invokeDestroyCallbacks(final EnumListenerEvent eventType, final EntryEventImpl event,
+      final boolean callDispatchListenerEvent, boolean notifyGateways) {
-    // initializing.  We can't block while initializing or a GII state flush
+    // initializing. We can't block while initializing or a GII state flush
-    @Released final EntryEventImpl prevent = createEventForPR(event);
+    @Released
+    final EntryEventImpl prevent = createEventForPR(event);
-      this.partitionedRegion.invokeDestroyCallbacks(eventType, prevent, this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false, false);
+      this.partitionedRegion.invokeDestroyCallbacks(eventType, prevent,
+          this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false, false);
-  /* (non-Javadoc)
-   * @see org.apache.geode.internal.cache.LocalRegion#invokeInvalidateCallbacks(org.apache.geode.internal.cache.EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
+  /*
+   * (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.LocalRegion#invokeInvalidateCallbacks(org.apache.geode.internal
+   * .cache.EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
-  public void invokeInvalidateCallbacks(
-      final EnumListenerEvent eventType, final EntryEventImpl event,
-      final boolean callDispatchListenerEvent)
-  {
+  public void invokeInvalidateCallbacks(final EnumListenerEvent eventType,
+      final EntryEventImpl event, final boolean callDispatchListenerEvent) {
-    // initializing.  We can't block while initializing or a GII state flush
+    // initializing. We can't block while initializing or a GII state flush
-    @Released final EntryEventImpl prevent = createEventForPR(event);
+    @Released
+    final EntryEventImpl prevent = createEventForPR(event);
-      this.partitionedRegion.invokeInvalidateCallbacks(eventType, prevent, this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false);
+      this.partitionedRegion.invokeInvalidateCallbacks(eventType, prevent,
+          this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false);
-  /* (non-Javadoc)
-   * @see org.apache.geode.internal.cache.LocalRegion#invokePutCallbacks(org.apache.geode.internal.cache.EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
+  /*
+   * (non-Javadoc)
+   * 
+   * @see
+   * org.apache.geode.internal.cache.LocalRegion#invokePutCallbacks(org.apache.geode.internal.cache.
+   * EnumListenerEvent, org.apache.geode.internal.cache.EntryEventImpl, boolean)
-  public void invokePutCallbacks(
-      final EnumListenerEvent eventType, final EntryEventImpl event,
-      final boolean callDispatchListenerEvent, boolean notifyGateways)
-  {
+  public void invokePutCallbacks(final EnumListenerEvent eventType, final EntryEventImpl event,
+      final boolean callDispatchListenerEvent, boolean notifyGateways) {
-    // initializing.  We can't block while initializing or a GII state flush
+    // initializing. We can't block while initializing or a GII state flush
-    @Released final EntryEventImpl prevent = createEventForPR(event);
+    @Released
+    final EntryEventImpl prevent = createEventForPR(event);
-              this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false, false);
+          this.partitionedRegion.isInitialized() ? callDispatchListenerEvent : false, false);
-  
+
-   * perform adjunct messaging for the given operation and return a set of
-   * members that should be attached to the operation's reply processor (if any)
+   * perform adjunct messaging for the given operation and return a set of members that should be
+   * attached to the operation's reply processor (if any)
+   * 
-  protected Set performAdjunctMessaging(EntryEventImpl event,
-      Set cacheOpRecipients, Set adjunctRecipients,
-      FilterRoutingInfo filterRoutingInfo,
-      DirectReplyProcessor processor,
-      boolean calculateDelta,
-      boolean sendDeltaWithFullValue) {
-    
+  protected Set performAdjunctMessaging(EntryEventImpl event, Set cacheOpRecipients,
+      Set adjunctRecipients, FilterRoutingInfo filterRoutingInfo, DirectReplyProcessor processor,
+      boolean calculateDelta, boolean sendDeltaWithFullValue) {
+
-      msg.setSender(this.partitionedRegion.getDistributionManager()
-          .getDistributionManagerId());
+      msg.setSender(this.partitionedRegion.getDistributionManager().getDistributionManagerId());
-      
-      failures = msg.relayToListeners(cacheOpRecipients, adjunctRecipients,
-          filterRoutingInfo, event, this.partitionedRegion, processor);
-    }
-    else {
-      // The primary bucket is being modified locally by an application thread locally 
+
+      failures = msg.relayToListeners(cacheOpRecipients, adjunctRecipients, filterRoutingInfo,
+          event, this.partitionedRegion, processor);
+    } else {
+      // The primary bucket is being modified locally by an application thread locally
-        failures = PutMessage.notifyListeners(cacheOpRecipients,
-            adjunctRecipients, filterRoutingInfo, this.partitionedRegion, 
-            event, op.isCreate(), !op.isCreate(), processor,
-            sendDeltaWithFullValue);
-      }
-      else if (op.isDestroy()) {
-        failures = DestroyMessage.notifyListeners(cacheOpRecipients,
-            adjunctRecipients, filterRoutingInfo,
-            this.partitionedRegion, event, processor);
-      }
-      else if (op.isInvalidate()) {
-        failures = InvalidateMessage.notifyListeners(cacheOpRecipients,
-            adjunctRecipients, filterRoutingInfo, 
-            this.partitionedRegion, event, processor);
-      }
-      else {
+        failures = PutMessage.notifyListeners(cacheOpRecipients, adjunctRecipients,
+            filterRoutingInfo, this.partitionedRegion, event, op.isCreate(), !op.isCreate(),
+            processor, sendDeltaWithFullValue);
+      } else if (op.isDestroy()) {
+        failures = DestroyMessage.notifyListeners(cacheOpRecipients, adjunctRecipients,
+            filterRoutingInfo, this.partitionedRegion, event, processor);
+      } else if (op.isInvalidate()) {
+        failures = InvalidateMessage.notifyListeners(cacheOpRecipients, adjunctRecipients,
+            filterRoutingInfo, this.partitionedRegion, event, processor);
+      } else {
-      @Unretained Object rawNewValue = event.getRawNewValue();
+      @Unretained
+      Object rawNewValue = event.getRawNewValue();
-          && ((org.apache.geode.Delta)instance).hasDelta()) {
+          && ((org.apache.geode.Delta) instance).hasDelta()) {
-          ((org.apache.geode.Delta)instance).toDelta(hdos);
+          ((org.apache.geode.Delta) instance).toDelta(hdos);
-        }
-        catch (RuntimeException re) {
+        } catch (RuntimeException re) {
-        }
-        catch (Exception e) {
+        } catch (Exception e) {
-                  .toLocalizedString(), e);
+                  .toLocalizedString(),
+              e);
-   * create a PutAllPRMessage for notify-only and send it to all adjunct nodes. 
-   * return a set of members that should be attached to the operation's reply processor (if any)
+   * create a PutAllPRMessage for notify-only and send it to all adjunct nodes. return a set of
+   * members that should be attached to the operation's reply processor (if any)
+   * 
-  public Set performPutAllAdjunctMessaging(DistributedPutAllOperation dpao,
-      Set cacheOpRecipients, Set adjunctRecipients, FilterRoutingInfo filterRoutingInfo,
-      DirectReplyProcessor processor) {
+  public Set performPutAllAdjunctMessaging(DistributedPutAllOperation dpao, Set cacheOpRecipients,
+      Set adjunctRecipients, FilterRoutingInfo filterRoutingInfo, DirectReplyProcessor processor) {
-    prMsg.setSender(this.partitionedRegion.getDistributionManager()
-        .getDistributionManagerId());
-    
+    prMsg.setSender(this.partitionedRegion.getDistributionManager().getDistributionManagerId());
+
-    // to the recipients list.  Also determine if there are any FilterInfo
+    // to the recipients list. Also determine if there are any FilterInfo
-//    boolean anyWithRouting = false;
+    // boolean anyWithRouting = false;
-    for (Iterator it=membersWithRouting.iterator(); it.hasNext(); ) {
+    for (Iterator it = membersWithRouting.iterator(); it.hasNext();) {
-//        anyWithRouting = true;
+        // anyWithRouting = true;
-//    Set failures = Collections.EMPTY_SET;
+    // Set failures = Collections.EMPTY_SET;
-//    if (!anyWithRouting) {
-      Set failures = this.partitionedRegion.getDistributionManager().putOutgoing(prMsg);
+    // if (!anyWithRouting) {
+    Set failures = this.partitionedRegion.getDistributionManager().putOutgoing(prMsg);
-//  } else {
-//      // Send message to each member.  We set a FilterRoutingInfo serialization
-//      // target so that serialization of the PutAllData objects held in the
-//      // message will only serialize the routing entry for the message recipient
-//      Iterator rIter = recipients.iterator();
-//      failures = new HashSet();
-//      while (rIter.hasNext()){
-//        InternalDistributedMember member = (InternalDistributedMember)rIter.next();
-//        FilterRoutingInfo.setSerializationTarget(member);
-//        try {
-//          prMsg.resetRecipients();
-//          prMsg.setRecipient(member);
-//          Set fs = this.partitionedRegion.getDistributionManager().putOutgoing(prMsg);
-//          if (fs != null && !fs.isEmpty()) {
-//            failures.addAll(fs);
-//          }
-//        } finally {
-//          FilterRoutingInfo.clearSerializationTarget();
-//        }
-//      }
-//    }
+    // } else {
+    // // Send message to each member. We set a FilterRoutingInfo serialization
+    // // target so that serialization of the PutAllData objects held in the
+    // // message will only serialize the routing entry for the message recipient
+    // Iterator rIter = recipients.iterator();
+    // failures = new HashSet();
+    // while (rIter.hasNext()){
+    // InternalDistributedMember member = (InternalDistributedMember)rIter.next();
+    // FilterRoutingInfo.setSerializationTarget(member);
+    // try {
+    // prMsg.resetRecipients();
+    // prMsg.setRecipient(member);
+    // Set fs = this.partitionedRegion.getDistributionManager().putOutgoing(prMsg);
+    // if (fs != null && !fs.isEmpty()) {
+    // failures.addAll(fs);
+    // }
+    // } finally {
+    // FilterRoutingInfo.clearSerializationTarget();
+    // }
+    // }
+    // }
-   * create a RemoveAllPRMessage for notify-only and send it to all adjunct nodes. 
-   * return a set of members that should be attached to the operation's reply processor (if any)
+   * create a RemoveAllPRMessage for notify-only and send it to all adjunct nodes. return a set of
+   * members that should be attached to the operation's reply processor (if any)
+   * 
-    prMsg.setSender(this.partitionedRegion.getDistributionManager()
-        .getDistributionManagerId());
-    
+    prMsg.setSender(this.partitionedRegion.getDistributionManager().getDistributionManagerId());
+
-    // to the recipients list.  Also determine if there are any FilterInfo
+    // to the recipients list. Also determine if there are any FilterInfo
-    for (Iterator it=membersWithRouting.iterator(); it.hasNext(); ) {
+    for (Iterator it = membersWithRouting.iterator(); it.hasNext();) {
-//        anyWithRouting = true;
+        // anyWithRouting = true;
-  protected Set getAdjunctReceivers(EntryEventImpl event, Set cacheOpReceivers,
-      Set twoMessages, FilterRoutingInfo routing) {
+  protected Set getAdjunctReceivers(EntryEventImpl event, Set cacheOpReceivers, Set twoMessages,
+      FilterRoutingInfo routing) {
-      Set r = this.partitionedRegion.getRegionAdvisor()
-        .adviseRequiresNotification(event);
-            
+      Set r = this.partitionedRegion.getRegionAdvisor().adviseRequiresNotification(event);
+
-      
+
-        }
-        else {
+        } else {
-        }  
-      }      
+        }
+      }
-        for (InternalDistributedMember id: routing.getMembers()) {
+        for (InternalDistributedMember id : routing.getMembers()) {
-    } 
-    else {
+    } else {
-      CacheWriter localWriter,
-      boolean requireOldValue, Object expectedOldValue)
-  throws CacheWriterException, TimeoutException {
-    
+      CacheWriter localWriter, boolean requireOldValue, Object expectedOldValue)
+      throws CacheWriterException, TimeoutException {
+
-        origRemoteState=event.isOriginRemote();
+        origRemoteState = event.isOriginRemote();
-      this.partitionedRegion.cacheWriteBeforePut(event, netWriteRecipients,
-          localWriter, requireOldValue, expectedOldValue);
+      this.partitionedRegion.cacheWriteBeforePut(event, netWriteRecipients, localWriter,
+          requireOldValue, expectedOldValue);
-  throws CacheWriterException, EntryNotFoundException, TimeoutException {
-    
+      throws CacheWriterException, EntryNotFoundException, TimeoutException {
+
-        origRemoteState=event.isOriginRemote();
+        origRemoteState = event.isOriginRemote();
-    //  return super.cacheWriteBeforeDestroy(event);
+    // return super.cacheWriteBeforeDestroy(event);
-  /* (non-Javadoc)
+  /*
+   * (non-Javadoc)
+   * 
+   * 
-    return getBucketAdvisor().getProxyBucketRegion().getBucketOwners();    
+    return getBucketAdvisor().getProxyBucketRegion().getBucketOwners();
-	  return 0;
-	}
-	return limit.get();
+      return 0;
+    }
+    return limit.get();
-	// This method can be called before object of this class is created
-	if (this.limit == null) {
-	  this.limit = new AtomicLong();
-	}
-	this.limit.set(limit);
+    // This method can be called before object of this class is created
+    if (this.limit == null) {
+      this.limit = new AtomicLong();
+    }
+    this.limit.set(limit);
-    // ezoerner:20090401 it's possible this value is a Delta
-      throw new InternalGemFireError("DEBUG: calcMemSize: weird value (class " 
-          + value.getClass() + "): " + value);
+      // ezoerner:20090401 it's possible this value is a Delta
+      throw new InternalGemFireError(
+          "DEBUG: calcMemSize: weird value (class " + value.getClass() + "): " + value);
-    
+
-    //a destroy could have already been applied to the map, and then updates
-    //the stat after we reset it, making the state negative.
-    
+    // a destroy could have already been applied to the map, and then updates
+    // the stat after we reset it, making the state negative.
+
-    if(this.isDestroyed || this.isDestroyingDiskRegion) {
-      //If this region is destroyed, mark the stat as destroyed.
+    if (this.isDestroyed || this.isDestroyingDiskRegion) {
+      // If this region is destroyed, mark the stat as destroyed.
-            
-    } else if(!this.isInitialized()) {
-      //This case is rather special. We clear the region if the GII failed.
-      //In the case of bucket regions, we know that there will be no concurrent operations
-      //if GII has failed, because there is not primary. So it's safe to set these
-      //counters to 0.
+
+    } else if (!this.isInitialized()) {
+      // This case is rather special. We clear the region if the GII failed.
+      // In the case of bucket regions, we know that there will be no concurrent operations
+      // if GII has failed, because there is not primary. So it's safe to set these
+      // counters to 0.
+    } else {
+      throw new InternalGemFireError(
+          "Trying to clear a bucket region that was not destroyed or in initialization.");
-    else {
-      throw new InternalGemFireError("Trying to clear a bucket region that was not destroyed or in initialization.");
-    }
-    if(oldMemValue != BUCKET_DESTROYED) {
+    if (oldMemValue != BUCKET_DESTROYED) {
+
-  
+
-  
+
-    //Bucket regions are not registered with ResourceListener,
-    //and should not get this event
+    // Bucket regions are not registered with ResourceListener,
+    // and should not get this event
-    //closeCacheCallback(getCacheLoader()); - fix bug 40228 - do NOT close loader
+    // closeCacheCallback(getCacheLoader()); - fix bug 40228 - do NOT close loader
-  
+
-    if(result == BUCKET_DESTROYED) {
+    if (result == BUCKET_DESTROYED) {
-  
+
-    if(result == BUCKET_DESTROYED) {
+    if (result == BUCKET_DESTROYED) {
-    
+
-  
-  public void preDestroyBucket(int bucketId) {
-  }
+
+  public void preDestroyBucket(int bucketId) {}
+
-  public void cleanupFailedInitialization()
-  {
+  public void cleanupFailedInitialization() {
-    }    
+    }
-    }    
+    }
-      case CREATE:
-        return newSize;
-      case DESTROY:
-        return - oldSize;
-      case UPDATE:
-        return newSize - oldSize;
-      case EVICT:
-        return - oldSize;
-      case FAULT_IN:
-        return newSize;
-      default:
-        throw new AssertionError("unhandled sizeOp: " + this);
+        case CREATE:
+          return newSize;
+        case DESTROY:
+          return -oldSize;
+        case UPDATE:
+          return newSize - oldSize;
+        case EVICT:
+          return -oldSize;
+        case FAULT_IN:
+          return newSize;
+        default:
+          throw new AssertionError("unhandled sizeOp: " + this);
-  
+
-  void updateBucket2Size(int oldSize, int newSize,
-                         SizeOp op) {
+  void updateBucket2Size(int oldSize, int newSize, SizeOp op) {
-    
-    if (memoryDelta == 0) return;
+
+    if (memoryDelta == 0)
+      return;
-  
+
-      if(bSize == BUCKET_DESTROYED) {
+      if (bSize == BUCKET_DESTROYED) {
-        throw new InternalGemFireError("Bucket " + this + " size (" +
-            bSize + ") negative after applying delta of " + memoryDelta);
+        throw new InternalGemFireError("Bucket " + this + " size (" + bSize
+            + ") negative after applying delta of " + memoryDelta);
-    
+
-  
+
-   * Returns the current number of entries whose value has been
-   * overflowed to disk by this bucket.This value will decrease when a value is
-   * faulted in. 
+   * Returns the current number of entries whose value has been overflowed to disk by this
+   * bucket.This value will decrease when a value is faulted in.
-   * Returns the current number of entries whose value resides in the
-   * VM for this bucket.  This value will decrease when the entry is overflowed to
-   * disk. 
+   * Returns the current number of entries whose value resides in the VM for this bucket. This value
+   * will decrease when the entry is overflowed to disk.
-   * Increments the current number of entries whose value has been
-   * overflowed to disk by this bucket, by a given amount.
+   * Increments the current number of entries whose value has been overflowed to disk by this
+   * bucket, by a given amount.
-    if (delta == 0) return;
+    if (delta == 0)
+      return;
-//     if (res < 0) {
-//       throw new IllegalStateException("numOverflowBytesOnDisk < 0 " + res);
-//     }
+    // if (res < 0) {
+    // throw new IllegalStateException("numOverflowBytesOnDisk < 0 " + res);
+    // }
-   * Increments the current number of entries whose value has been
-   * overflowed to disk by this bucket,by a given amount.
+   * Increments the current number of entries whose value has been overflowed to disk by this
+   * bucket,by a given amount.
-  
-  public void incEvictions(long delta ) {
-    this.evictions.getAndAdd(delta);
-   }
-  public long getEvictions( ) {
+  public void incEvictions(long delta) {
+    this.evictions.getAndAdd(delta);
+  }
+
+  public long getEvictions() {
-    public int getSizeForEviction() {
+
+  public int getSizeForEviction() {
-    int size = action.isLocalDestroy() ? this.getRegionMap().sizeInVM() : (int)this
-        .getNumEntriesInVM();
+    int size =
+        action.isLocalDestroy() ? this.getRegionMap().sizeInVM() : (int) this.getNumEntriesInVM();
+
-  public FilterProfile getFilterProfile(){
+  public FilterProfile getFilterProfile() {
-  public void setCloningEnabled(boolean isCloningEnabled){
+  public void setCloningEnabled(boolean isCloningEnabled) {
-  public boolean getCloningEnabled(){
+  public boolean getCloningEnabled() {
-  public void beforeAcquiringPrimaryState() {
-  }
+  public void beforeAcquiringPrimaryState() {}
-    
+
+
-  public void beforeReleasingPrimaryLockDuringDemotion() {
-  }
+  public void beforeReleasingPrimaryLockDuringDemotion() {}
-    
-    Set<InternalDistributedMember> hostingservers = this.partitionedRegion.getRegionAdvisor()
-        .getBucketOwners(this.getId());
+
+    Set<InternalDistributedMember> hostingservers =
+        this.partitionedRegion.getRegionAdvisor().getBucketOwners(this.getId());
-    
+
-      cache.getLoggerI18n().fine("Pinging secondaries of bucket " + this.getId() + " on servers "  + hostingservers);
-   
+      cache.getLoggerI18n()
+          .fine("Pinging secondaries of bucket " + this.getId() + " on servers " + hostingservers);
+
-    
-     return ServerPingMessage.send(cache, hostingservers);
-    
+
+    return ServerPingMessage.send(cache, hostingservers);
+
-  
+
-  
+

UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66