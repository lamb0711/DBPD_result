Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicLong;
-  
+
-   * The <code>Map</code> mapping the regionName->key to the queue key. This
-   * index allows fast updating of entries in the queue for conflation. This is
-   * necesaary for Colocated regions and if any of the regions use same key for
-   * data.
+   * The <code>Map</code> mapping the regionName->key to the queue key. This index allows fast
+   * updating of entries in the queue for conflation. This is necesaary for Colocated regions and if
+   * any of the regions use same key for data.
-   * A transient queue to maintain the eventSeqNum of the events that are to be
-   * sent to remote site. It is cleared when the queue is cleared.
+   * A transient queue to maintain the eventSeqNum of the events that are to be sent to remote site.
+   * It is cleared when the queue is cleared.
-  
-  //private final BlockingQueue<EventID> eventSeqNumQueueWithEventId = new LinkedBlockingQueue<EventID>();
+
+  // private final BlockingQueue<EventID> eventSeqNumQueueWithEventId = new
+  // LinkedBlockingQueue<EventID>();
+  private AtomicLong latestQueuedKey = new AtomicLong();
+
+  private AtomicLong latestAcknowledgedKey = new AtomicLong();
+
-   * @param regionName 
+   * @param regionName
-  public BucketRegionQueue(String regionName, RegionAttributes attrs,
-      LocalRegion parentRegion, GemFireCacheImpl cache,
-      InternalRegionArguments internalRegionArgs) {
+  public BucketRegionQueue(String regionName, RegionAttributes attrs, LocalRegion parentRegion,
+      GemFireCacheImpl cache, InternalRegionArguments internalRegionArgs) {
-  protected void cleanUpDestroyedTokensAndMarkGIIComplete(InitialImageOperation.GIIStatus giiStatus) {
+  protected void cleanUpDestroyedTokensAndMarkGIIComplete(
+      InitialImageOperation.GIIStatus giiStatus) {
-              int compareMem = new ByteComparator().compare(
-                  o1.getMembershipID(), o2.getMembershipID());
+              int compareMem =
+                  new ByteComparator().compare(o1.getMembershipID(), o2.getMembershipID());
-                  return o1.getSequenceID() < o2.getSequenceID() ? -1 : o1
-                      .getSequenceID() == o2.getSequenceID() ? 0 : 1;
+                  return o1.getSequenceID() < o2.getSequenceID() ? -1
+                      : o1.getSequenceID() == o2.getSequenceID() ? 0 : 1;
-          //although the empty check for this.keySet() is done above, 
-          //do the same for sortedKeys as well because the keySet() might have become 
-          //empty since the above check was made (keys might have been destroyed through BatchRemoval)
-          //fix for #49679 NoSuchElementException thrown from BucketRegionQueue.initialize
+          // although the empty check for this.keySet() is done above,
+          // do the same for sortedKeys as well because the keySet() might have become
+          // empty since the above check was made (keys might have been destroyed through
+          // BatchRemoval)
+          // fix for #49679 NoSuchElementException thrown from BucketRegionQueue.initialize
-          logger.debug("For bucket {} ,total keys recovered are : {} last key recovered is : {} and the seqNo is ",
+          logger.debug(
+              "For bucket {} ,total keys recovered are : {} last key recovered is : {} and the seqNo is ",
-      //Now, the bucket is initialized. Destroy the failedBatchRemovalKeys.
+      // Now, the bucket is initialized. Destroy the failedBatchRemovalKeys.
-    }
-    finally {
+    } finally {
-  
+
-   * When the GII was going, some of BatchRemoval messages (especially for events destroyed due to conflation) 
-   * might have failed since the event might not be found in the BucketRegionQueue. 
+   * When the GII was going, some of BatchRemoval messages (especially for events destroyed due to
+   * conflation) might have failed since the event might not be found in the BucketRegionQueue.
-   * Events found in the map need to be destroyed once GII is done. Fix for #47431.
-   * This method is invoked deliberately after this.initialized is set to true to fix defect #50316.
+   * Events found in the map need to be destroyed once GII is done. Fix for #47431. This method is
+   * invoked deliberately after this.initialized is set to true to fix defect #50316.
-    
+
-      //at this point, failedBatchRemovalMessageKeys contains messages failed during bucket 
-      //initialization only. Iterate over failedBatchRemovalMessageKeys and clear it completely.
+      // at this point, failedBatchRemovalMessageKeys contains messages failed during bucket
+      // initialization only. Iterate over failedBatchRemovalMessageKeys and clear it completely.
-    int batchSize = this.getPartitionedRegion().getParallelGatewaySender()
-        .getBatchSize();
+    int batchSize = this.getPartitionedRegion().getParallelGatewaySender().getBatchSize();
-  
+
-  
+
-  protected void clearQueues(){
+  protected void clearQueues() {
-    }
-    finally {
+    } finally {
-  
+
-  protected boolean virtualPut(EntryEventImpl event, boolean ifNew,
-      boolean ifOld, Object expectedOldValue, boolean requireOldValue,
-      long lastModified, boolean overwriteDestroyed) throws TimeoutException,
-      CacheWriterException {
-    boolean success = super.virtualPut(event, ifNew, ifOld, expectedOldValue,
-        requireOldValue, lastModified, overwriteDestroyed);
+  protected boolean virtualPut(EntryEventImpl event, boolean ifNew, boolean ifOld,
+      Object expectedOldValue, boolean requireOldValue, long lastModified,
+      boolean overwriteDestroyed) throws TimeoutException, CacheWriterException {
+    try {
+      boolean success = super.virtualPut(event, ifNew, ifOld, expectedOldValue, requireOldValue,
+          lastModified, overwriteDestroyed);
-    if (success) {
-      GatewaySenderEventImpl.release(event.getRawOldValue());
+      if (success) {
+        if (getPartitionedRegion().getColocatedWith() == null) {
+          return success;
+        }
-      if (getPartitionedRegion().getColocatedWith() == null) {
-        return success;
-      }
-
-      if (getPartitionedRegion().isConflationEnabled() && this.getBucketAdvisor().isPrimary()) {
-        Object object = event.getNewValue();
-        Long key = (Long)event.getKey();
-        if (object instanceof Conflatable) {
-          if (logger.isDebugEnabled()) {
-            logger.debug("Key :{} , Object : {} is conflatable", key, object);
-          }
-          // TODO: TO optimize by destroying on primary and secondary separately
-          // in case of conflation
-          conflateOldEntry((Conflatable)object, key);
-        } else {
-          if (logger.isDebugEnabled()) {
-            logger.debug("Object : {} is not conflatable", object);
+        if (getPartitionedRegion().isConflationEnabled() && this.getBucketAdvisor().isPrimary()) {
+          Object object = event.getNewValue();
+          Long key = (Long) event.getKey();
+          if (object instanceof Conflatable) {
+            if (logger.isDebugEnabled()) {
+              logger.debug("Key :{} , Object : {} is conflatable", key, object);
+            }
+            // TODO: TO optimize by destroying on primary and secondary separately
+            // in case of conflation
+            conflateOldEntry((Conflatable) object, key);
+          } else {
+            if (logger.isDebugEnabled()) {
+              logger.debug("Object : {} is not conflatable", object);
+            }
+      } else {
+        GatewaySenderEventImpl.release(event.getRawNewValue());
+      return success;
+    } finally {
+      GatewaySenderEventImpl.release(event.getRawOldValue());
-    return success;
-      Map latestIndexesForRegion = (Map)this.indexes.get(rName);
+      Map latestIndexesForRegion = (Map) this.indexes.get(rName);
-      Long previousTailKey = (Long)latestIndexesForRegion.put(keyToConflate,
-          tailKey);
+      Long previousTailKey = (Long) latestIndexesForRegion.put(keyToConflate, tailKey);
-          logger.debug("{}: Conflating {} at queue index={} and previousTailKey: ", this, object, tailKey, previousTailKey);
+          logger.debug("{}: Conflating {} at queue index={} and previousTailKey: ", this, object,
+              tailKey, previousTailKey);
-        AbstractGatewaySenderEventProcessor ep = region.getParallelGatewaySender().getEventProcessor();
-        if (ep == null) return;
-        ConcurrentParallelGatewaySenderQueue queue = (ConcurrentParallelGatewaySenderQueue)ep.getQueue();
+        AbstractGatewaySenderEventProcessor ep =
+            region.getParallelGatewaySender().getEventProcessor();
+        if (ep == null)
+          return;
+        ConcurrentParallelGatewaySenderQueue queue =
+            (ConcurrentParallelGatewaySenderQueue) ep.getQueue();
-        region.getParallelGatewaySender().getStatistics()
-            .incConflationIndexesMapSize();
+        region.getParallelGatewaySender().getStatistics().incConflationIndexesMapSize();
-      Conflatable object = (Conflatable)o;
+      Conflatable object = (Conflatable) o;
-        Map latestIndexesForRegion = (Map)this.indexes.get(rName);
+        Map latestIndexesForRegion = (Map) this.indexes.get(rName);
-          Long index = (Long)latestIndexesForRegion.remove(key);
+          Long index = (Long) latestIndexesForRegion.remove(key);
-            this.getPartitionedRegion().getParallelGatewaySender()
-                .getStatistics().decConflationIndexesMapSize();
+            this.getPartitionedRegion().getParallelGatewaySender().getStatistics()
+                .decConflationIndexesMapSize();
-  protected void basicDestroy(final EntryEventImpl event,
-      final boolean cacheWrite, Object expectedOldValue)
+  protected void basicDestroy(final EntryEventImpl event, final boolean cacheWrite,
+      Object expectedOldValue)
-      removeIndex((Long)event.getKey());
+      removeIndex((Long) event.getKey());
-    super.basicDestroy(event, cacheWrite, expectedOldValue);
+    try {
+      super.basicDestroy(event, cacheWrite, expectedOldValue);
+    } finally {
+      GatewaySenderEventImpl.release(event.getRawOldValue());
+    }
-    GatewaySenderEventImpl.release(event.getRawOldValue());
-      object = getValueInVMOrDiskWithoutFaultIn(k); 
-      if (object != null && object instanceof CachedDeserializable) { 
-    	object = ((CachedDeserializable)object).getDeserializedValue(this, this.getRegionEntry(k));
+      object = getValueInVMOrDiskWithoutFaultIn(k);
+      if (object != null && object instanceof CachedDeserializable) {
+        object = ((CachedDeserializable) object).getDeserializedValue(this, this.getRegionEntry(k));
-    return object;  // OFFHEAP: ok since callers are careful to do destroys on region queue after finished with peeked object.
+    return object; // OFFHEAP: ok since callers are careful to do destroys on region queue after
+                   // finished with peeked object.
-    //doing peek in initializationLock because during region destroy, the clearQueues 
-    //clears the eventSeqNumQueue and can cause data inconsistency (defect #48984) 
+    // doing peek in initializationLock because during region destroy, the clearQueues
+    // clears the eventSeqNumQueue and can cause data inconsistency (defect #48984)
-            logger.debug("The value against key {} in the bucket region queue with id {} is NULL for the GatewaySender {}",
+            logger.debug(
+                "The value against key {} in the bucket region queue with id {} is NULL for the GatewaySender {}",
-    }
-    finally {
+    } finally {
+        updateLargestQueuedKey((Long) key);
-        logger.debug("Put successfully in the queue : {} was initialized: {}", event.getRawNewValue(), this.initialized);
+        logger.debug("Put successfully in the queue : {} was initialized: {}",
+            event.getRawNewValue(), this.initialized);
-  
+
+  private void updateLargestQueuedKey(Long key) {
+    Atomics.setIfGreater(this.latestQueuedKey, key);
+  }
+
+  private void setLatestAcknowledgedKey(Long key) {
+    this.latestAcknowledgedKey.set(key);
+  }
+
+  public boolean waitUntilFlushed(long timeout, TimeUnit unit) throws InterruptedException {
+    if (logger.isDebugEnabled()) {
+      logger.debug("BucketRegionQueue: waitUntilFlushed bucket=" + getId() + "; time="
+          + System.currentTimeMillis() + "; timeout=" + timeout + "; unit=" + unit);
+    }
+    boolean result = false;
+    // Wait until latestAcknowledgedKey > latestQueuedKey or the queue is empty
+    if (this.initialized) {
+      long latestQueuedKeyToCheck = this.latestQueuedKey.get();
+      long nanosRemaining = unit.toNanos(timeout);
+      long endTime = System.nanoTime() + nanosRemaining;
+      while (nanosRemaining > 0) {
+        if (latestAcknowledgedKey.get() > latestQueuedKeyToCheck || isEmpty()) {
+          result = true;
+          break;
+        }
+        Thread.sleep(Math.min(TimeUnit.NANOSECONDS.toMillis(nanosRemaining) + 1, 100));
+        nanosRemaining = endTime - System.nanoTime();
+      }
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug("BucketRegionQueue: waitUntilFlushed completed bucket=" + getId() + "; time="
+          + System.currentTimeMillis() + "; result=" + result);
+    }
+    return result;
+  }
+
-    Object key = this.eventSeqNumQueue.remove();  
+    Object key = this.eventSeqNumQueue.remove();
-//     Object key = this.eventSeqNumQueue.remove();
-//     Object object = null;
-//     if (key != null) {
-//       object = PartitionRegionHelper
-//           .getLocalPrimaryData(getPartitionedRegion()).get(key);
-//       /**
-//        * TODO: For the time being this is same as peek. To do a batch peek we
-//        * need to remove the head key. We will destroy the key once the event is
-//        * delivered to the GatewayReceiver.
-//        */
-//       destroyKey(key);
-//     }
-//     return object;
+    // Object key = this.eventSeqNumQueue.remove();
+    // Object object = null;
+    // if (key != null) {
+    // object = PartitionRegionHelper
+    // .getLocalPrimaryData(getPartitionedRegion()).get(key);
+    // /**
+    // * TODO: For the time being this is same as peek. To do a batch peek we
+    // * need to remove the head key. We will destroy the key once the event is
+    // * delivered to the GatewayReceiver.
+    // */
+    // destroyKey(key);
+    // }
+    // return object;
-  
+
-   * Overriding this method from AbstractBucketRegionQueue in order to remove
-   * the event from eventSeqNumQueue if EntryNotFoundException is encountered 
-   * during basicDestroy. 
-   * This change is done during selective merge from r41425 from gemfire701X_maint.  
+   * Overriding this method from AbstractBucketRegionQueue in order to remove the event from
+   * eventSeqNumQueue if EntryNotFoundException is encountered during basicDestroy. This change is
+   * done during selective merge from r41425 from gemfire701X_maint.
-	@Released EntryEventImpl event = getPartitionedRegion().newDestroyEntryEvent(key,
-	  null);
-	try {
-	  event.setEventId(new EventID(cache.getSystem()));
-	  event.setRegion(this);
-	  basicDestroy(event, true, null);
-	  checkReadiness();
+    @Released
+    EntryEventImpl event = getPartitionedRegion().newDestroyEntryEvent(key, null);
+    try {
+      event.setEventId(new EventID(cache.getSystem()));
+      event.setRegion(this);
+      basicDestroy(event, true, null);
+      setLatestAcknowledgedKey((Long) key);
+      checkReadiness();
-          throw new ForceReattemptException(
-              "Bucket moved",
+          throw new ForceReattemptException("Bucket moved",
-                      .toLocalizedString(), getPartitionedRegion()
-                      .getFullPath()));
+                      .toLocalizedString(),
+                  getPartitionedRegion().getFullPath()));
-        throw new ForceReattemptException("Bucket moved while destroying key "
-            + key, rde);
+        throw new ForceReattemptException("Bucket moved while destroying key " + key, rde);
-    
+
-	return !this.getPartitionedRegion().isDestroyed() && !this.isEmpty() && !this.eventSeqNumQueue.isEmpty()
-        && getBucketAdvisor().isPrimary();
+    return !this.getPartitionedRegion().isDestroyed() && !this.isEmpty()
+        && !this.eventSeqNumQueue.isEmpty() && getBucketAdvisor().isPrimary();

INS26 INS26 INS40 INS40 INS23 INS23 INS31 INS31 INS31 INS83 INS43 INS59 INS83 INS43 INS59 INS83 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS43 INS8 INS42 INS42 INS14 INS42 INS42 INS14 INS54 INS54 INS43 INS42 INS21 INS43 INS42 INS21 INS39 INS42 INS43 INS42 INS42 INS25 INS60 INS25 INS25 INS41 UPD66 UPD66 UPD66 UPD66 UPD66 INS43 INS43 UPD66 UPD66 UPD66 UPD66 INS8 INS8 INS8 INS8 INS42 INS32 INS42 INS32 INS42 INS32 INS8 INS39 INS59 INS22 INS8 INS32 INS8 INS42 UPD66 UPD66 UPD66 INS42 INS42 MOV60 MOV25 MOV41 MOV21 MOV21 MOV21 INS42 INS42 INS22 INS42 INS22 INS42 INS42 INS42 INS42 INS21 INS42 INS9 INS52 INS42 INS60 INS60 INS60 INS61 INS42 INS42 INS21 INS21 INS8 INS52 INS42 INS52 INS42 INS32 INS39 INS59 INS39 INS59 INS39 INS59 INS27 INS8 INS32 INS32 INS21 INS21 INS42 INS42 INS27 INS42 INS32 INS42 INS32 INS42 INS27 INS42 INS34 INS25 INS21 INS21 INS42 INS42 INS27 INS42 INS11 INS32 INS32 INS45 INS32 INS45 INS32 INS45 INS42 INS45 INS42 INS22 INS42 INS42 INS42 INS42 INS32 INS42 INS27 INS8 INS32 INS7 INS45 INS32 INS45 INS32 INS45 INS42 INS43 INS42 INS42 INS42 INS32 INS42 INS11 INS42 INS42 INS42 INS52 INS42 INS42 INS42 INS27 INS32 INS21 INS10 INS42 INS42 INS32 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS32 INS42 INS42 INS7 INS42 INS42 INS27 INS34 INS42 INS32 INS42 INS42 INS42 INS42 INS9 INS32 INS34 INS42 INS42 INS40 INS42 INS42 DEL66 DEL66 DEL66