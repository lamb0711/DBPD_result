Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
-  
+
-  static final int OPLOG_FILE_ID_REC_SIZE = 1+8+1;
+  static final int OPLOG_FILE_ID_REC_SIZE = 1 + 8 + 1;
-   * Written to IF
-   * Byte Format:
-   *  8: leastSigBits of UUID
-   *  8: mostSigBits of UUID
-   *  1: EndOfRecordMarker
+   * Written to IF Byte Format: 8: leastSigBits of UUID 8: mostSigBits of UUID 1: EndOfRecordMarker
-  
+
-   * Written to IF
-   * Byte Format:
-   *  4: instantiatorID
-   *  4: classNameLength
-   *  classNameLength: className bytes
-   *  4: instClassNameLength
-   *  instClassNameLength: instClassName bytes
-   *  1: EndOfRecordMarker
+   * Written to IF Byte Format: 4: instantiatorID 4: classNameLength classNameLength: className
+   * bytes 4: instClassNameLength instClassNameLength: instClassName bytes 1: EndOfRecordMarker
-   * Written to IF
-   * Byte Format:
-   *  4: classNameLength
-   *  classNameLength: className bytes
-   *  1: EndOfRecordMarker
+   * Written to IF Byte Format: 4: classNameLength classNameLength: className bytes 1:
+   * EndOfRecordMarker
-   * Written to IF
-   * Used to say that persistent member id is online.
-   * Byte Format:
-   *   RegionId
-   *   4: blobLength
-   *   blobLength: member bytes
-   *   1: EndOfRecordMarker
+   * Written to IF Used to say that persistent member id is online. Byte Format: RegionId 4:
+   * blobLength blobLength: member bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF
-   * Used to say that persistent member id is offline.
-   * Byte Format:
-   *   RegionId
-   *   4: blobLength
-   *   blobLength: member bytes
-   *   1: EndOfRecordMarker
+   * Written to IF Used to say that persistent member id is offline. Byte Format: RegionId 4:
+   * blobLength blobLength: member bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF
-   * Used to say that persistent member id no longer exists.
-   * Byte Format:
-   *   RegionId
-   *   4: blobLength
-   *   blobLength: member bytes
-   *   1: EndOfRecordMarker
+   * Written to IF Used to say that persistent member id no longer exists. Byte Format: RegionId 4:
+   * blobLength blobLength: member bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record the persistent member id of this file.
-   * Byte Format:
-   *   RegionId
-   *   4: blobLength
-   *   blobLength: member bytes
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record the persistent member id of this file. Byte Format: RegionId 4:
+   * blobLength blobLength: member bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record the previous my member id completed initialization.
-   * Byte Format:
-   *   RegionId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record the previous my member id completed initialization. Byte Format:
+   * RegionId 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record create of region
-   * Byte Format:
-   *   RegionId
-   *   4: nameLength
-   *   nameLength: name bytes
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record create of region Byte Format: RegionId 4: nameLength nameLength:
+   * name bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record begin of destroy of region
-   * Byte Format:
-   *   RegionId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record begin of destroy of region Byte Format: RegionId 1:
+   * EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record clear of region
-   * Byte Format:
-   *   RegionId
-   *   8: oplogEntryId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record clear of region Byte Format: RegionId 8: oplogEntryId 1:
+   * EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record that the end of a destroy region.
-   * Byte Format:
-   *   RegionId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record that the end of a destroy region. Byte Format: RegionId 1:
+   * EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record that a region is about to be partially destroyed
-   * Byte Format:
-   *   RegionId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record that a region is about to be partially destroyed Byte Format:
+   * RegionId 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record that a region is partially destroyed
-   * Byte Format:
-   *   RegionId
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record that a region is partially destroyed Byte Format: RegionId 1:
+   * EndOfRecordMarker
+   * 
-   * Records the creation of an oplog crf file
-   * Byte Format:
-   * 8: oplogId
-   * 1: EndOfRecord
+   * Records the creation of an oplog crf file Byte Format: 8: oplogId 1: EndOfRecord
-   * Records the creation of an oplog drf file
-   * Byte Format:
-   * 8: oplogId
-   * 1: EndOfRecord
+   * Records the creation of an oplog drf file Byte Format: 8: oplogId 1: EndOfRecord
-   * Records the deletion of an oplog crf file
-   * Byte Format:
-   * 8: oplogId
-   * 1: EndOfRecord
+   * Records the deletion of an oplog crf file Byte Format: 8: oplogId 1: EndOfRecord
-   * Records the deletion of an oplog drf file
-   * Byte Format:
-   * 8: oplogId
-   * 1: EndOfRecord
+   * Records the deletion of an oplog drf file Byte Format: 8: oplogId 1: EndOfRecord
-   * Written to IF. Used to record regions config Byte Format: RegionId 1:
-   * lruAlgorithm 1: lruAction 4: lruLimit (int) // no need to ObjectSize during
-   * recovery since all data is in blob form 4: concurrencyLevel (int) 4:
-   * initialCapacity (int) 4: loadFactor (float) 1: statisticsEnabled (boolean)
-   * 1: isBucket (boolean) 1: EndOfRecordMarker
+   * Written to IF. Used to record regions config Byte Format: RegionId 1: lruAlgorithm 1: lruAction
+   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 4:
+   * concurrencyLevel (int) 4: initialCapacity (int) 4: loadFactor (float) 1: statisticsEnabled
+   * (boolean) 1: isBucket (boolean) 1: EndOfRecordMarker
-  public static final byte IFREC_REGION_CONFIG_ID = 74; 
-  
+  public static final byte IFREC_REGION_CONFIG_ID = 74;
+
-   * Written to IF
-   * Used to say that persistent member id is offline and has the same data on disk as this member
-   * Byte Format:
-   *   RegionId
-   *   4: blobLength
-   *   blobLength: member bytes
-   *   1: EndOfRecordMarker
+   * Written to IF Used to say that persistent member id is offline and has the same data on disk as
+   * this member Byte Format: RegionId 4: blobLength blobLength: member bytes 1: EndOfRecordMarker
+   * 
-   * Written to IF.
-   * Used to record regions config
-   * Byte Format:
-   *   RegionId
-   *   1: lruAlgorithm
-   *   1: lruAction
-   *   4: lruLimit (int)
-   *   // no need to ObjectSize during recovery since all data is in blob form
-   *   4: concurrencyLevel (int)
-   *   4: initialCapacity (int)
-   *   4: loadFactor (float)
-   *   1: statisticsEnabled (boolean)
-   *   1: isBucket (boolean)
-   *   4: length of partitionName String bytes (int)
-   *   length:actual bytes 
-   *   4: startingBucketId(int)
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record regions config Byte Format: RegionId 1: lruAlgorithm 1: lruAction
+   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 4:
+   * concurrencyLevel (int) 4: initialCapacity (int) 4: loadFactor (float) 1: statisticsEnabled
+   * (boolean) 1: isBucket (boolean) 4: length of partitionName String bytes (int) length:actual
+   * bytes 4: startingBucketId(int) 1: EndOfRecordMarker
-  
-  
+
+
-   * Records the creation of an oplog krf file
-   * The presence of this record indicates that the krf file
-   * is complete.
-   * Byte Format:
-   * 8: oplogId
-   * 1: EndOfRecord
+   * Records the creation of an oplog krf file The presence of this record indicates that the krf
+   * file is complete. Byte Format: 8: oplogId 1: EndOfRecord
-  
+
-   * Records the creation of a persistent partitioned
-   * region configuration.
-   * Byte Format:
-   * variable: pr name
-   * 4: total num buckets
-   * variable: colocated with
-   * 1: EndOfRecord
+   * Records the creation of a persistent partitioned region configuration. Byte Format: variable:
+   * pr name 4: total num buckets variable: colocated with 1: EndOfRecord
-  
+
-   * Records the deletion of persistent partitioned
-   * region.
-   * Byte Format:
-   * variable: pr name
-   * 1: EndOfRecord
+   * Records the deletion of persistent partitioned region. Byte Format: variable: pr name 1:
+   * EndOfRecord
-  
-  
+
+
-   * Maps a member id (either a disk store ID or a distributed system id
-   * plus a byte) to a single integer, which can be used in oplogs.
+   * Maps a member id (either a disk store ID or a distributed system id plus a byte) to a single
+   * integer, which can be used in oplogs.
-   * Byte Format:
-   * 4: the number assigned to this id.
-   * variable: serialized object representing the ID. 
-   * variable: pr name
-   * 1: EndOfRecord
+   * Byte Format: 4: the number assigned to this id. variable: serialized object representing the
+   * ID. variable: pr name 1: EndOfRecord
-   * Written to IF
-   * Used to say that a disk store has been revoked
-   * Byte Format:
-   *   variable: a PersistentMemberPattern
+   * Written to IF Used to say that a disk store has been revoked Byte Format: variable: a
+   * PersistentMemberPattern
+   * 
-  
+
-   * Written gemfire version to IF
-   * Byte Format:
-   * 1: version byte from Version.GFE_CURRENT.ordinal
-   * 1: EndOfRecord
+   * Written gemfire version to IF Byte Format: 1: version byte from Version.GFE_CURRENT.ordinal 1:
+   * EndOfRecord
+   * 
-   * Written to IF.
-   * Used to record clear of using an RVV
-   * Byte Format:
-   *   RegionId
-   *   variable: serialized RVV
-   *   1: EndOfRecordMarker
+   * Written to IF. Used to record clear of using an RVV Byte Format: RegionId variable: serialized
+   * RVV 1: EndOfRecordMarker
+   * 
-  
+
-   * Written to IF. Used to record regions config Byte Format: 
-   * RegionId 
-   * 1: lruAlgorithm 
-   * 1: lruAction 
-   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 
-   * 4: concurrencyLevel (int) 
-   * 4: initialCapacity (int) 
-   * 4: loadFactor (float)
-   * 1: statisticsEnabled (boolean)
-   * 1: isBucket (boolean) 
-   * variable: partitionName (utf)
-   * 4: startingBucketId (int)
-   * variable: compressorClassName (utf)
-   * 1: versioned (boolean)
-   * 1: EndOfRecordMarker
+   * Written to IF. Used to record regions config Byte Format: RegionId 1: lruAlgorithm 1: lruAction
+   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 4:
+   * concurrencyLevel (int) 4: initialCapacity (int) 4: loadFactor (float) 1: statisticsEnabled
+   * (boolean) 1: isBucket (boolean) variable: partitionName (utf) 4: startingBucketId (int)
+   * variable: compressorClassName (utf) 1: versioned (boolean) 1: EndOfRecordMarker
-  
+
-   * Persist oplog file magic number. Written once at the beginning of every
-   * oplog file; CRF, DRF, KRF, and IF. 
-   * Followed by 6 byte magic number. Each oplog type has a different magic
-   * number
-   * Followed by EndOfRecord
-   * Fix for bug 43824
+   * Persist oplog file magic number. Written once at the beginning of every oplog file; CRF, DRF,
+   * KRF, and IF. Followed by 6 byte magic number. Each oplog type has a different magic number
+   * Followed by EndOfRecord Fix for bug 43824
+   * 
-  
+
-   * Written to IF. Used to record regions config Byte Format: 
-   * RegionId 
-   * 1: lruAlgorithm 
-   * 1: lruAction 
-   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 
-   * 4: concurrencyLevel (int) 
-   * 4: initialCapacity (int) 
-   * 4: loadFactor (float)
-   * 1: statisticsEnabled (boolean)
-   * 1: isBucket (boolean) 
-   * variable: partitionName (utf)
-   * 4: startingBucketId (int)
-   * variable: compressorClassName (utf)
-   * 1: versioned (boolean)
-   * 1: offHeap (boolean) added in 9.0
-   * 1: EndOfRecordMarker
+   * Written to IF. Used to record regions config Byte Format: RegionId 1: lruAlgorithm 1: lruAction
+   * 4: lruLimit (int) // no need to ObjectSize during recovery since all data is in blob form 4:
+   * concurrencyLevel (int) 4: initialCapacity (int) 4: loadFactor (float) 1: statisticsEnabled
+   * (boolean) 1: isBucket (boolean) variable: partitionName (utf) 4: startingBucketId (int)
+   * variable: compressorClassName (utf) 1: versioned (boolean) 1: offHeap (boolean) added in 9.0 1:
+   * EndOfRecordMarker
+   * 
-  
+
-  
+
-   * Map used to keep track of regions we know of from the DiskInitFile
-   * but that do not yet exist (they have not yet been recovered or they have been closed).
+   * Map used to keep track of regions we know of from the DiskInitFile but that do not yet exist
+   * (they have not yet been recovered or they have been closed).
-  private final Map<String, PlaceHolderDiskRegion> drMapByName = new HashMap<String, PlaceHolderDiskRegion>();
-  
+  private final Map<String, PlaceHolderDiskRegion> drMapByName =
+      new HashMap<String, PlaceHolderDiskRegion>();
+
-   * Map of persistent partitioned regions configurations that are stored in this
-   * init file.
+   * Map of persistent partitioned regions configurations that are stored in this init file.
-  
+
-  
-  
+
+
-   * Used to calculate the highest oplog entry id we have seen
-   * in a clear entry.
+   * Used to calculate the highest oplog entry id we have seen in a clear entry.
-  
+
-   * Container for canonical ids held in the disk store. Member ids
-   * are canonicalized so they can be written as an integer in the 
-   * oplogs.
+   * Container for canonical ids held in the disk store. Member ids are canonicalized so they can be
+   * written as an integer in the oplogs.
-  
+
-   * Set of members that have been revoked. We keep track of the revoked
-   * members so that we can indicate to the user a member has been revoked,
-   * rather is simply conflicting
+   * Set of members that have been revoked. We keep track of the revoked members so that we can
+   * indicate to the user a member has been revoked, rather is simply conflicting
-  private final Set<PersistentMemberPattern> revokedMembers = new HashSet<PersistentMemberPattern>();
-  
+  private final Set<PersistentMemberPattern> revokedMembers =
+      new HashSet<PersistentMemberPattern>();
+
-  
+
-  
+
-   * Lock used to synchronize access to the init file.
-   * This is a lock rather than a synchronized block
-   * because the backup tool needs to acquire this lock.
+   * Lock used to synchronize access to the init file. This is a lock rather than a synchronized
+   * block because the backup tool needs to acquire this lock.
-          throw new IllegalStateException("Could not rename " + tmpFile
-                                          + " to " + this.ifFile);
+          throw new IllegalStateException("Could not rename " + tmpFile + " to " + this.ifFile);
-  
+
-        dis = new CountingDataInputStream(new BufferedInputStream(fis, 8 * 1024), this.ifFile.length());
+        dis = new CountingDataInputStream(new BufferedInputStream(fis, 8 * 1024),
+            this.ifFile.length());
-        
+
-          logger.trace(LogMarker.PERSIST_RECOVERY, "liveRecordCount={} totalRecordCount={}", this.ifLiveRecordCount, this.ifTotalRecordCount);
+          logger.trace(LogMarker.PERSIST_RECOVERY, "liveRecordCount={} totalRecordCount={}",
+              this.ifLiveRecordCount, this.ifTotalRecordCount);
-      }
-      finally {
+      } finally {
-      for (PlaceHolderDiskRegion drv: this.drMap.values()) {
-        if (drv.getMyPersistentID() != null
-              || drv.getMyInitializingID() != null) {
+      for (PlaceHolderDiskRegion drv : this.drMap.values()) {
+        if (drv.getMyPersistentID() != null || drv.getMyInitializingID() != null) {
-            drv.setRecoveredEntryMap(RegionMapFactory.createVM(drv,
-                getDiskStore(), getDiskStore().getInternalRegionArguments()));
+            drv.setRecoveredEntryMap(RegionMapFactory.createVM(drv, getDiskStore(),
+                getDiskStore().getInternalRegionArguments()));
-    }
-    catch (EOFException ex) {
+    } catch (EOFException ex) {
-//       throw new DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-//                                     .toLocalizedString(this.ifFile.getPath()), ex, this.parent);
-    }
-    catch (ClassNotFoundException ex) {
-      throw new DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-          .toLocalizedString(this.ifFile.getPath()), ex, this.parent);
-    }
-    catch (IOException ex) {
-      throw new DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-          .toLocalizedString(this.ifFile.getPath()), ex, this.parent);
-    }
-    catch (CancelException ignore) {
+      // throw new
+      // DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
+      // .toLocalizedString(this.ifFile.getPath()), ex, this.parent);
+    } catch (ClassNotFoundException ex) {
+      throw new DiskAccessException(
+          LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
+              .toLocalizedString(this.ifFile.getPath()),
+          ex, this.parent);
+    } catch (IOException ex) {
+      throw new DiskAccessException(
+          LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
+              .toLocalizedString(this.ifFile.getPath()),
+          ex, this.parent);
+    } catch (CancelException ignore) {
-    }
-    catch (RegionDestroyedException ignore) {
+    } catch (RegionDestroyedException ignore) {
-    }
-    catch (IllegalStateException ex) {
+    } catch (IllegalStateException ex) {
-  
+
-    if(clearOplogEntryId > clearOplogEntryIdHWM) {
+    if (clearOplogEntryId > clearOplogEntryIdHWM) {
-  
-  public void cmnClearRegion(long drId, ConcurrentHashMap<DiskStoreID, RegionVersionHolder<DiskStoreID>> memberToVersion) {
+
+  public void cmnClearRegion(long drId,
+      ConcurrentHashMap<DiskStoreID, RegionVersionHolder<DiskStoreID>> memberToVersion) {
-    
+
-    //Create a fake RVV for clear purposes. We only need to memberToVersion information
+    // Create a fake RVV for clear purposes. We only need to memberToVersion information
-    long  ownerVersion = ownerExceptions == null ? 0 : ownerExceptions.getVersion();
-    RegionVersionVector rvv = new DiskRegionVersionVector(ownerId,
-        memberToVersion, ownerVersion, new ConcurrentHashMap(), 0L, false,
-        ownerExceptions);
+    long ownerVersion = ownerExceptions == null ? 0 : ownerExceptions.getVersion();
+    RegionVersionVector rvv = new DiskRegionVersionVector(ownerId, memberToVersion, ownerVersion,
+        new ConcurrentHashMap(), 0L, false, ownerExceptions);
-      
+
-                              int concurrencyLevel, int initialCapacity,
-                              float loadFactor, boolean statisticsEnabled,
-                              boolean isBucket, EnumSet<DiskRegionFlag> flags,
-                              String partitionName, int startingBucketId,
-                              String compressorClassName, boolean offHeap) {
+      int concurrencyLevel, int initialCapacity, float loadFactor, boolean statisticsEnabled,
+      boolean isBucket, EnumSet<DiskRegionFlag> flags, String partitionName, int startingBucketId,
+      String compressorClassName, boolean offHeap) {
-      //We need to add the IS_WITH_VERSIONING to persistent regions
-      //during the upgrade. Previously, all regions had versioning enabled
-      //but now only regions that have this flag will have versioning enabled.
+      // We need to add the IS_WITH_VERSIONING to persistent regions
+      // during the upgrade. Previously, all regions had versioning enabled
+      // but now only regions that have this flag will have versioning enabled.
-      if(Version.GFE_80.compareTo(currentRecoveredGFVersion()) > 0
+      if (Version.GFE_80.compareTo(currentRecoveredGFVersion()) > 0
-    dr.setConfig(lruAlgorithm, lruAction, lruLimit,
-                 concurrencyLevel, initialCapacity, loadFactor,
-                 statisticsEnabled, isBucket, flags, 
-                 partitionName, startingBucketId, compressorClassName, offHeap);
+      dr.setConfig(lruAlgorithm, lruAction, lruLimit, concurrencyLevel, initialCapacity, loadFactor,
+          statisticsEnabled, isBucket, flags, partitionName, startingBucketId, compressorClassName,
+          offHeap);
-    // Just count this as a live record even though it is possible
-    // that we have an extra one due to the config changing while
-    // we were offline.
-    this.ifLiveRecordCount++;
-    this.ifTotalRecordCount++;
+      // Just count this as a live record even though it is possible
+      // that we have an extra one due to the config changing while
+      // we were offline.
+      this.ifLiveRecordCount++;
+      this.ifTotalRecordCount++;
-  
+
-    if(this.prMap.put(name, config) == null) {
+    if (this.prMap.put(name, config) == null) {
-    
+
-    if(this.prMap.remove(name) != null) {
+    if (this.prMap.remove(name) != null) {
-  
+
-    if (!dr.rmOnlineMember(pmid)) {
-      if(!dr.rmOfflineMember(pmid)) {
-        dr.rmEqualMember(pmid);
+      if (!dr.rmOnlineMember(pmid)) {
+        if (!dr.rmOfflineMember(pmid)) {
+          dr.rmEqualMember(pmid);
+        }
-    }
-    // since we removed a member don't inc the live count
-    // In fact decrement it by one since both this record
-    // and the previous one are both garbage.
-    this.ifLiveRecordCount--;
-    this.ifTotalRecordCount++;
+      // since we removed a member don't inc the live count
+      // In fact decrement it by one since both this record
+      // and the previous one are both garbage.
+      this.ifLiveRecordCount--;
+      this.ifTotalRecordCount++;
-  
+
-      if (this.parent.upgradeVersionOnly && Version.GFE_70.compareTo(currentRecoveredGFVersion()) > 0) {
+      if (this.parent.upgradeVersionOnly
+          && Version.GFE_70.compareTo(currentRecoveredGFVersion()) > 0) {
-    dr.addOnlineMember(pmid);
-    if (dr.rmOfflineMember(pmid) || dr.rmEqualMember(pmid)) {
-      this.ifLiveRecordCount--;
-    }
-    this.ifLiveRecordCount++;
-    this.ifTotalRecordCount++;
+      dr.addOnlineMember(pmid);
+      if (dr.rmOfflineMember(pmid) || dr.rmEqualMember(pmid)) {
+        this.ifLiveRecordCount--;
+      }
+      this.ifLiveRecordCount++;
+      this.ifTotalRecordCount++;
-      DataSerializer ds = InternalDataSerializer.register(dsc, /*dsId,*/ true);
+      DataSerializer ds = InternalDataSerializer.register(dsc, /* dsId, */ true);
+
+
+
+
+
-    if(this.krfIds.remove(oplogId)) {
+    if (this.krfIds.remove(oplogId)) {
+
-  
+
-  
+
-  
-  public void verifyOplogs(LongOpenHashSet foundCrfs, LongOpenHashSet foundDrfs, LongOpenHashSet expectedCrfIds, LongOpenHashSet expectedDrfIds) {
+
+  public void verifyOplogs(LongOpenHashSet foundCrfs, LongOpenHashSet foundDrfs,
+      LongOpenHashSet expectedCrfIds, LongOpenHashSet expectedDrfIds) {
-      msg = "*.crf files with these ids: "
-        + Arrays.toString(missingCrfs.toArray());
+      msg = "*.crf files with these ids: " + Arrays.toString(missingCrfs.toArray());
-      msg += "*.drf files with these ids: "
-        + Arrays.toString(missingDrfs.toArray());
+      msg += "*.drf files with these ids: " + Arrays.toString(missingDrfs.toArray());
-  
+
-  
+
+
-  DiskRegion createDiskRegion(DiskStoreImpl dsi, String name,
-                                     boolean isBucket, boolean isPersistBackup,
-                                     boolean overflowEnabled, boolean isSynchronous,
-                                     DiskRegionStats stats, CancelCriterion cancel,
-                                     DiskExceptionHandler exceptionHandler,
-                                     RegionAttributes ra, EnumSet<DiskRegionFlag> flags,
-                                     String partitionName, int startingBucketId, 
-                                     Compressor compressor, boolean offHeap) {
+
+  DiskRegion createDiskRegion(DiskStoreImpl dsi, String name, boolean isBucket,
+      boolean isPersistBackup, boolean overflowEnabled, boolean isSynchronous,
+      DiskRegionStats stats, CancelCriterion cancel, DiskExceptionHandler exceptionHandler,
+      RegionAttributes ra, EnumSet<DiskRegionFlag> flags, String partitionName,
+      int startingBucketId, Compressor compressor, boolean offHeap) {
-      DiskRegion result = new DiskRegion(dsi, name, isBucket, isPersistBackup,
-          overflowEnabled, isSynchronous,
-          stats, cancel, exceptionHandler, ra, flags, partitionName, startingBucketId,
-          compressor == null ? null : compressor.getClass().getName(), offHeap);
+      DiskRegion result = new DiskRegion(dsi, name, isBucket, isPersistBackup, overflowEnabled,
+          isSynchronous, stats, cancel, exceptionHandler, ra, flags, partitionName,
+          startingBucketId, compressor == null ? null : compressor.getClass().getName(), offHeap);
-  
+
-      for (PlaceHolderDiskRegion dr: this.drMapByName.values()) {
+      for (PlaceHolderDiskRegion dr : this.drMapByName.values()) {
-  
+
-  
+
-      ByteBuffer bb = getIFWriteBuffer(1+DR_ID_MAX_BYTES+1);
+      ByteBuffer bb = getIFWriteBuffer(1 + DR_ID_MAX_BYTES + 1);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
+
-      ByteBuffer bb = getIFWriteBuffer(1+DR_ID_MAX_BYTES+8+1);
+      ByteBuffer bb = getIFWriteBuffer(1 + DR_ID_MAX_BYTES + 8 + 1);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
+
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-      int hdosSize = 1+DR_ID_MAX_BYTES+estimateByteSize(s)+1;
+      int hdosSize = 1 + DR_ID_MAX_BYTES + estimateByteSize(s) + 1;
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      int hdosSize = 1+DR_ID_MAX_BYTES+estimateByteSize(fileName)+1;
+      int hdosSize = 1 + DR_ID_MAX_BYTES + estimateByteSize(fileName) + 1;
-      //TODO - plum the correct compactor info to this point, to optimize
-      //serialization
+      // TODO - plum the correct compactor info to this point, to optimize
+      // serialization
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      int hdosSize = 1+DR_ID_MAX_BYTES+estimateByteSize(fileName)+1;
+      int hdosSize = 1 + DR_ID_MAX_BYTES + estimateByteSize(fileName) + 1;
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-    return s == null ? 0 : ((s.length()+1)*3);
+    return s == null ? 0 : ((s.length() + 1) * 3);
-  
-  private void writePMIDRecord(byte opcode, DiskRegionView dr, PersistentMemberID pmid, boolean doStats) {
+
+  private void writePMIDRecord(byte opcode, DiskRegionView dr, PersistentMemberID pmid,
+      boolean doStats) {
-      ByteBuffer bb = getIFWriteBuffer(1+DR_ID_MAX_BYTES+4+pmidBytes.length+1);
+      ByteBuffer bb = getIFWriteBuffer(1 + DR_ID_MAX_BYTES + 4 + pmidBytes.length + 1);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-      bb.put((byte)drId);
+      bb.put((byte) drId);
-      byte bytesNeeded = (byte)Oplog.bytesNeeded(drId);
+      byte bytesNeeded = (byte) Oplog.bytesNeeded(drId);
-      for (int i=bytesNeeded-1; i >=0; i--) {
-        bytes[i] = (byte)(drId & 0xFF);
-        drId >>=8;
+      for (int i = bytesNeeded - 1; i >= 0; i--) {
+        bytes[i] = (byte) (drId & 0xFF);
+        drId >>= 8;
-      byte bytesNeeded = (byte)Oplog.bytesNeeded(drId);
+      byte bytesNeeded = (byte) Oplog.bytesNeeded(drId);
-      for (int i=bytesNeeded-1; i >=0; i--) {
-        bytes[i] = (byte)(drId & 0xFF);
-        drId >>=8;
+      for (int i = bytesNeeded - 1; i >= 0; i--) {
+        bytes[i] = (byte) (drId & 0xFF);
+        drId >>= 8;
-  
+
-    if (dr.addMyInitializingPMID(pmid) == null) {
-      this.ifLiveRecordCount++;
-    }
-    this.ifTotalRecordCount++;
+      if (dr.addMyInitializingPMID(pmid) == null) {
+        this.ifLiveRecordCount++;
+      }
+      this.ifTotalRecordCount++;
-    //this.ifLiveRecordCount--;
+    // this.ifLiveRecordCount--;
-    dr.markInitialized();
+      dr.markInitialized();
+
-    dr.markBeginDestroyRegion();
+      dr.markBeginDestroyRegion();
+
-    if (dr.getClearOplogEntryId() != DiskStoreImpl.INVALID_ID) {
-      // one for the clear record
+      if (dr.getClearOplogEntryId() != DiskStoreImpl.INVALID_ID) {
+        // one for the clear record
+        this.ifLiveRecordCount--;
+      }
+      // one for each online member
+      this.ifLiveRecordCount -= dr.getOnlineMembers().size();
+      // one for each offline member
+      this.ifLiveRecordCount -= dr.getOfflineMembers().size();
+      // one for each equal member
+      this.ifLiveRecordCount -= dr.getOfflineAndEqualMembers().size();
+
+
+
+      // one for the CREATE_REGION
-    }
-    // one for each online member
-    this.ifLiveRecordCount -= dr.getOnlineMembers().size();
-    // one for each offline member
-    this.ifLiveRecordCount -= dr.getOfflineMembers().size();
-    // one for each equal member
-    this.ifLiveRecordCount -= dr.getOfflineAndEqualMembers().size();
-    
-    
-    
-    // one for the CREATE_REGION
-    this.ifLiveRecordCount--;
-    
-    // one for the regions memberId
-    if (dr.getMyPersistentID() != null) {
-      this.ifLiveRecordCount--;
-    }
-    
-    this.liveRegions--;
-    this.drMap.remove(dr.getId());
-    this.drMapByName.remove(dr.getName());
-    this.parent.rmById(dr.getId());
-    
-    dr.markEndDestroyRegion();
+
+      // one for the regions memberId
+      if (dr.getMyPersistentID() != null) {
+        this.ifLiveRecordCount--;
+      }
+
+      this.liveRegions--;
+      this.drMap.remove(dr.getId());
+      this.drMapByName.remove(dr.getName());
+      this.parent.rmById(dr.getId());
+
+      dr.markEndDestroyRegion();
+
-  
+
+
-    
+
-    
+
-  
+
-    saveInstantiator(inst.getId(), inst.getClass().getName(), inst
-        .getInstantiatedClass().getName());
+    saveInstantiator(inst.getId(), inst.getClass().getName(),
+        inst.getInstantiatedClass().getName());
-      ByteBuffer bb = getIFWriteBuffer(1 + 4
-                                       + 4 + classNameBytes.length
-                                       + 4 + instClassNameBytes.length
-                                       + 1);
+      ByteBuffer bb =
+          getIFWriteBuffer(1 + 4 + 4 + classNameBytes.length + 4 + instClassNameBytes.length + 1);
-    }
-    catch (IOException ex) {
-      throw new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_SAVING_INSTANTIATOR_TO_DISK_BECAUSE_0.toLocalizedString(ex), this.parent);
+    } catch (IOException ex) {
+      throw new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_SAVING_INSTANTIATOR_TO_DISK_BECAUSE_0
+              .toLocalizedString(ex),
+          this.parent);
-      Object[] objects = InternalInstantiator
-          .getInstantiatorsForSerialization();
-      for (Object obj : objects) {
-        if (obj instanceof Instantiator) {
-          saveInstantiator((Instantiator)obj);
-        } else {
-          InstantiatorAttributesHolder iah = (InstantiatorAttributesHolder)obj;
-          saveInstantiator(iah.getId(), iah.getInstantiatorClassName(),
-              iah.getInstantiatedClassName());
-        }
+    Object[] objects = InternalInstantiator.getInstantiatorsForSerialization();
+    for (Object obj : objects) {
+      if (obj instanceof Instantiator) {
+        saveInstantiator((Instantiator) obj);
+      } else {
+        InstantiatorAttributesHolder iah = (InstantiatorAttributesHolder) obj;
+        saveInstantiator(iah.getId(), iah.getInstantiatorClassName(),
+            iah.getInstantiatedClassName());
+    }
-    }
-    catch (IOException ex) {
-      throw new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_SAVING_DATA_SERIALIZER_TO_DISK_BECAUSE_0.toLocalizedString(ex), this.parent);
+    } catch (IOException ex) {
+      throw new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_SAVING_DATA_SERIALIZER_TO_DISK_BECAUSE_0
+              .toLocalizedString(ex),
+          this.parent);
-  
+
+
-  private void writeIFRecord(ByteBuffer bb, boolean doStats)
-    throws IOException
-  {
+
+  private void writeIFRecord(ByteBuffer bb, boolean doStats) throws IOException {
-    //TODO soplog - this behavior isn't right.
-    //it should throw an exception or something.
+    // TODO soplog - this behavior isn't right.
+    // it should throw an exception or something.
-//    if (this.closed) {
-//      throw new DiskAccessException("Init file is closed!", parent);
-//    }
+    // if (this.closed) {
+    // throw new DiskAccessException("Init file is closed!", parent);
+    // }
-      logger.trace(LogMarker.PERSIST_WRITES, "DiskInitFile writeIFRecord bb[0] = {}", bb.array()[0]);
+      logger.trace(LogMarker.PERSIST_WRITES, "DiskInitFile writeIFRecord bb[0] = {}",
+          bb.array()[0]);
-  private void writeIFRecord(HeapDataOutputStream hdos, boolean doStats) throws IOException
-  {
+
+  private void writeIFRecord(HeapDataOutputStream hdos, boolean doStats) throws IOException {
-   * If the file is smaller than this constant then it
-   * does not need to be compacted.
+   * If the file is smaller than this constant then it does not need to be compacted.
-   * If the ratio of live vs. dead is not less than this constant
-   * then no need to compact.
+   * If the ratio of live vs. dead is not less than this constant then no need to compact.
-      if (this.compactInProgress) return;
-      if (this.ifTotalRecordCount == 0) return;
-      if (this.ifTotalRecordCount == this.ifLiveRecordCount) return;
-      if (this.ifRAF.length() <= MIN_SIZE_BEFORE_COMPACT) return;
-      if ((double)this.ifLiveRecordCount / (double)this.ifTotalRecordCount > COMPACT_RATIO) return;
+      if (this.compactInProgress)
+        return;
+      if (this.ifTotalRecordCount == 0)
+        return;
+      if (this.ifTotalRecordCount == this.ifLiveRecordCount)
+        return;
+      if (this.ifRAF.length() <= MIN_SIZE_BEFORE_COMPACT)
+        return;
+      if ((double) this.ifLiveRecordCount / (double) this.ifTotalRecordCount > COMPACT_RATIO)
+        return;
-    }  finally {
+    } finally {
-    return new File(this.ifFile.getAbsolutePath()+"tmp");
+    return new File(this.ifFile.getAbsolutePath() + "tmp");
-  
+
-      
+
-            throw new DiskAccessException("could not delete temporary file " + tmpFile, this.parent);
+            throw new DiskAccessException("could not delete temporary file " + tmpFile,
+                this.parent);
-          if(!success) {
-            //if we failed
+          if (!success) {
+            // if we failed
-            if(!tmpFile.renameTo(this.ifFile)) {
-              throw new DiskAccessException("could not rename file " + tmpFile + " to " + this.ifFile, this.parent);
+            if (!tmpFile.renameTo(this.ifFile)) {
+              throw new DiskAccessException(
+                  "could not rename file " + tmpFile + " to " + this.ifFile, this.parent);
-  
+
-    
+
-          LocalizedStrings.DiskRegion_COULD_NOT_OPEN_0.toLocalizedString(this.ifFile
-              .getPath()), ex, this.parent);
+          LocalizedStrings.DiskRegion_COULD_NOT_OPEN_0.toLocalizedString(this.ifFile.getPath()), ex,
+          this.parent);
-  
+
-        long maxSizeInMB = Math.min(
-            Math.max(this.parent.getMaxOplogSize() / 200L, 1L), 10L);
+        long maxSizeInMB = Math.min(Math.max(this.parent.getMaxOplogSize() / 200L, 1L), 10L);
-          LocalizedStrings.DiskRegion_COULD_NOT_OPEN_0.toLocalizedString(this.ifFile
-              .getPath()), ex, this.parent);
+          LocalizedStrings.DiskRegion_COULD_NOT_OPEN_0.toLocalizedString(this.ifFile.getPath()), ex,
+          this.parent);
-        
+
-      for (DiskRegionView drv: this.drMap.values()) {
+      for (DiskRegionView drv : this.drMap.values()) {
-      for (DiskRegionView drv: this.parent.getDiskRegions()) {
+      for (DiskRegionView drv : this.parent.getDiskRegions()) {
-        logger.debug("After compacting init file lrc={} trc={}", this.ifLiveRecordCount, this.ifTotalRecordCount);
+        logger.debug("After compacting init file lrc={} trc={}", this.ifLiveRecordCount,
+            this.ifTotalRecordCount);
-    for (LongIterator i = this.crfIds.iterator(); i.hasNext(); ) {
+    for (LongIterator i = this.crfIds.iterator(); i.hasNext();) {
-    for (LongIterator i = this.drfIds.iterator(); i.hasNext(); ) {
+    for (LongIterator i = this.drfIds.iterator(); i.hasNext();) {
-  
+
-    for (LongIterator i = this.krfIds.iterator(); i.hasNext(); ) {
+    for (LongIterator i = this.krfIds.iterator(); i.hasNext();) {
-  
+
-    for(Map.Entry<String, PRPersistentConfig> entry : prMap.entrySet()) {
+    for (Map.Entry<String, PRPersistentConfig> entry : prMap.entrySet()) {
-  
+
-    for(ObjectIterator<Int2ObjectMap.Entry<?> > i = mappings.int2ObjectEntrySet().fastIterator(); i.hasNext();) {
+    for (ObjectIterator<Int2ObjectMap.Entry<?>> i = mappings.int2ObjectEntrySet().fastIterator(); i
+        .hasNext();) {
-  
+
-    for(PersistentMemberPattern revoked : revokedMembers) {
+    for (PersistentMemberPattern revoked : revokedMembers) {
-      ByteBuffer bb = getIFWriteBuffer(1+6+1);
+      ByteBuffer bb = getIFWriteBuffer(1 + 6 + 1);
-      bb = getIFWriteBuffer(1+8+8+1);
+      bb = getIFWriteBuffer(1 + 8 + 8 + 1);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
+
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      HeapDataOutputStream bb = new HeapDataOutputStream(1+DR_ID_MAX_BYTES+1+1+4+4+4+1+1+4+len+4+1+1+1, Version.CURRENT);
+      HeapDataOutputStream bb = new HeapDataOutputStream(
+          1 + DR_ID_MAX_BYTES + 1 + 1 + 4 + 4 + 4 + 1 + 1 + 4 + len + 4 + 1 + 1 + 1,
+          Version.CURRENT);
-      bb.write((byte)(drv.getStatisticsEnabled()?1:0));
-      bb.write((byte)(drv.isBucket()?1:0));
+      bb.write((byte) (drv.getStatisticsEnabled() ? 1 : 0));
+      bb.write((byte) (drv.isBucket() ? 1 : 0));
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      HeapDataOutputStream hdos = new HeapDataOutputStream(1+nameLength+4+colocatedLength+1, Version.CURRENT);
+      HeapDataOutputStream hdos =
+          new HeapDataOutputStream(1 + nameLength + 4 + colocatedLength + 1, Version.CURRENT);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-    if(drv.getClearRVV() != null) {
+    if (drv.getClearRVV() != null) {
-    for (PersistentMemberID pmid: drv.getOnlineMembers()) {
+    for (PersistentMemberID pmid : drv.getOnlineMembers()) {
-    for (PersistentMemberID pmid: drv.getOfflineMembers()) {
+    for (PersistentMemberID pmid : drv.getOfflineMembers()) {
-    for (PersistentMemberID pmid: drv.getOfflineAndEqualMembers()) {
+    for (PersistentMemberID pmid : drv.getOfflineAndEqualMembers()) {
-      throw new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      throw new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-  
+
-      throw new DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-                                    .toLocalizedString(this.ifFile.getPath()),
-                                    io, this.parent);
+      throw new DiskAccessException(
+          LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
+              .toLocalizedString(this.ifFile.getPath()),
+          io, this.parent);
-      throw new DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-                                    .toLocalizedString(this.ifFile.getPath()),
-                                    cnf, this.parent);
+      throw new DiskAccessException(
+          LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
+              .toLocalizedString(this.ifFile.getPath()),
+          cnf, this.parent);
-  // non-private methods 
+  // non-private methods
-    File f = new File(this.parent.getInfoFileDir().getDir(),
-                      "BACKUP" + name + IF_FILE_EXT);
+    File f = new File(this.parent.getInfoFileDir().getDir(), "BACKUP" + name + IF_FILE_EXT);
-      String msg = LocalizedStrings.DiskInitFile_THE_INIT_FILE_0_DOES_NOT_EXIST.toLocalizedString(new Object[] {f});
+      String msg = LocalizedStrings.DiskInitFile_THE_INIT_FILE_0_DOES_NOT_EXIST
+          .toLocalizedString(new Object[] {f});
-        msg += LocalizedStrings.DiskInitFile_IF_IT_NO_LONGER_EXISTS_DELETE_FOLLOWING_FILES_TO_CREATE_THIS_DISK_STORE_EXISTING_OPLOGS_0.toLocalizedString(new Object[] {allOplogs});
+        msg +=
+            LocalizedStrings.DiskInitFile_IF_IT_NO_LONGER_EXISTS_DELETE_FOLLOWING_FILES_TO_CREATE_THIS_DISK_STORE_EXISTING_OPLOGS_0
+                .toLocalizedString(new Object[] {allOplogs});
-    if (this.parent.isOffline() && !this.parent.isOfflineCompacting() && !this.parent.isOfflineModify()) {
+    if (this.parent.isOffline() && !this.parent.isOfflineCompacting()
+        && !this.parent.isOfflineModify()) {
-          public void newInstantiator(Instantiator i) {
-            saveInstantiator(i);
-          }
-          public void newDataSerializer(DataSerializer ds) {
-            saveDataSerializer(ds);
-          }
-        };
+        public void newInstantiator(Instantiator i) {
+          saveInstantiator(i);
+        }
+
+        public void newDataSerializer(DataSerializer ds) {
+          saveDataSerializer(ds);
+        }
+      };
-        if(clearOplogEntryId > clearOplogEntryIdHWM) {
+        if (clearOplogEntryId > clearOplogEntryIdHWM) {
-    } 
+    }
-  
+
-    } 
-    
+    }
+
-  private void writeClearRecord(DiskRegionView dr,
-      RegionVersionVector rvv) {
+  private void writeClearRecord(DiskRegionView dr, RegionVersionVector rvv) {
-      //We only need the memberToVersionMap for clear purposes
+      // We only need the memberToVersionMap for clear purposes
-      for(Map.Entry<DiskStoreID, RegionVersionHolder> entry : memberToVersion.entrySet()) {
+      for (Map.Entry<DiskStoreID, RegionVersionHolder> entry : memberToVersion.entrySet()) {
-        synchronized(entry.getValue()) {
+        synchronized (entry.getValue()) {
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);
-    
+
-      } 
+      }
+
-          logger.trace(LogMarker.PERSIST_WRITES, "DiskInitFile IFREC_END_DESTROY_REGION_ID drId={}", dr.getId());
+          logger.trace(LogMarker.PERSIST_WRITES, "DiskInitFile IFREC_END_DESTROY_REGION_ID drId={}",
+              dr.getId());
+
+
+
-      if(cmnPRCreate(name, config)) {
+      if (cmnPRCreate(name, config)) {
+
-      if(cmnPRDestroy(name)) {
+      if (cmnPRDestroy(name)) {
+
+
+
+
+
+
+
+
-      if(id <=0) {
+      if (id <= 0) {
+
+
-      if (this.closed) return;
+      if (this.closed)
+        return;
-      for (DiskRegionView k: this.getKnown()) {
+      for (DiskRegionView k : this.getKnown()) {
-  
+
+
+
+
-          if (dr.rmOnlineMember(pmid) || dr.rmEqualMember(pmid)) { 
+          if (dr.rmOnlineMember(pmid) || dr.rmEqualMember(pmid)) {
-  void addOfflineAndEqualPMID(DiskRegionView dr,
-        PersistentMemberID pmid) {
+
+  void addOfflineAndEqualPMID(DiskRegionView dr, PersistentMemberID pmid) {
-          if (dr.rmOnlineMember(pmid) || dr.rmOfflineMember(pmid)) { 
+          if (dr.rmOnlineMember(pmid) || dr.rmOfflineMember(pmid)) {
+
-        if (dr.rmOnlineMember(pmid)
-            || dr.rmOfflineMember(pmid)
-            || dr.rmEqualMember(pmid)) {
+        if (dr.rmOnlineMember(pmid) || dr.rmOfflineMember(pmid) || dr.rmEqualMember(pmid)) {
-  
+
-    //We're only going to record members revoked with the new API - 
-    //using the UUID
-    if(revokedPattern.getUUID() == null) {
+    // We're only going to record members revoked with the new API -
+    // using the UUID
+    if (revokedPattern.getUUID() == null) {
-    
+
-      if(cmnRevokeDiskStoreId(revokedPattern)) {
+      if (cmnRevokeDiskStoreId(revokedPattern)) {
-  
+
-      //Return a copy of the set, because we modify it in place.
+      // Return a copy of the set, because we modify it in place.
-    
+
-     * True if this disk region has entries with versioning enabled. Depending
-     * on this flag, the appropriate RegionEntryFactory gets instantiated.
+     * True if this disk region has entries with versioning enabled. Depending on this flag, the
+     * appropriate RegionEntryFactory gets instantiated.
-    
+
-  
+
-  
+
-  
+
-  
+
+   * 
-      Map<String, List<PlaceHolderDiskRegion>> regions = new HashMap<String, List<PlaceHolderDiskRegion>>();
-      for (DiskRegionView drv: this.drMap.values()) {
+      Map<String, List<PlaceHolderDiskRegion>> regions =
+          new HashMap<String, List<PlaceHolderDiskRegion>>();
+      for (DiskRegionView drv : this.drMap.values()) {
-          PlaceHolderDiskRegion dr = (PlaceHolderDiskRegion)drv;
+          PlaceHolderDiskRegion dr = (PlaceHolderDiskRegion) drv;
-            if(buckets == null) {
+            if (buckets == null) {
-        for (PlaceHolderDiskRegion dr: this.drMapByName.values()) {
+        for (PlaceHolderDiskRegion dr : this.drMapByName.values()) {
-        if(buckets.isEmpty()) {
-          throw new IllegalArgumentException("The disk store does not contain a region named " + regName);  
+        if (buckets.isEmpty()) {
+          throw new IllegalArgumentException(
+              "The disk store does not contain a region named " + regName);
-        return Collections.singletonMap(regName, Collections.singletonList((PlaceHolderDiskRegion) drv));
+        return Collections.singletonMap(regName,
+            Collections.singletonList((PlaceHolderDiskRegion) drv));
-  
+
-    for (Map.Entry<String, List<PlaceHolderDiskRegion>> regionEntry : getRegionsToDump(regName).entrySet()) {
+    for (Map.Entry<String, List<PlaceHolderDiskRegion>> regionEntry : getRegionsToDump(regName)
+        .entrySet()) {
-      if(logger.isTraceEnabled(LogMarker.PERSIST_RECOVERY)) { 
-        for(PlaceHolderDiskRegion region : regions) {
+      if (logger.isTraceEnabled(LogMarker.PERSIST_RECOVERY)) {
+        for (PlaceHolderDiskRegion region : regions) {
-        //NOTE, regions  will always have at least 1 item.
+        // NOTE, regions will always have at least 1 item.
-  
+
-    for (Map.Entry<String, List<PlaceHolderDiskRegion>> regionEntry : getRegionsToDump(null).entrySet()) {
+    for (Map.Entry<String, List<PlaceHolderDiskRegion>> regionEntry : getRegionsToDump(null)
+        .entrySet()) {
-      if(region0.isBucket()) {
+      if (region0.isBucket()) {
-        
+
-   * Dump the metadata for a partitioned region, optionally dumping the meta
-   * data for individual buckets. 
+   * Dump the metadata for a partitioned region, optionally dumping the meta data for individual
+   * buckets.
-    
-    if(showBuckets) {
-      for(PlaceHolderDiskRegion region : regions) {
+
+    if (showBuckets) {
+      for (PlaceHolderDiskRegion region : regions) {
-      Map<DiskStoreID, String> online = new HashMap<DiskStoreID,String>();
-      Map<DiskStoreID, String> offline = new HashMap<DiskStoreID,String>();
-      Map<DiskStoreID, String> equal = new HashMap<DiskStoreID,String>();
-      for(PlaceHolderDiskRegion region : regions) {
-        for(PersistentMemberID mem: region.getOnlineMembers()) {
+      Map<DiskStoreID, String> online = new HashMap<DiskStoreID, String>();
+      Map<DiskStoreID, String> offline = new HashMap<DiskStoreID, String>();
+      Map<DiskStoreID, String> equal = new HashMap<DiskStoreID, String>();
+      for (PlaceHolderDiskRegion region : regions) {
+        for (PersistentMemberID mem : region.getOnlineMembers()) {
-        for(PersistentMemberID mem: region.getOfflineMembers()) {
+        for (PersistentMemberID mem : region.getOfflineMembers()) {
-        for(PersistentMemberID mem: region.getOfflineAndEqualMembers()) {
+        for (PersistentMemberID mem : region.getOfflineAndEqualMembers()) {
-      
+
-      for (Map.Entry<DiskStoreID,String> id : online.entrySet()) {
+      for (Map.Entry<DiskStoreID, String> id : online.entrySet()) {
-      for (Map.Entry<DiskStoreID,String> id : offline.entrySet()) {
+      for (Map.Entry<DiskStoreID, String> id : offline.entrySet()) {
-      for (Map.Entry<DiskStoreID,String> id : equal.entrySet()) {
+      for (Map.Entry<DiskStoreID, String> id : equal.entrySet()) {
-    
+
-      for (PlaceHolderDiskRegion dr: this.drMapByName.values()) {
+      for (PlaceHolderDiskRegion dr : this.drMapByName.values()) {
-    for (PlaceHolderDiskRegion dr: buckets) {
+    for (PlaceHolderDiskRegion dr : buckets) {
-    
-    //Remove the partitioned region record
-    //for this disk store.
+
+    // Remove the partitioned region record
+    // for this disk store.
-                             
-  public String modifyPRRegion(String prName,
-                             String lruOption,
-                             String lruActionOption,
-                             String lruLimitOption,
-                             String concurrencyLevelOption,
-                             String initialCapacityOption,
-                             String loadFactorOption,
-                             String compressorClassNameOption,
-                             String statisticsEnabledOption,
-                             String offHeapOption,
-                             boolean printToConsole) {
+
+  public String modifyPRRegion(String prName, String lruOption, String lruActionOption,
+      String lruLimitOption, String concurrencyLevelOption, String initialCapacityOption,
+      String loadFactorOption, String compressorClassNameOption, String statisticsEnabledOption,
+      String offHeapOption, boolean printToConsole) {
-      for (PlaceHolderDiskRegion dr: this.drMapByName.values()) {
+      for (PlaceHolderDiskRegion dr : this.drMapByName.values()) {
-      
+
-      for (PlaceHolderDiskRegion dr: buckets) {
-        String message = basicModifyRegion(printInfo, dr, lruOption, lruActionOption, lruLimitOption,
-            concurrencyLevelOption, initialCapacityOption, loadFactorOption,
+      for (PlaceHolderDiskRegion dr : buckets) {
+        String message = basicModifyRegion(printInfo, dr, lruOption, lruActionOption,
+            lruLimitOption, concurrencyLevelOption, initialCapacityOption, loadFactorOption,
-  public String modifyRegion(DiskRegionView drv,
-                           String lruOption,
-                           String lruActionOption,
-                           String lruLimitOption,
-                           String concurrencyLevelOption,
-                           String initialCapacityOption,
-                           String loadFactorOption,
-                           String compressorClassNameOption,
-                           String statisticsEnabledOption,
-                           String offHeapOption,
-                           boolean printToConsole) {
+
+  public String modifyRegion(DiskRegionView drv, String lruOption, String lruActionOption,
+      String lruLimitOption, String concurrencyLevelOption, String initialCapacityOption,
+      String loadFactorOption, String compressorClassNameOption, String statisticsEnabledOption,
+      String offHeapOption, boolean printToConsole) {
-          concurrencyLevelOption, initialCapacityOption,
-          loadFactorOption, compressorClassNameOption,
-          statisticsEnabledOption, offHeapOption, printToConsole);
+          concurrencyLevelOption, initialCapacityOption, loadFactorOption,
+          compressorClassNameOption, statisticsEnabledOption, offHeapOption, printToConsole);
-  private String basicModifyRegion(boolean printInfo, DiskRegionView drv,
-                                 String lruOption,
-                                 String lruActionOption,
-                                 String lruLimitOption,
-                                 String concurrencyLevelOption,
-                                 String initialCapacityOption,
-                                 String loadFactorOption,
-                                 String compressorClassNameOption,
-                                 String statisticsEnabledOption,
-                                 String offHeapOption,
-                                 boolean printToConsole) {
+
+  private String basicModifyRegion(boolean printInfo, DiskRegionView drv, String lruOption,
+      String lruActionOption, String lruLimitOption, String concurrencyLevelOption,
+      String initialCapacityOption, String loadFactorOption, String compressorClassNameOption,
+      String statisticsEnabledOption, String offHeapOption, boolean printToConsole) {
-    
+
-        lruAlgorithm = (byte)ea.getValue();
+        lruAlgorithm = (byte) ea.getValue();
-        throw new IllegalArgumentException("Expected lru to be one of the following: \"none\", \"lru-entry-count\", \"lru-heap-percentage\", or \"lru-memory-size\"");
+        throw new IllegalArgumentException(
+            "Expected lru to be one of the following: \"none\", \"lru-entry-count\", \"lru-heap-percentage\", or \"lru-memory-size\"");
-        lruAction = (byte)EvictionAction.NONE.getValue();
+        lruAction = (byte) EvictionAction.NONE.getValue();
-        lruAction = (byte)ea.getValue();
+        lruAction = (byte) ea.getValue();
-        throw new IllegalArgumentException("Expected lruAction to be one of the following: \"none\", \"overflow-to-disk\", or \"local-destroy\"");
+        throw new IllegalArgumentException(
+            "Expected lruAction to be one of the following: \"none\", \"overflow-to-disk\", or \"local-destroy\"");
-        throw new IllegalArgumentException("Expected concurrencyLevel to be greater than or equal to zero");
+        throw new IllegalArgumentException(
+            "Expected concurrencyLevel to be greater than or equal to zero");
-        throw new IllegalArgumentException("Expected initialCapacity to be greater than or equal to zero");
+        throw new IllegalArgumentException(
+            "Expected initialCapacity to be greater than or equal to zero");
-        throw new IllegalArgumentException("Expected loadFactor to be greater than or equal to zero");
+        throw new IllegalArgumentException(
+            "Expected loadFactor to be greater than or equal to zero");
-      compressorClassName = (compressorClassNameOption.isEmpty() ? null : compressorClassNameOption);
+      compressorClassName =
+          (compressorClassNameOption.isEmpty() ? null : compressorClassNameOption);
-        throw new IllegalArgumentException("Expected statisticsEnabled to be \"true\" or \"false\"");
+          throw new IllegalArgumentException(
+              "Expected statisticsEnabled to be \"true\" or \"false\"");
-        throw new IllegalArgumentException("Expected offHeap to be \"true\" or \"false\"");
+          throw new IllegalArgumentException("Expected offHeap to be \"true\" or \"false\"");
-    
+
-    sb.append(((PlaceHolderDiskRegion)drv).dump2());
+    sb.append(((PlaceHolderDiskRegion) drv).dump2());
-    
-    drv.setConfig(lruAlgorithm, lruAction, lruLimit,
-                  concurrencyLevel, initialCapacity, loadFactor, statisticsEnabled,
-                  drv.isBucket(), drv.getFlags(), drv.getPartitionName(), drv.getStartingBucketId(),
-                  compressorClassName, offHeap);
+
+    drv.setConfig(lruAlgorithm, lruAction, lruLimit, concurrencyLevel, initialCapacity, loadFactor,
+        statisticsEnabled, drv.isBucket(), drv.getFlags(), drv.getPartitionName(),
+        drv.getStartingBucketId(), compressorClassName, offHeap);
-    ((PlaceHolderDiskRegion)drv).getEvictionAttributes();
+    ((PlaceHolderDiskRegion) drv).getEvictionAttributes();
-    
+
-    sb.append(((PlaceHolderDiskRegion)drv).dump2());
+    sb.append(((PlaceHolderDiskRegion) drv).dump2());
-    
+
-    
+
-  
+
-  
+
-  
+
-  
+
-      ByteBuffer bb = getIFWriteBuffer(1+3+1);
+      ByteBuffer bb = getIFWriteBuffer(1 + 3 + 1);
-      DiskAccessException dae
-        = new DiskAccessException(LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex), this.parent);
+      DiskAccessException dae = new DiskAccessException(
+          LocalizedStrings.DiskInitFile_FAILED_INIT_FILE_WRITE_BECAUSE_0.toLocalizedString(ex),
+          this.parent);

MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 MOV65 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66