GEODE-2632: change dependencies on GemFireCacheImpl to InternalCache

* misc cleanup of code where possible

+import java.io.BufferedInputStream;
+import java.io.BufferedOutputStream;
+import java.io.DataInput;
+import java.io.DataInputStream;
+import java.io.DataOutput;
+import java.io.DataOutputStream;
+import java.io.EOFException;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InterruptedIOException;
+import java.io.SyncFailedException;
+import java.nio.ByteBuffer;
+import java.nio.channels.ClosedChannelException;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.apache.logging.log4j.Logger;
+
-import org.apache.logging.log4j.Logger;
-
-import java.io.BufferedInputStream;
-import java.io.BufferedOutputStream;
-import java.io.DataInput;
-import java.io.DataInputStream;
-import java.io.DataOutput;
-import java.io.DataOutputStream;
-import java.io.EOFException;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileNotFoundException;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InterruptedIOException;
-import java.io.SyncFailedException;
-import java.nio.ByteBuffer;
-import java.nio.channels.ClosedChannelException;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
- * 
-
-public final class Oplog implements CompactableOplog, Flushable {
+public class Oplog implements CompactableOplog, Flushable {
-  /** preallocated space available for writing to* */
-  // volatile private long opLogSpace = 0L;
+
+
-  private OpState opState;
-  /** OPCODES - byte appended before being written to disk* */
+  private OpState opState;
+
+
+
+
+
+
+
+
+
+
+
+
+
+
-  public static enum OPLOG_TYPE {
+  public enum OPLOG_TYPE {
-    private byte[] bytes;
+    private final byte[] bytes;
-   * Asif: This object is used to correctly identify the OpLog size so as to cause a switch of
-   * oplogs
+   * This object is used to correctly identify the OpLog size so as to cause a switch of oplogs
+
-   * Extra bytes to be skipped before reading value bytes. Value is currently 6 : 1 byte for opcode,
-   * 1 byte for userbits and 4 bytes for value length.
-   */
-  private static final long SKIP_BYTES = 6;
-
-  private static final ByteBuffer EMPTY = ByteBuffer.allocate(0);
-
-  // ///////////////////// Constructors ////////////////////////
-  /**
-   * Creates new <code>Oplog</code> for the given region.
+   * Creates new {@code Oplog} for the given region.
-   * Asif: A copy constructor used for creating a new oplog based on the previous Oplog. This
-   * constructor is invoked only from the function switchOplog
+   * A copy constructor used for creating a new oplog based on the previous Oplog. This constructor
+   * is invoked only from the function switchOplog
-  public final Version currentRecoveredGFVersion() {
+  public Version currentRecoveredGFVersion() {
-   * @throws IOException
-   * 
-   * @param oplogId
-   * @param parent
-    long maxOplogSizeParam = getParent().getMaxOplogSizeInBytes();
-    this.maxOplogSize = maxOplogSizeParam;
+    this.maxOplogSize = getParent().getMaxOplogSizeInBytes();
-   * 
-   * @throws IOException
-      return ByteBuffer.allocateDirect(Integer.getInteger("WRITE_BUF_SIZE", 32768).intValue());
+      return ByteBuffer.allocateDirect(Integer.getInteger("WRITE_BUF_SIZE", 32768));
-   * 
-   * @throws IOException
-   * Returns the <code>DiskStoreStats</code> for this oplog
+   * Returns the {@code DiskStoreStats} for this oplog
-   * Flushes any pending writes to disk.
-   * 
-   * public final void flush() { forceFlush(); }
-   */
-
-  /**
-   * 
-   * @throws IOException
-   * @throws SyncFailedException
-  public final BytesAndBits getBytesAndBits(DiskRegionView dr, DiskId id, boolean faultingIn,
+  public BytesAndBits getBytesAndBits(DiskRegionView dr, DiskId id, boolean faultingIn,
-    // Asif: If the offset happens to be -1, still it is possible that
+    // If the offset happens to be -1, still it is possible that
-      // Asif: Since it is given that a get operation has alreadty
+      // Since it is given that a get operation has alreadty
-      // synchronized (id) {
-      // if (id.getOplogId() == this.oplogId) {
-      // }
-      // }
-    // Asif :If the current OpLog is not destroyed ( its opLogRaf file
+    // If the current OpLog is not destroyed ( its opLogRaf file
-              .toLocalizedString(new Object[] {id, Boolean.valueOf(dr.isSync())}));
+              .toLocalizedString(new Object[] {id, dr.isSync()}));
-   * 
-  public final BytesAndBits getNoBuffer(DiskRegion dr, DiskId id) {
+  public BytesAndBits getNoBuffer(DiskRegion dr, DiskId id) {
-      BytesAndBits bb =
-          basicGet(dr, id.getOffsetInOplog(), false, id.getValueLength(), id.getUserBits());
-      return bb;
+      return basicGet(dr, id.getOffsetInOplog(), false, id.getValueLength(), id.getUserBits());
-      } catch (EOFException ex) {
+      } catch (EOFException ignore) {
-        // if (byteCount < fileLength) {
-        // throw new
-        // DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-        // .toLocalizedString(drfFile.getPath()), ex, getParent());
-        // }// else do nothing, this is expected in crash scenarios
-      } catch (CancelException ignore) {
+      } catch (CancelException e) {
-          logger.debug("Oplog::readOplog:Error in recovery as Cache was closed", ignore);
+          logger.debug("Oplog::readOplog:Error in recovery as Cache was closed", e);
-      } catch (RegionDestroyedException ignore) {
+      } catch (RegionDestroyedException e) {
-          logger.debug("Oplog::readOplog:Error in recovery as Region was destroyed", ignore);
+          logger.debug("Oplog::readOplog:Error in recovery as Region was destroyed", e);
-      } catch (IllegalStateException ex) {
-        // @todo
-        // if (!rgn.isClosed()) {
-        throw ex;
-        // }
+      } catch (IllegalStateException e) {
+        throw e;
-    } catch (FileNotFoundException ex) {
+    } catch (FileNotFoundException ignore) {
-        } catch (DiskAccessException notInNewFormatErr) {
+        } catch (DiskAccessException ignore) {
-        } catch (IllegalStateException notOldFileErr) {
+        } catch (IllegalStateException ignore) {
-    } catch (EOFException ex) {
+    } catch (EOFException ignore) {
-      // if (byteCount < fileLength) {
-      // throw new
-      // DiskAccessException(LocalizedStrings.Oplog_FAILED_READING_FILE_DURING_RECOVERY_FROM_0
-      // .toLocalizedString(this.crf.f.getPath()), ex, getParent());
-      // }// else do nothing, this is expected in crash scenarios
-    } catch (CancelException ignore) {
+    } catch (CancelException e) {
-        logger.debug("Oplog::readOplog:Error in recovery as Cache was closed", ignore);
+        logger.debug("Oplog::readOplog:Error in recovery as Cache was closed", e);
-    } catch (RegionDestroyedException ignore) {
+    } catch (RegionDestroyedException e) {
-        logger.debug("Oplog::readOplog:Error in recovery as Region was destroyed", ignore);
+        logger.debug("Oplog::readOplog:Error in recovery as Region was destroyed", e);
-    } catch (IllegalStateException ex) {
-      // @todo
-      // if (!rgn.isClosed()) {
-      throw ex;
-      // }
+    } catch (IllegalStateException e) {
+      throw e;
-        sb.append(" " + seq[i]);
+        sb.append(" ").append(seq[i]);
-        boolean rvvTrusted = InternalDataSerializer.readBoolean(dis);
+        boolean rvvTrusted = DataSerializer.readBoolean(dis);
-   * @param recoverValue
-   * @throws IOException
-   * @param recoverValue
-   * @param currentRegion
-   * @param keyRequiresRegionContext
-   * @throws IOException
-              logger.debug("Could not deserialize recovered value: {}" + ex.getCause(), ex);
+              logger.debug("Could not deserialize recovered value: {}", ex.getCause(), ex);
-   * @param deletedIds
-   * @param recoverValue
-   * @throws IOException
-   * @throws IOException
-      DiskStoreImpl parent) throws IOException
-
-  {
+      DiskStoreImpl parent) throws IOException {
-   * 
-   * @param tag
-   * 
-   * @param tag
-    byte firstByte = dis.readByte();
-    // if (firstByte < 0) {
-    // delta = 0xFFFFFFFFFFFFFF00L | firstByte;
-    // } else {
-    // delta = firstByte;
-    // }
-    delta = firstByte;
+    delta = dis.readByte();
-    // this.lastDelta = delta; // HACK DEBUG
-  // private long lastDelta; // HACK DEBUG
-
-   * @param userBits
-   * @throws IOException
-   * Asif: Modified the code so as to reuse the already created ByteBuffer during transition.
-   * Creates a key/value pair from a region entry on disk. Updates all of the necessary
+   * Modified the code so as to reuse the already created ByteBuffer during transition. Creates a
+   * key/value pair from a region entry on disk. Updates all of the necessary
-   * @throws DiskAccessException
-   * @throws IllegalStateException
-   * 
-  public final void create(LocalRegion region, DiskEntry entry, ValueWrapper value, boolean async) {
+  public void create(LocalRegion region, DiskEntry entry, ValueWrapper value, boolean async) {
-   * Asif: A helper function which identifies whether to create the entry in the current oplog or to
-   * make the switch to the next oplog. This function enables us to reuse the byte buffer which got
+   * A helper function which identifies whether to create the entry in the current oplog or to make
+   * the switch to the next oplog. This function enables us to reuse the byte buffer which got
-   * @throws IOException
-   * @throws InterruptedException
-      // Asif : Check if the current data in ByteBuffer will cause a
+      // Check if the current data in ByteBuffer will cause a
-        // Asif: Allow it to be added to the OpLOg so increase the
+        // Allow it to be added to the OpLOg so increase the
-        // Asif: It is necessary that we set the
+        // It is necessary that we set the
-        // Asif: As such for any put or get operation , a synch is taken
+        // As such for any put or get operation , a synch is taken
-   * 
-   * 
-   * public void forceRolling() { if (getOplogSet().getChild() == this) { synchronized (this.lock) {
-   * if (getOplogSet().getChild() == this) { switchOpLog(0, null); } } if (!this.sync) {
-   * this.writer.activateThreadToTerminate(); } } }
-   */
-
-  /**
-   * This oplog will be forced to switch to a new oplog
-   * Asif: This function is used to switch from one op Log to another , when the size of the current
-   * oplog has reached the maximum permissible. It is always called from synch block with lock
-   * object being the OpLog File object We will reuse the ByteBuffer Pool. We should add the current
-   * Oplog for compaction first & then try to get next directory holder as in case there is only a
-   * single directory with space being full, compaction has to happen before it can be given a new
+   * This function is used to switch from one op Log to another , when the size of the current oplog
+   * has reached the maximum permissible. It is always called from synch block with lock object
+   * being the OpLog File object We will reuse the ByteBuffer Pool. We should add the current Oplog
+   * for compaction first & then try to get next directory holder as in case there is only a single
+   * directory with space being full, compaction has to happen before it can be given a new
-      // Asif: Remove the Oplog which was added in the DiskStoreImpl
+      // Remove the Oplog which was added in the DiskStoreImpl
-   * 
-   * Asif:This function retrieves the value for an entry being compacted subject to entry
-   * referencing the oplog being compacted. Attempt is made to retrieve the value from in memory ,
-   * if available, else from asynch buffers ( if asynch mode is enabled), else from the Oplog being
-   * compacted. It is invoked from switchOplog as well as OplogCompactor's compact function.
+   * This function retrieves the value for an entry being compacted subject to entry referencing the
+   * oplog being compacted. Attempt is made to retrieve the value from in memory , if available,
+   * else from asynch buffers ( if asynch mode is enabled), else from the Oplog being compacted. It
+   * is invoked from switchOplog as well as OplogCompactor's compact function.
-    // TODO:KIRK:OK Object value = entry.getValueWithContext(dr);
-      // Asif: If the mode is synch it is guaranteed to be present in the disk
+      // If the mode is synch it is guaranteed to be present in the disk
-        // Asif: If the value is already a byte array then the user bit
+        // If the value is already a byte array then the user bit
+   * <p>
+   * Modified the code so as to reuse the already created ByteBuffer during transition. Minimizing
+   * the synchronization allowing multiple put operations for different entries to proceed
+   * concurrently for asynch mode
-   * @throws DiskAccessException
-   * @throws IllegalStateException
-  /*
-   * Asif: Modified the code so as to reuse the already created ByteBuffer during transition.
-   * Minimizing the synchronization allowing multiple put operations for different entries to
-   * proceed concurrently for asynch mode
-   */
-  public final void modify(LocalRegion region, DiskEntry entry, ValueWrapper value, boolean async) {
-
+  public void modify(LocalRegion region, DiskEntry entry, ValueWrapper value, boolean async) {
-
-  public final void saveConflictVersionTag(LocalRegion region, VersionTag tag, boolean async) {
+  public void saveConflictVersionTag(LocalRegion region, VersionTag tag, boolean async) {
-  private final void copyForwardForOfflineCompact(long oplogKeyId, byte[] keyBytes,
-      byte[] valueBytes, byte userBits, long drId, VersionTag tag) {
+  private void copyForwardForOfflineCompact(long oplogKeyId, byte[] keyBytes, byte[] valueBytes,
+      byte userBits, long drId, VersionTag tag) {
-  private final void copyForwardModifyForCompact(DiskRegionView dr, DiskEntry entry,
+  private void copyForwardModifyForCompact(DiskRegionView dr, DiskEntry entry,
-   * Asif: A helper function which identifies whether to modify the entry in the current oplog or to
-   * make the switch to the next oplog. This function enables us to reuse the byte buffer which got
+   * A helper function which identifies whether to modify the entry in the current oplog or to make
+   * the switch to the next oplog. This function enables us to reuse the byte buffer which got
-   * @throws IOException
-   * @throws InterruptedException
-                "basicSaveConflictVersionTag: drId={} versionStamp={} oplog#", dr.getId(), tag,
+                "basicSaveConflictVersionTag: drId={} versionStamp={} oplog#{}", dr.getId(), tag,
-                baToString(valueBytes), getOplogId());
+                baToString(valueBytes), drId, getOplogId());
-      // }
-  public final void remove(LocalRegion region, DiskEntry entry, boolean async, boolean isClear) {
+  public void remove(LocalRegion region, DiskEntry entry, boolean async, boolean isClear) {
-
-
-  public final void writeGCRVV(DiskRegion dr) {
+  public void writeGCRVV(DiskRegion dr) {
-   * 
-   * Asif: A helper function which identifies whether to record a removal of entry in the current
-   * oplog or to make the switch to the next oplog. This function enables us to reuse the byte
-   * buffer which got created for an oplog which no longer permits us to use itself. It will also
-   * take acre of compaction if required
+   * A helper function which identifies whether to record a removal of entry in the current oplog or
+   * to make the switch to the next oplog. This function enables us to reuse the byte buffer which
+   * got created for an oplog which no longer permits us to use itself. It will also take acre of
+   * compaction if required
-   * @throws IOException
-   * @throws InterruptedException
-          // @todo if we don't sync write destroys what will happen if
+          // TODO: if we don't sync write destroys what will happen if
-          if (logger.isTraceEnabled(LogMarker.PERSIST_WRITES)) {
+          if (logger.isDebugEnabled(LogMarker.PERSIST_WRITES)) {
-          // new RuntimeException("STACK"));
-
-        {
-          Oplog rmOplog = null;
-          if (oldOplogId == getOplogId()) {
-            rmOplog = this;
-          } else {
-            rmOplog = getOplogSet().getChild(oldOplogId);
-          }
-          if (rmOplog != null) {
-            rmOplog.rmLive(dr, entry);
-            emptyOplog = rmOplog;
-          }
+        Oplog rmOplog = null;
+        if (oldOplogId == getOplogId()) {
+          rmOplog = this;
+        } else {
+          rmOplog = getOplogSet().getChild(oldOplogId);
+        }
+        if (rmOplog != null) {
+          rmOplog.rmLive(dr, entry);
+          emptyOplog = rmOplog;
-  // /**
-  // * This is only used for an assertion check.
-  // */
-  // private long lastWritePos = -1;
-
-  public final ByteBuffer getWriteBuf() {
+  ByteBuffer getWriteBuf() {
-  private final void flushNoSync(OplogFile olf) throws IOException {
+  private void flushNoSync(OplogFile olf) throws IOException {
-    // flush(olf, false);
-  private final void flushAndSync(OplogFile olf) throws IOException {
-    flushAll(false); // @todo
-    // flush(olf, true);
+  private void flushAndSync(OplogFile olf) throws IOException {
+    flushAll(false);
-  private final void flush(OplogFile olf, boolean doSync) throws IOException {
+  private void flush(OplogFile olf, boolean doSync) throws IOException {
-  private final void flush(OplogFile olf, ByteBuffer b1, ByteBuffer b2) throws IOException {
+  private void flush(OplogFile olf, ByteBuffer b1, ByteBuffer b2) throws IOException {
-  public final void flushAll() {
+  public void flushAll() {
-  public final void flushAllNoSync(boolean skipDrf) {
+  public void flushAllNoSync(boolean skipDrf) {
-  public final void flushAll(boolean skipDrf) {
+  public void flushAll(boolean skipDrf) {
-  public final void flushAll(boolean skipDrf, boolean doSync) {
+  public void flushAll(boolean skipDrf, boolean doSync) {
-      // if (!skipDrf) {
-      // @todo if skipDrf then only need to do drf if crf has flushable data
+      // TODO: if skipDrf then only need to do drf if crf has flushable data
-      // }
-   * Asif: Since the ByteBuffer being writen to can have additional bytes which are used for
-   * extending the size of the file, it is necessary that the ByteBuffer provided should have limit
-   * which is set to the position till which it contains the actual bytes. If the mode is synched
-   * write then only we will write up to the capacity & opLogSpace variable have any meaning. For
-   * asynch mode it will be zero. Also this method must be synchronized on the file , whether we use
-   * synch or asynch write because the fault in operations can clash with the asynch writing. Write
-   * the specified bytes to the oplog. Note that since extending a file is expensive this code will
+   * Since the ByteBuffer being writen to can have additional bytes which are used for extending the
+   * size of the file, it is necessary that the ByteBuffer provided should have limit which is set
+   * to the position till which it contains the actual bytes. If the mode is synched write then only
+   * we will write up to the capacity & opLogSpace variable have any meaning. For asynch mode it
+   * will be zero. Also this method must be synchronized on the file , whether we use synch or
+   * asynch write because the fault in operations can clash with the asynch writing. Write the
+   * specified bytes to the oplog. Note that since extending a file is expensive this code will
-      // Asif : It is assumed that the file pointer is already at the
+      // It is assumed that the file pointer is already at the
-        final long readPosition = offsetInOplog;
-             */(readPosition + valueLength) > this.crf.bytesFlushed && !this.closed) {
+             */(offsetInOplog + valueLength) > this.crf.bytesFlushed && !this.closed) {
-            if ((readPosition + valueLength) > writePosition) {
+            if ((offsetInOplog + valueLength) > writePosition) {
-                      .toLocalizedString(
-                          new Object[] {readPosition + valueLength, writePosition, this.crf.raf}),
+                      .toLocalizedString(offsetInOplog + valueLength, writePosition, this.crf.raf),
-            } else if (readPosition < 0) {
+            } else if (offsetInOplog < 0) {
-                  LocalizedStrings.Oplog_CANNOT_FIND_RECORD_0_WHEN_READING_FROM_1.toLocalizedString(
-                      new Object[] {offsetInOplog, this.diskFile.getPath()}),
+                  LocalizedStrings.Oplog_CANNOT_FIND_RECORD_0_WHEN_READING_FROM_1
+                      .toLocalizedString(offsetInOplog, this.diskFile.getPath()),
-              myRAF.seek(readPosition);
+              myRAF.seek(offsetInOplog);
-   * Asif: Extracts the Value byte array & UserBit from the OpLog
+   * Extracts the Value byte array & UserBit from the OpLog
-          } catch (InterruptedIOException e) { // bug 39756
+          } catch (InterruptedIOException ignore) { // bug 39756
-                .toLocalizedString(new Object[] {this.diskFile.getPath(),
-                    Long.valueOf(this.oplogId), Long.valueOf(offsetInOplog),
-                    Long.valueOf(this.crf.currSize), Long.valueOf(this.crf.bytesFlushed),
-                    Boolean.valueOf(!dr.isSync()), Boolean.valueOf(false)}),
+                .toLocalizedString(this.diskFile.getPath(), this.oplogId, offsetInOplog,
+                    this.crf.currSize, this.crf.bytesFlushed, !dr.isSync(), Boolean.FALSE),
-   * Asif: Extracts the Value byte array & UserBit from the OpLog and inserts it in the wrapper
-   * Object of type BytesAndBitsForCompactor which is passed
+   * Extracts the Value byte array & UserBit from the OpLog and inserts it in the wrapper Object of
+   * type BytesAndBitsForCompactor which is passed
-          final long readPosition = offsetInOplog;
-               */(readPosition + valueLength) > this.crf.bytesFlushed && !this.closed) {
+               */(offsetInOplog + valueLength) > this.crf.bytesFlushed && !this.closed) {
-          if ((readPosition + valueLength) > writePosition) {
+          if ((offsetInOplog + valueLength) > writePosition) {
-                    .toLocalizedString(
-                        new Object[] {readPosition + valueLength, writePosition, this.crf.raf}),
+                    .toLocalizedString(offsetInOplog + valueLength, writePosition, this.crf.raf),
-          } else if (readPosition < 0) {
+          } else if (offsetInOplog < 0) {
-                LocalizedStrings.Oplog_CANNOT_FIND_RECORD_0_WHEN_READING_FROM_1.toLocalizedString(
-                    new Object[] {Long.valueOf(offsetInOplog), this.diskFile.getPath()}),
+                LocalizedStrings.Oplog_CANNOT_FIND_RECORD_0_WHEN_READING_FROM_1
+                    .toLocalizedString(offsetInOplog, this.diskFile.getPath()),
-          // if (this.closed || this.deleted.get()) {
-          // throw new DiskAccessException("attempting get on "
-          // + (this.deleted.get() ? "destroyed" : "closed")
-          // + " oplog #" + getOplogId(), this.owner);
-          // }
-            this.crf.raf.seek(readPosition);
+            this.crf.raf.seek(offsetInOplog);
-                .toLocalizedString(new Object[] {this.diskFile.getPath(),
-                    Long.valueOf(this.oplogId), Long.valueOf(offsetInOplog),
-                    Long.valueOf(this.crf.currSize), Long.valueOf(this.crf.bytesFlushed),
-                    Boolean.valueOf(/*
-                                     * ! dr . isSync ( )
-                                     * 
-                                     * @ todo
-                                     */false), Boolean.valueOf(false)}),
+                .toLocalizedString(this.diskFile.getPath(), this.oplogId, offsetInOplog,
+                    this.crf.currSize, this.crf.bytesFlushed, Boolean.FALSE, Boolean.FALSE),
-      double rvHWM = rvHWMtmp;
-      if (((rv / rvHWM) * 100) <= parent.getCompactionThreshold()) {
+      if (((rv / (double) rvHWMtmp) * 100) <= parent.getCompactionThreshold()) {
-  private GemFireCacheImpl getGemFireCache() {
+  private InternalCache getInternalCache() {
-        // Asif:Start with a fresh wrapper on every compaction so that
+        // Start with a fresh wrapper on every compaction so that
-              // Asif: Check if the value byte array happens to be any of the
+              // Check if the value byte array happens to be any of the
-   * 
-   * @param diskRecoveryStores
-            } catch (RegionDestroyedException e) {
+            } catch (RegionDestroyedException ignore) {
-        InternalDataSerializer.writeBoolean(dr.getRVVTrusted(), out);
+        DataSerializer.writeBoolean(dr.getRVVTrusted(), out);
-    byte[] rvvBytes = out.toByteArray();
-    return rvvBytes;
+    return out.toByteArray();
-  // // Comparable code //
-  // public int compareTo(Oplog o) {
-  // return getOplogId() - o.getOplogId();
-  // }
-  // public boolean equals(Object o) {
-  // if (o instanceof Oplog) {
-  // return compareTo((Oplog)o) == 0;
-  // } else {
-  // return false;
-  // }
-  // }
-  // public int hashCode() {
-  // return getOplogId();
-  // }
-    return "oplog#" + getOplogId() /* + "DEBUG" + System.identityHashCode(this) */;
+    return "oplog#" + getOplogId();
-  // //////// Methods used during recovery //////////////
-
-  // ////////////////////Inner Classes //////////////////////
-
-    if (ba == null)
+    if (ba == null) {
-    StringBuffer sb = new StringBuffer();
+    }
+    StringBuilder sb = new StringBuilder();
-  private static String laToString(long[] la) {
-    if (la == null)
-      return "null";
-    StringBuffer sb = new StringBuffer();
-    for (int i = 0; i < la.length; i++) {
-      sb.append(la[i]).append(", ");
-    }
-    return sb.toString();
-  }
-
-    byte[] versionsBytes = out.toByteArray();
-    return versionsBytes;
+    return out.toByteArray();
-    // private int entryVersion;
-    // private long regionVersion;
-    // private int memberId; // canonicalId of memberID
-
-    public final int getSize() {
+    public int getSize() {
-    private final void write(OplogFile olf, ValueWrapper vw) throws IOException {
+    private void write(OplogFile olf, ValueWrapper vw) throws IOException {
-    private final void write(OplogFile olf, byte[] bytes, int byteLength) throws IOException {
+    private void write(OplogFile olf, byte[] bytes, int byteLength) throws IOException {
-      final int maxOffset = byteLength;
-      while (offset < maxOffset) {
+      while (offset < byteLength) {
-        int bytesThisTime = maxOffset - offset;
+        int bytesThisTime = byteLength - offset;
-    private final void writeByte(OplogFile olf, byte v) throws IOException {
+    private void writeByte(OplogFile olf, byte v) throws IOException {
-    private final void writeOrdinal(OplogFile olf, short ordinal) throws IOException {
+    private void writeOrdinal(OplogFile olf, short ordinal) throws IOException {
-    private final void writeInt(OplogFile olf, int v) throws IOException {
+    private void writeInt(OplogFile olf, int v) throws IOException {
-    private final void writeLong(OplogFile olf, long v) throws IOException {
+    private void writeLong(OplogFile olf, long v) throws IOException {
-     * 
-     * @param rvv
-     * @param pendingKrfTags
-     * 
-     * @param pendingKrfTags
-      // int result = 0;
-      // DiskEntry n = getNext();
-      // while (n != this) {
-      // DiskEntry nextEntry = n.getNext();
-      // VersionSource member = null;
-      // long version = -1;
-      // if(pendingKrfTags != null) {
-      // VersionTag tag = pendingKrfTags.get(n);
-      // if(tag != null) {
-      // member = tag.getMemberID();
-      // version = tag.getRegionVersion();
-      // }
-      // }
-      // if(member == null) {
-      // VersionStamp stamp = n.getVersionStamp();
-      // member = stamp.getMemberID();
-      // version = stamp.getRegionVersion();
-      // }
-      //
-      // if(rvv.contains(member, version)) {
-      // result++;
-      // remove(n);
-      // if(pendingKrfTags != null) {
-      // pendingKrfTags.remove(n);
-      // }
-      // }
-      // n = nextEntry;
-      // }
-      // return result;
-    // private synchronized void checkForDuplicate(DiskEntry v) {
-    // DiskEntry de = getPrev();
-    // final long newKeyId = v.getDiskId().getKeyId();
-    // while (de != this) {
-    // if (de.getDiskId().getKeyId() == newKeyId) {
-    // throw new IllegalStateException(
-    // "DEBUG: found duplicate for oplogKeyId=" + newKeyId + " de="
-    // + System.identityHashCode(v) + " ode="
-    // + System.identityHashCode(de) + " deKey=" + v.getKey()
-    // + " odeKey=" + de.getKey() + " deOffset="
-    // + v.getDiskId().getOffsetInOplog() + " odeOffset="
-    // + de.getDiskId().getOffsetInOplog());
-    // }
-    // de = de.getPrev();
-    // }
-    // }
-
-     * @param pendingKrfTags
-    final public DiskRegionView getDiskRegion() {
+    public DiskRegionView getDiskRegion() {
-    final public void setDiskRegion(DiskRegionView dr) {
+    public void setDiskRegion(DiskRegionView dr) {
-    final synchronized public boolean getUnrecovered() {
+    synchronized public boolean getUnrecovered() {
-    final synchronized public boolean testAndSetRecovered(DiskRegionView dr) {
+    synchronized public boolean testAndSetRecovered(DiskRegionView dr) {
-        int result = this.liveEntries.addLiveEntriesToList(liveEntries, idx, getDiskRegion(),
+        return this.liveEntries.addLiveEntriesToList(liveEntries, idx, getDiskRegion(),
-        return result;
+
+

MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 MOV26 UPD43 UPD42 INS83 UPD42 UPD66 INS66 INS65 UPD66 UPD66 UPD66 INS66 INS65 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 INS66 INS66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 MOV32 INS8 UPD43 MOV32 INS66 MOV32 INS66 MOV44 MOV32 MOV41 UPD42 MOV32 MOV32 MOV32 UPD42 UPD42 UPD42 UPD42 UPD43 UPD42 UPD42 INS42 MOV12 MOV32 MOV32 UPD42 UPD42 MOV32 UPD42 UPD42 UPD42 UPD42 INS32 MOV60 MOV25 MOV25 MOV32 MOV32 UPD42 MOV44 INS44 INS32 INS42 MOV2 UPD42 UPD42 MOV32 UPD42 MOV43 INS42 UPD42 UPD42 MOV42 MOV42 INS45 UPD42 MOV43 MOV32 MOV22 MOV42 MOV22 MOV22 MOV38 INS40 MOV32 MOV22 MOV42 MOV22 MOV22 INS40 INS40 INS11 UPD42 UPD42 UPD42 UPD42 UPD42 UPD42 INS39 INS42 UPD45 INS42 UPD42 MOV43 MOV32 UPD42 MOV44 UPD42 UPD42 INS27 INS42 MOV22 MOV32 UPD42 MOV43 MOV32 UPD42 UPD42 MOV42 MOV42 INS42 MOV32 INS45 MOV32 INS27 INS42 MOV22 MOV43 MOV32 UPD42 MOV42 UPD42 MOV42 MOV42 INS42 MOV32 DEL83 DEL83 DEL66 DEL66 DEL66 DEL65 DEL29 DEL83 DEL83 DEL83 DEL39 DEL42 DEL34 DEL59 DEL23 DEL83 DEL83 DEL83 DEL42 DEL43 DEL42 DEL42 DEL42 DEL34 DEL32 DEL59 DEL23 DEL83 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL39 DEL42 DEL59 DEL60 DEL42 DEL42 DEL65 DEL42 DEL42 DEL32 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL83 DEL42 DEL42 DEL32 DEL83 DEL42 DEL43 DEL42 DEL59 DEL60 DEL42 DEL42 DEL44 DEL45 DEL27 DEL32 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL45 DEL27 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL39 DEL42 DEL59 DEL60 DEL42 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL83 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL83 DEL83 DEL83 DEL83 DEL42 DEL65 DEL42 DEL65 DEL83 DEL83 DEL42 DEL65 DEL42 DEL65 DEL8 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL83 DEL39 DEL42 DEL42 DEL59 DEL60 DEL42 DEL43 DEL85 DEL5 DEL27 DEL42 DEL4 DEL3 DEL42 DEL43 DEL85 DEL5 DEL42 DEL4 DEL3 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL9 DEL32 DEL4 DEL3 DEL83 DEL39 DEL42 DEL42 DEL59 DEL60 DEL42 DEL43 DEL85 DEL5 DEL27 DEL42 DEL4 DEL3 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL4 DEL3 DEL42 DEL43 DEL85 DEL5 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL32 DEL42 DEL42 DEL9 DEL32 DEL42 DEL42 DEL9 DEL32 DEL4 DEL3 DEL39 DEL42 DEL42 DEL59 DEL60 DEL42 DEL42 DEL65 DEL39 DEL85 DEL5 DEL42 DEL59 DEL60 DEL42 DEL83 DEL83 DEL42 DEL43 DEL42 DEL39 DEL85 DEL5 DEL42 DEL44 DEL42 DEL33 DEL27 DEL45 DEL41 DEL25 DEL42 DEL43 DEL42 DEL42 DEL43 DEL14 DEL59 DEL60 DEL39 DEL42 DEL34 DEL59 DEL58 DEL42 DEL40 DEL27 DEL42 DEL37 DEL42 DEL42 DEL42 DEL42 DEL2 DEL32 DEL42 DEL45 DEL32 DEL21 DEL8 DEL24 DEL42 DEL42 DEL32 DEL41 DEL8 DEL31 DEL39 DEL85 DEL5 DEL42 DEL59 DEL60 DEL42 DEL83 DEL83 DEL83 DEL83 DEL39 DEL42 DEL42 DEL59 DEL60 DEL83 DEL83 DEL83 DEL83 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL42 DEL65 DEL83 DEL83 DEL83 DEL83 DEL39 DEL42 DEL59 DEL60 DEL42