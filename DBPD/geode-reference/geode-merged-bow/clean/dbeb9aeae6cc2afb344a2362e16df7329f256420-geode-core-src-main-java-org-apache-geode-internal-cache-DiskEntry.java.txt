Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * Represents an entry in an {@link RegionMap} whose value may be
- * stored on disk.  This interface provides accessor and mutator
- * methods for a disk entry's state.  This allows us to abstract all
- * of the interesting behavior into a {@linkplain DiskEntry.Helper
- * helper class} that we only need to implement once.
+ * Represents an entry in an {@link RegionMap} whose value may be stored on disk. This interface
+ * provides accessor and mutator methods for a disk entry's state. This allows us to abstract all of
+ * the interesting behavior into a {@linkplain DiskEntry.Helper helper class} that we only need to
+ * implement once.
- * Each <code>DiskEntry</code> has a unique <code>id</code> that is
- * used by the {@link DiskRegion} to identify the key/value pair.
- * Before the disk entry is written to disk, the value of the
- * <code>id</code> is {@link DiskRegion#INVALID_ID invalid}.  Once the
- * object has been written to disk, the <code>id</code> is a positive
- * number.  If the value is {@linkplain Helper#update updated}, then the
- * <code>id</code> is negated to signify that the value on disk is
- * dirty.
+ * Each <code>DiskEntry</code> has a unique <code>id</code> that is used by the {@link DiskRegion}
+ * to identify the key/value pair. Before the disk entry is written to disk, the value of the
+ * <code>id</code> is {@link DiskRegion#INVALID_ID invalid}. Once the object has been written to
+ * disk, the <code>id</code> is a positive number. If the value is {@linkplain Helper#update
+ * updated}, then the <code>id</code> is negated to signify that the value on disk is dirty.
+   * 
-  public void setValueWithContext(RegionEntryContext context,Object value);
-  
+  public void setValueWithContext(RegionEntryContext context, Object value);
+
-   * In some cases we need to do something just before we drop the value
-   * from a DiskEntry that is being moved (i.e. overflowed) to disk.
+   * In some cases we need to do something just before we drop the value from a DiskEntry that is
+   * being moved (i.e. overflowed) to disk.
+   * 
-   * Returns true if the DiskEntry value is equal to {@link Token#DESTROYED}, {@link Token#REMOVED_PHASE1}, or {@link Token#REMOVED_PHASE2}.
+   * Returns true if the DiskEntry value is equal to {@link Token#DESTROYED},
+   * {@link Token#REMOVED_PHASE1}, or {@link Token#REMOVED_PHASE2}.
-  
+
-  
+
-  
+
+
+
+
-    
-  ///////////////////////  Inner Classes  //////////////////////
+
+  /////////////////////// Inner Classes //////////////////////
-   * A Helper class for performing functions common to all
-   * <code>DiskEntry</code>s. 
+   * A Helper class for performing functions common to all <code>DiskEntry</code>s.
-     * Testing purpose only
-     * Get the value of an entry that is on disk without faulting
-     * it in and without looking in the io buffer.
+     * Testing purpose only Get the value of an entry that is on disk without faulting it in and
+     * without looking in the io buffer.
+     * 
-      synchronized (id) {
-        if (id == null
-            || (dr.isBackup() && id.getKeyId() == DiskRegion.INVALID_ID)
-            || (!entry.isValueNull() && id.needsToBeWritten() && !EntryBits.isRecoveredFromDisk(id.getUserBits()))/*fix for bug 41942*/) {
-          return null;
-        }
+        synchronized (id) {
+          if (id == null || (dr.isBackup() && id.getKeyId() == DiskRegion.INVALID_ID)
+              || (!entry.isValueNull() && id.needsToBeWritten()
+                  && !EntryBits.isRecoveredFromDisk(id.getUserBits()))/* fix for bug 41942 */) {
+            return null;
+          }
-        return dr.getNoBuffer(id);
-      }
+          return dr.getNoBuffer(id);
+        }
-    
+
-     * Get the serialized value directly from disk.  Returned object may be
-     * a {@link CachedDeserializable}.  Goes straight to disk without faulting
-     * into memory.  Only looks at the disk storage, not at heap storage.
+     * Get the serialized value directly from disk. Returned object may be a
+     * {@link CachedDeserializable}. Goes straight to disk without faulting into memory. Only looks
+     * at the disk storage, not at heap storage.
+     * 
-    public static Object getSerializedValueOnDisk(
-        DiskEntry entry, DiskRegion dr) {
+    public static Object getSerializedValueOnDisk(DiskEntry entry, DiskRegion dr) {
-      synchronized (did) {
-        if (did == null
-            || (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID)) {
-          return null;
-        } else if (!entry.isValueNull() && did.needsToBeWritten() && !EntryBits.isRecoveredFromDisk(did.getUserBits())/*fix for bug 41942*/) {
-          return null;
+        synchronized (did) {
+          if (did == null || (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID)) {
+            return null;
+          } else if (!entry.isValueNull() && did.needsToBeWritten()
+              && !EntryBits.isRecoveredFromDisk(did.getUserBits())/* fix for bug 41942 */) {
+            return null;
+          }
+          return dr.getSerializedData(did);
-        return dr.getSerializedData(did);
-      }
-    
+
-     * Get the value of an entry that is on disk without
-     * faulting it in . It checks for the presence in the buffer also.
-     * This method is used for concurrent map operations and CQ processing
+     * Get the value of an entry that is on disk without faulting it in . It checks for the presence
+     * in the buffer also. This method is used for concurrent map operations and CQ processing
-    static Object getValueOnDiskOrBuffer(DiskEntry entry, DiskRegion dr, RegionEntryContext context) {
-      @Released Object v = getOffHeapValueOnDiskOrBuffer(entry, dr, context);
+    static Object getValueOnDiskOrBuffer(DiskEntry entry, DiskRegion dr,
+        RegionEntryContext context) {
+      @Released
+      Object v = getOffHeapValueOnDiskOrBuffer(entry, dr, context);
-    
+
-    static Object getOffHeapValueOnDiskOrBuffer(DiskEntry entry, DiskRegion dr, RegionEntryContext context) {
+    static Object getOffHeapValueOnDiskOrBuffer(DiskEntry entry, DiskRegion dr,
+        RegionEntryContext context) {
-            @Retained Object v = entry._getValueRetain(context, true); // TODO:KIRK:OK Rusty had Object v = entry.getValueWithContext(context);
+            @Retained
+            Object v = entry._getValueRetain(context, true); // TODO:KIRK:OK Rusty had Object v =
+                                                             // entry.getValueWithContext(context);
-          if (did == null
-              || ( dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID)
-              || (!entry.isValueNull() && did.needsToBeWritten() && !EntryBits.isRecoveredFromDisk(did.getUserBits()))/*fix for bug 41942*/) {
+          if (did == null || (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID)
+              || (!entry.isValueNull() && did.needsToBeWritten()
+                  && !EntryBits.isRecoveredFromDisk(did.getUserBits()))/* fix for bug 41942 */) {
-    static boolean isOverflowedToDisk(DiskEntry de, DiskRegion dr, DistributedRegion.DiskPosition dp,RegionEntryContext context) {
+    static boolean isOverflowedToDisk(DiskEntry de, DiskRegion dr,
+        DistributedRegion.DiskPosition dp, RegionEntryContext context) {
-      synchronized (syncObj) {
-        if (de.isValueNull()) {
-          if (did == null) {
-            synchronized (de) {
-              did = de.getDiskId();
+        synchronized (syncObj) {
+          if (de.isValueNull()) {
+            if (did == null) {
+              synchronized (de) {
+                did = de.getDiskId();
+              }
+              assert did != null;
+              return isOverflowedToDisk(de, dr, dp, context);
+            } else {
+              dp.setPosition(did.getOplogId(), did.getOffsetInOplog());
+              return true;
-            assert did != null;
-            return isOverflowedToDisk(de, dr, dp, context);
-            dp.setPosition(did.getOplogId(), did.getOffsetInOplog());
-            return true;
+            return false;
-        } else {
-          return false;
-      }
-    
+
-     * Get the value of an entry that is on disk without faulting
-     * it in.
+     * Get the value of an entry that is on disk without faulting it in.
+     * 
-    static boolean fillInValue(DiskEntry de, InitialImageOperation.Entry entry,
-                               DiskRegion dr, DM mgr, ByteArrayDataInput in, RegionEntryContext context) {
-      @Retained @Released Object v = null;
+    static boolean fillInValue(DiskEntry de, InitialImageOperation.Entry entry, DiskRegion dr,
+        DM mgr, ByteArrayDataInput in, RegionEntryContext context) {
+      @Retained
+      @Released
+      Object v = null;
-      synchronized (syncObj) {
-        entry.setLastModified(mgr, de.getLastModified());
-                              
-        ReferenceCountHelper.setReferenceCountOwner(entry);
-        v = de._getValueRetain(context, true); // OFFHEAP copied to heap entry; todo allow entry to refer to offheap since it will be copied to network.
-        ReferenceCountHelper.setReferenceCountOwner(null);
-        if (v == null) {
-          if (did == null) {
-            // fix for bug 41449
-            synchronized (de) {
-              did = de.getDiskId();
+        synchronized (syncObj) {
+          entry.setLastModified(mgr, de.getLastModified());
+
+          ReferenceCountHelper.setReferenceCountOwner(entry);
+          v = de._getValueRetain(context, true); // OFFHEAP copied to heap entry; todo allow entry
+                                                 // to refer to offheap since it will be copied to
+                                                 // network.
+          ReferenceCountHelper.setReferenceCountOwner(null);
+          if (v == null) {
+            if (did == null) {
+              // fix for bug 41449
+              synchronized (de) {
+                did = de.getDiskId();
+              }
+              assert did != null;
+              // do recursive call to get readLock on did
+              return fillInValue(de, entry, dr, mgr, in, context);
-            assert did != null;
-            // do recursive call to get readLock on did
-            return fillInValue(de, entry, dr, mgr, in, context);
+            if (logger.isDebugEnabled()) {
+              logger.debug(
+                  "DiskEntry.Helper.fillInValue, key={}; getting value from disk, disk id={}",
+                  entry.key, did);
+            }
+            BytesAndBits bb = null;
+            try {
+              bb = dr.getBytesAndBits(did, false);
+            } catch (DiskAccessException dae) {
+              return false;
+            }
+            if (EntryBits.isInvalid(bb.getBits())) {
+              entry.setInvalid();
+            } else if (EntryBits.isLocalInvalid(bb.getBits())) {
+              entry.setLocalInvalid();
+            } else if (EntryBits.isTombstone(bb.getBits())) {
+              entry.setTombstone();
+            } else {
+              entry.value = bb.getBytes();
+              entry.setSerialized(EntryBits.isSerialized(bb.getBits()));
+            }
+            return true;
-          if (logger.isDebugEnabled()) {
-            logger.debug("DiskEntry.Helper.fillInValue, key={}; getting value from disk, disk id={}", entry.key, did);
-          }
-          BytesAndBits bb  = null;
-          try {
-            bb = dr.getBytesAndBits(did, false);
-          }catch(DiskAccessException dae){
-            return false;
-          }
-          if (EntryBits.isInvalid(bb.getBits())) {
-            entry.setInvalid();
-          }
-          else if (EntryBits.isLocalInvalid(bb.getBits())) {
-            entry.setLocalInvalid();
-          }
-          else if (EntryBits.isTombstone(bb.getBits())) {
-            entry.setTombstone();
-          }
-          else {
-            entry.value = bb.getBytes();
-            entry.setSerialized(EntryBits.isSerialized(bb.getBits()));
-          }
-          return true;
-      }
-            
+
-            
+
-              byte[] bb = (byte[])tmp;
+              byte[] bb = (byte[]) tmp;
-            }
-            else {
+            } else {
-                RuntimeException e2 = new IllegalArgumentException(LocalizedStrings.DiskEntry_AN_IOEXCEPTION_WAS_THROWN_WHILE_SERIALIZING.toLocalizedString());
+                RuntimeException e2 = new IllegalArgumentException(
+                    LocalizedStrings.DiskEntry_AN_IOEXCEPTION_WAS_THROWN_WHILE_SERIALIZING
+                        .toLocalizedString());
-      }
-      else if (v instanceof byte[]) {
+      } else if (v instanceof byte[]) {
-      }
-      else if (v == Token.INVALID) {
+      } else if (v == Token.INVALID) {
-      }
-      else if (v == Token.LOCAL_INVALID) {
+      } else if (v == Token.LOCAL_INVALID) {
-      }
-      else {
+      } else {
-      {
-        try {
-          HeapDataOutputStream hdos = new HeapDataOutputStream(Version.CURRENT);
-          BlobHelper.serializeTo(preparedValue, hdos);
-          hdos.trim();
-          entry.value = hdos;
-          entry.setSerialized(true);
-        } catch (IOException e) {
-          RuntimeException e2 = new IllegalArgumentException(LocalizedStrings.DiskEntry_AN_IOEXCEPTION_WAS_THROWN_WHILE_SERIALIZING.toLocalizedString());
-          e2.initCause(e);
-          throw e2;
+        {
+          try {
+            HeapDataOutputStream hdos = new HeapDataOutputStream(Version.CURRENT);
+            BlobHelper.serializeTo(preparedValue, hdos);
+            hdos.trim();
+            entry.value = hdos;
+            entry.setSerialized(true);
+          } catch (IOException e) {
+            RuntimeException e2 = new IllegalArgumentException(
+                LocalizedStrings.DiskEntry_AN_IOEXCEPTION_WAS_THROWN_WHILE_SERIALIZING
+                    .toLocalizedString());
+            e2.initCause(e);
+            throw e2;
+          }
-      }
-        drv = ((LocalRegion)r).getDiskRegion();
+        drv = ((LocalRegion) r).getDiskRegion();
-        drv = (DiskRegionView)r;
+        drv = (DiskRegionView) r;
-        throw new IllegalArgumentException(LocalizedStrings.DiskEntry_DISK_REGION_IS_NULL.toLocalizedString());
+        throw new IllegalArgumentException(
+            LocalizedStrings.DiskEntry_DISK_REGION_IS_NULL.toLocalizedString());
-        RecoveredEntry re = (RecoveredEntry)newValue;
+        RecoveredEntry re = (RecoveredEntry) newValue;
-          updateStats(drv, r, 0/*InVM*/, 1/*OnDisk*/, did.getValueLength());
-        }
-        else {
-          entry.setValueWithContext(drv, entry.prepareValueForCache((RegionEntryContext) r,
-              re.getValue(), false));
+          updateStats(drv, r, 0/* InVM */, 1/* OnDisk */, did.getValueLength());
+        } else {
+          entry.setValueWithContext(drv,
+              entry.prepareValueForCache((RegionEntryContext) r, re.getValue(), false));
-            updateStats(drv, r, 1/*InVM*/, 0/*OnDisk*/, 0);
+            updateStats(drv, r, 1/* InVM */, 0/* OnDisk */, 0);
-      }
-      else {
+      } else {
-          updateStats(drv, r, 1/*InVM*/, 0/*OnDisk*/, 0);
+          updateStats(drv, r, 1/* InVM */, 0/* OnDisk */, 0);
-    
+
-    private static final ValueWrapper LOCAL_INVALID_VW = new ByteArrayValueWrapper(true, LOCAL_INVALID_BYTES);
-    private static final ValueWrapper TOMBSTONE_VW = new ByteArrayValueWrapper(true, TOMBSTONE_BYTES);
-    
+    private static final ValueWrapper LOCAL_INVALID_VW =
+        new ByteArrayValueWrapper(true, LOCAL_INVALID_BYTES);
+    private static final ValueWrapper TOMBSTONE_VW =
+        new ByteArrayValueWrapper(true, TOMBSTONE_BYTES);
+
+
+
+
+
-      
-     public ByteArrayValueWrapper(boolean isSerializedObject, byte[] bytes) {
+
+      public ByteArrayValueWrapper(boolean isSerializedObject, byte[] bytes) {
-    
+
-     * This class is a bit of a hack used by the compactor.
-     * For the compactor always copies to a byte[] so
-     * this class is just a simple wrapper.
-     * It is possible that the length of the byte array is greater
-     * than the actual length of the wrapped data.
-     * At the time we create this we are all done with isSerialized
-     * and userBits so those methods are not supported.
+     * This class is a bit of a hack used by the compactor. For the compactor always copies to a
+     * byte[] so this class is just a simple wrapper. It is possible that the length of the byte
+     * array is greater than the actual length of the wrapped data. At the time we create this we
+     * are all done with isSerialized and userBits so those methods are not supported.
-      
+
-      
+
-    
+
-     * Note that the StoredObject this ValueWrapper is created with
-     * is unretained so it must be used before the owner of
-     * the StoredObject releases it.
-     * Since the RegionEntry that has the value we are writing to
-     * disk has it retained we are ok as long as this ValueWrapper's
-     * life ends before the RegionEntry sync is released.
-     * Note that this class is only used with uncompressed StoredObjects.
+     * Note that the StoredObject this ValueWrapper is created with is unretained so it must be used
+     * before the owner of the StoredObject releases it. Since the RegionEntry that has the value we
+     * are writing to disk has it retained we are ok as long as this ValueWrapper's life ends before
+     * the RegionEntry sync is released. Note that this class is only used with uncompressed
+     * StoredObjects.
+
+
+
+
+
-              bb.position(bb.position()+availableSpace);
+              bb.position(bb.position() + availableSpace);
-          bb.position(bb.position()+bytesRemaining);
+          bb.position(bb.position() + bytesRemaining);
+
-     * Returns true if the given object is off-heap
-     * and it is worth wrapping a reference to it
-     * instead of copying its data to the heap.
-     * Currently all StoredObject's with a refCount are
+     * Returns true if the given object is off-heap and it is worth wrapping a reference to it
+     * instead of copying its data to the heap. Currently all StoredObject's with a refCount are
-          // 
+          //
-    
+
-      }
-      else if (value == Token.LOCAL_INVALID) {
+      } else if (value == Token.LOCAL_INVALID) {
-      }
-      else if (value == Token.TOMBSTONE) {
+      } else if (value == Token.TOMBSTONE) {
-      }
-      else {
+      } else {
-          CachedDeserializable proxy = (CachedDeserializable)value;
+          CachedDeserializable proxy = (CachedDeserializable) value;
-        }
-        else if (value instanceof byte[]) {
+        } else if (value instanceof byte[]) {
-          bytes = (byte[])value;
-        }
-        else {
+          bytes = (byte[]) value;
+        } else {
-              throw new IllegalStateException("serializing <" + value + "> produced empty byte array");
+              throw new IllegalStateException(
+                  "serializing <" + value + "> produced empty byte array");
-    public static ValueWrapper createValueWrapperFromEntry(DiskEntry entry, LocalRegion region, EntryEventImpl event) {
+
+    public static ValueWrapper createValueWrapperFromEntry(DiskEntry entry, LocalRegion region,
+        EntryEventImpl event) {
-      @Retained Object value = entry._getValueRetain(region, true);
+      @Retained
+      Object value = entry._getValueRetain(region, true);
-    
-    private static void writeToDisk(DiskEntry entry, LocalRegion region, boolean async) throws RegionClearedException {
+
+    private static void writeToDisk(DiskEntry entry, LocalRegion region, boolean async)
+        throws RegionClearedException {
+     * 
-    private static void writeToDisk(DiskEntry entry, LocalRegion region, boolean async, EntryEventImpl event) throws RegionClearedException {
+    private static void writeToDisk(DiskEntry entry, LocalRegion region, boolean async,
+        EntryEventImpl event) throws RegionClearedException {
-    
-    private static void writeBytesToDisk(DiskEntry entry, LocalRegion region, boolean async, ValueWrapper vw) throws RegionClearedException {
+
+    private static void writeBytesToDisk(DiskEntry entry, LocalRegion region, boolean async,
+        ValueWrapper vw) throws RegionClearedException {
-    public static void update(DiskEntry entry, LocalRegion region, Object newValue) throws RegionClearedException {
+    public static void update(DiskEntry entry, LocalRegion region, Object newValue)
+        throws RegionClearedException {
+
-     * Updates the value of the disk entry with a new value. This allows us to
-     * free up disk space in the non-backup case.
+     * Updates the value of the disk entry with a new value. This allows us to free up disk space in
+     * the non-backup case.
-    public static void update(DiskEntry entry, LocalRegion region, Object newValue, EntryEventImpl event) throws RegionClearedException {
+    public static void update(DiskEntry entry, LocalRegion region, Object newValue,
+        EntryEventImpl event) throws RegionClearedException {
-        throw new NullPointerException(LocalizedStrings.DiskEntry_ENTRYS_VALUE_SHOULD_NOT_BE_NULL.toLocalizedString());
+        throw new NullPointerException(
+            LocalizedStrings.DiskEntry_ENTRYS_VALUE_SHOULD_NOT_BE_NULL.toLocalizedString());
-      
+
-    private static AsyncDiskEntry basicUpdate(DiskEntry entry, LocalRegion region, Object newValue, EntryEventImpl event) throws RegionClearedException {
+    private static AsyncDiskEntry basicUpdate(DiskEntry entry, LocalRegion region, Object newValue,
+        EntryEventImpl event) throws RegionClearedException {
-           // 47616: not to set the value to be removedFromDisk since it failed to persist
+            // 47616: not to set the value to be removedFromDisk since it failed to persist
-            entry.setValueWithContext(region, newValue); // OFFHEAP newValue was already preparedForCache
+            entry.setValueWithContext(region, newValue); // OFFHEAP newValue was already
+                                                         // preparedForCache
-      }
-      else if (newValue instanceof RecoveredEntry) {
+      } else if (newValue instanceof RecoveredEntry) {
-        RecoveredEntry re = (RecoveredEntry)newValue;
+        RecoveredEntry re = (RecoveredEntry) newValue;
-        
+
-          entry.setValueWithContext(region, entry.prepareValueForCache(region, re.getValue(), false));
+          entry.setValueWithContext(region,
+              entry.prepareValueForCache(region, re.getValue(), false));
-        
+
-            updateStats(dr, region, inVM, 1/*OnDisk*/, did.getValueLength());
+            updateStats(dr, region, inVM, 1/* OnDisk */, did.getValueLength());
-          if(oldKeyId < 0) { // the entry's old value is on disk
-            updateStats(dr, region, inVM, -1/*OnDisk*/, -oldValueLength);
+          if (oldKeyId < 0) { // the entry's old value is on disk
+            updateStats(dr, region, inVM, -1/* OnDisk */, -oldValueLength);
-      }
-      else {
-        //The new value in the entry needs to be set after the disk writing 
+      } else {
+        // The new value in the entry needs to be set after the disk writing
-        
-        //entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
-        
-        if(did != null && did.isPendingAsync()) {
-          //if the entry was not yet written to disk, we didn't update
-          //the bytes on disk.
+
+        // entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+
+        if (did != null && did.isPendingAsync()) {
+          // if the entry was not yet written to disk, we didn't update
+          // the bytes on disk.
-        
+
-              //In case of compression the value is being set first
-              //so that writeToDisk can get it back from the entry
-              //decompressed if it does not have it already in the event.
+              // In case of compression the value is being set first
+              // so that writeToDisk can get it back from the entry
+              // decompressed if it does not have it already in the event.
-              //       writeToDisk can throw RegionClearedException which
-              //       was supposed to stop us from changing entry.
+              // writeToDisk can throw RegionClearedException which
+              // was supposed to stop us from changing entry.
-            
+
-            //If we have concurrency checks enabled for a persistent region, we need
-            //to add an entry to the async queue for every update to maintain the RVV
+            // If we have concurrency checks enabled for a persistent region, we need
+            // to add an entry to the async queue for every update to maintain the RVV
-            
+
-              //if the entry is not async, we need to schedule it
-              //for regions with concurrency checks enabled, we add an entry
-              //to the queue for every entry.
+              // if the entry is not async, we need to schedule it
+              // for regions with concurrency checks enabled, we add an entry
+              // to the queue for every entry.
-              if(stamp != null) {
+              if (stamp != null) {
-          
+
-          //did.setValueSerializedSize(0);
-        }else {
+          // did.setValueSerializedSize(0);
+        } else {
-        
+
-            updateStats(dr, region, 0/*InVM*/, -1/*OnDisk*/, -oldValueLength);
-          } else if (!Token.isInvalidOrRemoved(oldValue)){
-            updateStats(dr, region, -1/*InVM*/, 0/*OnDisk*/, 0);
+            updateStats(dr, region, 0/* InVM */, -1/* OnDisk */, -oldValueLength);
+          } else if (!Token.isInvalidOrRemoved(oldValue)) {
+            updateStats(dr, region, -1/* InVM */, 0/* OnDisk */, 0);
-            updateStats(dr, region, 1/*InVM*/, -1/*OnDisk*/, -oldValueLength);
+            updateStats(dr, region, 1/* InVM */, -1/* OnDisk */, -oldValueLength);
-            updateStats(dr, region, 1/*InVM*/, 0/*OnDisk*/, 0/*overflowBytesOnDisk*/);
+            updateStats(dr, region, 1/* InVM */, 0/* OnDisk */, 0/* overflowBytesOnDisk */);
-        LRUEntry le = (LRUEntry)entry;
-        le.unsetEvicted();          
+        LRUEntry le = (LRUEntry) entry;
+        le.unsetEvicted();
-    public static void updateRecoveredEntry(PlaceHolderDiskRegion drv,
-                                              DiskEntry entry,
-                                              RecoveredEntry newValue,RegionEntryContext context)
-    {
+    public static void updateRecoveredEntry(PlaceHolderDiskRegion drv, DiskEntry entry,
+        RecoveredEntry newValue, RegionEntryContext context) {
-        throw new NullPointerException(LocalizedStrings.DiskEntry_ENTRYS_VALUE_SHOULD_NOT_BE_NULL.toLocalizedString());
+        throw new NullPointerException(
+            LocalizedStrings.DiskEntry_ENTRYS_VALUE_SHOULD_NOT_BE_NULL.toLocalizedString());
-          entry.setValueWithContext(context, entry.prepareValueForCache(drv, newValue.getValue(), 
-              false));
+          entry.setValueWithContext(context,
+              entry.prepareValueForCache(drv, newValue.getValue(), false));
-          if(oldValueWasNull) { // the entry's old value is on disk
-            updateStats(drv, null, inVM, -1/*OnDisk*/, -oldValueLength);
+          if (oldValueWasNull) { // the entry's old value is on disk
+            updateStats(drv, null, inVM, -1/* OnDisk */, -oldValueLength);
-            entry.setValueWithContext(context,null); // fixes bug 41119
+            entry.setValueWithContext(context, null); // fixes bug 41119
-            updateStats(drv, null, inVM, 1/*OnDisk*/, did.getValueLength());
+            updateStats(drv, null, inVM, 1/* OnDisk */, did.getValueLength());
-      Object result = OffHeapHelper.copyAndReleaseIfNeeded(getValueOffHeapOrDiskWithoutFaultIn(entry, region));
+      Object result =
+          OffHeapHelper.copyAndReleaseIfNeeded(getValueOffHeapOrDiskWithoutFaultIn(entry, region));
-        result = ((CachedDeserializable)result).getDeserializedValue(null, null);
+        result = ((CachedDeserializable) result).getDeserializedValue(null, null);
-    
+
-      @Retained Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
-      if (v == null || Token.isRemovedFromDisk(v)
-          && !region.isIndexCreationThread()) {
+      @Retained
+      Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v =
+                                                      // entry.getValueWithContext(region);
+      if (v == null || Token.isRemovedFromDisk(v) && !region.isIndexCreationThread()) {
-          v = entry._getValueRetain(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
+          v = entry._getValueRetain(region, true); // TODO:KIRK:OK v =
+                                                   // entry.getValueWithContext(region);
-            v = Helper.getOffHeapValueOnDiskOrBuffer(entry, region.getDiskRegion(),region);
+            v = Helper.getOffHeapValueOnDiskOrBuffer(entry, region.getDiskRegion(), region);
-//      } else if (v instanceof ByteSource) {
-//        // If the ByteSource contains a Delta or ListOfDelta then we want to deserialize it
-//        Object deserVal = ((CachedDeserializable)v).getDeserializedForReading();
-//        if (deserVal != v) {
-//          OffHeapHelper.release(v);
-//          v = deserVal;
-//        }
+        // } else if (v instanceof ByteSource) {
+        // // If the ByteSource contains a Delta or ListOfDelta then we want to deserialize it
+        // Object deserVal = ((CachedDeserializable)v).getDeserializedForReading();
+        // if (deserVal != v) {
+        // OffHeapHelper.release(v);
+        // v = deserVal;
+        // }
+
+
-    private static Object faultInValue(DiskEntry entry, LocalRegion region, boolean retainResult)
-    {
+    private static Object faultInValue(DiskEntry entry, LocalRegion region, boolean retainResult) {
-      @Retained Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
+      @Retained
+      Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v =
+                                                      // entry.getValueWithContext(region);
-      if ( entry instanceof LRUEntry && !dr.isSync() ) {
-        synchronized (entry) {
-          DiskId did = entry.getDiskId();
-          if (did != null && did.isPendingAsync()) {
-            done = true;
-            // See if it is pending async because of a faultOut.
-            // If so then if we are not a backup then we can unschedule the pending async.
-            // In either case we need to do the lruFaultIn logic.
-            boolean evicted = ((LRUEntry)entry).testEvicted();
-            if (evicted) {
-              if (!dr.isBackup()) {
-                // @todo do we also need a bit that tells us if it is in the async queue?
-                // Seems like we could end up adding it to the queue multiple times.
-                did.setPendingAsync(false);
+        if (entry instanceof LRUEntry && !dr.isSync()) {
+          synchronized (entry) {
+            DiskId did = entry.getDiskId();
+            if (did != null && did.isPendingAsync()) {
+              done = true;
+              // See if it is pending async because of a faultOut.
+              // If so then if we are not a backup then we can unschedule the pending async.
+              // In either case we need to do the lruFaultIn logic.
+              boolean evicted = ((LRUEntry) entry).testEvicted();
+              if (evicted) {
+                if (!dr.isBackup()) {
+                  // @todo do we also need a bit that tells us if it is in the async queue?
+                  // Seems like we could end up adding it to the queue multiple times.
+                  did.setPendingAsync(false);
+                }
+              lruEntryFaultIn((LRUEntry) entry, region);
+              lruFaultedIn = true;
-            lruEntryFaultIn((LRUEntry) entry, region);
-            lruFaultedIn = true;
-      }
-      if (!done
-          && (v == null || Token.isRemovedFromDisk(v) && !region.isIndexCreationThread())) {
-        synchronized (entry) {
-          v = entry._getValueRetain(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
-          if (v == null) {
-            v = readValueFromDisk(entry, region);
-            if (entry instanceof LRUEntry) {
-              if (v != null && !Token.isInvalid(v)) {
-                lruEntryFaultIn((LRUEntry) entry, region);
-                       
-                lruFaultedIn = true;
+        if (!done && (v == null || Token.isRemovedFromDisk(v) && !region.isIndexCreationThread())) {
+          synchronized (entry) {
+            v = entry._getValueRetain(region, true); // TODO:KIRK:OK v =
+                                                     // entry.getValueWithContext(region);
+            if (v == null) {
+              v = readValueFromDisk(entry, region);
+              if (entry instanceof LRUEntry) {
+                if (v != null && !Token.isInvalid(v)) {
+                  lruEntryFaultIn((LRUEntry) entry, region);
+
+                  lruFaultedIn = true;
+                }
-      }
-        ((RegionEntry)entry).setRecentlyUsed();
+        ((RegionEntry) entry).setRecentlyUsed();
-       lruUpdateCallback(region);
+        lruUpdateCallback(region);
-    
-    public static void recoverValue(DiskEntry entry, long oplogId, DiskRecoveryStore recoveryStore, ByteArrayDataInput in) {
+
+    public static void recoverValue(DiskEntry entry, long oplogId, DiskRecoveryStore recoveryStore,
+        ByteArrayDataInput in) {
-    
+
-     *  Caller must have "did" synced.
+     * Caller must have "did" synced.
-          did.setKeyId(- did.getKeyId());
+          did.setKeyId(-did.getKeyId());
-          BytesAndBits bb = (BytesAndBits)value;
+          BytesAndBits bb = (BytesAndBits) value;
-    
+
-      /* 
-       * Used conditional check to see if
-       * if its a LIFO Enabled,
-       * yes then disable lruUpdateCallback()
-       * and called updateStats()
-       * its keep track of actual entries
-       * present in memory - useful when 
-       * checking capacity constraint
-       */ 
+      /*
+       * Used conditional check to see if if its a LIFO Enabled, yes then disable
+       * lruUpdateCallback() and called updateStats() its keep track of actual entries present in
+       * memory - useful when checking capacity constraint
+       */
-      }catch( DiskAccessException dae) {
+      } catch (DiskAccessException dae) {
-    
+
-      RegionMap rm = (RegionMap)recoveryStore.getRegionMap();
+      RegionMap rm = (RegionMap) recoveryStore.getRegionMap();
-      }catch(DiskAccessException dae) {
+      } catch (DiskAccessException dae) {
-    
+
-     * Returns the value of this map entry, reading it from disk, if necessary.
-     * Sets the value in the entry.
-     * This is only called by the faultIn code once it has determined that
-     * the value is no longer in memory.
-     * Caller must have "entry" synced.
+     * Returns the value of this map entry, reading it from disk, if necessary. Sets the value in
+     * the entry. This is only called by the faultIn code once it has determined that the value is
+     * no longer in memory. Caller must have "entry" synced.
-      synchronized (did) {
-        Object value = getValueFromDisk(dr, did, null);
-        if (value == null) return null;
-        setValueOnFaultIn(value, did, entry, dr, region);
-        return value;
-      }
+        synchronized (did) {
+          Object value = getValueFromDisk(dr, did, null);
+          if (value == null)
+            return null;
+          setValueOnFaultIn(value, did, entry, dr, region);
+          return value;
+        }
-    
+
-     * @return the unretained result must be used by the caller before it releases the sync on "entry".
+     * 
+     * @return the unretained result must be used by the caller before it releases the sync on
+     *         "entry".
-    private static Object setValueOnFaultIn(Object value, DiskId did, DiskEntry entry, DiskRegionView dr, DiskRecoveryStore region) {
-//    dr.getOwner().getCache().getLogger().info("DEBUG: faulting in entry with key " + entry.getKey());
+    private static Object setValueOnFaultIn(Object value, DiskId did, DiskEntry entry,
+        DiskRegionView dr, DiskRecoveryStore region) {
+      // dr.getOwner().getCache().getLogger().info("DEBUG: faulting in entry with key " +
+      // entry.getKey());
-      // NOTE that we return this value unretained because the retain is owned by the region entry not the caller.
-      @Retained Object preparedValue = entry.prepareValueForCache((RegionEntryContext) region, value,
-          false);
-      region.updateSizeOnFaultIn(entry.getKey(), region.calculateValueSize(preparedValue), bytesOnDisk);
-      //did.setValueSerializedSize(0);
+      // NOTE that we return this value unretained because the retain is owned by the region entry
+      // not the caller.
+      @Retained
+      Object preparedValue = entry.prepareValueForCache((RegionEntryContext) region, value, false);
+      region.updateSizeOnFaultIn(entry.getKey(), region.calculateValueSize(preparedValue),
+          bytesOnDisk);
+      // did.setValueSerializedSize(0);
-      //Assert.assertTrue(entry._getValue() == null);
+      // Assert.assertTrue(entry._getValue() == null);
-        updateStats(dr, region, 1/*InVM*/, -1/*OnDisk*/, -bytesOnDisk);
+        updateStats(dr, region, 1/* InVM */, -1/* OnDisk */, -bytesOnDisk);
-    static Object readSerializedValue(byte[] valueBytes, Version version,
-        ByteArrayDataInput in, boolean forceDeserialize) {
+    static Object readSerializedValue(byte[] valueBytes, Version version, ByteArrayDataInput in,
+        boolean forceDeserialize) {
-      }
-      else {
+      } else {
-    static Object readRawValue(byte[] valueBytes, Version version,
-        ByteArrayDataInput in) {
+    static Object readRawValue(byte[] valueBytes, Version version, ByteArrayDataInput in) {
-    public static void updateStats(DiskRegionView drv, Object owner,
-        int entriesInVmDelta,
-        int overflowOnDiskDelta,
-        int overflowBytesOnDiskDelta) {
+    public static void updateStats(DiskRegionView drv, Object owner, int entriesInVmDelta,
+        int overflowOnDiskDelta, int overflowBytesOnDiskDelta) {
-     * Writes the value of this <code>DiskEntry</code> to disk and
-     * <code>null</code> s out the reference to the value to free up VM space.
+     * Writes the value of this <code>DiskEntry</code> to disk and <code>null</code> s out the
+     * reference to the value to free up VM space.
-     * Note that if the value had already been written to disk, it is not
-     * written again.
+     * Note that if the value had already been written to disk, it is not written again.
+     * 
-    public static int overflowToDisk(DiskEntry entry, LocalRegion region, EnableLRU ccHelper) throws RegionClearedException {
+    public static int overflowToDisk(DiskEntry entry, LocalRegion region, EnableLRU ccHelper)
+        throws RegionClearedException {
-      //Asif:Get diskID . If it is null, it implies it is
+      // Asif:Get diskID . If it is null, it implies it is
-      //long id = entry.getDiskId().getKeyId();
+      // long id = entry.getDiskId().getKeyId();
-        ((LRUEntry)entry).setDelayedDiskId(region);
+        ((LRUEntry) entry).setDelayedDiskId(region);
-      
+
-      synchronized (did) {
-        // check for a concurrent freeAllEntriesOnDisk which syncs on DiskId but not on the entry
-        if (entry.isRemovedFromDisk()) {
-          return 0;
-        }
+        synchronized (did) {
+          // check for a concurrent freeAllEntriesOnDisk which syncs on DiskId but not on the entry
+          if (entry.isRemovedFromDisk()) {
+            return 0;
+          }
-        //TODO:Asif: Check if we need to overflow even when id is = 0
-        boolean wasAlreadyPendingAsync = did.isPendingAsync();
-        if (did.needsToBeWritten()) {
-          if (dr.isSync()) {
-            writeToDisk(entry, region, false);
-          } else if (!wasAlreadyPendingAsync) {
-            scheduledAsyncHere = true;
-            did.setPendingAsync(true);
+          // TODO:Asif: Check if we need to overflow even when id is = 0
+          boolean wasAlreadyPendingAsync = did.isPendingAsync();
+          if (did.needsToBeWritten()) {
+            if (dr.isSync()) {
+              writeToDisk(entry, region, false);
+            } else if (!wasAlreadyPendingAsync) {
+              scheduledAsyncHere = true;
+              did.setPendingAsync(true);
+            } else {
+              // it may have been scheduled to be written (isBackup==true)
+              // and now we are faulting it out
+            }
+          }
+
+          // If async then if it does not need to be written (because it already was)
+          // then treat it like the sync case. This fixes bug 41310
+          if (scheduledAsyncHere || wasAlreadyPendingAsync) {
+            // we call _setValue(null) after it is actually written to disk
+            change = entry.updateAsyncEntrySize(ccHelper);
+            // do the stats when it is actually written to disk
-            // it may have been scheduled to be written (isBackup==true)
-            // and now we are faulting it out
+            region.updateSizeOnEvict(entry.getKey(), oldSize);
+            entry.handleValueOverflow(region);
+            entry.setValueWithContext(region, null);
+            change = ((LRUClockNode) entry).updateEntrySize(ccHelper);
+            // the caller checked to make sure we had something to overflow
+            // so dec inVM and inc onDisk
+            updateStats(dr, region, -1/* InVM */, 1/* OnDisk */, getValueLength(did));
-        
-        // If async then if it does not need to be written (because it already was)
-        // then treat it like the sync case. This fixes bug 41310
-        if (scheduledAsyncHere || wasAlreadyPendingAsync) {
-          // we call _setValue(null) after it is actually written to disk
-          change = entry.updateAsyncEntrySize(ccHelper);
-          // do the stats when it is actually written to disk
-        } else {
-          region.updateSizeOnEvict(entry.getKey(), oldSize);
-          entry.handleValueOverflow(region);
-          entry.setValueWithContext(region,null);
-          change = ((LRUClockNode)entry).updateEntrySize(ccHelper);
-          // the caller checked to make sure we had something to overflow
-          // so dec inVM and inc onDisk
-          updateStats(dr, region, -1/*InVM*/, 1/*OnDisk*/, getValueLength(did));
-        }
-      }
-    
+
-    
+
-      if (region.isThisRegionBeingClosedOrDestroyed()) return;
+      if (region.isThisRegionBeingClosedOrDestroyed())
+        return;
-    
+
+     * 
+
-     * Does a synchronous write to disk for a region that uses async.
-     * This method is used by both doAsyncFlush and handleFullAsyncQueue to fix GEODE-1700.
-     * @param asyncQueueWasFull true if caller wanted to put this entry in the queue
-     *        but could not do so because it was full
+     * Does a synchronous write to disk for a region that uses async. This method is used by both
+     * doAsyncFlush and handleFullAsyncQueue to fix GEODE-1700.
+     * 
+     * @param asyncQueueWasFull true if caller wanted to put this entry in the queue but could not
+     *        do so because it was full
-    private static void writeEntryToDisk(DiskEntry entry, LocalRegion region, VersionTag tag, boolean asyncQueueWasFull) {
-      if (region.isThisRegionBeingClosedOrDestroyed()) return;
+    private static void writeEntryToDisk(DiskEntry entry, LocalRegion region, VersionTag tag,
+        boolean asyncQueueWasFull) {
+      if (region.isThisRegionBeingClosedOrDestroyed())
+        return;
-      try {
-      dr.acquireReadLock();
-      try {
-        DiskId did = entry.getDiskId();
-        synchronized (did) {
-          if (did.isPendingAsync()) {
-            did.setPendingAsync(false);
-            final Token entryVal = entry.getValueAsToken();
-            final int entryValSize = region.calculateRegionEntryValueSize(entry);
-            try {
-              if (Token.isRemovedFromDisk(entryVal)) {
-                if (region.isThisRegionBeingClosedOrDestroyed()) return;
-                dr.remove(region, entry, true, false);
-                if (dr.isBackup()) {
-                  did.setKeyId(DiskRegion.INVALID_ID); // fix for bug 41340
+        try {
+          dr.acquireReadLock();
+          try {
+            DiskId did = entry.getDiskId();
+            synchronized (did) {
+              if (did.isPendingAsync()) {
+                did.setPendingAsync(false);
+                final Token entryVal = entry.getValueAsToken();
+                final int entryValSize = region.calculateRegionEntryValueSize(entry);
+                try {
+                  if (Token.isRemovedFromDisk(entryVal)) {
+                    if (region.isThisRegionBeingClosedOrDestroyed())
+                      return;
+                    dr.remove(region, entry, true, false);
+                    if (dr.isBackup()) {
+                      did.setKeyId(DiskRegion.INVALID_ID); // fix for bug 41340
+                    }
+                  } else if ((Token.isInvalid(entryVal) || entryVal == Token.TOMBSTONE)
+                      && !dr.isBackup()) {
+                    // no need to write invalid or tombstones to disk if overflow only
+                  } else if (entryVal != null) {
+                    writeToDisk(entry, region, true);
+                    assert !dr.isSync();
+                    // Only setValue to null if this was an evict.
+                    // We could just be a backup that is writing async.
+                    if (!Token.isInvalid(entryVal) && (entryVal != Token.TOMBSTONE)
+                        && entry instanceof LRUEntry && ((LRUEntry) entry).testEvicted()) {
+                      // Moved this here to fix bug 40116.
+                      region.updateSizeOnEvict(entry.getKey(), entryValSize);
+                      updateStats(dr, region, -1/* InVM */, 1/* OnDisk */, did.getValueLength());
+                      entry.handleValueOverflow(region);
+                      entry.setValueWithContext(region, null);
+                    }
+                  } else {
+                    // if we have a version tag we need to record the operation
+                    // to update the RVV
+                    if (tag != null) {
+                      DiskEntry.Helper.doAsyncFlush(tag, region);
+                    }
+                    return;
+                  }
+                } catch (RegionClearedException ignore) {
+                  // no need to do the op since it was clobbered by a region clear
-              } else if ((Token.isInvalid(entryVal) || entryVal == Token.TOMBSTONE) && !dr.isBackup()) {
-                // no need to write invalid or tombstones to disk if overflow only
-              } else if (entryVal != null) {
-                writeToDisk(entry, region, true);
-                assert !dr.isSync();
-                // Only setValue to null if this was an evict.
-                // We could just be a backup that is writing async.
-                if (!Token.isInvalid(entryVal)
-                    && (entryVal != Token.TOMBSTONE)
-                    && entry instanceof LRUEntry
-                    && ((LRUEntry)entry).testEvicted()) {
-                  // Moved this here to fix bug 40116.
-                  region.updateSizeOnEvict(entry.getKey(), entryValSize);
-                  updateStats(dr, region, -1/*InVM*/, 1/*OnDisk*/, did.getValueLength());
-                  entry.handleValueOverflow(region);
-                  entry.setValueWithContext(region,null);
-                }
-              } else {
-                //if we have a version tag we need to record the operation
-                //to update the RVV
-                if(tag != null) {
+
+                // See if we the entry we wrote to disk has the same tag
+                // as this entry. If not, write the tag as a conflicting operation.
+                // to update the RVV.
+                VersionStamp stamp = entry.getVersionStamp();
+                if (tag != null && stamp != null && (stamp.getMemberID() != tag.getMemberID()
+                    || stamp.getRegionVersion() != tag.getRegionVersion())) {
-                return;
+              } else {
+                // if we have a version tag we need to record the operation
+                // to update the RVV
+                if (tag != null) {
+                  DiskEntry.Helper.doAsyncFlush(tag, region);
+                }
-            } catch (RegionClearedException ignore) {
-              // no need to do the op since it was clobbered by a region clear
-            
-            //See if we the entry we wrote to disk has the same tag
-            //as this entry. If not, write the tag as a conflicting operation.
-            //to update the RVV.
-            VersionStamp stamp = entry.getVersionStamp();
-            if(tag != null && stamp != null 
-                && (stamp.getMemberID() != tag.getMemberID() 
-                || stamp.getRegionVersion() != tag.getRegionVersion())) {
-              DiskEntry.Helper.doAsyncFlush(tag, region);
-            }
-          } else {
-            //if we have a version tag we need to record the operation
-            //to update the RVV
-            if(tag != null) {
-              DiskEntry.Helper.doAsyncFlush(tag, region);
-            }
+          } finally {
+            dr.releaseReadLock();
+          }
+        } finally {
+          if (!asyncQueueWasFull) {
+            dr.removeClearCountReference();
-      } finally {
-        dr.releaseReadLock();
-      }
-      } finally {
-        if (!asyncQueueWasFull) {
-          dr.removeClearCountReference();
-        }
-      }
-    
+
-     * @throws RegionClearedException If the operation is aborted due to a clear 
+     * @throws RegionClearedException If the operation is aborted due to a clear
-    public static void removeFromDisk(DiskEntry entry, LocalRegion region, boolean isClear) throws RegionClearedException {
+    public static void removeFromDisk(DiskEntry entry, LocalRegion region, boolean isClear)
+        throws RegionClearedException {
-    private static AsyncDiskEntry basicRemoveFromDisk(DiskEntry entry, LocalRegion region, boolean isClear) throws RegionClearedException {
+    private static AsyncDiskEntry basicRemoveFromDisk(DiskEntry entry, LocalRegion region,
+        boolean isClear) throws RegionClearedException {
-      if (did == null || (dr.isBackup() && did.getKeyId()== DiskRegion.INVALID_ID)) {
+      if (did == null || (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID)) {
-          updateStats(dr, region, -1/*InVM*/, 0/*OnDisk*/, 0);
+          updateStats(dr, region, -1/* InVM */, 0/* OnDisk */, 0);
-      
-      //Asif: This will convert the -ve OplogKeyId to positive as part of fixing
-      //Bug # 39989
+
+      // Asif: This will convert the -ve OplogKeyId to positive as part of fixing
+      // Bug # 39989
-      //System.out.println("DEBUG: removeFromDisk doing remove(" + id + ")");
+      // System.out.println("DEBUG: removeFromDisk doing remove(" + id + ")");
-        //If this is a clear, we should unschedule the async write for this
-        //entry
+        // If this is a clear, we should unschedule the async write for this
+        // entry
-        //If we have concurrency checks enabled for a persistent region, we need
-        //to add an entry to the async queue for every update to maintain the RVV
+        // If we have concurrency checks enabled for a persistent region, we need
+        // to add an entry to the async queue for every update to maintain the RVV
-          if(stamp != null) {
+          if (stamp != null) {
-        updateStats(dr, region, 0/*InVM*/, -1/*OnDisk*/, -oldValueLength);
+        updateStats(dr, region, 0/* InVM */, -1/* OnDisk */, -oldValueLength);
-        updateStats(dr, region, -1/*InVM*/, 0/*OnDisk*/, 0);
+        updateStats(dr, region, -1/* InVM */, 0/* OnDisk */, 0);
-    public static void updateVersionOnly(DiskEntry entry, LocalRegion region,
-        VersionTag tag) {
+    public static void updateVersionOnly(DiskEntry entry, LocalRegion region, VersionTag tag) {
-      
-      assert tag != null && tag.getMemberID()!=null;
+
+      assert tag != null && tag.getMemberID() != null;
-   * A marker object for an entry that has been recovered from disk.
-   * It is handled specially when it is placed in a region.
+   * A marker object for an entry that has been recovered from disk. It is handled specially when it
+   * is placed in a region.
-     * Only for this constructor, the value is not loaded into the region & it is lying
-     * on the oplogs. Since Oplogs rely on DiskId to furnish user bits so as to correctly 
-     * interpret bytes, the userbit needs to be set correctly here.
+     * Only for this constructor, the value is not loaded into the region & it is lying on the
+     * oplogs. Since Oplogs rely on DiskId to furnish user bits so as to correctly interpret bytes,
+     * the userbit needs to be set correctly here.
-    public RecoveredEntry(long keyId, long oplogId, long offsetInOplog,
-                          byte userBits, int valueLength) {
+    public RecoveredEntry(long keyId, long oplogId, long offsetInOplog, byte userBits,
+        int valueLength) {
-    public RecoveredEntry(long keyId, long oplogId, long offsetInOplog,
-                          byte userBits, int valueLength, Object value) {
+    public RecoveredEntry(long keyId, long oplogId, long offsetInOplog, byte userBits,
+        int valueLength, Object value) {
+
-     * Returns the value of the recovered entry. Note that if the
-     * disk id is < 0 then the value has not been faulted in and
-     * this method will return null.
+     * Returns the value of the recovered entry. Note that if the disk id is < 0 then the value has
+     * not been faulted in and this method will return null.
+
-     * @return byte indicating the user bits. The correct value is returned only in the specific case of
-     * entry  recovered from oplog ( & not rolled to Htree) & the RECOVER_VALUES flag is false . In other cases
-     * the exact value is not needed
+     * @return byte indicating the user bits. The correct value is returned only in the specific
+     *         case of entry recovered from oplog ( & not rolled to Htree) & the RECOVER_VALUES flag
+     *         is false . In other cases the exact value is not needed
+
+
+
+
+

UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 INS66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66 DEL66