Merge branch 'feature/GEODE-8' into develop

+import java.util.concurrent.atomic.AtomicReference;
+import com.gemstone.gemfire.GemFireIOException;
+import com.gemstone.gemfire.cache.CustomEvictionAttributes;
+import com.gemstone.gemfire.cache.EvictionCriteria;
+import com.gemstone.gemfire.cache.hdfs.HDFSIOException;
+import com.gemstone.gemfire.cache.hdfs.internal.hoplog.HoplogOrganizer;
+import com.gemstone.gemfire.internal.cache.wan.parallel.ConcurrentParallelGatewaySenderQueue;
+import com.gemstone.gemfire.internal.offheap.StoredObject;
+import com.gemstone.gemfire.internal.offheap.annotations.Unretained;
+import com.gemstone.gemfire.internal.concurrent.AtomicLong5;
+
-  private volatile AtomicLong eventSeqNum = null;
+  private volatile AtomicLong5 eventSeqNum = null;
-  public AtomicLong getEventSeqNum() {
+  public AtomicLong5 getEventSeqNum() {
+  protected final AtomicReference<HoplogOrganizer> hoplog = new AtomicReference<HoplogOrganizer>();
+  
-          parentBucket.eventSeqNum = new AtomicLong(getId());
+          parentBucket.eventSeqNum = new AtomicLong5(getId());
-        this.eventSeqNum = new AtomicLong(getId());
+        this.eventSeqNum = new AtomicLong5(getId());
-        if (!(this instanceof BucketRegionQueue)) {
-          forceSerialized(event);
-        }
+        forceSerialized(event);
+  
+  public long generateTailKey() {
+    long key = this.eventSeqNum.addAndGet(this.partitionedRegion
+        .getTotalNumberOfBuckets());
+    if (key < 0
+        || key % getPartitionedRegion().getTotalNumberOfBuckets() != getId()) {
+      logger
+          .error(LocalizedMessage
+              .create(
+                  LocalizedStrings.GatewaySender_SEQUENCENUMBER_GENERATED_FOR_EVENT_IS_INVALID,
+                  new Object[] { key, getId() }));
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug("WAN: On primary bucket {}, setting the seq number as {}",
+          getId(), this.eventSeqNum.get());
+    }
+    return eventSeqNum.get();
+  }
+  
-    if (!(this instanceof BucketRegionQueue)) {
+    if (!(this instanceof AbstractBucketRegionQueue)) {
-  private void beginLocalWrite(EntryEventImpl event) {
+  private boolean beginLocalWrite(EntryEventImpl event) {
-      return;
+      return false;
-      lockedForPrimary = true;
+      return lockedForPrimary = true;
+      // increment the tailKey so that invalidate operations are written to HDFS
+      if (this.partitionedRegion.hdfsStoreName != null) {
+        /* MergeGemXDHDFSToGFE Disabled this while porting. Is this required? */
+        //assert this.partitionedRegion.isLocalParallelWanEnabled();
+        handleWANEvent(event);
+      }
+      // In GemFire EVICT_DESTROY is not distributed, so in order to remove the entry
+      // from memory, allow the destroy to proceed. fixes #49784
+      if (event.isLoadedFromHDFS() && !getBucketAdvisor().isPrimary()) {
+        if (logger.isDebugEnabled()) {
+          logger.debug("Put the destory event in HDFS queue on secondary "
+              + "and return as event is HDFS loaded " + event);
+        }
+        notifyGatewaySender(EnumListenerEvent.AFTER_DESTROY, event);
+        return;
+      }else{
+        if (logger.isDebugEnabled()) {
+          logger.debug("Going ahead with the destroy on GemFire system");
+        }
+      }
-  
+
+  @Override
+  public boolean isHDFSRegion() {
+    return this.partitionedRegion.isHDFSRegion();
+  }
+
+  @Override
+  public boolean isHDFSReadWriteRegion() {
+    return this.partitionedRegion.isHDFSReadWriteRegion();
+  }
+
+  @Override
+  protected boolean isHDFSWriteOnly() {
+    return this.partitionedRegion.isHDFSWriteOnly();
+  }
+
+  @Override
+  public int sizeEstimate() {
+    if (isHDFSReadWriteRegion()) {
+      try {
+        checkForPrimary();
+        ConcurrentParallelGatewaySenderQueue q = getHDFSQueue();
+        if (q == null) return 0;
+        int hdfsBucketRegionSize = q.getBucketRegionQueue(
+            partitionedRegion, getId()).size();
+        int hoplogEstimate = (int) getHoplogOrganizer().sizeEstimate();
+        if (logger.isDebugEnabled()) {
+          logger.debug("for bucket " + getName() + " estimateSize returning "
+                  + (hdfsBucketRegionSize + hoplogEstimate));
+        }
+        return hdfsBucketRegionSize + hoplogEstimate;
+      } catch (ForceReattemptException e) {
+        throw new PrimaryBucketException(e.getLocalizedMessage(), e);
+      }
+    }
+    return size();
+  }
+
-   * @see LocalRegion#getDeserializedValue(KeyInfo, boolean, boolean, boolean, EntryEventImpl, boolean)
+   * see LocalRegion#getDeserializedValue(RegionEntry, KeyInfo, boolean, boolean,  boolean, EntryEventImpl, boolean, boolean, boolean)
-  private RawValue getSerialized(Object key, boolean updateStats, boolean doNotLockEntry, EntryEventImpl clientEvent, boolean returnTombstones) 
+  private RawValue getSerialized(Object key, boolean updateStats, boolean doNotLockEntry, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) 
-    RegionEntry re = this.entries.getEntry(key);
+    RegionEntry re = null;
+    if (allowReadFromHDFS) {
+      re = this.entries.getEntry(key);
+    } else {
+      re = this.entries.getOperationalEntryInVM(key);
+    }
-  public RawValue getSerialized(KeyInfo keyInfo, boolean generateCallbacks, boolean doNotLockEntry, EntryEventImpl clientEvent, boolean returnTombstones) throws IOException {
+  public RawValue getSerialized(KeyInfo keyInfo, boolean generateCallbacks, boolean doNotLockEntry, EntryEventImpl clientEvent, boolean returnTombstones, boolean allowReadFromHDFS) throws IOException {
-      RawValue result = getSerialized(keyInfo.getKey(), true, doNotLockEntry, clientEvent, returnTombstones);
+      RawValue result = getSerialized(keyInfo.getKey(), true, doNotLockEntry, clientEvent, returnTombstones, allowReadFromHDFS);
-              generateCallbacks, result.getRawValue(), true, true, clientEvent, false);
+              generateCallbacks, result.getRawValue(), true, true, clientEvent, false, allowReadFromHDFS);
+    boolean returned = false;
+    try {
+    returned = true;
+    } finally {
+      if (!returned) {
+        e2.release();
+      }
+    }
+    try {
+    } finally {
+      prevent.release();
+    }
+    try {
+    } finally {
+      prevent.release();
+    }
+    try {
+    } finally {
+      prevent.release();
+    }
+    try {
+    } finally {
+      prevent.release();
+    }
-      Object rawNewValue = event.getRawNewValue();
+      @Unretained Object rawNewValue = event.getRawNewValue();
+      if (rawNewValue instanceof StoredObject && !((StoredObject) rawNewValue).isSerialized()) {
+        // it is a byte[]; not a Delta
+        return;
+      }
-      value = ((GatewaySenderEventImpl)value).getValue();
+      return ((GatewaySenderEventImpl)value).getSerializedValueSize();
+    // Gemfire PRs don't support clear. allowing it via a hack for tests
+    else if (LocalRegion.simulateClearForTests) {
+      oldMemValue = this.bytesInMemory.getAndSet(0);
+    }
-  protected void setHeapThresholdFlag(MemoryEvent event) {
+  protected void setMemoryThresholdFlag(MemoryEvent event) {
+  @Override
+  public void cleanupFailedInitialization()
+  {
+    this.preDestroyBucket(this.getId());
+    super.cleanupFailedInitialization();
+  }
-  protected boolean isHeapThresholdReachedForLoad() {
+  protected boolean isMemoryThresholdReachedForLoad() {
-    // dummy method. Can be used in future to execute code before
-    // this bucket becomes primary. Currently used only in BucketRegionQueue
+    try {
+      createHoplogOrganizer();
+    } catch (IOException e) {
+      // 48990: when HDFS was down, gemfirexd should still start normally
+      logger.warn(LocalizedStrings.HOPLOG_NOT_STARTED_YET, e);
+    } catch(Throwable e) {
+      /*MergeGemXDHDFSToGFE changed this code to checkReadiness*/
+      // SystemFailure.checkThrowable(e);
+      this.checkReadiness();
+      //49333 - no matter what, we should elect a primary.
+      logger.error(LocalizedStrings.LocalRegion_UNEXPECTED_EXCEPTION, e);
+    }
+  }
+
+  public HoplogOrganizer<?> createHoplogOrganizer() throws IOException {
+    if (getPartitionedRegion().isHDFSRegion()) {
+      HoplogOrganizer<?> organizer = hoplog.get();
+      if (organizer != null) {
+        //  hoplog is recreated by anther thread
+        return organizer;
+      }
+
+      HoplogOrganizer hdfs = hoplog.getAndSet(getPartitionedRegion().hdfsManager.create(getId()));
+      assert hdfs == null;
+      return hoplog.get();
+    } else {
+      return null;
+    }
+  /**
+   * Invoked when a primary bucket is demoted.
+   */
+  public void beforeReleasingPrimaryLockDuringDemotion() {
+    releaseHoplogOrganizer();
+  }
+
+  protected void releaseHoplogOrganizer() {
+    // release resources during a clean transition
+    HoplogOrganizer hdfs = hoplog.getAndSet(null);
+    if (hdfs != null) {
+      getPartitionedRegion().hdfsManager.close(getId());
+    }
+  }
+  
+  public HoplogOrganizer<?> getHoplogOrganizer() throws HDFSIOException {
+    HoplogOrganizer<?> organizer = hoplog.get();
+    if (organizer == null) {
+      synchronized (getBucketAdvisor()) {
+        checkForPrimary();
+        try {
+          organizer = createHoplogOrganizer();
+        } catch (IOException e) {
+          throw new HDFSIOException("Failed to create Hoplog organizer due to ", e);
+        }
+        if (organizer == null) {
+          throw new HDFSIOException("Hoplog organizer is not available for " + this);
+        }
+      }
+    }
+    return organizer;
+  }
+
+  @Override
+  public void hdfsCalled(Object key) {
+    this.partitionedRegion.hdfsCalled(key);
+  }
+
+  @Override
+  protected void clearHDFSData() {
+    //clear the HDFS data if present
+    if (getPartitionedRegion().isHDFSReadWriteRegion()) {
+      // Clear the queue
+      ConcurrentParallelGatewaySenderQueue q = getHDFSQueue();
+      if (q == null) return;
+      q.clear(getPartitionedRegion(), this.getId());
+      HoplogOrganizer organizer = hoplog.get();
+      if (organizer != null) {
+        try {
+          organizer.clear();
+        } catch (IOException e) {
+          throw new GemFireIOException(LocalizedStrings.HOPLOG_UNABLE_TO_DELETE_HDFS_DATA.toLocalizedString(), e);
+        }
+      }
+    }
+  }
+  
+  public EvictionCriteria getEvictionCriteria() {
+    return this.partitionedRegion.getEvictionCriteria();
+  }
+  
+  public CustomEvictionAttributes getCustomEvictionAttributes() {
+    return this.partitionedRegion.getCustomEvictionAttributes();
+  }
+  
+  /**
+   * @return true if the evict destroy was done; false if it was not needed
+   */
+  public boolean customEvictDestroy(Object key)
+  {
+    checkReadiness();
+    final EntryEventImpl event = 
+          generateCustomEvictDestroyEvent(key);
+    event.setCustomEviction(true);
+    boolean locked = false;
+    try {
+      locked = beginLocalWrite(event);
+      return mapDestroy(event,
+                        false, // cacheWrite
+                        true,  // isEviction
+                        null); // expectedOldValue
+    }
+    catch (CacheWriterException error) {
+      throw new Error(LocalizedStrings.LocalRegion_CACHE_WRITER_SHOULD_NOT_HAVE_BEEN_CALLED_FOR_EVICTDESTROY.toLocalizedString(), error);
+    }
+    catch (TimeoutException anotherError) {
+      throw new Error(LocalizedStrings.LocalRegion_NO_DISTRIBUTED_LOCK_SHOULD_HAVE_BEEN_ATTEMPTED_FOR_EVICTDESTROY.toLocalizedString(), anotherError);
+    }
+    catch (EntryNotFoundException yetAnotherError) {
+      throw new Error(LocalizedStrings.LocalRegion_ENTRYNOTFOUNDEXCEPTION_SHOULD_BE_MASKED_FOR_EVICTDESTROY.toLocalizedString(), yetAnotherError);
+    } finally {
+      if (locked) {
+        endLocalWrite(event);
+      }
+      event.release();
+    }
+  }
+
+  public boolean areSecondariesPingable() {
+    
+    Set<InternalDistributedMember> hostingservers = this.partitionedRegion.getRegionAdvisor()
+        .getBucketOwners(this.getId());
+    hostingservers.remove(cache.getDistributedSystem().getDistributedMember());
+    
+    if (cache.getLoggerI18n().fineEnabled())
+      cache.getLoggerI18n().fine("Pinging secondaries of bucket " + this.getId() + " on servers "  + hostingservers);
+   
+    if (hostingservers.size() == 0)
+      return true;
+    
+     return ServerPingMessage.send(cache, hostingservers);
+    
+  }
+  
+  @Override
+  public boolean notifiesMultipleSerialGateways() {
+    return getPartitionedRegion().notifiesMultipleSerialGateways();
+  }
+  

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 UPD43 UPD43 INS83 INS83 INS74 INS59 INS83 INS39 INS42 INS8 UPD39 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS44 INS44 INS8 UPD42 INS78 INS83 INS39 INS42 INS8 UPD42 INS8 INS83 INS74 INS42 INS43 INS8 INS29 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS74 INS42 INS43 INS8 INS78 INS83 INS39 INS42 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS83 INS43 INS42 INS8 INS83 INS43 INS42 INS8 INS29 INS83 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 UPD42 UPD42 INS43 INS43 INS42 INS14 INS60 INS25 INS25 INS41 INS42 INS41 INS42 INS41 INS42 INS41 INS42 INS25 INS41 INS39 INS42 INS25 INS39 INS42 MOV60 INS60 INS54 INS54 INS54 INS54 INS54 INS42 INS21 INS21 INS54 INS43 INS76 INS42 INS25 INS65 INS21 INS60 INS25 INS43 INS76 INS42 INS60 INS25 INS41 INS42 INS43 INS42 INS21 INS42 INS25 INS42 INS41 INS42 INS41 INS65 INS43 INS42 INS21 INS60 INS21 INS60 INS54 INS60 INS21 INS25 INS25 INS41 INS42 INS41 INS42 INS42 INS74 INS39 INS59 INS27 INS8 INS32 INS8 INS32 INS8 INS32 INS32 INS32 INS32 INS8 INS32 INS66 INS42 INS8 INS8 INS39 INS59 MOV8 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS8 INS32 INS48 INS8 INS12 INS12 INS42 INS32 INS8 INS8 INS66 INS32 INS43 INS59 INS27 INS8 INS42 INS74 INS59 INS27 INS8 INS42 INS42 INS32 INS32 INS8 INS32 INS32 INS66 INS42 INS32 INS83 MOV43 INS59 INS32 INS39 INS59 INS8 INS12 INS12 INS12 INS8 INS74 INS59 INS32 INS32 INS21 INS27 INS41 INS32 INS32 INS43 INS43 INS42 INS32 INS27 INS27 INS21 INS42 INS42 INS21 INS42 INS42 INS41 INS41 INS25 INS25 INS22 INS42 INS22 INS42 INS22 INS42 INS42 INS54 INS42 INS33 INS21 INS21 INS42 INS9 INS21 INS25 MOV21 INS21 MOV21 INS21 MOV21 INS21 MOV21 INS21 INS25 INS41 INS25 INS52 INS42 INS32 INS42 INS21 INS44 INS8 INS44 INS8 INS32 INS42 INS60 INS25 INS60 INS6 INS41 INS41 INS42 INS42 INS42 INS32 INS42 INS33 INS21 INS43 INS76 INS42 INS32 INS42 INS33 INS51 INS22 INS42 INS42 INS32 INS42 INS60 INS25 INS21 INS60 INS25 INS22 INS42 INS22 INS42 INS42 INS42 INS32 INS42 INS42 INS9 INS42 INS9 INS21 INS41 INS44 INS8 INS44 INS8 INS44 INS8 INS25 INS21 INS43 INS43 INS42 INS32 INS42 INS42 INS32 INS32 INS42 INS32 INS32 INS34 INS9 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS42 MOV8 INS22 INS42 INS32 INS42 INS34 INS27 INS32 INS32 INS32 INS9 MOV7 INS27 INS8 INS27 INS8 INS8 INS52 INS42 INS52 INS42 INS52 INS42 INS8 INS12 INS7 INS7 INS7 INS38 INS8 INS32 INS32 INS32 INS32 INS78 INS27 MOV8 MOV32 INS40 INS8 MOV8 INS52 INS42 INS32 INS43 INS42 INS21 INS43 INS42 INS21 INS21 INS42 INS74 INS59 INS27 INS8 INS43 INS59 INS27 INS32 INS33 INS42 INS42 INS33 INS32 INS42 INS42 INS42 INS32 INS8 INS52 INS42 INS42 INS43 INS59 INS27 INS41 INS32 INS43 INS59 INS27 INS8 INS52 INS42 INS52 INS42 INS42 INS42 INS7 INS32 INS43 INS42 INS53 INS43 INS42 INS53 INS43 INS42 INS53 INS42 INS8 INS32 INS42 INS42 INS32 INS42 INS32 INS32 INS42 INS42 INS42 INS32 INS42 INS27 INS42 INS42 INS42 MOV21 INS52 INS42 INS22 INS42 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS42 INS45 INS32 INS32 UPD43 INS22 INS33 INS21 INS32 INS38 INS25 INS21 INS41 INS25 INS21 INS60 INS25 INS60 INS60 INS25 INS41 INS44 INS8 INS42 MOV32 INS42 INS32 INS42 INS9 INS42 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS62 INS38 UPD42 INS21 INS42 INS42 INS32 INS42 INS32 INS32 INS43 INS76 INS42 INS32 INS42 INS33 INS41 INS42 INS42 INS32 INS42 INS33 INS42 INS42 INS22 INS42 INS32 INS42 INS21 INS54 INS25 INS42 INS42 INS32 INS42 INS33 INS42 INS42 INS32 INS32 INS42 INS42 INS32 INS42 INS33 INS54 INS42 INS32 INS42 INS42 INS9 INS9 INS33 INS42 INS14 INS42 INS14 INS42 INS14 INS21 INS42 INS42 INS22 INS42 INS52 INS42 INS42 INS42 INS42 INS42 INS45 INS32 INS45 INS42 INS8 INS52 INS42 INS32 INS42 INS42 INS42 INS40 INS3 INS42 INS22 INS42 UPD42 INS22 INS42 INS32 INS42 INS42 INS32 INS32 INS8 INS32 INS32 INS8 INS32 INS43 INS59 INS27 INS41 INS39 INS59 INS39 INS59 INS32 INS8 INS27 INS43 INS42 INS53 INS22 INS42 INS42 INS42 INS32 INS42 INS43 INS32 INS7 INS42 INS42 INS40 INS42 INS52 INS42 INS42 INS42 INS40 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS32 INS8 INS12 INS27 INS8 INS42 INS42 INS52 INS42 INS42 INS42 INS8 INS12 INS42 INS42 INS43 INS32 INS42 INS43 INS32 INS42 INS43 INS32 INS42 INS32 INS52 INS42 INS52 INS42 INS21 MOV22 INS42 INS5 INS4 INS52 INS42 INS52 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS21 INS42 INS40 INS42 INS42 INS42 INS21 INS42 INS42 INS42 INS32 INS42 INS33 INS34 INS42 INS32 INS42 INS11 INS42 INS42 INS21 INS42 INS42 INS42 INS14 INS52 INS42 INS42 INS42 INS42 INS36 INS42 INS42 INS32 INS22 INS42 INS32 INS42 INS42 INS21 INS44 INS8 INS42 INS33 INS53 INS21 INS44 INS8 INS42 INS40 INS42 INS42 INS40 INS42 INS42 INS40 INS42 INS42 INS42 INS7 UPD43 INS43 INS85 INS42 INS32 INS42 INS32 INS32 INS42 INS32 INS42 INS39 INS32 INS32 INS43 INS32 INS42 INS11 INS22 INS42 INS34 INS32 INS42 INS42 INS7 INS43 INS42 INS53 INS14 INS32 INS43 INS42 INS53 INS40 INS14 UPD42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS45 INS42 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS43 INS42 INS52 INS42 INS42 INS42 INS32 INS42 INS14 INS43 INS27 INS42 INS42 INS42 INS14 INS43 MOV32 INS45 INS45 INS42 INS42 INS42 INS45 INS32 INS45 INS36 INS42 INS42 INS42 INS43 INS45 INS42 INS42 INS45 INS52 INS43 INS32 INS42 INS42 INS42 INS27 INS42 INS42 INS40 INS42 INS42 INS42 DEL40 DEL42 DEL43 DEL14 DEL7 DEL21 DEL8 DEL52 DEL42 DEL43 DEL62 DEL36 DEL38 DEL8 DEL25 DEL21 DEL42 DEL42 DEL42 DEL43 DEL69 DEL39 DEL69 DEL39 DEL69 DEL39 DEL69 DEL69 DEL39 DEL69 DEL68 DEL65 DEL42 DEL7 DEL21 DEL8