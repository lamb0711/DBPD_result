Merge branch 'feature/GEODE-8' into develop

+import java.nio.ByteBuffer;
+import com.gemstone.gemfire.internal.cache.DiskEntry.Helper.ValueWrapper;
+import com.gemstone.gemfire.internal.offheap.OffHeapHelper;
+import com.gemstone.gemfire.internal.offheap.Releasable;
+import com.gemstone.gemfire.internal.offheap.SimpleMemoryAllocatorImpl;
+import com.gemstone.gemfire.internal.offheap.UnsafeMemoryChunk;
+import com.gemstone.gemfire.internal.offheap.SimpleMemoryAllocatorImpl.Chunk;
+import com.gemstone.gemfire.internal.offheap.StoredObject;
+import com.gemstone.gemfire.internal.offheap.annotations.Released;
+import com.gemstone.gemfire.internal.offheap.annotations.Retained;
+import com.gemstone.gemfire.internal.offheap.annotations.Unretained;
+  
+  /**
+   * In some cases we need to do something just before we drop the value
+   * from a DiskEntry that is being moved (i.e. overflowed) to disk.
+   * @param context
+   */
+  public void handleValueOverflow(RegionEntryContext context);
+  
+  /**
+   * In some cases we need to do something just after we unset the value
+   * from a DiskEntry that has been moved (i.e. overflowed) to disk.
+   * @param context
+   */
+  public void afterValueOverflow(RegionEntryContext context);
-      Object v = getOffHeapValueOnDiskOrBuffer(entry, dr, context);
+      @Released Object v = getOffHeapValueOnDiskOrBuffer(entry, dr, context);
+        if (v instanceof Chunk) {
+          @Released Chunk ohv = (Chunk) v;
+          try {
+            v = ohv.getDeserializedValue(null, null);
+            if (v == ohv) {
+              throw new IllegalStateException("sqlf tried to use getValueOnDiskOrBuffer");
+            }
+          } finally {
+            ohv.release(); // OFFHEAP the offheap ref is decremented here
+          }
+        } else {
+        }
+    @Retained
-            Object v = entry._getValueUse(context, true); // TODO:KIRK:OK Rusty had Object v = entry.getValueWithContext(context);
+            @Retained Object v = entry._getValueRetain(context, true); // TODO:KIRK:OK Rusty had Object v = entry.getValueWithContext(context);
-      Object v = null;
+      @Retained @Released Object v = null;
-        v = de._getValueUse(context, true); // OFFHEAP copied to heap entry; todo allow entry to refer to offheap since it will be copied to network.
+        SimpleMemoryAllocatorImpl.setReferenceCountOwner(entry);
+        v = de._getValueRetain(context, true); // OFFHEAP copied to heap entry; todo allow entry to refer to offheap since it will be copied to network.
+        SimpleMemoryAllocatorImpl.setReferenceCountOwner(null);
-          {
+        try {
+          if (v instanceof StoredObject && !((StoredObject) v).isSerialized()) {
+            entry.setSerialized(false);
+            entry.value = ((StoredObject) v).getDeserializedForReading();
+            
+            //For SQLFire we prefer eager deserialized
+//            if(v instanceof ByteSource) {
+//              entry.setEagerDeserialize();
+//            }
+          } else {
+            
+          //For SQLFire we prefer eager deserialized
+//            if(v instanceof ByteSource) {
+//              entry.setEagerDeserialize();
+//            }
+        } finally {
+          // If v == entry.value then v is assumed to be an OffHeapByteSource
+          // and release() will be called on v after the bytes have been read from
+          // off-heap.
+          if (v != entry.value) {
+            OffHeapHelper.releaseWithNoTracking(v);
+          }
+        }
-      } else {
+      }
+      else {
+        Object preparedValue = v;
+        if (preparedValue != null) {
+          preparedValue = AbstractRegionEntry.prepareValueForGII(preparedValue);
+          if (preparedValue == null) {
+            return false;
+          }
+        }
+      if (CachedDeserializableFactory.preferObject()) {
+        entry.value = preparedValue;
+        entry.setEagerDeserialize();
+      }
+      else {
-          BlobHelper.serializeTo(v, hdos);
+          BlobHelper.serializeTo(preparedValue, hdos);
+      }
-          entry.setValueWithContext(drv, AbstractRegionMap.prepareValueForCache((RegionEntryContext) r, re.getValue()));
+          entry.setValueWithContext(drv, entry.prepareValueForCache((RegionEntryContext) r,
+              re.getValue(), false));
+    private static final ValueWrapper INVALID_VW = new ByteArrayValueWrapper(true, INVALID_BYTES);
+    private static final ValueWrapper LOCAL_INVALID_VW = new ByteArrayValueWrapper(true, LOCAL_INVALID_BYTES);
+    private static final ValueWrapper TOMBSTONE_VW = new ByteArrayValueWrapper(true, TOMBSTONE_BYTES);
+    
+    public static interface ValueWrapper {
+      public boolean isSerialized();
+      public int getLength();
+      public byte getUserBits();
+      public void sendTo(ByteBuffer bb, Flushable flushable) throws IOException;
+      public String getBytesAsString();
+    }
+    public static interface Flushable {
+      public void flush() throws IOException;
+
+      public void flush(ByteBuffer bb, ByteBuffer chunkbb) throws IOException;
+    }
+    public static class ByteArrayValueWrapper implements ValueWrapper {
+      public final boolean isSerializedObject;
+      public final byte[] bytes;
+      
+     public ByteArrayValueWrapper(boolean isSerializedObject, byte[] bytes) {
+        this.isSerializedObject = isSerializedObject;
+        this.bytes = bytes;
+      }
+
+      @Override
+      public boolean isSerialized() {
+        return this.isSerializedObject;
+      }
+
+      @Override
+      public int getLength() {
+        return (this.bytes != null) ? this.bytes.length : 0;
+      }
+
+      private boolean isInvalidToken() {
+        return this == INVALID_VW;
+      }
+
+      private boolean isLocalInvalidToken() {
+        return this == LOCAL_INVALID_VW;
+      }
+
+      private boolean isTombstoneToken() {
+        return this == TOMBSTONE_VW;
+      }
+
+      @Override
+      public byte getUserBits() {
+        byte userBits = 0x0;
+        if (isSerialized()) {
+          if (isTombstoneToken()) {
+            userBits = EntryBits.setTombstone(userBits, true);
+          } else if (isInvalidToken()) {
+            userBits = EntryBits.setInvalid(userBits, true);
+          } else if (isLocalInvalidToken()) {
+            userBits = EntryBits.setLocalInvalid(userBits, true);
+          } else {
+            if (this.bytes == null) {
+              throw new IllegalStateException("userBits==1 and value is null");
+            } else if (this.bytes.length == 0) {
+              throw new IllegalStateException("userBits==1 and value is zero length");
+            }
+            userBits = EntryBits.setSerialized(userBits, true);
+          }
+        }
+        return userBits;
+      }
+
+      @Override
+      public void sendTo(ByteBuffer bb, Flushable flushable) throws IOException {
+        int offset = 0;
+        final int maxOffset = getLength();
+        while (offset < maxOffset) {
+          int bytesThisTime = maxOffset - offset;
+          boolean needsFlush = false;
+          if (bytesThisTime > bb.remaining()) {
+            needsFlush = true;
+            bytesThisTime = bb.remaining();
+          }
+          bb.put(this.bytes, offset, bytesThisTime);
+          offset += bytesThisTime;
+          if (needsFlush) {
+            flushable.flush();
+          }
+        }
+      }
+
+      @Override
+      public String getBytesAsString() {
+        if (this.bytes == null) {
+          return "null";
+        }
+        StringBuffer sb = new StringBuffer();
+        int len = getLength();
+        for (int i = 0; i < len; i++) {
+          sb.append(this.bytes[i]).append(", ");
+        }
+        return sb.toString();
+      }
+    }
+    
+    /**
+     * This class is a bit of a hack used by the compactor.
+     * For the compactor always copies to a byte[] so
+     * this class is just a simple wrapper.
+     * It is possible that the length of the byte array is greater
+     * than the actual length of the wrapped data.
+     * At the time we create this we are all done with isSerialized
+     * and userBits so those methods are not supported.
+     */
+    public static class CompactorValueWrapper extends ByteArrayValueWrapper {
+      private final int length;
+      
+      public CompactorValueWrapper(byte[] bytes, int length) {
+        super(false, bytes);
+        this.length = length;
+      }
+      
+      @Override
+      public boolean isSerialized() {
+        throw new UnsupportedOperationException();
+      }
+
+      @Override
+      public int getLength() {
+        return this.length;
+      }
+
+      @Override
+      public byte getUserBits() {
+        throw new UnsupportedOperationException();
+      }
+    }
+    
+    /**
+     * Note that the Chunk this ValueWrapper is created with
+     * is unretained so it must be used before the owner of
+     * the chunk releases it.
+     * Since the RegionEntry that has the value we are writing to
+     * disk has it retained we are ok as long as this ValueWrapper's
+     * life ends before the RegionEntry sync is released.
+     * Note that this class is only used with uncompressed chunks.
+     */
+    public static class ChunkValueWrapper implements ValueWrapper {
+      private final @Unretained Chunk chunk;
+      public ChunkValueWrapper(Chunk c) {
+        assert !c.isCompressed();
+        this.chunk = c;
+      }
+      @Override
+      public boolean isSerialized() {
+        return this.chunk.isSerialized();
+      }
+      @Override
+      public int getLength() {
+        return this.chunk.getDataSize();
+      }
+      @Override
+      public byte getUserBits() {
+        byte userBits = 0x0;
+        if (isSerialized()) {
+          userBits = EntryBits.setSerialized(userBits, true);
+        }
+        return userBits;
+      }
+      @Override
+      public void sendTo(ByteBuffer bb, Flushable flushable) throws IOException {
+        final int maxOffset = getLength();
+        if (maxOffset == 0) {
+          return;
+        }
+        if (maxOffset > bb.capacity()) {
+          ByteBuffer chunkbb = this.chunk.createDirectByteBuffer();
+          if (chunkbb != null) {
+            flushable.flush(bb, chunkbb);
+            return;
+          }
+        }
+        final long bbAddress = Chunk.getDirectByteBufferAddress(bb);
+        if (bbAddress != 0L) {
+          int bytesRemaining = maxOffset;
+          int availableSpace = bb.remaining();
+          long addrToWrite = bbAddress + bb.position();
+          long addrToRead = this.chunk.getAddressForReading(0, maxOffset);
+          if (bytesRemaining > availableSpace) {
+            do {
+              UnsafeMemoryChunk.copyMemory(addrToRead, addrToWrite, availableSpace);
+              bb.position(bb.position()+availableSpace);
+              addrToRead += availableSpace;
+              bytesRemaining -= availableSpace;
+              flushable.flush();
+              addrToWrite = bbAddress + bb.position();
+              availableSpace = bb.remaining();
+            } while (bytesRemaining > availableSpace);
+          }
+          UnsafeMemoryChunk.copyMemory(addrToRead, addrToWrite, bytesRemaining);
+          bb.position(bb.position()+bytesRemaining);
+        } else {
+          long addr = this.chunk.getAddressForReading(0, maxOffset);
+          final long endAddr = addr + maxOffset;
+          while (addr != endAddr) {
+            bb.put(UnsafeMemoryChunk.readAbsoluteByte(addr));
+            addr++;
+            if (!bb.hasRemaining()) {
+              flushable.flush();
+            }
+          }
+        }
+      }
+      @Override
+      public String getBytesAsString() {
+        return this.chunk.getStringForm();
+      }
+    }
+
+    public static ValueWrapper createValueWrapper(Object value, EntryEventImpl event) {
+      if (value == Token.INVALID) {
+        // even though it is not serialized we say it is because
+        // bytes will never be an empty array when it is serialized
+        // so that gives us a way to specify the invalid value
+        // given a byte array and a boolean flag.
+        return INVALID_VW;
+      }
+      else if (value == Token.LOCAL_INVALID) {
+        // even though it is not serialized we say it is because
+        // bytes will never be an empty array when it is serialized
+        // so that gives us a way to specify the local-invalid value
+        // given a byte array and a boolean flag.
+        return LOCAL_INVALID_VW;
+      }
+      else if (value == Token.TOMBSTONE) {
+        return TOMBSTONE_VW;
+      }
+      else {
+        boolean isSerializedObject = true;
+        byte[] bytes;
+        if (value instanceof CachedDeserializable) {
+          CachedDeserializable proxy = (CachedDeserializable)value;
+          if (proxy instanceof Chunk) {
+            return new ChunkValueWrapper((Chunk) proxy);
+          }
+          if (proxy instanceof StoredObject) {
+            StoredObject ohproxy = (StoredObject) proxy;
+            isSerializedObject = ohproxy.isSerialized();
+            if (isSerializedObject) {
+              bytes = ohproxy.getSerializedValue();
+            } else {
+              bytes = (byte[]) ohproxy.getDeserializedForReading();
+            }
+          } else {
+            bytes = proxy.getSerializedValue();
+          }
+          if (event != null && isSerializedObject) {
+            event.setCachedSerializedNewValue(bytes);
+          }
+        }
+        else if (value instanceof byte[]) {
+          isSerializedObject = false;
+          bytes = (byte[])value;
+        }
+        else {
+          Assert.assertTrue(!Token.isRemovedFromDisk(value));
+          if (event != null && event.getCachedSerializedNewValue() != null) {
+            bytes = event.getCachedSerializedNewValue();
+          } else {
+            bytes = EntryEventImpl.serialize(value);
+            if (bytes.length == 0) {
+              throw new IllegalStateException("serializing <" + value + "> produced empty byte array");
+            }
+            if (event != null) {
+              event.setCachedSerializedNewValue(bytes);
+            }
+          }
+        }
+        return new ByteArrayValueWrapper(isSerializedObject, bytes);
+      }
+    }
+    public static ValueWrapper createValueWrapperFromEntry(DiskEntry entry, LocalRegion region, EntryEventImpl event) {
+      if (event != null) {
+        // For off-heap it should be faster to pass a reference to the
+        // StoredObject instead of using the cached byte[] (unless it is also compressed).
+        // Since NIO is used if the chunk of memory is large we can write it
+        // to the file with using the off-heap memory with no extra copying.
+        // So we give preference to getRawNewValue over getCachedSerializedNewValue
+        Object rawValue = null;
+        if (!event.hasDelta()) {
+          // We don't do this for the delta case because getRawNewValue returns delta
+          // and we want to write the entire new value to disk.
+          rawValue = event.getRawNewValue();
+          if (rawValue instanceof Chunk) {
+            return new ChunkValueWrapper((Chunk) rawValue);
+          }
+        }
+        if (event.getCachedSerializedNewValue() != null) {
+          return new ByteArrayValueWrapper(true, event.getCachedSerializedNewValue());
+        }
+        if (rawValue != null) {
+          return createValueWrapper(rawValue, event);
+        }
+      }
+      // TODO OFFHEAP: No need to retain since we hold the sync on entry but we need a flavor of _getValue that will decompress
+      @Retained Object value = entry._getValueRetain(region, true);
+      try {
+        return createValueWrapper(value, event);
+      } finally {
+        OffHeapHelper.release(value);
+      }
+    }
+    
+
-      DiskRegion dr = region.getDiskRegion();
-      byte[] bytes = null;
-      boolean isSerializedObject = true;
-
-      if (event != null && event.getCachedSerializedNewValue() != null) {
-        bytes = event.getCachedSerializedNewValue();
-      } else {
-        // If event != null then we could get the new value from it.
-        // Getting it from the entry is expensive on a compressed region.
-        Object value;
-        if (event != null && !event.hasDelta() && event.getRawNewValue() != null) {
-          // We don't do this for the delta case because getRawNewValue returns delta
-          // and we want to write the entire new value to disk.
-          value = event.getRawNewValue();
-        } else {
-          value = entry._getValueUse(region, true);
-        }
-
-      if (value == Token.INVALID) {
-        // even though it is not serialized we say it is because
-        // bytes will never be an empty array when it is serialized
-        // so that gives us a way to specify the invalid value
-        // given a byte array and a boolean flag.
-        bytes = INVALID_BYTES;
-      }
-      else if (value == Token.LOCAL_INVALID) {
-        // even though it is not serialized we say it is because
-        // bytes will never be an empty array when it is serialized
-        // so that gives us a way to specify the local-invalid value
-        // given a byte array and a boolean flag.
-        bytes = LOCAL_INVALID_BYTES;
-      }
-      else if (value == Token.TOMBSTONE) {
-        bytes = TOMBSTONE_BYTES;
-      }
-      else if (value instanceof byte[]) {
-        isSerializedObject = false;
-        bytes = (byte[])value;
-      }
-      else if (value instanceof CachedDeserializable) {
-        CachedDeserializable proxy = (CachedDeserializable)value;
-        bytes = proxy.getSerializedValue();
-        if (event != null) {
-          event.setCachedSerializedNewValue(bytes);
-        }
-      }
-      else {
-        Assert.assertTrue(!Token.isRemovedFromDisk(value));
-        if (event != null && event.getCachedSerializedNewValue() != null) {
-          bytes = event.getCachedSerializedNewValue();
-        } else {
-          bytes = EntryEventImpl.serialize(value);
-          if (bytes.length == 0) {
-            throw new IllegalStateException("serializing <" + value + "> produced empty byte array");
-          }
-          if (event != null) {
-            event.setCachedSerializedNewValue(bytes);
-          }
-        }
-      }
-      }
-
-      {
-        DiskId did = entry.getDiskId();
-        // @todo does the following unmark need to be called when an async
-        // write is scheduled or is it ok for doAsyncFlush to do it?
-        did.unmarkForWriting();
-        dr.put(entry, region, bytes, isSerializedObject, async);
-      }
+      writeBytesToDisk(entry, region, async, createValueWrapperFromEntry(entry, region, event));
+    }
+    
+    private static void writeBytesToDisk(DiskEntry entry, LocalRegion region, boolean async, ValueWrapper vw) throws RegionClearedException {
+      // @todo does the following unmark need to be called when an async
+      // write is scheduled or is it ok for doAsyncFlush to do it?
+      entry.getDiskId().unmarkForWriting();
+      region.getDiskRegion().put(entry, region, vw, async);
-              entry.setValueWithContext(region, null); // fixes bug 41119
+              try {
+                entry.handleValueOverflow(region);
+                entry.setValueWithContext(region, null); // fixes bug 41119
+              }finally {
+                entry.afterValueOverflow(region);
+              }
+              
-            entry.setValueWithContext(region, AbstractRegionMap.prepareValueForCache(region, re.getValue()));
+            entry.setValueWithContext(region, entry.prepareValueForCache(region, re.getValue(), false));
-          entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+          //The new value in the entry needs to be set after the disk writing 
+          // has succeeded. If not , for GemFireXD , it is possible that other thread
+          // may pick this transient value from region entry ( which for 
+          //offheap will eventually be released ) as index key, 
+          //given that this operation is bound to fail in case of
+          //disk access exception.
+          
+          //entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
-              writeToDisk(entry, region, false, event);
+              //In case of compression the value is being set first 
+              // because atleast for now , GemFireXD does not support compression
+              // if and when it does support, this needs to be taken care of else
+              // we risk Bug 48965
+              if (AbstractRegionEntry.isCompressible(dr, newValue)) {
+                entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+                
+                // newValue is prepared and compressed. We can't write compressed values to disk.
+                writeToDisk(entry, region, false, event);
+              } else {
+                writeBytesToDisk(entry, region, false, createValueWrapper(newValue, event));
+                entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+              }
+              
+              entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+              
+              entry.setValueWithContext(region, newValue); 
+            entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
+            
+          }else {
+            entry.setValueWithContext(region, newValue);
+          
-          entry.setValueWithContext(context, AbstractRegionMap.prepareValueForCache(drv, newValue.getValue()));
+          entry.setValueWithContext(context, entry.prepareValueForCache(drv, newValue.getValue(), 
+              false));
-            entry.setValueWithContext(context,null); // fixes bug 41119
+            try {
+              entry.handleValueOverflow(context);
+              entry.setValueWithContext(context,null); // fixes bug 41119
+            }finally {
+              entry.afterValueOverflow(context);
+            }
-      Object result = getValueOffHeapOrDiskWithoutFaultIn(entry, region);
+      Object result = OffHeapHelper.copyAndReleaseIfNeeded(getValueOffHeapOrDiskWithoutFaultIn(entry, region));
+      if (result instanceof StoredObject) {
+        ((StoredObject) result).release();
+        throw new IllegalStateException("sqlf tried to use getValueInVMOrDiskWithoutFaultIn");
+      }
+    @Retained
-      Object v = entry._getValueUse(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
+      @Retained Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
-          v = entry._getValueUse(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
+          v = entry._getValueRetain(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
+//      } else if (v instanceof ByteSource) {
+//        // If the ByteSource contains a Delta or ListOfDelta then we want to deserialize it
+//        Object deserVal = ((CachedDeserializable)v).getDeserializedForReading();
+//        if (deserVal != v) {
+//          OffHeapHelper.release(v);
+//          v = deserVal;
+//        }
+
-
-    public static Object faultInValue(DiskEntry entry, LocalRegion region)
+    public static Object faultInValue(DiskEntry entry, LocalRegion region) {
+      return faultInValue(entry, region, false);
+    }
+    @Retained
+    public static Object faultInValueRetain(DiskEntry entry, LocalRegion region) {
+      return faultInValue(entry, region, true);
+    }
+    /**
+     * @param retainResult if true then the result may be a retained off-heap reference
+     */
+    @Retained
+    private static Object faultInValue(DiskEntry entry, LocalRegion region, boolean retainResult)
-      Object v = entry._getValueUse(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
+      @Retained Object v = entry._getValueRetain(region, true); // TODO:KIRK:OK Object v = entry.getValueWithContext(region);
+      try {
-          v = entry._getValueUse(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
+          v = entry._getValueRetain(region, true); // TODO:KIRK:OK v = entry.getValueWithContext(region);
-            v = readValueFromDisk(entry, region, -1, false, null);
+            v = readValueFromDisk(entry, region);
+      } finally {
+        if (!retainResult) {
+          v = OffHeapHelper.copyAndReleaseIfNeeded(v);
+          // At this point v should be either a heap object
+        }
+      }
-          Object v = readValueFromDisk(entry, recoveryStore, oplogId, true, in); // OFFHEAP: Off heap value ok since only used for token check
-          if (entry instanceof LRUEntry) {
-            if (v != null && !Token.isInvalid(v)) {
-              lruEntryFaultIn((LRUEntry) entry, recoveryStore);
-              
-              lruFaultedIn = true;
+          DiskId did = entry.getDiskId();
+          if (did != null) {
+            Object value = null;
+            DiskRecoveryStore region = recoveryStore;
+            DiskRegionView dr = region.getDiskRegionView();
+            dr.acquireReadLock();
+            try {
+              synchronized (did) {
+                // don't read if the oplog has changed.
+                if (oplogId == did.getOplogId()) {
+                  value = getValueFromDisk(dr, did, in);
+                  if (value != null) {
+                    setValueOnFaultIn(value, did, entry, dr, region);
+                  }
+                }
+              }
+            } finally {
+              dr.releaseReadLock();
+            }
+            if (entry instanceof LRUEntry) {
+              if (value != null && !Token.isInvalid(value)) {
+                lruEntryFaultIn((LRUEntry) entry, recoveryStore);
+                lruFaultedIn = true;
+              }
+    /**
+     *  Caller must have "did" synced.
+     */
+    private static Object getValueFromDisk(DiskRegionView dr, DiskId did, ByteArrayDataInput in) {
+      Object value;
+      if (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID) {
+        // must have been destroyed
+        value = null;
+      } else {
+        if (did.isKeyIdNegative()) {
+          did.setKeyId(- did.getKeyId());
+        }
+        // if a bucket region then create a CachedDeserializable here instead of object
+        value = dr.getRaw(did); // fix bug 40192
+        if (value instanceof BytesAndBits) {
+          BytesAndBits bb = (BytesAndBits)value;
+          if (EntryBits.isInvalid(bb.getBits())) {
+            value = Token.INVALID;
+          } else if (EntryBits.isLocalInvalid(bb.getBits())) {
+            value = Token.LOCAL_INVALID;
+          } else if (EntryBits.isTombstone(bb.getBits())) {
+            value = Token.TOMBSTONE;
+          } else if (EntryBits.isSerialized(bb.getBits())) {
+            value = readSerializedValue(bb.getBytes(), bb.getVersion(), in, false);
+          } else {
+            value = readRawValue(bb.getBytes(), bb.getVersion(), in);
+          }
+        }
+      }
+      return value;
+    }
+    
+     * return the result will only be off-heap if the value is a sqlf ByteSource. Otherwise result will be on-heap.
+     * Caller must have "entry" synced.
-    private static Object readValueFromDisk(DiskEntry entry,
-        DiskRecoveryStore region, long oplogId, boolean checkOplogId,
-        ByteArrayDataInput in) {
+    @Retained
+    private static Object readValueFromDisk(DiskEntry entry, DiskRecoveryStore region) {
-        // long id = diskId.getKeyId();
-        if (dr.isBackup() && did.getKeyId() == DiskRegion.INVALID_ID) {
-          return null; // must have been destroyed
+        Object value = getValueFromDisk(dr, did, null);
+        if (value == null) return null;
+        @Unretained Object preparedValue = setValueOnFaultIn(value, did, entry, dr, region);
+        // For Sqlfire we want to return the offheap representation.
+        // So we need to retain it for the caller to release.
+        /*if (preparedValue instanceof ByteSource) {
+          // This is the only case in which we return a retained off-heap ref.
+          ((ByteSource)preparedValue).retain();
+          return preparedValue;
+        } else */{
+          return value;
-        if(checkOplogId) {
-          // If we're only supposed to read from this specific oplog, don't
-          // read if the oplog has changed.
-          if(oplogId != did.getOplogId()) {
-            return null;
-          }
-        }
-        if (did.isKeyIdNegative()) {
-          did.setKeyId(- did.getKeyId());
-        }
-        // if a bucket region then create a CachedDeserializable here instead of object
-        Object value = dr.getRaw(did); // fix bug 40192
-        if (value instanceof BytesAndBits) {
-          BytesAndBits bb = (BytesAndBits)value;
-          if (EntryBits.isInvalid(bb.getBits())) {
-            value = Token.INVALID;
-          } else if (EntryBits.isLocalInvalid(bb.getBits())) {
-            value = Token.LOCAL_INVALID;
-          } else if (EntryBits.isTombstone(bb.getBits())) {
-            value = Token.TOMBSTONE;
-          } else if (EntryBits.isSerialized(bb.getBits())) {
-            value = readSerializedValue(bb.getBytes(), bb.getVersion(),
-                in, false);
-          } else {
-            value = readRawValue(bb.getBytes(), bb.getVersion(), in);
-          }
-        }
-        int bytesOnDisk = getValueLength(did);
-        Assert.assertTrue(value != null);
-        Object preparedValue = AbstractRegionMap.prepareValueForCache((RegionEntryContext) region, value);
-        region.updateSizeOnFaultIn(entry.getKey(), region.calculateValueSize(preparedValue), bytesOnDisk);
-        //did.setValueSerializedSize(0);
-        // I think the following assertion is true but need to run
-        // a regression with it. Reenable this post 6.5
-        //Assert.assertTrue(entry._getValue() == null);
-        entry.setValueWithContext((RegionEntryContext) region, preparedValue);
-        dr.incNumEntriesInVM(1L);
-        dr.incNumOverflowOnDisk(-1L);
-        incrementBucketStats(region, 1/*InVM*/, -1/*OnDisk*/, -bytesOnDisk);
-        return value; // OFFHEAP: off heap value return ok
+    
+    /**
+     * Caller must have "entry" and "did" synced and "dr" readLocked.
+     * @return the unretained result must be used by the caller before it releases the sync on "entry".
+     */
+    @Unretained
+    private static Object setValueOnFaultIn(Object value, DiskId did, DiskEntry entry, DiskRegionView dr, DiskRecoveryStore region) {
+//    dr.getOwner().getCache().getLogger().info("DEBUG: faulting in entry with key " + entry.getKey());
+      int bytesOnDisk = getValueLength(did);
+      // Retained by the prepareValueForCache call for the region entry.
+      // NOTE that we return this value unretained because the retain is owned by the region entry not the caller.
+      @Retained Object preparedValue = entry.prepareValueForCache((RegionEntryContext) region, value,
+          false);
+      region.updateSizeOnFaultIn(entry.getKey(), region.calculateValueSize(preparedValue), bytesOnDisk);
+      //did.setValueSerializedSize(0);
+      // I think the following assertion is true but need to run
+      // a regression with it. Reenable this post 6.5
+      //Assert.assertTrue(entry._getValue() == null);
+      entry.setValueWithContext((RegionEntryContext) region, preparedValue);
+      dr.incNumEntriesInVM(1L);
+      dr.incNumOverflowOnDisk(-1L);
+      incrementBucketStats(region, 1/*InVM*/, -1/*OnDisk*/, -bytesOnDisk);
+      return preparedValue;
+    }
-
+      
+      // Notify the SQLFire IndexManager if present
+     /* final IndexUpdater indexUpdater = region.getIndexUpdater();
+      if(indexUpdater != null && dr.isSync()) {
+        indexUpdater.onOverflowToDisk(entry);
+      }*/
+      
-          entry.setValueWithContext(region,null);
+          try {
+            entry.handleValueOverflow(region);
+            entry.setValueWithContext(region,null);
+          }finally {
+            entry.afterValueOverflow(region);
+          }
-                entry.setValueWithContext(region,null);
+                try {
+                  entry.handleValueOverflow(region);
+                  entry.setValueWithContext(region,null);
+                }finally {
+                  entry.afterValueOverflow(region);
+                }
+      if (region.isThisRegionBeingClosedOrDestroyed()) return;
+      if (region.isThisRegionBeingClosedOrDestroyed()) return;
+                if (region.isThisRegionBeingClosedOrDestroyed()) return;
-                entry.setValueWithContext(region,null);
+                try {
+                 entry.handleValueOverflow(region);
+                 entry.setValueWithContext(region,null);
+                }finally {
+                  entry.afterValueOverflow(region);
+                }

INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS40 INS31 INS31 MOV31 MOV31 INS29 INS83 INS39 INS42 INS44 INS29 INS83 INS39 INS42 INS44 INS23 INS23 INS23 INS55 INS55 INS55 INS55 INS55 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS65 INS65 INS43 INS42 INS65 INS65 INS43 INS42 INS78 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS83 INS43 INS59 INS83 INS83 INS42 INS31 INS31 INS31 INS31 INS31 INS83 INS83 INS42 INS31 INS31 INS83 INS83 INS42 INS43 INS23 INS23 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS29 INS83 INS83 INS42 INS43 INS23 INS31 INS31 INS31 INS31 INS29 INS83 INS83 INS42 INS43 INS23 INS31 INS31 INS31 INS31 INS31 INS31 UPD83 INS43 INS42 INS44 MOV8 INS83 INS83 INS43 INS42 INS44 INS44 INS44 INS8 MOV29 INS83 INS83 INS39 INS42 MOV44 MOV44 MOV44 INS44 MOV43 INS8 INS83 INS83 INS39 INS42 INS44 INS44 INS44 INS44 INS43 INS8 INS78 MOV29 INS83 INS83 INS43 INS42 INS44 INS44 INS8 INS78 INS83 INS83 INS43 INS42 INS44 INS44 INS8 INS29 INS78 UPD83 INS44 UPD42 INS44 MOV8 INS29 INS78 INS83 INS83 INS43 INS42 INS44 INS44 INS8 INS29 INS78 INS83 INS83 INS43 INS42 INS44 INS44 MOV44 INS44 MOV44 INS8 INS66 INS66 INS42 INS42 INS66 INS66 INS42 INS42 INS25 INS42 INS42 INS42 INS14 INS42 INS42 INS14 INS42 INS42 INS14 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS83 INS39 INS42 INS44 INS44 INS43 INS83 INS43 INS42 INS83 INS39 INS42 INS43 INS83 INS39 INS42 INS44 INS44 INS43 INS42 INS83 INS83 INS39 INS59 INS83 INS83 INS5 INS59 INS83 INS42 INS44 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS44 INS44 INS43 INS8 INS78 INS83 INS43 INS42 INS8 INS65 INS42 INS83 INS83 INS39 INS59 INS83 INS42 INS44 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS65 INS42 INS83 INS83 INS78 INS43 INS59 INS83 INS42 INS44 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS8 INS78 INS83 INS39 INS42 INS44 INS44 INS43 INS8 INS78 INS83 INS43 INS42 INS8 UPD42 MOV42 INS43 INS42 INS42 INS43 INS42 INS43 INS42 INS43 INS42 INS25 INS60 INS54 INS43 INS42 INS21 INS43 INS42 INS43 INS42 INS39 INS42 INS43 INS42 INS42 INS21 INS21 INS25 INS42 INS42 INS43 INS42 INS43 INS42 INS41 INS42 INS42 INS43 INS42 INS43 INS42 INS41 INS65 INS42 INS39 INS42 INS54 INS43 INS42 INS43 INS42 MOV60 INS25 INS65 INS42 INS42 INS43 INS42 INS43 INS42 MOV60 MOV60 MOV25 MOV21 INS54 INS65 INS65 INS42 INS42 INS43 INS42 INS43 INS42 INS43 INS42 MOV60 MOV60 MOV21 MOV21 MOV21 MOV21 MOV21 INS41 INS25 INS25 INS78 MOV62 INS8 INS78 INS78 INS43 INS9 INS42 INS43 INS9 INS42 INS43 INS9 INS42 INS43 INS42 INS43 INS42 INS42 INS42 INS42 INS43 INS42 INS43 INS42 INS42 INS42 INS39 INS85 INS42 INS39 INS42 MOV5 INS42 INS21 INS21 INS42 INS41 INS42 INS41 INS41 INS41 INS41 INS42 INS60 INS25 INS41 INS42 INS43 INS42 INS43 INS42 INS42 INS60 INS60 INS61 INS42 INS42 INS25 INS60 INS60 INS24 INS41 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS5 INS42 INS39 INS42 INS46 INS21 INS42 INS53 INS42 INS41 INS42 INS53 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS42 INS43 INS42 INS6 INS21 INS42 INS41 INS42 INS41 INS42 INS60 INS25 INS41 INS42 INS43 INS42 INS43 INS42 INS42 INS60 INS25 INS25 INS60 INS25 INS42 INS42 INS41 INS42 INS42 INS42 INS42 MOV27 INS8 INS78 INS43 INS59 INS8 INS8 INS42 INS32 INS42 INS42 INS42 INS32 INS32 INS62 INS8 INS78 INS42 INS42 INS32 INS42 INS42 INS32 INS42 INS66 INS78 INS43 INS8 INS8 INS8 UPD66 INS42 INS42 MOV27 MOV8 INS8 INS66 INS66 INS66 INS66 INS66 INS66 INS42 INS42 INS8 INS8 INS66 INS66 INS42 INS42 INS42 INS78 INS42 INS32 INS41 INS32 INS41 INS42 INS25 INS42 INS42 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS7 INS7 INS22 INS16 INS27 INS27 INS27 INS39 INS59 INS32 INS8 INS42 INS42 INS42 INS39 INS59 INS83 INS39 INS59 INS27 INS8 INS27 INS8 INS43 INS59 INS39 INS59 INS58 INS27 INS37 INS8 INS32 INS39 INS85 INS9 INS42 INS7 INS14 INS22 INS14 INS42 INS38 INS7 INS32 INS32 INS39 INS59 INS32 INS8 INS42 INS42 INS42 INS83 INS39 INS59 INS27 INS8 INS27 INS8 INS83 INS39 INS59 INS27 INS8 INS8 INS32 INS41 INS60 INS25 INS25 INS25 INS42 INS42 INS42 INS32 INS41 INS21 INS42 INS42 INS42 INS42 INS32 INS32 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS43 INS21 INS53 INS42 INS42 INS42 INS42 INS9 INS42 INS42 INS42 INS9 INS42 INS42 MOV25 MOV25 INS25 INS25 INS21 MOV25 MOV21 MOV25 INS51 INS21 INS42 INS42 INS42 INS42 INS42 INS62 INS8 MOV8 INS54 INS22 INS42 INS22 INS42 INS52 INS42 INS36 INS22 INS34 INS52 INS42 INS52 INS42 INS52 INS42 INS42 INS34 INS42 INS25 INS42 INS34 INS42 INS32 INS42 INS42 INS60 INS60 INS25 INS21 INS21 INS25 INS22 INS33 INS41 INS42 INS42 INS14 INS42 INS32 INS39 INS59 INS42 INS42 INS42 INS21 INS42 INS42 INS22 INS42 INS43 INS52 INS42 INS43 INS32 INS22 INS42 INS22 INS42 INS22 INS42 INS42 INS34 INS42 INS21 INS42 INS32 INS42 INS34 INS41 INS42 INS32 INS60 INS25 INS42 INS32 INS42 INS34 INS60 INS60 INS60 INS60 INS25 INS21 INS21 INS60 INS60 INS61 INS22 INS42 INS42 INS41 INS8 MOV43 INS59 MOV38 MOV8 MOV27 INS8 INS27 INS8 INS42 INS42 INS42 INS9 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV32 INS42 INS32 INS14 UPD42 UPD42 INS38 INS8 MOV32 INS8 INS7 INS7 INS42 INS8 INS32 UPD42 INS9 INS42 INS43 INS60 INS54 INS21 INS21 MOV8 INS8 INS52 INS42 INS52 INS42 INS27 INS22 INS42 INS32 INS8 INS25 INS42 INS39 INS59 INS39 INS59 INS27 INS8 INS32 INS7 INS42 INS8 INS52 INS42 INS45 INS43 INS42 INS42 INS34 INS32 INS52 INS42 INS42 INS42 INS42 INS42 INS52 INS42 INS52 INS42 INS52 INS42 INS7 INS42 INS42 INS42 INS43 INS59 INS27 INS8 INS42 INS42 INS42 INS39 INS59 INS39 INS59 INS39 INS59 INS39 INS59 INS27 INS8 INS32 INS32 INS39 INS59 INS83 INS39 INS59 INS27 INS8 INS52 INS42 INS42 INS41 MOV60 INS60 MOV25 INS41 INS42 INS33 INS25 INS41 INS42 INS33 INS41 INS42 INS42 INS42 INS42 INS42 INS42 INS36 INS42 INS43 INS45 INS42 INS21 MOV60 MOV25 INS42 INS33 INS42 MOV32 INS60 INS25 INS60 INS8 INS42 INS42 INS42 INS78 INS43 INS59 INS8 INS8 INS32 INS32 INS25 INS25 INS22 INS33 INS52 INS42 INS42 INS21 INS32 INS8 INS25 INS42 INS27 INS42 INS9 INS42 INS32 INS21 INS21 INS42 INS42 INS22 INS42 INS42 INS42 INS42 INS21 INS42 INS32 INS42 INS45 INS42 INS32 INS42 INS42 INS32 INS42 INS33 INS21 INS41 INS42 INS42 INS42 INS32 INS42 INS27 INS42 INS32 INS42 INS42 INS19 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS32 INS42 INS27 INS42 INS42 INS21 INS21 INS25 INS42 INS5 INS59 MOV62 MOV8 INS14 INS62 INS8 INS14 INS32 INS8 INS11 INS42 INS7 INS27 MOV43 INS59 INS27 MOV41 INS78 INS43 INS59 INS41 INS42 INS42 INS42 INS11 INS21 MOV25 INS21 INS42 INS42 INS42 INS42 INS42 INS33 INS27 INS8 MOV8 INS27 INS8 INS25 INS52 INS42 INS7 INS42 INS21 INS32 INS8 INS8 INS42 INS42 INS42 INS42 INS7 INS7 INS52 INS42 INS32 INS42 INS42 INS2 INS42 INS42 INS42 INS9 INS22 INS42 INS32 INS42 INS42 INS42 INS32 INS22 INS42 INS34 INS42 INS8 INS27 INS32 INS42 INS22 INS42 INS34 INS42 INS42 INS42 INS32 INS37 INS38 INS8 INS39 INS85 INS42 INS25 INS25 MOV62 MOV8 INS43 INS42 INS42 UPD42 INS42 INS43 INS41 INS43 INS9 MOV32 INS42 INS42 INS42 INS54 INS43 INS42 INS42 INS32 INS42 INS33 INS60 INS60 INS60 INS21 INS54 INS42 INS32 INS42 INS33 INS42 INS42 INS42 INS32 INS42 INS54 INS43 INS42 INS7 INS27 INS8 INS32 INS78 INS43 UPD42 INS62 INS38 INS21 INS21 INS42 INS40 INS21 MOV27 MOV8 INS8 INS42 INS32 INS7 INS42 INS21 INS25 INS21 INS42 INS9 INS42 INS32 INS42 INS42 INS22 INS42 INS52 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS52 INS42 INS21 INS21 INS21 INS21 INS21 INS21 INS21 INS42 INS42 INS42 INS42 INS52 INS42 INS42 INS42 INS32 INS42 INS32 INS21 INS62 INS8 INS62 INS8 INS8 INS27 INS42 INS42 INS14 INS42 UPD42 INS9 MOV8 INS8 INS42 UPD42 INS42 INS42 INS42 MOV43 INS59 INS43 INS59 INS43 INS59 INS32 INS8 MOV8 INS42 INS42 INS42 INS33 INS42 INS42 INS42 INS42 INS42 INS42 INS8 INS8 INS42 INS42 INS32 INS42 INS42 INS53 INS42 INS42 INS42 INS42 INS42 INS43 INS32 INS32 INS7 INS32 INS60 INS25 MOV25 UPD42 INS9 INS42 INS42 INS42 INS9 INS42 INS32 INS7 INS27 INS8 INS25 INS7 INS42 INS42 INS52 INS42 INS32 INS32 INS7 INS7 INS32 INS7 INS7 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS43 INS41 INS42 INS43 INS60 INS21 INS25 MOV21 MOV27 INS42 INS43 INS11 INS21 INS21 UPD42 MOV42 INS33 INS42 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS51 INS21 MOV21 INS21 INS42 INS42 INS33 INS33 INS14 UPD42 INS42 INS36 INS42 INS42 INS42 INS9 INS40 INS32 INS42 INS42 INS42 MOV43 INS59 INS27 INS8 INS32 INS8 INS42 INS42 INS42 INS9 INS42 INS32 INS22 INS33 INS53 INS27 INS8 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS42 INS32 INS42 INS42 INS42 INS14 INS42 INS43 INS59 INS7 INS42 INS8 INS8 INS42 INS43 INS42 INS8 INS32 INS32 UPD42 INS42 INS42 INS42 INS8 INS32 INS32 INS43 INS45 INS11 INS36 INS42 INS42 INS42 INS42 INS33 INS21 INS25 INS42 INS42 INS21 INS21 INS42 INS42 INS42 INS9 INS52 INS42 INS14 INS22 INS34 INS53 INS42 INS42 INS42 INS9 INS32 INS42 INS42 INS32 INS42 INS42 INS43 INS11 INS42 INS42 INS11 INS42 INS32 INS21 INS21 INS42 INS8 INS8 INS21 INS21 INS42 INS42 INS42 INS42 INS42 INS42 INS25 INS42 INS42 INS42 MOV42 MOV33 INS42 INS42 INS42 INS42 INS43 INS42 INS11 INS7 INS27 INS8 INS7 INS32 INS43 INS45 INS22 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS43 INS42 INS42 INS42 INS7 INS7 INS54 INS25 INS32 INS32 INS27 INS8 UPD42 INS8 INS42 INS43 INS42 INS42 INS32 INS42 INS33 INS41 INS40 INS42 INS42 INS42 INS42 INS52 INS42 INS43 INS45 INS42 INS42 INS42 INS32 INS42 INS11 INS8 INS8 UPD42 INS9 INS32 MOV8 INS8 INS21 MOV21 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV32 INS21 INS25 UPD42 MOV21 MOV21 INS54 INS42 INS42 INS42 INS42 INS9 INS42 INS42 INS42 INS5 INS32 INS21 INS21 INS21 INS42 INS42 INS42 INS42 INS21 INS21 INS21 INS32 INS7 MOV27 INS8 INS8 INS8 MOV8 UPD42 INS39 INS85 INS42 INS42 INS32 INS32 INS32 INS32 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS32 INS21 INS21 MOV21 INS21 INS25 INS54 INS42 INS42 INS42 INS42 INS42 INS42 INS33 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS9 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 MOV42 INS32 INS32 INS32 INS32 INS41 MOV8 INS8 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS21 INS21 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 DEL39 DEL42 DEL42 DEL33 DEL27 DEL27 DEL42 DEL42 DEL32 DEL33 DEL27 DEL27 DEL42 DEL42 DEL42 DEL42 DEL9 DEL32 DEL7 DEL21 DEL8 DEL25 DEL42 DEL42 DEL7 DEL21 DEL42 DEL42 DEL7 DEL21 DEL42 DEL42 DEL7 DEL21 DEL43 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL33 DEL59 DEL60 DEL27 DEL42 DEL7 DEL21 DEL8 DEL25 DEL42 DEL42 DEL32 DEL21 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL42 DEL32 DEL21 DEL8 DEL8 DEL34 DEL38 DEL9 DEL33 DEL42 DEL42 DEL42 DEL42 DEL9 DEL32 DEL59 DEL60 DEL8 DEL66 DEL66 DEL66 DEL39 DEL42 DEL39 DEL42 DEL44 DEL33 DEL41 DEL42 DEL42 DEL32 DEL25 DEL42 DEL42 DEL27 DEL8 DEL25 DEL8 DEL25 DEL42 DEL59 DEL60 DEL42 DEL51 DEL8 DEL54 DEL8 DEL8