Merge branch 'release/1.1.0'

- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license
+ * agreements. See the NOTICE file distributed with this work for additional information regarding
+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License. You may obtain a
+ * copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
+ * http://www.apache.org/licenses/LICENSE-2.0
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
+ * Unless required by applicable law or agreed to in writing, software distributed under the License
+ * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+ * or implied. See the License for the specific language governing permissions and limitations under
+ * the License.
- * Represents a statistics type that can be archived to vsd. Loading of this
- * class automatically triggers statistics archival.
+ * Represents a statistics type that can be archived to vsd. Loading of this class automatically
+ * triggers statistics archival.
- * A singleton instance can be requested with the initSingleton(...) and
- * getSingleton() methods.
+ * A singleton instance can be requested with the initSingleton(...) and getSingleton() methods.
- * To manipulate the statistic values, use (inc|dec|set|get)&lt;fieldName&gt;
- * methods.
+ * To manipulate the statistic values, use (inc|dec|set|get)&lt;fieldName&gt; methods.
-  
+
-  
+
-  
+
-  
+
-  
+
-  private final static int totalNumBucketsId; // total number of buckets  
+  private final static int totalNumBucketsId; // total number of buckets
-  private final static int lowRedundancyBucketCountId; // number of buckets currently without full redundancy
-  
+  private final static int lowRedundancyBucketCountId; // number of buckets currently without full
+                                                       // redundancy
+
-  
+
-  
+
-  
+
-  
+
-  
+
-  
+
-  
+
-    type = f.createType(
-      "PartitionedRegionStats", 
-      "Statistics for operations and connections in the Partitioned Region",
-      new StatisticDescriptor[] {
+    type = f.createType("PartitionedRegionStats",
+        "Statistics for operations and connections in the Partitioned Region",
+        new StatisticDescriptor[] {
-        f.createIntGauge(
-            "bucketCount", 
-            "Number of buckets in this node.",
-            "buckets"),
-        f.createIntCounter(
-            "putsCompleted", 
-            "Number of puts completed.",
-            "operations", 
-            largerIsBetter),         
-        f.createIntCounter(
-            "putOpsRetried", 
-            "Number of put operations which had to be retried due to failures.",
-            "operations", 
-            false),          
-        f.createIntCounter(
-            "putRetries", 
-            "Total number of times put operations had to be retried.",
-            "retry attempts", 
-            false),
-        f.createIntCounter(
-            "createsCompleted", 
-            "Number of creates completed.",
-            "operations", 
-            largerIsBetter),
-        f.createIntCounter(
-            "createOpsRetried", 
-            "Number of create operations which had to be retried due to failures.",
-            "operations", 
-            false),
-        f.createIntCounter(
-            "createRetries", 
-            "Total number of times put operations had to be retried.",
-            "retry attempts", 
-            false),
-        f.createIntCounter(
-            "preferredReadLocal", 
-            "Number of reads satisfied from local store",
-            "operations", 
-            largerIsBetter),
-        f.createIntCounter(PUTALLS_COMPLETED, "Number of putAlls completed.",
-            "operations", largerIsBetter),         
-        f.createIntCounter(PUTALL_MSGS_RETRIED, "Number of putAll messages which had to be retried due to failures.",
-            "operations", false),          
-        f.createIntCounter(PUTALL_RETRIES, "Total number of times putAll messages had to be retried.",
-            "retry attempts", false),
-        f.createLongCounter(PUTALL_TIME, "Total time spent doing putAlls.",
-            "nanoseconds", !largerIsBetter),
-        f.createIntCounter(REMOVE_ALLS_COMPLETED, "Number of removeAlls completed.",
-            "operations", largerIsBetter),         
-        f.createIntCounter(REMOVE_ALL_MSGS_RETRIED, "Number of removeAll messages which had to be retried due to failures.",
-            "operations", false),          
-        f.createIntCounter(REMOVE_ALL_RETRIES, "Total number of times removeAll messages had to be retried.",
-            "retry attempts", false),
-        f.createLongCounter(REMOVE_ALL_TIME, "Total time spent doing removeAlls.",
-            "nanoseconds", !largerIsBetter),
-       f.createIntCounter(
-            "preferredReadRemote", 
-            "Number of reads satisfied from remote store",
-            "operations", 
-            false),
-        f.createIntCounter(
-            "getsCompleted", 
-            "Number of gets completed.",
-            "operations", 
-            largerIsBetter),
-        f.createIntCounter(
-            "getOpsRetried", 
-            "Number of get operations which had to be retried due to failures.",
-            "operations", 
-            false),
-        f.createIntCounter(
-            "getRetries", 
-            "Total number of times get operations had to be retried.",
-            "retry attempts", 
-            false),
-        f.createIntCounter(
-            "destroysCompleted",
-            "Number of destroys completed.", 
-            "operations", 
-            largerIsBetter),
-        f.createIntCounter(
-            "destroyOpsRetried",
-            "Number of destroy operations which had to be retried due to failures.", 
-            "operations", 
-            false),
-        f.createIntCounter(
-            "destroyRetries",
-            "Total number of times destroy operations had to be retried.", 
-            "retry attempts", 
-            false),
-        f.createIntCounter(
-            "invalidatesCompleted",
-            "Number of invalidates completed.", 
-            "operations", 
-            largerIsBetter),
+            f.createIntGauge("bucketCount", "Number of buckets in this node.", "buckets"),
+            f.createIntCounter("putsCompleted", "Number of puts completed.", "operations",
+                largerIsBetter),
+            f.createIntCounter("putOpsRetried",
+                "Number of put operations which had to be retried due to failures.", "operations",
+                false),
+            f.createIntCounter("putRetries",
+                "Total number of times put operations had to be retried.", "retry attempts", false),
+            f.createIntCounter("createsCompleted", "Number of creates completed.", "operations",
+                largerIsBetter),
+            f.createIntCounter("createOpsRetried",
+                "Number of create operations which had to be retried due to failures.",
+                "operations", false),
+            f.createIntCounter("createRetries",
+                "Total number of times put operations had to be retried.", "retry attempts", false),
+            f.createIntCounter("preferredReadLocal", "Number of reads satisfied from local store",
+                "operations", largerIsBetter),
+            f.createIntCounter(PUTALLS_COMPLETED, "Number of putAlls completed.", "operations",
+                largerIsBetter),
+            f.createIntCounter(PUTALL_MSGS_RETRIED,
+                "Number of putAll messages which had to be retried due to failures.", "operations",
+                false),
+            f.createIntCounter(PUTALL_RETRIES,
+                "Total number of times putAll messages had to be retried.", "retry attempts",
+                false),
+            f.createLongCounter(PUTALL_TIME, "Total time spent doing putAlls.", "nanoseconds",
+                !largerIsBetter),
+            f.createIntCounter(REMOVE_ALLS_COMPLETED, "Number of removeAlls completed.",
+                "operations", largerIsBetter),
+            f.createIntCounter(REMOVE_ALL_MSGS_RETRIED,
+                "Number of removeAll messages which had to be retried due to failures.",
+                "operations", false),
+            f.createIntCounter(REMOVE_ALL_RETRIES,
+                "Total number of times removeAll messages had to be retried.", "retry attempts",
+                false),
+            f.createLongCounter(REMOVE_ALL_TIME, "Total time spent doing removeAlls.",
+                "nanoseconds", !largerIsBetter),
+            f.createIntCounter("preferredReadRemote", "Number of reads satisfied from remote store",
+                "operations", false),
+            f.createIntCounter("getsCompleted", "Number of gets completed.", "operations",
+                largerIsBetter),
+            f.createIntCounter("getOpsRetried",
+                "Number of get operations which had to be retried due to failures.", "operations",
+                false),
+            f.createIntCounter("getRetries",
+                "Total number of times get operations had to be retried.", "retry attempts", false),
+            f.createIntCounter("destroysCompleted", "Number of destroys completed.", "operations",
+                largerIsBetter),
+            f.createIntCounter("destroyOpsRetried",
+                "Number of destroy operations which had to be retried due to failures.",
+                "operations", false),
+            f.createIntCounter("destroyRetries",
+                "Total number of times destroy operations had to be retried.", "retry attempts",
+                false),
+            f.createIntCounter("invalidatesCompleted", "Number of invalidates completed.",
+                "operations", largerIsBetter),
-        f.createIntCounter(
-            "invalidateOpsRetried",
-            "Number of invalidate operations which had to be retried due to failures.", 
-            "operations", 
-            false),
-        f.createIntCounter(
-            "invalidateRetries",
-            "Total number of times invalidate operations had to be retried.", 
-            "retry attempts", 
-            false),
-        f.createIntCounter(
-            "containsKeyCompleted",
-            "Number of containsKeys completed.", 
-            "operations", 
-            largerIsBetter),
+            f.createIntCounter("invalidateOpsRetried",
+                "Number of invalidate operations which had to be retried due to failures.",
+                "operations", false),
+            f.createIntCounter("invalidateRetries",
+                "Total number of times invalidate operations had to be retried.", "retry attempts",
+                false),
+            f.createIntCounter("containsKeyCompleted", "Number of containsKeys completed.",
+                "operations", largerIsBetter),
-        f.createIntCounter(
-            "containsKeyOpsRetried",
-            "Number of containsKey or containsValueForKey operations which had to be retried due to failures.", 
-            "operations", 
-            false),
-        f.createIntCounter(
-            "containsKeyRetries",
-            "Total number of times containsKey or containsValueForKey operations had to be retried.", 
-            "operations", 
-            false),
-        f.createIntCounter(
-            "containsValueForKeyCompleted",
-            "Number of containsValueForKeys completed.", 
-            "operations",
-            largerIsBetter),
-        f.createIntCounter(
-            "PartitionMessagesSent",
-            "Number of PartitionMessages Sent.", 
-            "operations",
-            largerIsBetter),
-        f.createIntCounter(
-            "PartitionMessagesReceived",
-            "Number of PartitionMessages Received.", 
-            "operations",
-            largerIsBetter),
-        f.createIntCounter(
-            "PartitionMessagesProcessed",
-            "Number of PartitionMessages Processed.", 
-            "operations",
-            largerIsBetter),
-        f.createLongCounter(
-            "putTime", 
-            "Total time spent doing puts.",
-            "nanoseconds", 
-            false),
-        f.createLongCounter(
-            "createTime",
-            "Total time spent doing create operations.", 
-            "nanoseconds",
-            false),
-        f.createLongCounter(
-            "getTime",
-            "Total time spent performing get operations.", 
-            "nanoseconds",
-            false),
-        f.createLongCounter(
-            "destroyTime", 
-            "Total time spent doing destroys.",
-            "nanoseconds", 
-            false),
-        f.createLongCounter(
-            "invalidateTime",
-            "Total time spent doing invalidates.", 
-            "nanoseconds",
-            false),
-        f.createLongCounter(
-            "containsKeyTime",
-            "Total time spent performing containsKey operations.",
-            "nanoseconds", 
-            false),
-        f.createLongCounter(
-            "containsValueForKeyTime",
-            "Total time spent performing containsValueForKey operations.",
-            "nanoseconds", 
-            false),
-        f.createLongCounter(
-            "partitionMessagesProcessingTime",
-            "Total time spent on PartitionMessages processing.",
-            "nanoseconds", 
-            false),
-        f.createIntGauge(
-            "dataStoreEntryCount", 
-            "The number of entries stored in this Cache for the named Partitioned Region. This does not include entries which are tombstones. See CachePerfStats.tombstoneCount.",
-            "entries"),
-        f.createLongGauge(
-            "dataStoreBytesInUse", 
-            "The current number of bytes stored in this Cache for the named Partitioned Region",
-            "bytes"),
-        f.createIntGauge(
-            "volunteeringInProgress", 
-            "Current number of attempts to volunteer for primary of a bucket.", 
-            "operations"), 
-        f.createIntCounter(
-            "volunteeringBecamePrimary", 
-            "Total number of attempts to volunteer that ended when this member became primary.", 
-            "operations"), 
-        f.createLongCounter(
-            "volunteeringBecamePrimaryTime", 
-            "Total time spent volunteering that ended when this member became primary.", 
-            "nanoseconds", 
-            false),
-        f.createIntCounter(
-            "volunteeringOtherPrimary", 
-            "Total number of attempts to volunteer that ended when this member discovered other primary.", 
-            "operations"), 
-        f.createLongCounter(
-            "volunteeringOtherPrimaryTime", 
-            "Total time spent volunteering that ended when this member discovered other primary.", 
-            "nanoseconds", 
-            false),
-        f.createIntCounter(
-            "volunteeringClosed", 
-            "Total number of attempts to volunteer that ended when this member's bucket closed.", 
-            "operations"), 
-        f.createLongCounter(
-            "volunteeringClosedTime", 
-            "Total time spent volunteering that ended when this member's bucket closed.", 
-            "nanoseconds", 
-            false),
-        f.createIntGauge(
-            "totalNumBuckets", 
-            "The total number of buckets.", 
-            "buckets"), 
-        f.createIntGauge(
-            "primaryBucketCount", 
-            "Current number of primary buckets hosted locally.", 
-            "buckets"), 
-        f.createIntGauge(
-            "volunteeringThreads", 
-            "Current number of threads volunteering for primary.", 
-            "threads"),
-        f.createIntGauge(
-            "lowRedundancyBucketCount", 
-            "Current number of buckets without full redundancy.", 
-            "buckets"),
-        f.createIntGauge(
-            "configuredRedundantCopies", 
-            "Configured number of redundant copies for this partitioned region.", 
-            "copies"),
-        f.createIntGauge(
-            "actualRedundantCopies", 
-            "Actual number of redundant copies for this partitioned region.", 
-            "copies"),
-        f.createIntCounter(
-            "getEntryCompleted", 
-            "Number of getEntry operations completed.",
-            "operations", 
-            largerIsBetter),
-        f.createLongCounter(
-            "getEntryTime",
-            "Total time spent performing getEntry operations.", 
-            "nanoseconds", 
-            false),
-            
-        f.createIntGauge(
-            "recoveriesInProgress",
-            "Current number of redundancy recovery operations in progress for this region.",
-            "operations"),
-        f.createIntCounter(
-            "recoveriesCompleted",
-            "Total number of redundancy recovery operations performed on this region.",
-            "operations"),
-        f.createLongCounter(
-            "recoveryTime",
-            "Total number time spent recovering redundancy.",
-            "operations"),
-        f.createIntGauge(
-            "bucketCreatesInProgress",
-            "Current number of bucket create operations being performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "bucketCreatesCompleted",
-            "Total number of bucket create operations performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "bucketCreatesFailed",
-            "Total number of bucket create operations performed for rebalancing that failed.",
-            "operations"),
-        f.createLongCounter(
-            "bucketCreateTime",
-            "Total time spent performing bucket create operations for rebalancing.",
-            "nanoseconds", 
-            false),
-        f.createIntGauge(
-            "primaryTransfersInProgress",
-            "Current number of primary transfer operations being performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "primaryTransfersCompleted",
-            "Total number of primary transfer operations performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "primaryTransfersFailed",
-            "Total number of primary transfer operations performed for rebalancing that failed.",
-            "operations"),
-        f.createLongCounter(
-            "primaryTransferTime",
-            "Total time spent performing primary transfer operations for rebalancing.",
-            "nanoseconds", false),
+            f.createIntCounter("containsKeyOpsRetried",
+                "Number of containsKey or containsValueForKey operations which had to be retried due to failures.",
+                "operations", false),
+            f.createIntCounter("containsKeyRetries",
+                "Total number of times containsKey or containsValueForKey operations had to be retried.",
+                "operations", false),
+            f.createIntCounter("containsValueForKeyCompleted",
+                "Number of containsValueForKeys completed.", "operations", largerIsBetter),
+            f.createIntCounter("PartitionMessagesSent", "Number of PartitionMessages Sent.",
+                "operations", largerIsBetter),
+            f.createIntCounter("PartitionMessagesReceived", "Number of PartitionMessages Received.",
+                "operations", largerIsBetter),
+            f.createIntCounter("PartitionMessagesProcessed",
+                "Number of PartitionMessages Processed.", "operations", largerIsBetter),
+            f.createLongCounter("putTime", "Total time spent doing puts.", "nanoseconds", false),
+            f.createLongCounter("createTime", "Total time spent doing create operations.",
+                "nanoseconds", false),
+            f.createLongCounter("getTime", "Total time spent performing get operations.",
+                "nanoseconds", false),
+            f.createLongCounter("destroyTime", "Total time spent doing destroys.", "nanoseconds",
+                false),
+            f.createLongCounter("invalidateTime", "Total time spent doing invalidates.",
+                "nanoseconds", false),
+            f.createLongCounter("containsKeyTime",
+                "Total time spent performing containsKey operations.", "nanoseconds", false),
+            f.createLongCounter("containsValueForKeyTime",
+                "Total time spent performing containsValueForKey operations.", "nanoseconds",
+                false),
+            f.createLongCounter("partitionMessagesProcessingTime",
+                "Total time spent on PartitionMessages processing.", "nanoseconds", false),
+            f.createIntGauge("dataStoreEntryCount",
+                "The number of entries stored in this Cache for the named Partitioned Region. This does not include entries which are tombstones. See CachePerfStats.tombstoneCount.",
+                "entries"),
+            f.createLongGauge("dataStoreBytesInUse",
+                "The current number of bytes stored in this Cache for the named Partitioned Region",
+                "bytes"),
+            f.createIntGauge("volunteeringInProgress",
+                "Current number of attempts to volunteer for primary of a bucket.", "operations"),
+            f.createIntCounter("volunteeringBecamePrimary",
+                "Total number of attempts to volunteer that ended when this member became primary.",
+                "operations"),
+            f.createLongCounter("volunteeringBecamePrimaryTime",
+                "Total time spent volunteering that ended when this member became primary.",
+                "nanoseconds", false),
+            f.createIntCounter("volunteeringOtherPrimary",
+                "Total number of attempts to volunteer that ended when this member discovered other primary.",
+                "operations"),
+            f.createLongCounter("volunteeringOtherPrimaryTime",
+                "Total time spent volunteering that ended when this member discovered other primary.",
+                "nanoseconds", false),
+            f.createIntCounter("volunteeringClosed",
+                "Total number of attempts to volunteer that ended when this member's bucket closed.",
+                "operations"),
+            f.createLongCounter("volunteeringClosedTime",
+                "Total time spent volunteering that ended when this member's bucket closed.",
+                "nanoseconds", false),
+            f.createIntGauge("totalNumBuckets", "The total number of buckets.", "buckets"),
+            f.createIntGauge("primaryBucketCount",
+                "Current number of primary buckets hosted locally.", "buckets"),
+            f.createIntGauge("volunteeringThreads",
+                "Current number of threads volunteering for primary.", "threads"),
+            f.createIntGauge("lowRedundancyBucketCount",
+                "Current number of buckets without full redundancy.", "buckets"),
+            f.createIntGauge("configuredRedundantCopies",
+                "Configured number of redundant copies for this partitioned region.", "copies"),
+            f.createIntGauge("actualRedundantCopies",
+                "Actual number of redundant copies for this partitioned region.", "copies"),
+            f.createIntCounter("getEntryCompleted", "Number of getEntry operations completed.",
+                "operations", largerIsBetter),
+            f.createLongCounter("getEntryTime", "Total time spent performing getEntry operations.",
+                "nanoseconds", false),
-        f.createIntCounter("applyReplicationCompleted",
-            "Total number of replicated values sent from a primary to this redundant data store.",
-            "operations", largerIsBetter),
-        f.createIntGauge("applyReplicationInProgress",
-            "Current number of replication operations in progress on this redundant data store.",
-            "operations", !largerIsBetter),
-        f.createLongCounter("applyReplicationTime",
-            "Total time spent storing replicated values on this redundant data store.",
-            "nanoseconds", !largerIsBetter),
-        f.createIntCounter("sendReplicationCompleted",
-            "Total number of replicated values sent from this primary to a redundant data store.",
-            "operations", largerIsBetter),
-        f.createIntGauge("sendReplicationInProgress",
-            "Current number of replication operations in progress from this primary.",
-            "operations", !largerIsBetter),
-        f.createLongCounter("sendReplicationTime",
-            "Total time spent replicating values from this primary to a redundant data store.",
-            "nanoseconds", !largerIsBetter),
-        f.createIntCounter("putRemoteCompleted",
-            "Total number of completed puts that did not originate in the primary. These puts require an extra network hop to the primary.",
-            "operations", largerIsBetter),
-        f.createIntGauge("putRemoteInProgress",
-            "Current number of puts in progress that did not originate in the primary.",
-            "operations", !largerIsBetter),
-        f.createLongCounter("putRemoteTime",
-            "Total time spent doing puts that did not originate in the primary.",
-            "nanoseconds", !largerIsBetter),
-        f.createIntCounter("putLocalCompleted",
-            "Total number of completed puts that did originate in the primary. These puts are optimal.",
-            "operations", largerIsBetter),
-        f.createIntGauge("putLocalInProgress",
-            "Current number of puts in progress that did originate in the primary.",
-            "operations", !largerIsBetter),
-        f.createLongCounter("putLocalTime",
-            "Total time spent doing puts that did originate in the primary.",
-            "nanoseconds", !largerIsBetter),
-            
-        f.createIntGauge(
-            "rebalanceBucketCreatesInProgress",
-            "Current number of bucket create operations being performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "rebalanceBucketCreatesCompleted",
-            "Total number of bucket create operations performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "rebalanceBucketCreatesFailed",
-            "Total number of bucket create operations performed for rebalancing that failed.",
-            "operations"),
-        f.createLongCounter(
-            "rebalanceBucketCreateTime",
-            "Total time spent performing bucket create operations for rebalancing.",
-            "nanoseconds", 
-            false),
-        f.createIntGauge(
-            "rebalancePrimaryTransfersInProgress",
-            "Current number of primary transfer operations being performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "rebalancePrimaryTransfersCompleted",
-            "Total number of primary transfer operations performed for rebalancing.",
-            "operations"),
-        f.createIntCounter(
-            "rebalancePrimaryTransfersFailed",
-            "Total number of primary transfer operations performed for rebalancing that failed.",
-            "operations"),
-        f.createLongCounter(
-            "rebalancePrimaryTransferTime",
-            "Total time spent performing primary transfer operations for rebalancing.",
-            "nanoseconds", false),
-        f.createLongCounter(
-                "prMetaDataSentCount",
-                "total number of times meta data refreshed sent on client's request.",
-                "operation", false),    
-                
-        f.createLongGauge("localMaxMemory", 
-            "local max memory in bytes for this region on this member", 
-            "bytes")
-            
-      });
-    
+            f.createIntGauge("recoveriesInProgress",
+                "Current number of redundancy recovery operations in progress for this region.",
+                "operations"),
+            f.createIntCounter("recoveriesCompleted",
+                "Total number of redundancy recovery operations performed on this region.",
+                "operations"),
+            f.createLongCounter("recoveryTime", "Total number time spent recovering redundancy.",
+                "operations"),
+            f.createIntGauge("bucketCreatesInProgress",
+                "Current number of bucket create operations being performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("bucketCreatesCompleted",
+                "Total number of bucket create operations performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("bucketCreatesFailed",
+                "Total number of bucket create operations performed for rebalancing that failed.",
+                "operations"),
+            f.createLongCounter("bucketCreateTime",
+                "Total time spent performing bucket create operations for rebalancing.",
+                "nanoseconds", false),
+            f.createIntGauge("primaryTransfersInProgress",
+                "Current number of primary transfer operations being performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("primaryTransfersCompleted",
+                "Total number of primary transfer operations performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("primaryTransfersFailed",
+                "Total number of primary transfer operations performed for rebalancing that failed.",
+                "operations"),
+            f.createLongCounter("primaryTransferTime",
+                "Total time spent performing primary transfer operations for rebalancing.",
+                "nanoseconds", false),
+
+            f.createIntCounter("applyReplicationCompleted",
+                "Total number of replicated values sent from a primary to this redundant data store.",
+                "operations", largerIsBetter),
+            f.createIntGauge("applyReplicationInProgress",
+                "Current number of replication operations in progress on this redundant data store.",
+                "operations", !largerIsBetter),
+            f.createLongCounter("applyReplicationTime",
+                "Total time spent storing replicated values on this redundant data store.",
+                "nanoseconds", !largerIsBetter),
+            f.createIntCounter("sendReplicationCompleted",
+                "Total number of replicated values sent from this primary to a redundant data store.",
+                "operations", largerIsBetter),
+            f.createIntGauge("sendReplicationInProgress",
+                "Current number of replication operations in progress from this primary.",
+                "operations", !largerIsBetter),
+            f.createLongCounter("sendReplicationTime",
+                "Total time spent replicating values from this primary to a redundant data store.",
+                "nanoseconds", !largerIsBetter),
+            f.createIntCounter("putRemoteCompleted",
+                "Total number of completed puts that did not originate in the primary. These puts require an extra network hop to the primary.",
+                "operations", largerIsBetter),
+            f.createIntGauge("putRemoteInProgress",
+                "Current number of puts in progress that did not originate in the primary.",
+                "operations", !largerIsBetter),
+            f.createLongCounter("putRemoteTime",
+                "Total time spent doing puts that did not originate in the primary.", "nanoseconds",
+                !largerIsBetter),
+            f.createIntCounter("putLocalCompleted",
+                "Total number of completed puts that did originate in the primary. These puts are optimal.",
+                "operations", largerIsBetter),
+            f.createIntGauge("putLocalInProgress",
+                "Current number of puts in progress that did originate in the primary.",
+                "operations", !largerIsBetter),
+            f.createLongCounter("putLocalTime",
+                "Total time spent doing puts that did originate in the primary.", "nanoseconds",
+                !largerIsBetter),
+
+            f.createIntGauge("rebalanceBucketCreatesInProgress",
+                "Current number of bucket create operations being performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("rebalanceBucketCreatesCompleted",
+                "Total number of bucket create operations performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("rebalanceBucketCreatesFailed",
+                "Total number of bucket create operations performed for rebalancing that failed.",
+                "operations"),
+            f.createLongCounter("rebalanceBucketCreateTime",
+                "Total time spent performing bucket create operations for rebalancing.",
+                "nanoseconds", false),
+            f.createIntGauge("rebalancePrimaryTransfersInProgress",
+                "Current number of primary transfer operations being performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("rebalancePrimaryTransfersCompleted",
+                "Total number of primary transfer operations performed for rebalancing.",
+                "operations"),
+            f.createIntCounter("rebalancePrimaryTransfersFailed",
+                "Total number of primary transfer operations performed for rebalancing that failed.",
+                "operations"),
+            f.createLongCounter("rebalancePrimaryTransferTime",
+                "Total time spent performing primary transfer operations for rebalancing.",
+                "nanoseconds", false),
+            f.createLongCounter("prMetaDataSentCount",
+                "total number of times meta data refreshed sent on client's request.", "operation",
+                false),
+
+            f.createLongGauge("localMaxMemory",
+                "local max memory in bytes for this region on this member", "bytes")
+
+        });
+
-    containsKeyOpsRetriedId= type.nameToId("containsKeyOpsRetried");
+    containsKeyOpsRetriedId = type.nameToId("containsKeyOpsRetried");
-    
+
-    
+
-    
+
-    
+
-  
+
-  /** 
+  /**
-   * This was originally added to avoid having to add a long 
-   * volunteeringStarted variable to every instance of BucketAdvisor. Majority
-   * of BucketAdvisors never volunteer and an instance of BucketAdvisor exists
-   * for every bucket defined in a PartitionedRegion which could result in a
-   * lot of unused longs. Volunteering is a rare event and thus the performance
-   * implications of a HashMap lookup is small and preferrable to so many
-   * longs. Key: BucketAdvisor, Value: Long
+   * This was originally added to avoid having to add a long volunteeringStarted variable to every
+   * instance of BucketAdvisor. Majority of BucketAdvisors never volunteer and an instance of
+   * BucketAdvisor exists for every bucket defined in a PartitionedRegion which could result in a
+   * lot of unused longs. Volunteering is a rare event and thus the performance implications of a
+   * HashMap lookup is small and preferrable to so many longs. Key: BucketAdvisor, Value: Long
+
-    this.stats = factory.createAtomicStatistics(
-type, name /* fixes bug 42343 */);
-    
+    this.stats = factory.createAtomicStatistics(type, name /* fixes bug 42343 */);
+
-    }
-    else {
+    } else {
-  
+
-  
+
+
-  public void endPutAll(long start)
-  {
+  public void endPutAll(long start) {
-  public void endRemoveAll(long start)
-  {
+
+  public void endRemoveAll(long start) {
+
+
+
+
+
+
-  public void endPutAll(long start, int numInc)
-  {
+  public void endPutAll(long start, int numInc) {
-//      this.putStatsHistogram.endOp(delta);
-      
+      // this.putStatsHistogram.endOp(delta);
+
-  public void endRemoveAll(long start, int numInc)
-  {
+
+  public void endRemoveAll(long start, int numInc) {
+
+
-      final long delta = CachePerfStats.getStatTime() - start; 
+      final long delta = CachePerfStats.getStatTime() - start;
+
+
+
+
+
-    this.stats.incInt(containsKeyRetriesId, 1); 
+    this.stats.incInt(containsKeyRetriesId, 1);
+
-    this.stats.incInt(containsKeyOpsRetriedId, 1); 
+    this.stats.incInt(containsKeyOpsRetriedId, 1);
+
+
+
+
+
+
+
+
+
+
-  
+
+
-  
+
-  
+
+
+
-  
+
-  
+
+
+
+
+
+
-  public void incPutAllRetries()
-  {
+  public void incPutAllRetries() {
-  public void incPutAllMsgsRetried()
-  {
+  public void incPutAllMsgsRetried() {
+
-  
+
-  
+
+
+
+
+
+
+
-    return CachePerfStats.getStatTime(); 
+    return CachePerfStats.getStatTime();
+
-      long time = ts-start;
+      long time = ts - start;
+
-      long time = ts-start;
+      long time = ts - start;
+
-      long time = ts-start;
+      long time = ts - start;
+
-  
+
+
-  
+
+
-  
+
+
-  
+
+
+
+
+
-  
+
-  
+
+
-    Long startTime = (Long)this.startTimeMap.remove(key);
+    Long startTime = (Long) this.startTimeMap.remove(key);
-   * Statistic to track the {@link  Region#getEntry(Object)} call
+   * Statistic to track the {@link Region#getEntry(Object)} call
+   * 
-  
+
-  
+
-      this.stats.incLong(recoveriesTimeId, ts-start);
+      this.stats.incLong(recoveriesTimeId, ts - start);
-  
+
+
-      this.stats.incLong(bucketCreateTimeId, ts-start);
+      this.stats.incLong(bucketCreateTimeId, ts - start);
-  
+
+
-      this.stats.incLong(primaryTransferTimeId, ts-start);
+      this.stats.incLong(primaryTransferTimeId, ts - start);
-  
+
+
+
+
+
+
+
+
-  
+
-  
+
+
-      this.stats.incLong(rebalanceBucketCreateTimeId, end-start);
+      this.stats.incLong(rebalanceBucketCreateTimeId, end - start);
-  
+
+
-      this.stats.incLong(rebalancePrimaryTransferTimeId, end-start);
+      this.stats.incLong(rebalancePrimaryTransferTimeId, end - start);
-  
+
+
+
+
+
+
+
+
+
-  
-  public void incPRMetaDataSentCount(){
+
+  public void incPRMetaDataSentCount() {
-  
-  public long getPRMetaDataSentCount(){
+
+  public long getPRMetaDataSentCount() {

UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 DEL66 DEL66 DEL66 DEL66