OPENNLP-949: Add more eval tests for qn and others

+  private final File dutchTrainingFile;
+  private final File dutchTestAFile;
+  private final File dutchTestBFile;
+
+  private final File spanishTrainingFile;
+  private final File spanishTestAFile;
+  private final File spanishTestBFile;
+
+  public Conll02NameFinderEval() {
+    dutchTrainingFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/ned.train");
+    dutchTestAFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/ned.testa");
+    dutchTestBFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/ned.testb");
+
+    spanishTrainingFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/esp.train");
+    spanishTestAFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/esp.testa");
+    spanishTestBFile = new File(EvalUtil.getOpennlpDataDir(), "conll02/ner/data/esp.testb");
+  }
+
-  public void evalDutchPerson() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalDutchPersonPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.train"), LANGUAGE.NL, params,
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testa"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.6238361266294227d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.744312026002167d);
+  }
+
+  @Test
+  public void evalDutchPersonMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testb"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
-  public void evalDutchOrganization() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalDutchPersonMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.train"), LANGUAGE.NL, params,
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.6363636363636364d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.7482403898213319d);
+  }
+
+  @Test
+  public void evalDutchOrganizationPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testa"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.6081871345029239d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.6502808988764045d);
+  }
+
+  @Test
+  public void evalDutchOrganizationMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testb"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
-  public void evalDutchLocation() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalDutchOrganizationMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.train"), LANGUAGE.NL, params,
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.5412748171368861d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.5764966740576497d);
+  }
+
+  @Test
+  public void evalDutchLocationPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testa"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7978609625668449d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7880434782608695d);
+  }
+
+  @Test
+  public void evalDutchLocationMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testb"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
-  public void evalDutchMisc() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalDutchLocationMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.train"), LANGUAGE.NL, params,
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.6737683089214381d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7433903576982893d);
+  }
+
+  @Test
+  public void evalDutchMiscPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testa"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.6651198762567672d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.6748166259168704d);
+  }
+
+  @Test
+  public void evalDutchMiscMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testb"), LANGUAGE.NL,
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
-  public void evalDutchCombined() throws IOException {
+  public void evalDutchMiscMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.4227642276422764d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.455294863665187d);
+  }
+
+  @Test
+  public void evalDutchCombinedPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    int combinedType = Conll02NameSampleStream.GENERATE_PERSON_ENTITIES
+        | Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_MISC_ENTITIES;
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        combinedType);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,   combinedType, 0.727808326787117d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL, combinedType, 0.7388253638253639d);
+  }
+
+  @Test
+  public void evalDutchCombinedMaxentGis() throws IOException {
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.train"), LANGUAGE.NL, params,
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testa"), LANGUAGE.NL,   combinedType, 0.6728164867517175d);
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,   combinedType, 0.6728164867517175d);
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/ned.testb"), LANGUAGE.NL, combinedType, 0.6985893619774816d);
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL, combinedType, 0.6985893619774816d);
-  public void evalSpanishPerson() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalDutchCombinedMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.train"), LANGUAGE.ES, params,
+    int combinedType = Conll02NameSampleStream.GENERATE_PERSON_ENTITIES
+        | Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_MISC_ENTITIES;
+
+    TokenNameFinderModel maxentModel = train(dutchTrainingFile, LANGUAGE.NL, params,
+        combinedType);
+
+    eval(maxentModel, dutchTestAFile, LANGUAGE.NL,   combinedType, 0.6999800915787379d);
+
+    eval(maxentModel, dutchTestBFile, LANGUAGE.NL, combinedType, 0.7101430258496261d);
+  }
+
+  @Test
+  public void evalSpanishPersonPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testa"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.8331210191082803d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.8419705694177864d);
+  }
+
+  @Test
+  public void evalSpanishPersonMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testb"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
-  @Test
-  public void evalSpanishOrganization() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.train"), LANGUAGE.ES, params,
+  @Test
+  public void evalSpanishPersonMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.7432498772704957d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_PERSON_ENTITIES, 0.8218773096821878d);
+  }
+
+  @Test
+  public void evalSpanishOrganizationPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testa"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.7478819748758399d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.7715330894579315d);
+  }
+
+  @Test
+  public void evalSpanishOrganizationMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testb"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
-  public void evalSpanishLocation() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalSpanishOrganizationMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.train"), LANGUAGE.ES, params,
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.6827859978347167d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES, 0.7766212970376302d);
+  }
+
+  @Test
+  public void evalSpanishLocationPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testa"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7018867924528303d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.6315158777711205d);
+  }
+
+  @Test
+  public void evalSpanishLocationMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testb"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
-  public void evalSpanishMisc() throws IOException {
-    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+  public void evalSpanishLocationMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.train"), LANGUAGE.ES, params,
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7544565842438182d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES, 0.7005019520356944d);
+  }
+
+  @Test
+  public void evalSpanishMiscPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testa"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.5102880658436214d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.5842696629213483d);
+  }
+
+  @Test
+  public void evalSpanishMiscMaxentGis() throws IOException {
+    TrainingParameters params = ModelUtil.createDefaultTrainingParameters();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testb"), LANGUAGE.ES,
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
-  public void evalSpanishCombined() throws IOException {
+  public void evalSpanishMiscMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.47095761381475676d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES,
+        Conll02NameSampleStream.GENERATE_MISC_ENTITIES, 0.4926931106471817d);
+  }
+
+  @Test
+  public void evalSpanishCombinedPerceptron() throws IOException {
+    TrainingParameters params = EvalUtil.createPerceptronParams();
+
+    int combinedType = Conll02NameSampleStream.GENERATE_PERSON_ENTITIES
+        | Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_MISC_ENTITIES;
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        combinedType);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES, combinedType, 0.7476700838769804d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES, combinedType, 0.7692307692307693d);
+  }
+
+  @Test
+  public void evalSpanishCombinedMaxentGis() throws IOException {
-    TokenNameFinderModel maxentModel = train(new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.train"), LANGUAGE.ES, params,
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testa"), LANGUAGE.ES, combinedType, 0.706765154179857d);
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES, combinedType, 0.706765154179857d);
-    eval(maxentModel, new File(EvalUtil.getOpennlpDataDir(),
-        "conll02/ner/data/esp.testb"), LANGUAGE.ES, combinedType, 0.7583580194667795d);
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES, combinedType, 0.7583580194667795d);
+  }
+
+  @Test
+  public void evalSpanishCombinedMaxentQn() throws IOException {
+    TrainingParameters params = EvalUtil.createMaxentQnParams();
+
+    int combinedType = Conll02NameSampleStream.GENERATE_PERSON_ENTITIES
+        | Conll02NameSampleStream.GENERATE_ORGANIZATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_LOCATION_ENTITIES
+        | Conll02NameSampleStream.GENERATE_MISC_ENTITIES;
+
+    TokenNameFinderModel maxentModel = train(spanishTrainingFile, LANGUAGE.ES, params,
+        combinedType);
+
+    eval(maxentModel, spanishTestAFile, LANGUAGE.ES, combinedType, 0.7455564833591795d);
+
+    eval(maxentModel, spanishTestBFile, LANGUAGE.ES, combinedType, 0.7856735159817352d);
