OPENNLP-237 Adds abbreviation dictionary to Tokenizer. The Factory class was inspired in SentenceDetector component. 

git-svn-id: https://svn.apache.org/repos/asf/incubator/opennlp/trunk@1149660 13f79535-47bb-0310-9956-ffa450edef68

+import java.util.Collections;
+import java.util.Set;
+import opennlp.tools.dictionary.Dictionary;
+import opennlp.tools.tokenize.lang.Factory;
+   * @deprecated As of release 1.5.2, replaced by {@link Factory#getAlphanumericPattern(String)} 
-  public static final Pattern alphaNumeric = Pattern.compile("^[A-Za-z0-9]+$");
+  public static final Pattern alphaNumeric = Pattern.compile(Factory.DEFAULT_ALPHANUMERIC);
+  
+  private final Pattern alphanumeric;
-  private final TokenContextGenerator cg = new DefaultTokenContextGenerator();
+  private final TokenContextGenerator cg;
+    this(model, new Factory());
+  }
+  
+  public TokenizerME(TokenizerModel model, Factory factory) {
+    String languageCode = model.getLanguage();
+
+    this.alphanumeric = factory.getAlphanumeric(languageCode);
+    this.cg = factory.createTokenContextGenerator(languageCode,
+        getAbbreviations(model.getAbbreviations()));
+
+  
+  private static Set<String> getAbbreviations(Dictionary abbreviations) {
+    if(abbreviations == null) {
+      return Collections.<String>emptySet();
+    }
+    return abbreviations.asStringSet();
+  }
-      else if (useAlphaNumericOptimization() && alphaNumeric.matcher(tok).matches()) {
+      else if (useAlphaNumericOptimization() && alphanumeric.matcher(tok).matches()) {
+  /**
+   * Trains a model for the {@link TokenizerME}.
+   *
+   * @param languageCode the language of the natural text
+   * @param samples the samples used for the training.
+   * @param useAlphaNumericOptimization - if true alpha numerics are skipped
+   * @param mlParams the machine learning train parameters
+   * 
+   * @return the trained {@link TokenizerModel}
+   *
+   * @throws IOException it throws an {@link IOException} if an {@link IOException}
+   * is thrown during IO operations on a temp file which is created during training.
+   * Or if reading from the {@link ObjectStream} fails.
+   * 
+   */
+    return train(languageCode, samples, null, useAlphaNumericOptimization,
+        mlParams);
+  }
+  
+  /**
+   * Trains a model for the {@link TokenizerME}.
+   *
+   * @param languageCode the language of the natural text
+   * @param samples the samples used for the training.
+   * @param abbreviations an abbreviations dictionary
+   * @param useAlphaNumericOptimization - if true alpha numerics are skipped
+   * @param mlParams the machine learning train parameters
+   * 
+   * @return the trained {@link TokenizerModel}
+   *
+   * @throws IOException it throws an {@link IOException} if an {@link IOException}
+   * is thrown during IO operations on a temp file which is created during training.
+   * Or if reading from the {@link ObjectStream} fails.
+   * 
+   */
+  public static TokenizerModel train(String languageCode,
+      ObjectStream<TokenSample> samples, Dictionary abbreviations,
+      boolean useAlphaNumericOptimization, TrainingParameters mlParams)
+      throws IOException {
+    Factory factory = new Factory();
-    
-    EventStream eventStream = new TokSpanEventStream(samples,
-        useAlphaNumericOptimization);
-    AbstractModel maxentModel = TrainUtil.train(eventStream, mlParams.getSettings(), manifestInfoEntries);
-    
-    return new TokenizerModel(languageCode, maxentModel, 
+    EventStream eventStream = new TokSpanEventStream(samples,
+        useAlphaNumericOptimization, factory.getAlphanumeric(languageCode),
+        factory.createTokenContextGenerator(languageCode,
+            getAbbreviations(abbreviations)));
+
+    AbstractModel maxentModel = TrainUtil.train(eventStream,
+        mlParams.getSettings(), manifestInfoEntries);
+
+    return new TokenizerModel(languageCode, maxentModel, abbreviations,
