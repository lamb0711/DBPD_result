OPENNLP-1155: Remove deprecated leipzig doccat format support

+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
-import opennlp.tools.doccat.DocumentSample;
-import opennlp.tools.formats.LeipzigDoccatSampleStream;
+import opennlp.tools.tokenize.SimpleTokenizer;
+import opennlp.tools.util.FilterObjectStream;
+import opennlp.tools.util.InputStreamFactory;
+import opennlp.tools.util.PlainTextByLineStream;
+  private static class LeipzigTestSample {
+    private final List<String> text;
+
+    private LeipzigTestSample(String[] text) {
+      Objects.requireNonNull(text, "text must not be null");
+      this.text = Collections.unmodifiableList(new ArrayList<>(Arrays.asList(text)));
+    }
+
+    public String[] getText() {
+      return text.toArray(new String[text.size()]);
+    }
+
+    @Override
+    public String toString() {
+
+      StringBuilder sampleString = new StringBuilder("eng");
+
+      sampleString.append('\t');
+
+      for (String s : text) {
+        sampleString.append(s).append(' ');
+      }
+
+      if (sampleString.length() > 0) {
+        // remove last space
+        sampleString.setLength(sampleString.length() - 1);
+      }
+
+      return sampleString.toString();
+    }
+  }
+
+  private static class LeipzigTestSampleStream extends FilterObjectStream<String, LeipzigTestSample> {
+
+    private final int sentencePerDocument;
+    private final Tokenizer tokenizer;
+
+    private LeipzigTestSampleStream(int sentencePerDocument, Tokenizer tokenizer, InputStreamFactory in)
+            throws IOException {
+      super(new PlainTextByLineStream(in, StandardCharsets.UTF_8));
+      this.sentencePerDocument = sentencePerDocument;
+      this.tokenizer = tokenizer;
+    }
+
+    @Override
+    public LeipzigTestSample read() throws IOException {
+      int count = 0;
+      List<String> tokensList = new ArrayList<>();
+
+      String line;
+      while (count < sentencePerDocument && (line = samples.read()) != null) {
+
+        String[] tokens = tokenizer.tokenize(line);
+
+        if (tokens.length == 0) {
+          throw new IOException("Empty lines are not allowed!");
+        }
+
+        // Always skip first token, that is the sentence number!
+        tokensList.addAll(Arrays.asList(tokens).subList(1, tokens.length));
+
+        count++;
+      }
+
+      if (tokensList.size() > 0) {
+        return new LeipzigTestSample(tokensList.toArray(new String[tokensList.size()]));
+      }
+
+      return null;
+    }
+  }
+
-    verifyTrainingData(new LeipzigDoccatSampleStream("eng", 25,
+    verifyTrainingData(new LeipzigTestSampleStream(25, SimpleTokenizer.INSTANCE,
-                    "leipzig/eng_news_2010_300K-sentences.txt"))), 
+                    "leipzig/eng_news_2010_300K-sentences.txt"))),
-        new File(getOpennlpDataDir(), "models-sf/en-sent.bin"));
+            new File(getOpennlpDataDir(), "models-sf/en-sent.bin"));
-    try (ObjectStream<DocumentSample> lineBatches = new LeipzigDoccatSampleStream("eng", 25,
-        new MarkableFileInputStreamFactory(new File(getOpennlpDataDir(),
-            "leipzig/eng_news_2010_300K-sentences.txt")))) {
+    try (ObjectStream<LeipzigTestSample> lineBatches = new LeipzigTestSampleStream(25,
+            SimpleTokenizer.INSTANCE,
+            new MarkableFileInputStreamFactory(new File(getOpennlpDataDir(),
+                    "leipzig/eng_news_2010_300K-sentences.txt")))) {
-      DocumentSample lineBatch;
+      LeipzigTestSample lineBatch;
-        new BigInteger(1, digest.digest()));
+            new BigInteger(1, digest.digest()));
-        new File(getOpennlpDataDir(), "models-sf/en-token.bin"));
+            new File(getOpennlpDataDir(), "models-sf/en-token.bin"));
-    try (ObjectStream<DocumentSample> lines = new LeipzigDoccatSampleStream("eng", 1,
-        WhitespaceTokenizer.INSTANCE,
-        new MarkableFileInputStreamFactory(new File(getOpennlpDataDir(),
-            "leipzig/eng_news_2010_300K-sentences.txt")))) {
+    try (ObjectStream<LeipzigTestSample> lines = new LeipzigTestSampleStream(1,
+            WhitespaceTokenizer.INSTANCE,
+            new MarkableFileInputStreamFactory(new File(getOpennlpDataDir(),
+                    "leipzig/eng_news_2010_300K-sentences.txt")))) {
-      DocumentSample line;
+      LeipzigTestSample line;
-        new BigInteger(1, digest.digest()));
+            new BigInteger(1, digest.digest()));
-  private ObjectStream<DocumentSample> createLineWiseStream() throws IOException {
-    return new LeipzigDoccatSampleStream("eng", 1,
+  private ObjectStream<LeipzigTestSample> createLineWiseStream() throws IOException {
+    return new LeipzigTestSampleStream(1,
+        SimpleTokenizer.INSTANCE,
-    try (ObjectStream<DocumentSample> lines = createLineWiseStream()) {
+    try (ObjectStream<LeipzigTestSample> lines = createLineWiseStream()) {
-      DocumentSample line;
+      LeipzigTestSample line;
-    try (ObjectStream<DocumentSample> lines = createLineWiseStream()) {
+    try (ObjectStream<LeipzigTestSample> lines = createLineWiseStream()) {
-      DocumentSample line;
+      LeipzigTestSample line;
-    try (ObjectStream<DocumentSample> lines = createLineWiseStream()) {
+    try (ObjectStream<LeipzigTestSample> lines = createLineWiseStream()) {
-      DocumentSample line;
+      LeipzigTestSample line;
-    try (ObjectStream<DocumentSample> lines = createLineWiseStream()) {
+    try (ObjectStream<LeipzigTestSample> lines = createLineWiseStream()) {
-      DocumentSample line;
+      LeipzigTestSample line;
