OPENNLP-1193: Add support for multi fragment annotation


+import java.util.Collections;
-        Span span = ((SpanAnnotation) ann).getSpan();
-        for (int i = span.getStart(); i < span.getEnd(); i++) {
-          coveredIndexes.put(i, span);
+        for (Span span : ((SpanAnnotation) ann).getSpans()) {
+          for (int i = span.getStart(); i < span.getEnd(); i++) {
+            coveredIndexes.put(i, span);
+          }
+    // Map spans to tokens, and merge fragments based on token
+
+    //
+
+
+    // Detect sentence and correct sentence spans assuming no split can be inside a name annotation
-          Span entitySpan = entity.getSpan();
+          List<Span> mappedFragments = new ArrayList<>();
-          if (sentence.contains(entitySpan)) {
-            entityIdSet.remove(ann.getId());
+          for (Span entitySpan : entity.getSpans()) {
+            if (sentence.contains(entitySpan)) {
+              entityIdSet.remove(ann.getId());
-            entitySpan = entitySpan.trim(sample.getText());
+              entitySpan = entitySpan.trim(sample.getText());
-            Integer nameBeginIndex = tokenIndexMap.get(-entitySpan.getStart());
-            Integer nameEndIndex = tokenIndexMap.get(entitySpan.getEnd());
+              Integer nameBeginIndex = tokenIndexMap.get(-entitySpan.getStart());
+              Integer nameEndIndex = tokenIndexMap.get(entitySpan.getEnd());
-            if (nameBeginIndex != null && nameEndIndex != null) {
-              names.add(new Span(nameBeginIndex, nameEndIndex, entity.getType()));
+              if (nameBeginIndex != null && nameEndIndex != null) {
+                mappedFragments.add(new Span(nameBeginIndex, nameEndIndex, entity.getType()));
+              } else {
+                System.err.println("Dropped entity " + entity.getId() + " ("
+                    + entitySpan.getCoveredText(sample.getText()) + ") " + " in document "
+                    + sample.getId() + ", it is not matching tokenization!");
+              }
-            else {
-              System.err.println("Dropped entity " + entity.getId() + " ("
-                  + entitySpan.getCoveredText(sample.getText()) + ") " + " in document "
-                  + sample.getId() + ", it is not matching tokenization!");
+          }
+
+          Collections.sort(mappedFragments);
+
+          for (int i = 1; i < mappedFragments.size(); i++) {
+            if (mappedFragments.get(i - 1).getEnd() ==
+                mappedFragments.get(i).getStart()) {
+              mappedFragments.set(i, new Span(mappedFragments.get(i - 1).getStart(),
+                  mappedFragments.get(i).getEnd(), mappedFragments.get(i).getType()));
+              mappedFragments.set(i - 1, null);
+            }
+          }
+
+          for (Span span : mappedFragments) {
+            if (span != null ) {
+              names.add(span);
