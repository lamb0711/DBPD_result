OPENNLP-199 Fixed the perceptron, most importantly: uses standard update, stepsize is gradually diminished to ensure stability, and averaging is simplified and improved. Added prepositional phrase attachment dataset and added perceptron unit test on that data.

git-svn-id: https://svn.apache.org/repos/asf/incubator/opennlp/trunk@1133246 13f79535-47bb-0310-9956-ffa450edef68

-  /** Stores the estimated parameter value of each predicate during iteration. */
-  private MutableContext[] params; 
-
-  private int[][][] updates;
-  private int VALUE = 0;
-  private int ITER = 1;
-  private int EVENT = 2;
-  
-  /** Stores the average parameter values of each predicate during iteration. */
-  private MutableContext[] averageParams;
-
-  private EvalParameters evalParams;
-
-  double[] modelDistribution;
-  
-  private int iterations;
-  private boolean useAverage;
-  
-    this.iterations = iterations;
-    this.useAverage = useAverage;
-    this.iterations = iterations;
-    if (useAverage) updates = new int[numPreds][numOutcomes][3];
-
-    params = new MutableContext[numPreds];
-    if (useAverage) averageParams = new MutableContext[numPreds];
-    evalParams = new EvalParameters(params,numOutcomes);
-    
-    int[] allOutcomesPattern= new int[numOutcomes];
-    for (int oi = 0; oi < numOutcomes; oi++) {
-      allOutcomesPattern[oi] = oi;
-    }
-    
-    for (int pi = 0; pi < numPreds; pi++) {
-      params[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
-      if (useAverage) 
-        averageParams[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
-        for (int aoi=0;aoi<numOutcomes;aoi++) {
-          params[pi].setParameter(aoi, 0.0);
-          if (useAverage) 
-            averageParams[pi].setParameter(aoi, 0.0);
-        }
-    }
-    modelDistribution = new double[numOutcomes];
-
-    findParameters(iterations);
+
+    MutableContext[] finalParameters = findParameters(iterations, useAverage);
+
-    if (useAverage)
-      return new PerceptronModel(averageParams, predLabels, outcomeLabels);
-    else
-      return new PerceptronModel(params, predLabels, outcomeLabels);
-  }
-
-  private void display(String s) {
-    if (printMessages)
-      System.out.print(s);
+    return new PerceptronModel(finalParameters, predLabels, outcomeLabels);
-  private void findParameters(int iterations) {
+  private MutableContext[] findParameters (int iterations, boolean useAverage) {
-    int numTimesSameAccuracy = 0;
-    double prevAccuracy = 0.0;
-    for (int i = 1; i <= iterations; i++) {
-      if (i < 10)
-        display("  " + i + ":  ");
-      else if (i < 100)
-        display(" " + i + ":  ");
-      else
-        display(i + ":  ");
-      nextIteration(i);
+    int[] allOutcomesPattern= new int[numOutcomes];
+    for (int oi = 0; oi < numOutcomes; oi++) 
+      allOutcomesPattern[oi] = oi;
-      // Need to do this for the full set to get a representative
-      // accuracy -- doing it while training is biased because the
-      // events are ordered according to their outcomes.
-      double currAccuracy = trainingStats(averageParams);
+    /** Stores the estimated parameter value of each predicate during iteration. */
+    MutableContext[] params = new MutableContext[numPreds];
+    for (int pi = 0; pi < numPreds; pi++) {
+      params[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
+      for (int aoi=0;aoi<numOutcomes;aoi++)
+        params[pi].setParameter(aoi, 0.0);
+    }
+
+    EvalParameters evalParams = new EvalParameters(params,numOutcomes);
+  
+    /** Stores the sum of parameter values of each predicate over many iterations. */
+    MutableContext[] summedParams = new MutableContext[numPreds];
+    if (useAverage) {
+      for (int pi = 0; pi < numPreds; pi++) {
+        summedParams[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
+        for (int aoi=0;aoi<numOutcomes;aoi++)
+          summedParams[pi].setParameter(aoi, 0.0);
+      }
+    }
+
+    // If the change in training set accuracy is less than this, stop iterating.
+    double tolerance = .00001;
+
+    // Keep track of the previous three accuracies. The difference of
+    // the mean of these and the current training set accuracy is used
+    // with tolerance to decide whether to stop.
+    double prevAccuracy1 = 0.0;
+    double prevAccuracy2 = 0.0;
+    double prevAccuracy3 = 0.0;
+
+    // A counter for the denominator for averaging.
+    int numTimesSummed = 0;
+
+    double stepsize = 1.05;
+    for (int i = 1; i <= iterations; i++) {
+
+      // Decrease the stepsize by a small amount.
+      stepsize /= 1.05;
-      if (currAccuracy == prevAccuracy) {
-        numTimesSameAccuracy++;
-      } else {
-        prevAccuracy = currAccuracy;
-        numTimesSameAccuracy = 0;
+      displayIteration(i);
+
+      int numCorrect = 0;
+      int total = 0;
+
+      for (int ei = 0; ei < numUniqueEvents; ei++) {
+        int targetOutcome = outcomeList[ei];
+
+        for (int ni=0; ni<this.numTimesEventsSeen[ei]; ni++) {
+
+          // Compute the model's prediction according to the current parameters.
+          double[] modelDistribution = new double[numOutcomes];
+          if (values != null)
+            PerceptronModel.eval(contexts[ei], values[ei], modelDistribution, evalParams, false);
+          else
+            PerceptronModel.eval(contexts[ei], null, modelDistribution, evalParams, false);
+
+          int maxOutcome = maxIndex(modelDistribution);
+
+          // If the predicted outcome is different from the target
+          // outcome, do the standard update: boost the parameters
+          // associated with the target and reduce those associated
+          // with the incorrect predicted outcome.
+          if (maxOutcome != targetOutcome) {
+            for (int ci = 0; ci < contexts[ei].length; ci++) {
+              int pi = contexts[ei][ci];
+              if (values == null) {
+                params[pi].updateParameter(targetOutcome, stepsize);
+                params[pi].updateParameter(maxOutcome, -stepsize);
+              } else {
+                params[pi].updateParameter(targetOutcome, stepsize*values[ei][ci]);
+                params[pi].updateParameter(maxOutcome, -stepsize*values[ei][ci]);
+              }
+            }
+          }
+
+          // Update the counts for accuracy.
+          total++;
+          if (maxOutcome == targetOutcome) 
+            numCorrect++;
+        }
-      // If the accuracy hasn't changed for four iterations, stop training.
-      if (numTimesSameAccuracy == 4) {
-        display("Accuracy repeated 4 times, stopping training.\n");
+      // Calculate the training accuracy and display.
+      double trainingAccuracy = (double) numCorrect / numEvents;
+      if (i < 10 || (i%10) == 0)
+        display(". (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+          
+      // If we are doing averaging, and the current iteration is one
+      // of the first 20 or it is a perfect square, then updated the
+      // summed parameters. The reason we don't take all of them is
+      // that the parameters change less toward the end of training,
+      // so they drown out the contributions of the more volatile
+      // early iterations. The use of perfect squares allows us to
+      // sample from successively farther apart iterations.
+      if (useAverage && (i < 20 || isPerfectSquare(i))) {
+        numTimesSummed++;
+        for (int pi = 0; pi < numPreds; pi++) 
+          for (int aoi=0;aoi<numOutcomes;aoi++)
+            summedParams[pi].updateParameter(aoi, params[pi].getParameters()[aoi]);
+      }
+
+      // If the tolerance is greater than the difference between the
+      // current training accuracy and all of the previous three
+      // training accuracies, stop training.
+      if (Math.abs(prevAccuracy1-trainingAccuracy) < tolerance
+          && Math.abs(prevAccuracy2-trainingAccuracy) < tolerance
+          && Math.abs(prevAccuracy3-trainingAccuracy) < tolerance) {
+        display("Stopping: change in training set accuracy less than " + tolerance + "\n");
+      
+      // Update the previous training accuracies.
+      prevAccuracy1 = prevAccuracy2;
+      prevAccuracy2 = prevAccuracy3;
+      prevAccuracy3 = trainingAccuracy;
-    if (useAverage)
-      trainingStats(averageParams);
-    else
-      trainingStats(params);
-    // kill a bunch of these big objects now that we don't need them
-    numTimesEventsSeen = null;
-    contexts = null;
+    // Output the final training stats.
+    trainingStats(evalParams);
+
+    // Create averaged parameters
+    if (useAverage) {
+      for (int pi = 0; pi < numPreds; pi++) 
+        for (int aoi=0;aoi<numOutcomes;aoi++)
+          summedParams[pi].setParameter(aoi, summedParams[pi].getParameters()[aoi]/numTimesSummed);
+
+      return summedParams;
+
+    } else {
+
+      return params;
+
+    }
+        
-  /* Compute one iteration of Perceptron.*/
-  private void nextIteration(int iteration) {
-    iteration--; //move to 0-based index
-    int oei = 0;
-    for (int ei = 0; ei < numUniqueEvents; ei++, oei++) {
-      for (int ni=0;ni<this.numTimesEventsSeen[ei];ni++) {
-
-        for (int oi = 0; oi < numOutcomes; oi++)
-          modelDistribution[oi] = 0;
-
-        if (values != null)
-          PerceptronModel.eval(contexts[ei], values[ei], modelDistribution, evalParams,false);
-        else
-          PerceptronModel.eval(contexts[ei], null, modelDistribution, evalParams, false);
-
-        int max = 0;
-        for (int oi = 1; oi < numOutcomes; oi++) 
-          if (modelDistribution[oi] > modelDistribution[max]) 
-            max = oi;
-
-        for (int oi = 0;oi<numOutcomes;oi++) {
-          int updateValue = -1;
-          if (oi == outcomeList[oei])
-            updateValue = 1;
-
-    	  if (modelDistribution[oi]*updateValue <= 0) {
-    	    for (int ci = 0; ci < contexts[ei].length; ci++) {
-    	      int pi = contexts[ei][ci];
-    	      if (values == null)
-    	        params[pi].updateParameter(oi, updateValue);
-    	      else
-    	        params[pi].updateParameter(oi, updateValue*values[ei][ci]);
-    
-    	      if (useAverage) {
-    
-    	        if (updates[pi][oi][VALUE] != 0)
-    	          averageParams[pi].updateParameter(oi, updates[pi][oi][VALUE] *
-    	              (numEvents * (iteration-updates[pi][oi][ITER])
-    	              + (ei-updates[pi][oi][EVENT])));
-    	        
-    	        updates[pi][oi][VALUE] = (int) params[pi].getParameters()[oi];
-    	        updates[pi][oi][ITER] = iteration;
-    	        updates[pi][oi][EVENT] = ei;
-    	      }
-    	    }
-    	  }
-        }
-      }
-    }
-
-    //finish average computation
-    double totIterations = (double) iterations*numEvents;
-    if (useAverage && iteration == iterations-1) {
-      for (int pi = 0; pi < numPreds; pi++) {
-        double[] predParams = averageParams[pi].getParameters();
-        for (int oi = 0;oi<numOutcomes;oi++) {
-          if (updates[pi][oi][VALUE] != 0) 
-            predParams[oi] +=  updates[pi][oi][VALUE] *
-                (numEvents * (iterations-updates[pi][oi][ITER])
-                - updates[pi][oi][EVENT]);
-
-          if (predParams[oi] != 0) {
-            predParams[oi] /=totIterations;  
-            averageParams[pi].setParameter(oi, predParams[oi]);
-          }
-        }
-      }
-    }
-  }  
-  
-  private double trainingStats(MutableContext[] params) {
+  private double trainingStats (EvalParameters evalParams) {
-    int oei = 0;
-    for (int ei = 0; ei < numUniqueEvents; ei++, oei++) {
+
+    for (int ei = 0; ei < numUniqueEvents; ei++) {
-        for (int oi = 0; oi < numOutcomes; oi++)
-          modelDistribution[oi] = 0;
+
+        double[] modelDistribution = new double[numOutcomes];
+
-        int max = 0;
-        for (int oi = 1; oi < numOutcomes; oi++)
-          if (modelDistribution[oi] > modelDistribution[max])
-            max = oi;
-        if (max == outcomeList[oei])
+
+        int max = maxIndex(modelDistribution);
+        if (max == outcomeList[ei])
-    display(". (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+    display("Stats: (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+
+
+  private int maxIndex (double[] values) {
+    int max = 0;
+    for (int i = 1; i < values.length; i++)
+      if (values[i] > values[max])
+        max = i;
+    return max;
+  }
+
+  private void display (String s) {
+    if (printMessages)
+      System.out.print(s);
+  }
+
+  private void displayIteration (int i) {
+    if (i > 10 && (i%10) != 0)
+      return;
+
+    if (i < 10)
+      display("  " + i + ":  ");
+    else if (i < 100)
+      display(" " + i + ":  ");
+    else
+      display(i + ":  ");
+  }
+
+  // See whether a number is a perfect square. Inefficient, but fine
+  // for our purposes.
+  private final static boolean isPerfectSquare (int n) {
+    int root = (int)Math.sqrt(n);
+    return root*root == n;
+  }
+
