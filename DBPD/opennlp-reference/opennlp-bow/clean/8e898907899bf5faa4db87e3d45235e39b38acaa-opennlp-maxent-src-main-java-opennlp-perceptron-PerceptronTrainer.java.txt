OPENNLP-199 Step size decrease is now disabled by default and configurable, special averaging is disabled by default, and can be enabled.

git-svn-id: https://svn.apache.org/repos/asf/incubator/opennlp/trunk@1145601 13f79535-47bb-0310-9956-ffa450edef68

+  public static final double TOLERANCE_DEFAULT = .00001;
+  
+  
+  private double tolerance = TOLERANCE_DEFAULT;
+  
+  private Double stepSizeDecrease;
+  
+  private boolean useSkippedlAveraging;
+  
+  /**
+   * Specifies the tolerance. If the change in training set accuracy
+   * is less than this, stop iterating.
+   * 
+   * @param tolerance
+   */
+  public void setTolerance(double tolerance) {
+    if (tolerance < 0)
+      throw new IllegalArgumentException("tolerance must be a positive number!");
+    
+    this.tolerance = tolerance;
+  }
+
+  /**
+   * Enables and sets step size decrease. The step size is
+   * decreased every iteration by the specified value.
+   * 
+   * @param decrease - step size decrease in percent
+   */
+  public void setStepSizeDecrease(double decrease) {
+    
+    if (decrease < 0 || decrease > 100)
+      throw new IllegalArgumentException("decrease must be between 0 and 100");
+    
+    stepSizeDecrease = decrease;
+  }
+  
+  /**
+   * Enables skipped averaging, this flag changes the standard
+   * averaging to special averaging instead.
+   * <p>
+   * If we are doing averaging, and the current iteration is one
+   * of the first 20 or it is a perfect square, then updated the
+   * summed parameters. 
+   * <p>
+   * The reason we don't take all of them is that the parameters change
+   * less toward the end of training, so they drown out the contributions
+   * of the more volatile early iterations. The use of perfect
+   * squares allows us to sample from successively farther apart iterations.
+   *  
+   * @param averaging
+   * 
+   * @return
+   */
+  public void setSkippedAveraging(boolean averaging) {
+    useSkippedlAveraging = averaging;
+  }
+  
-    // If the change in training set accuracy is less than this, stop iterating.
-    double tolerance = .00001;
-
-    double stepsize = 1.05;
+    double stepsize = 1;
-      stepsize /= 1.05;
+      if (stepSizeDecrease != null)
+        stepsize *= 1 - stepSizeDecrease;
-      int total = 0;
-          total++;
-      // If we are doing averaging, and the current iteration is one
-      // of the first 20 or it is a perfect square, then updated the
-      // summed parameters. The reason we don't take all of them is
-      // that the parameters change less toward the end of training,
-      // so they drown out the contributions of the more volatile
-      // early iterations. The use of perfect squares allows us to
-      // sample from successively farther apart iterations.
-      if (useAverage && (i < 20 || isPerfectSquare(i))) {
+      // TODO: Make averaging configurable !!!
+      
+      boolean doAveraging;
+      
+      if (useAverage && useSkippedlAveraging && (i < 20 || isPerfectSquare(i))) {
+        doAveraging = true;
+      }
+      else if (useAverage) {
+        doAveraging = true;
+      }
+      else {
+        doAveraging = false;
+      }
+      
+      if (doAveraging) {
