OPENNLP-180 Removed old main methods

git-svn-id: https://svn.apache.org/repos/asf/incubator/opennlp/trunk@1124657 13f79535-47bb-0310-9956-ffa450edef68

-
-  @Deprecated
-  private static void usage() {
-    System.err.println("Usage: Parser -[dict|tag|chunk|build|check|fun] trainingFile parserModelDirectory [iterations cutoff]");
-    System.err.println();
-    System.err.println("Training file should be one sentence per line where each line consists of a Penn Treebank Style parse");
-    System.err.println("-dict Just build the dictionaries.");
-    System.err.println("-tag Just build the tagging model.");
-    System.err.println("-chunk Just build the chunking model.");
-    System.err.println("-build Just build the build model");
-    System.err.println("-check Just build the check model");
-    System.err.println("-fun Predict function tags");
-  }
-
-
-
-  @Deprecated
-  public static void main(String[] args) throws IOException, InvalidFormatException {
-    if (args.length < 2) {
-      usage();
-      System.exit(1);
-    }
-    boolean dict = false;
-    boolean tag = false;
-    boolean chunk = false;
-    boolean build = false;
-    boolean check = false;
-    boolean fun = false;
-    boolean all = true;
-    int argIndex = 0;
-    while (args[argIndex].startsWith("-")) {
-      all = false;
-      if (args[argIndex].equals("-dict")) {
-        dict = true;
-      }
-      else if (args[argIndex].equals("-tag")) {
-        tag = true;
-      }
-      else if (args[argIndex].equals("-chunk")) {
-        chunk = true;
-      }
-      else if (args[argIndex].equals("-build")) {
-        build = true;
-      }
-      else if (args[argIndex].equals("-check")) {
-        check = true;
-      }
-      else if (args[argIndex].equals("-fun")) {
-        fun = true;
-      }
-      else if (args[argIndex].equals("--")) {
-        argIndex++;
-        break;
-      }
-      else {
-        System.err.println("Invalid option " + args[argIndex]);
-        usage();
-        System.exit(1);
-      }
-      argIndex++;
-    }
-    java.io.File inFile = new java.io.File(args[argIndex++]);
-    String modelDirectory = args[argIndex++];
-    HeadRules rules = new opennlp.tools.parser.lang.en.HeadRules(modelDirectory+"/head_rules");
-    java.io.File dictFile = new java.io.File(modelDirectory+"/dict.bin.gz");
-    java.io.File tagFile = new java.io.File(modelDirectory+"/tag.bin.gz");
-    java.io.File chunkFile = new java.io.File(modelDirectory+"/chunk.bin.gz");
-    java.io.File buildFile = new java.io.File(modelDirectory+"/build.bin.gz");
-    java.io.File checkFile = new java.io.File(modelDirectory+"/check.bin.gz");
-    int iterations = 100;
-    int cutoff = 5;
-    if (args.length > argIndex) {
-      iterations = Integer.parseInt(args[argIndex++]);
-      cutoff = Integer.parseInt(args[argIndex++]);
-    }
-    // TODO: This option is missing in the current CLI tools,
-    // and it is not thread safe ...
-    if (fun) {
-      Parse.useFunctionTags(true);
-    }
-    
-    if (dict || all) {
-      System.err.println("Building dictionary");
-      ObjectStream<Parse> data = new ParseSampleStream(new PlainTextByLineStream(new FileReader(inFile)));
-      Dictionary mdict = buildDictionary(data, rules, cutoff);
-      System.out.println("Saving the dictionary");
-      mdict.serialize(new FileOutputStream(dictFile));
-    }
-    
-    if (tag || all) {
-      System.err.println("Training tagger");
-      ObjectStream<POSSample> tes = new PosSampleStream(new ParseSampleStream(new PlainTextByLineStream(new java.io.FileReader(inFile))));
-      POSModel posModel = POSTaggerME.train("en", tes, ModelType.MAXENT, null, null, cutoff, 100);
-      System.out.println("Saving the tagger model as: " + tagFile);
-      OutputStream posOutputStream = new FileOutputStream(tagFile);
-      posModel.serialize(posOutputStream);
-      posOutputStream.close();
-    }
-
-    if (chunk || all) {
-      System.err.println("Training chunker");
-      ObjectStream<ChunkSample> ces = new ChunkSampleStream(new ParseSampleStream(new PlainTextByLineStream(new java.io.FileReader(inFile))));
-      ChunkerModel chunkModel = ChunkerME.train("en", ces, cutoff, iterations, 
-          new ChunkContextGenerator());
-      System.out.println("Saving the chunker model as: " + chunkFile);
-      OutputStream chunkOutputStream = new FileOutputStream(chunkFile);
-      chunkModel.serialize(chunkOutputStream);
-      chunkOutputStream.close();
-    }
-
-    if (build || all) {
-      System.err.println("Loading Dictionary");
-      Dictionary tridict = new Dictionary(new FileInputStream(dictFile.toString()),true);
-      System.err.println("Training builder");
-      opennlp.model.EventStream bes = new ParserEventStream(new ParseSampleStream(new PlainTextByLineStream(new java.io.FileReader(inFile))), rules, ParserEventTypeEnum.BUILD,tridict);
-      AbstractModel buildModel = train(bes, iterations, cutoff);
-      System.out.println("Saving the build model as: " + buildFile);
-      new opennlp.maxent.io.SuffixSensitiveGISModelWriter(buildModel, buildFile).persist();
-    }
-
-    if (check || all) {
-      System.err.println("Training checker");
-      opennlp.model.EventStream kes = new ParserEventStream(new ParseSampleStream(new PlainTextByLineStream(new java.io.FileReader(inFile))), rules, ParserEventTypeEnum.CHECK);
-      AbstractModel checkModel = train(kes, iterations, cutoff);
-      System.out.println("Saving the check model as: " + checkFile);
-      new opennlp.maxent.io.SuffixSensitiveGISModelWriter(checkModel, checkFile).persist();
-    }
-  }
