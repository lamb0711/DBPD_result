OPENNLP-123: Feature cutoff should only be done by data indexers, this closes apache/opennlp#65

- *
+ * <p>
- *
+ * <p>
+  private static final double LLThreshold = 0.0001;
+  private final boolean printMessages;
-
-
-
-
-  private final boolean printMessages;
-
-
-
-
-
-
-
-
-  /**
-   * The number of times a predicate occured in the training data.
-   */
-  private int[] predicateCounts;
-
-  private int cutoff;
-
-
-
-
-
-
-
-  private static final double LLThreshold = 0.0001;
-
-   *
-   *
+   *
-   * @param iterations The number of iterations to use for GIS.
-   * @param cutoff The number of times a feature must occur to be included.
+   * @param iterations  The number of iterations to use for GIS.
+   * @param cutoff      The number of times a feature must occur to be included.
-  public GISModel trainModel(ObjectStream<Event> eventStream, int iterations, int cutoff) throws IOException {
+  public GISModel trainModel(ObjectStream<Event> eventStream, int iterations,
+                             int cutoff) throws IOException {
-    return trainModel(iterations, indexer, cutoff);
+    return trainModel(iterations, indexer);
-   * @param iterations  The number of GIS iterations to perform.
-   * @param di The data indexer used to compress events in memory.
+   * @param iterations The number of GIS iterations to perform.
+   * @param di         The data indexer used to compress events in memory.
-   *         to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
+   * to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
-  public GISModel trainModel(int iterations, DataIndexer di, int cutoff) {
-    return trainModel(iterations,di,new UniformPrior(),cutoff,1);
+  public GISModel trainModel(int iterations, DataIndexer di) {
+    return trainModel(iterations, di, new UniformPrior(), 1);
-   * @param iterations  The number of GIS iterations to perform.
-   * @param di The data indexer used to compress events in memory.
+   * @param iterations The number of GIS iterations to perform.
+   * @param di         The data indexer used to compress events in memory.
-   *         to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
+   * to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
-  public GISModel trainModel(int iterations, DataIndexer di, Prior modelPrior, int cutoff, int threads) {
+  public GISModel trainModel(int iterations, DataIndexer di, Prior modelPrior, int threads) {
-    this.cutoff = cutoff;
-    predicateCounts = di.getPredCounts();
+    /*
+    The number of times a predicate occured in the training data.
+   */
+    int[] predicateCounts = di.getPredCounts();
-      }
-      else {
+      } else {
-    prior.setLabels(outcomeLabels,predLabels);
+    prior.setLabels(outcomeLabels, predLabels);
-        }
-        else {
+        } else {
-    //printTable(predCount);
-    di = null; // don't need it anymore
-
-    for (int i = 0; i < modelExpects.length; i++)
+    for (int i = 0; i < modelExpects.length; i++) {
+    }
-    evalParams = new EvalParameters(params,0,1,numOutcomes);
+    evalParams = new EvalParameters(params, 0, 1, numOutcomes);
-      }
-      else { //determine active outcomes
+      } else { //determine active outcomes
-          if (predCount[pi][oi] > 0 && predicateCounts[pi] >= cutoff) {
+          if (predCount[pi][oi] > 0) {
-        }
-        else {
+        } else {
-      params[pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      for (int i = 0; i < modelExpects.length; i++)
-        modelExpects[i][pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      observedExpects[pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      for (int aoi = 0;aoi < numActiveOutcomes; aoi++) {
+      params[pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      for (int i = 0; i < modelExpects.length; i++) {
+        modelExpects[i][pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      }
+      observedExpects[pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      for (int aoi = 0; aoi < numActiveOutcomes; aoi++) {
-        }
-        else if (useSimpleSmoothing) {
-          observedExpects[pi].setParameter(aoi,smoothingObservation);
+        } else if (useSimpleSmoothing) {
+          observedExpects[pi].setParameter(aoi, smoothingObservation);
-    predCount = null; // don't need it anymore
-
-    if (threads == 1)
+    if (threads == 1) {
-    else
+    } else {
+    }
-    CompletionService<ModelExpactationComputeTask> completionService =
+    CompletionService<ModelExpectationComputeTask> completionService =
-      if (i < 10)
+      if (i < 10) {
-      else if (i < 100)
+      } else if (i < 100) {
-      else
+      } else {
-      currLL = nextIteration(correctionConstant,completionService);
+      }
+      currLL = nextIteration(correctionConstant, completionService);
-  private double gaussianUpdate(int predicate, int oid, int n, double correctionConstant) {
+  private double gaussianUpdate(int predicate, int oid, double correctionConstant) {
-  private class ModelExpactationComputeTask implements Callable<ModelExpactationComputeTask> {
-
-    private final int startIndex;
-    private final int length;
-
-    private double loglikelihood = 0;
-
-    private int numEvents = 0;
-    private int numCorrect = 0;
-
-    final private int threadIndex;
-
-    // startIndex to compute, number of events to compute
-    ModelExpactationComputeTask(int threadIndex, int startIndex, int length) {
-      this.startIndex = startIndex;
-      this.length = length;
-      this.threadIndex = threadIndex;
-    }
-
-    public ModelExpactationComputeTask call() {
-
-      final double[] modelDistribution = new double[numOutcomes];
-
-
-      for (int ei = startIndex; ei < startIndex + length; ei++) {
-
-        // TODO: check interruption status here, if interrupted set a poisoned flag and return
-
-        if (values != null) {
-          prior.logPrior(modelDistribution, contexts[ei], values[ei]);
-          GISModel.eval(contexts[ei], values[ei], modelDistribution, evalParams);
-        }
-        else {
-          prior.logPrior(modelDistribution,contexts[ei]);
-          GISModel.eval(contexts[ei], modelDistribution, evalParams);
-        }
-        for (int j = 0; j < contexts[ei].length; j++) {
-          int pi = contexts[ei][j];
-          if (predicateCounts[pi] >= cutoff) {
-            int[] activeOutcomes = modelExpects[threadIndex][pi].getOutcomes();
-            for (int aoi = 0;aoi < activeOutcomes.length; aoi++) {
-              int oi = activeOutcomes[aoi];
-
-              // numTimesEventsSeen must also be thread safe
-              if (values != null && values[ei] != null) {
-                modelExpects[threadIndex][pi].updateParameter(aoi,modelDistribution[oi]
-                    * values[ei][j] * numTimesEventsSeen[ei]);
-              }
-              else {
-                modelExpects[threadIndex][pi].updateParameter(aoi,modelDistribution[oi]
-                    * numTimesEventsSeen[ei]);
-              }
-            }
-          }
-        }
-
-        loglikelihood += Math.log(modelDistribution[outcomeList[ei]]) * numTimesEventsSeen[ei];
-
-        numEvents += numTimesEventsSeen[ei];
-        if (printMessages) {
-          int max = 0;
-          for (int oi = 1; oi < numOutcomes; oi++) {
-            if (modelDistribution[oi] > modelDistribution[max]) {
-              max = oi;
-            }
-          }
-          if (max == outcomeList[ei]) {
-            numCorrect += numTimesEventsSeen[ei];
-          }
-        }
-
-      }
-
-      return this;
-    }
-
-    synchronized int getNumEvents() {
-      return numEvents;
-    }
-
-    synchronized int getNumCorrect() {
-      return numCorrect;
-    }
-
-    synchronized double getLoglikelihood() {
-      return loglikelihood;
-    }
-  }
-
-                               CompletionService<ModelExpactationComputeTask> completionService) {
+                               CompletionService<ModelExpectationComputeTask> completionService) {
-    // is not divisible by the number of threads, the first "leftOver" 
+    // is not divisible by the number of threads, the first "leftOver"
-      if (i < leftOver)
-        completionService.submit(new ModelExpactationComputeTask(i, i * taskSize + i, taskSize + 1));
-      else
-        completionService.submit(new ModelExpactationComputeTask(i, i * taskSize + leftOver, taskSize));
+      if (i < leftOver) {
+        completionService.submit(new ModelExpectationComputeTask(i, i * taskSize + i,
+            taskSize + 1));
+      } else {
+        completionService.submit(new ModelExpectationComputeTask(i,
+            i * taskSize + leftOver, taskSize));
+      }
-      ModelExpactationComputeTask finishedTask;
+      ModelExpectationComputeTask finishedTask;
-          params[pi].updateParameter(aoi,gaussianUpdate(pi,aoi,numEvents,correctionConstant));
-        }
-        else {
+          params[pi].updateParameter(aoi, gaussianUpdate(pi, aoi, correctionConstant));
+        } else {
-          params[pi].updateParameter(aoi,((Math.log(observed[aoi]) - Math.log(model[aoi]))
+          params[pi].updateParameter(aoi, ((Math.log(observed[aoi]) - Math.log(model[aoi]))
-    if (printMessages)
+    if (printMessages) {
+    }
+  }
+
+  private class ModelExpectationComputeTask implements Callable<ModelExpectationComputeTask> {
+
+    private final int startIndex;
+    private final int length;
+    final private int threadIndex;
+    private double loglikelihood = 0;
+    private int numEvents = 0;
+    private int numCorrect = 0;
+
+    // startIndex to compute, number of events to compute
+    ModelExpectationComputeTask(int threadIndex, int startIndex, int length) {
+      this.startIndex = startIndex;
+      this.length = length;
+      this.threadIndex = threadIndex;
+    }
+
+    public ModelExpectationComputeTask call() {
+
+      final double[] modelDistribution = new double[numOutcomes];
+
+
+      for (int ei = startIndex; ei < startIndex + length; ei++) {
+
+        // TODO: check interruption status here, if interrupted set a poisoned flag and return
+
+        if (values != null) {
+          prior.logPrior(modelDistribution, contexts[ei], values[ei]);
+          GISModel.eval(contexts[ei], values[ei], modelDistribution, evalParams);
+        } else {
+          prior.logPrior(modelDistribution, contexts[ei]);
+          GISModel.eval(contexts[ei], modelDistribution, evalParams);
+        }
+        for (int j = 0; j < contexts[ei].length; j++) {
+          int pi = contexts[ei][j];
+          int[] activeOutcomes = modelExpects[threadIndex][pi].getOutcomes();
+          for (int aoi = 0; aoi < activeOutcomes.length; aoi++) {
+            int oi = activeOutcomes[aoi];
+
+            // numTimesEventsSeen must also be thread safe
+            if (values != null && values[ei] != null) {
+              modelExpects[threadIndex][pi].updateParameter(aoi, modelDistribution[oi]
+                  * values[ei][j] * numTimesEventsSeen[ei]);
+            } else {
+              modelExpects[threadIndex][pi].updateParameter(aoi, modelDistribution[oi]
+                  * numTimesEventsSeen[ei]);
+            }
+          }
+        }
+
+        loglikelihood += Math.log(modelDistribution[outcomeList[ei]]) * numTimesEventsSeen[ei];
+
+        numEvents += numTimesEventsSeen[ei];
+        if (printMessages) {
+          int max = 0;
+          for (int oi = 1; oi < numOutcomes; oi++) {
+            if (modelDistribution[oi] > modelDistribution[max]) {
+              max = oi;
+            }
+          }
+          if (max == outcomeList[ei]) {
+            numCorrect += numTimesEventsSeen[ei];
+          }
+        }
+
+      }
+
+      return this;
+    }
+
+    synchronized int getNumEvents() {
+      return numEvents;
+    }
+
+    synchronized int getNumCorrect() {
+      return numCorrect;
+    }
+
+    synchronized double getLoglikelihood() {
+      return loglikelihood;
+    }
