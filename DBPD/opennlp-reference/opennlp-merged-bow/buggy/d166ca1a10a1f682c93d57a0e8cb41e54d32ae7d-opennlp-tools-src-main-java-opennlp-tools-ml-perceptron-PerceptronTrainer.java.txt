OPENNLP-581 Added Trainer, EventTrainer and SequenceTrainer interfaces and some abstract implementations. Modified existing trainers to extend the abstract classes

git-svn-id: https://svn.apache.org/repos/asf/opennlp/trunk@1489970 13f79535-47bb-0310-9956-ffa450edef68

+import java.io.IOException;
+import java.util.Collections;
+import java.util.Map;
+
+import opennlp.tools.ml.AbstractEventTrainer;
-public class PerceptronTrainer {
+public class PerceptronTrainer extends AbstractEventTrainer {
+  public static final String PERCEPTRON_VALUE = "PERCEPTRON";
+  // >> members related to AbstractSequenceTrainer
+  public PerceptronTrainer(Map<String, String> trainParams,
+      Map<String, String> reportMap) {
+    super(trainParams, reportMap);
+  }
+
+  public PerceptronTrainer() {
+    super(Collections.<String, String> emptyMap(), Collections
+        .<String, String> emptyMap());
+  }
+
+  public boolean isValid() {
+
+    if (!super.isValid()) {
+      return false;
+    }
+
+    String algorithmName = getAlgorithm();
+
+    if (algorithmName != null && !(PERCEPTRON_VALUE.equals(algorithmName))) {
+      return false;
+    }
+
+    return true;
+  }
+
+  public boolean isSortAndMerge() {
+    return false;
+  }
+
+  public AbstractModel doTrain(DataIndexer indexer) throws IOException {
+    if (!isValid()) {
+      throw new IllegalArgumentException("trainParams are not valid!");
+    }
+
+    int iterations = getIterations();
+    int cutoff = getCutoff();
+
+    AbstractModel model;
+
+    boolean useAverage = getBooleanParam("UseAverage", true);
+
+    boolean useSkippedAveraging = getBooleanParam("UseSkippedAveraging", false);
+
+    // overwrite otherwise it might not work
+    if (useSkippedAveraging)
+      useAverage = true;
+
+    double stepSizeDecrease = getDoubleParam("StepSizeDecrease", 0);
+
+    double tolerance = getDoubleParam("Tolerance",
+        PerceptronTrainer.TOLERANCE_DEFAULT);
+
+    this.setSkippedAveraging(useSkippedAveraging);
+
+    if (stepSizeDecrease > 0)
+      this.setStepSizeDecrease(stepSizeDecrease);
+
+    this.setTolerance(tolerance);
+
+    model = this.trainModel(iterations, indexer, cutoff, useAverage);
+
+    return model;
+  }
+
+  // << members related to AbstractSequenceTrainer
+

INS26 INS26 INS26 INS26 INS40 INS40 INS40 INS40 INS43 INS23 INS31 INS31 INS31 INS31 INS31 INS42 INS83 INS83 INS83 INS43 INS59 INS83 INS42 INS44 INS44 INS8 INS83 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS39 INS42 INS8 INS83 INS43 INS42 INS44 INS43 INS8 INS42 INS42 INS45 INS74 INS42 INS74 INS42 INS46 INS46 INS25 INS60 INS25 INS41 INS41 INS42 INS43 INS42 INS42 INS25 INS60 INS60 INS60 INS60 INS60 INS25 INS60 INS60 INS21 INS25 INS21 INS21 INS41 INS43 INS43 INS43 INS43 INS43 INS43 INS42 INS42 INS32 INS32 INS38 INS8 INS43 INS59 INS27 INS8 INS9 INS9 INS42 INS38 INS8 INS39 INS59 INS39 INS59 INS43 INS59 INS39 INS59 INS39 INS59 INS42 INS21 INS39 INS59 INS39 INS59 INS32 INS27 INS21 INS32 INS7 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS43 INS42 INS42 INS43 INS43 INS42 INS48 INS41 INS42 INS42 INS32 INS27 INS38 INS41 INS32 INS53 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS32 INS42 INS32 INS7 INS42 INS32 INS42 INS32 INS52 INS42 INS42 INS42 INS34 INS32 INS52 INS42 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS9 INS42 INS42 INS33 INS36 INS9 INS42 INS14 INS42 INS42 INS42 INS45 INS9 INS42 INS45 INS9 INS42 INS9 INS42 INS45 INS34 INS42 INS45 INS40 INS52 INS42 INS42 INS52 INS42 INS42 INS42 INS42 INS42 INS32 INS43 INS45 INS42 INS42 INS42 INS42