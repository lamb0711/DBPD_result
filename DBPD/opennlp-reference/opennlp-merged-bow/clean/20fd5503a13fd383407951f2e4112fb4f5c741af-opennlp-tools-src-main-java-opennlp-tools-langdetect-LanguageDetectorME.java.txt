OPENNLP-1267 -- add a ProbingLanguageDetector that can stop early. (#357)

* OPENNLP-1267 -- add a ProbingLanguageDetector that can stop early.

* OPENNLP-1267 -- updates based on discussion.  This moves probing
into LanguageDetectorME.

+import java.util.LinkedList;
+import java.util.List;
+import opennlp.tools.util.MutableInt;
+ *
+ * <p>
+ * This will process the entire string when called with
+ * {@link #predictLanguage(CharSequence)} or
+ * {@link #predictLanguages(CharSequence)}.
+ * </p>
+ * <p>
+ * If you want this to stop early, use {@link #probingPredictLanguages(CharSequence)}
+ * or {@link #probingPredictLanguages(CharSequence, LanguageDetectorConfig)}.
+ * When run in probing mode, this starts at the beginning of the charsequence
+ * and runs language detection on chunks of text.  If the end of the
+ * string is reached or there are {@link LanguageDetectorConfig#getMinConsecImprovements()}
+ * consecutive predictions for the best language and the confidence
+ * increases over those last predictions and if the difference
+ * in confidence between the highest confidence language
+ * and the second highest confidence language is greater than
+ * {@link LanguageDetectorConfig#getMinDiff()}, the language detector will
+ * stop and report the results.
+ * </p>
+ * <p>
+ * The authors wish to thank Ken Krugler and
+ * <a href="https://github.com/kkrugler/yalder">Yalder</a>}
+ * for the inspiration for many of the design
+ * components of this detector.
+ *
-  private LanguageDetectorModel model;
+  protected LanguageDetectorModel model;
+  /**
+   * This will process the full content length.
+   *
+   * @param content
+   * @return the predicted languages
+   */
-    double[] eval = model.getMaxentModel().eval(mContextGenerator.getContext(content.toString()));
-    Language[] arr = new Language[eval.length];
-    for (int i = 0; i < eval.length; i++) {
-      arr[i] = new Language(model.getMaxentModel().getOutcome(i), eval[i]);
-    }
-
-    Arrays.sort(arr, (o1, o2) -> Double.compare(o2.getConfidence(), o1.getConfidence()));
-    return arr;
+    return predict(arrayToCounts(
+            mContextGenerator.getContext(content)));
+  /**
+   * This will process the full content length.
+   *
+   * @param content
+   * @return the language with the highest confidence
+   */
+  /**
+   * This will stop processing early if the stopping criteria
+   * specified in {@link LanguageDetectorConfig#DEFAULT_LANGUAGE_DETECTOR_CONFIG}
+   * are met.
+   *
+   * @param content content to be processed
+   * @return result
+   */
+  public ProbingLanguageDetectionResult probingPredictLanguages(CharSequence content) {
+    return probingPredictLanguages(content,
+            LanguageDetectorConfig.DEFAULT_LANGUAGE_DETECTOR_CONFIG);
+  }
+
+  /**
+   * This will stop processing early if the stopping criteria
+   * specified in {@link LanguageDetectorConfig#DEFAULT_LANGUAGE_DETECTOR_CONFIG}
+   * are met.
+   *
+   * @param content content to process
+   * @param config config to customize detection
+   * @return
+   */
+  public ProbingLanguageDetectionResult probingPredictLanguages(CharSequence content,
+                                                                LanguageDetectorConfig config) {
+    //list of the languages that received the highest
+    //confidence over the last n chunk detections
+    List<Language[]> predictions = new LinkedList();
+    int start = 0;//where to start the next chunk in codepoints
+    Language[] currPredictions = null;
+    //cache ngram counts across chunks
+    Map<String, MutableInt> ngramCounts = new HashMap<>();
+    while (true) {
+      int actualChunkSize =
+              (start + config.getChunkSize() > config.getMaxLength()) ?
+                      config.getMaxLength() - start : config.getChunkSize();
+      StringCPLengthPair chunk = chunk(content, start, actualChunkSize);
+
+      if (chunk.length() == 0) {
+        if (currPredictions == null) {
+          return new ProbingLanguageDetectionResult(predict(ngramCounts), start);
+        } else {
+          return new ProbingLanguageDetectionResult(currPredictions, start);
+        }
+      }
+      start += chunk.length();
+      updateCounts(mContextGenerator.getContext(chunk.getString()), ngramCounts);
+      currPredictions = predict(ngramCounts);
+      if (seenEnough(predictions, currPredictions, ngramCounts, config)) {
+        return new ProbingLanguageDetectionResult(currPredictions, start);
+      }
+    }
+  }
+
+  private void updateCounts(String[] context, Map<String, MutableInt> ngrams) {
+    for (String ngram : context) {
+      MutableInt i = ngrams.get(ngram);
+      if (i == null) {
+        i = new MutableInt(1);
+        ngrams.put(ngram, i);
+      } else {
+        i.increment();
+      }
+    }
+  }
+
+  private Map<String, MutableInt> arrayToCounts(String[] context) {
+    Map<String, MutableInt> ngrams = new HashMap<>();
+    updateCounts(context, ngrams);
+    return ngrams;
+  }
+
+  private Language[] predict(Map<String, MutableInt> ngramCounts) {
+    String[] allGrams = new String[ngramCounts.size()];
+    float[] counts = new float[ngramCounts.size()];
+    int i = 0;
+    for (Map.Entry<String, MutableInt> e : ngramCounts.entrySet()) {
+      allGrams[i] = e.getKey();
+      // TODO -- once OPENNLP-1261 is fixed,
+      // change this to e.getValue().getValue().
+      counts[i] = 1;
+      i++;
+    }
+    double[] eval = model.getMaxentModel().eval(allGrams, counts);
+    Language[] arr = new Language[eval.length];
+    for (int j = 0; j < eval.length; j++) {
+      arr[j] = new Language(model.getMaxentModel().getOutcome(j), eval[j]);
+    }
+
+    Arrays.sort(arr, (o1, o2) -> Double.compare(o2.getConfidence(), o1.getConfidence()));
+    return arr;
+  }
+
+  /**
+   * Override this for different behavior to determine if there is enough
+   * confidence in the predictions to stop.
+   *
+   * @param predictionsQueue queue of earlier predictions
+   * @param newPredictions most recent predictions
+   * @param ngramCounts -- not currently used, but might be useful
+   * @return whether or not enough text has been processed to make a determination
+   */
+  boolean seenEnough(List<Language[]> predictionsQueue, Language[] newPredictions,
+                     Map<String, MutableInt> ngramCounts, LanguageDetectorConfig config) {
+
+    if (predictionsQueue.size() < config.getMinConsecImprovements()) {
+      predictionsQueue.add(newPredictions);
+      return false;
+    } else if (predictionsQueue.size() > config.getMinConsecImprovements()
+            && predictionsQueue.size() > 0) {
+      predictionsQueue.remove(0);
+    }
+    predictionsQueue.add(newPredictions);
+    if (config.getMinDiff() > 0.0 &&
+            newPredictions[0].getConfidence() -
+                    newPredictions[1].getConfidence() < config.getMinDiff()) {
+      return false;
+    }
+    String lastLang = null;
+    double lastConf = -1.0;
+    //iterate through the last predictions
+    //and check that the lang with the highest confidence
+    //hasn't changed, and that the confidence in it
+    //hasn't decreased
+    for (Language[] predictions : predictionsQueue) {
+      if (lastLang == null) {
+        lastLang = predictions[0].getLang();
+        lastConf = predictions[0].getConfidence();
+        continue;
+      } else {
+        if (!lastLang.equals(predictions[0].getLang())) {
+          return false;
+        }
+        if (lastConf > predictions[0].getConfidence()) {
+          return false;
+        }
+      }
+      lastLang = predictions[0].getLang();
+      lastConf = predictions[0].getConfidence();
+    }
+    return true;
+  }
+
+  private StringCPLengthPair chunk(CharSequence content, int start, int chunkSize) {
+    if (start == 0 && chunkSize > content.length()) {
+      String s = content.toString();
+      int codePointLength = s.codePointCount(0, s.length());
+      return
+              new StringCPLengthPair(s, codePointLength);
+    }
+    int[] codepoints = content.codePoints().skip(start).limit(chunkSize).toArray();
+    return
+            new StringCPLengthPair(
+                    new String(codepoints, 0, codepoints.length),
+                    codepoints.length);
+  }
+
+  private static class StringCPLengthPair {
+    private final String s;
+    private final int length;
+
+    StringCPLengthPair(String s, int length) {
+      this.s = s;
+      this.length = length;
+    }
+
+    int length() {
+      return length;
+    }
+
+    String getString() {
+      return s;
+    }
+  }

INS26 INS26 INS26 MOV31 INS40 INS40 INS40 INS31 INS31 INS31 INS31 INS31 INS31 INS31 INS55 UPD83 INS29 MOV78 INS83 INS5 INS42 INS44 INS8 INS29 INS29 INS83 INS43 INS42 MOV44 INS8 INS29 INS83 INS43 INS42 INS44 INS44 INS8 INS83 INS39 INS42 INS44 INS44 INS8 INS83 INS74 INS42 INS44 INS8 UPD83 UPD42 INS44 INS29 INS39 INS42 INS44 INS44 INS44 INS44 INS8 INS83 INS43 INS42 INS44 INS44 INS44 INS8 INS83 INS83 INS42 INS23 INS23 INS31 INS31 INS31 INS66 INS66 INS65 INS66 INS65 INS66 INS66 INS66 INS66 INS65 INS66 INS65 INS66 INS66 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS65 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS66 INS65 INS65 INS65 INS43 INS85 INS43 INS42 INS41 INS65 INS65 INS65 INS65 INS65 INS65 INS42 INS41 INS65 INS65 INS65 INS65 INS42 INS43 INS42 INS43 INS42 INS60 INS60 INS60 INS60 INS61 INS5 INS42 INS74 INS42 INS70 INS43 INS43 INS43 INS5 INS42 INS60 INS21 INS41 INS74 INS42 INS60 INS60 INS70 INS60 INS65 INS65 INS65 INS65 INS65 INS74 INS42 INS5 INS42 INS74 INS42 INS43 INS42 INS25 INS21 INS25 INS60 INS60 INS70 INS41 INS42 INS43 INS42 INS39 INS42 INS39 INS42 INS25 INS60 INS41 INS83 INS83 INS43 INS59 INS83 INS83 INS39 INS59 INS42 INS44 INS44 INS8 INS39 INS42 INS8 INS43 INS42 INS8 INS68 INS68 INS68 INS68 INS68 INS68 INS66 INS42 INS66 INS42 INS42 INS32 INS66 INS42 INS66 INS66 INS66 INS65 INS66 INS42 INS66 INS66 INS32 INS66 INS66 INS65 INS66 INS42 INS66 INS42 INS66 INS42 INS42 INS74 INS59 INS39 INS59 INS5 INS59 INS74 INS59 INS9 INS8 INS43 INS85 INS43 INS43 INS43 INS44 INS42 INS8 INS42 INS42 INS42 INS43 INS85 INS74 INS59 INS32 INS42 INS43 INS43 INS43 INS5 INS5 INS59 INS39 MOV59 INS44 INS32 INS8 MOV5 INS59 INS37 INS66 INS66 INS42 INS66 INS42 INS66 INS42 INS66 INS66 INS43 INS5 INS43 INS85 INS43 INS43 INS43 INS42 INS27 INS8 INS25 INS32 INS27 INS8 INS43 INS59 INS39 INS59 INS44 INS42 INS8 INS9 INS42 INS27 INS8 INS5 INS59 INS14 INS42 INS42 INS42 INS43 INS42 INS39 INS42 INS21 INS21 INS41 INS42 INS41 INS42 INS69 INS42 INS69 INS42 INS69 INS42 INS69 INS69 INS42 INS42 INS42 INS42 INS42 INS32 INS67 INS42 INS42 INS40 INS67 INS43 INS5 INS42 INS14 INS42 INS34 INS43 INS85 INS42 INS33 INS43 INS43 INS43 INS42 INS14 INS60 INS60 INS25 INS21 INS21 INS21 INS25 INS42 INS42 INS42 INS42 INS43 INS42 INS60 INS25 INS42 INS43 INS43 INS43 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS85 UPD42 INS3 INS39 INS85 INS42 INS3 INS74 INS42 INS42 INS42 INS21 INS21 INS21 INS42 MOV32 INS59 UPD42 INS42 INS42 INS43 INS85 INS42 INS42 INS42 INS42 INS32 INS32 INS21 INS41 INS27 INS8 INS42 INS42 INS42 INS27 INS27 INS41 INS42 INS42 INS33 INS42 INS38 INS5 INS42 INS25 INS21 INS21 INS27 INS27 INS60 INS60 INS41 INS39 INS85 INS42 INS32 INS43 INS14 INS40 INS42 INS7 INS7 INS42 INS42 INS43 INS43 INS43 INS43 INS43 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS43 INS85 INS43 INS42 INS42 INS42 INS42 INS74 INS39 INS59 INS43 INS59 INS27 INS8 INS7 INS32 INS7 INS32 INS8 INS42 INS43 INS59 INS27 INS8 INS8 INS42 INS42 INS42 INS74 INS42 INS5 INS32 INS5 INS32 INS43 INS43 INS43 INS7 INS7 MOV37 UPD42 UPD42 INS42 INS42 INS34 INS42 INS42 INS42 INS42 INS42 INS32 INS9 INS27 INS27 INS21 INS32 INS34 INS27 INS32 INS9 INS34 INS43 INS85 INS27 INS8 INS8 INS7 INS7 INS42 INS34 INS42 INS32 INS43 INS59 INS39 INS59 INS14 INS32 INS42 INS42 INS43 INS42 INS34 INS40 INS22 INS42 INS22 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS43 INS42 INS16 INS42 INS42 INS32 INS32 INS34 INS25 INS42 INS32 INS42 INS32 INS42 INS42 INS32 INS42 INS42 INS42 INS42 INS42 INS41 INS42 INS42 INS32 INS42 INS33 INS21 INS21 INS21 INS43 INS43 INS85 UPD42 MOV42 UPD42 MOV42 INS39 INS85 INS42 INS42 INS40 INS42 INS42 INS2 INS32 INS2 INS34 INS42 INS42 INS42 INS32 INS32 INS32 INS34 INS32 INS42 INS42 INS32 INS32 INS42 INS42 INS42 INS42 INS33 INS21 INS21 INS18 INS25 INS25 INS42 INS32 INS42 INS32 INS42 INS42 INS42 INS42 MOV32 INS42 INS32 INS43 INS42 INS42 INS32 INS42 INS42 INS42 INS52 INS42 INS52 INS42 INS42 INS36 INS27 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS27 INS8 INS8 INS42 INS42 INS42 INS42 INS32 INS42 INS42 INS14 INS42 INS42 INS42 INS7 INS32 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 UPD42 INS32 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 INS2 INS42 INS2 INS42 INS7 INS7 INS38 INS8 INS27 INS8 INS2 INS42 INS2 INS42 INS42 INS42 INS34 INS32 INS42 INS32 INS42 INS42 INS27 INS32 INS42 INS42 INS42 INS42 INS33 INS41 INS41 INS42 INS42 INS43 INS42 INS42 INS42 INS14 INS42 INS42 INS42 INS42 INS42 INS42 MOV32 INS42 INS42 UPD42 INS42 INS34 INS42 INS34 INS42 INS32 INS42 INS32 INS32 INS41 INS42 INS32 INS41 INS42 INS34 INS42 INS34 INS42 INS42 INS42 INS42 INS27 INS32 INS42 INS42 INS14 INS14 INS42 INS43 INS34 INS2 INS42 INS2 INS42 INS42 INS42 INS32 INS9 INS2 INS42 INS9 INS42 INS32 INS42 INS42 INS43 INS32 INS42 INS43 INS42 INS42 INS42 INS42 INS34 INS42 INS34 INS2 INS42 INS42 INS34 INS42 INS42 INS42 INS42 INS42 INS42 INS42 INS34 DEL42 DEL32 DEL32