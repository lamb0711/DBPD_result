OPENNLP-199 Fixed the perceptron, most importantly: uses standard update, stepsize is gradually diminished to ensure stability, and averaging is simplified and improved. Added prepositional phrase attachment dataset and added perceptron unit test on that data.

git-svn-id: https://svn.apache.org/repos/asf/incubator/opennlp/trunk@1133246 13f79535-47bb-0310-9956-ffa450edef68

-  /** Stores the estimated parameter value of each predicate during iteration. */
-  private MutableContext[] params; 
-
-  private int[][][] updates;
-  private int VALUE = 0;
-  private int ITER = 1;
-  private int EVENT = 2;
-  
-  /** Stores the average parameter values of each predicate during iteration. */
-  private MutableContext[] averageParams;
-
-  private EvalParameters evalParams;
-
-  double[] modelDistribution;
-  
-  private int iterations;
-  private boolean useAverage;
-  
-    this.iterations = iterations;
-    this.useAverage = useAverage;
-    this.iterations = iterations;
-    if (useAverage) updates = new int[numPreds][numOutcomes][3];
-
-    params = new MutableContext[numPreds];
-    if (useAverage) averageParams = new MutableContext[numPreds];
-    evalParams = new EvalParameters(params,numOutcomes);
-    
-    int[] allOutcomesPattern= new int[numOutcomes];
-    for (int oi = 0; oi < numOutcomes; oi++) {
-      allOutcomesPattern[oi] = oi;
-    }
-    
-    for (int pi = 0; pi < numPreds; pi++) {
-      params[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
-      if (useAverage) 
-        averageParams[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
-        for (int aoi=0;aoi<numOutcomes;aoi++) {
-          params[pi].setParameter(aoi, 0.0);
-          if (useAverage) 
-            averageParams[pi].setParameter(aoi, 0.0);
-        }
-    }
-    modelDistribution = new double[numOutcomes];
-
-    findParameters(iterations);
+
+    MutableContext[] finalParameters = findParameters(iterations, useAverage);
+
-    if (useAverage)
-      return new PerceptronModel(averageParams, predLabels, outcomeLabels);
-    else
-      return new PerceptronModel(params, predLabels, outcomeLabels);
-  }
-
-  private void display(String s) {
-    if (printMessages)
-      System.out.print(s);
+    return new PerceptronModel(finalParameters, predLabels, outcomeLabels);
-  private void findParameters(int iterations) {
+  private MutableContext[] findParameters (int iterations, boolean useAverage) {
-    int numTimesSameAccuracy = 0;
-    double prevAccuracy = 0.0;
-    for (int i = 1; i <= iterations; i++) {
-      if (i < 10)
-        display("  " + i + ":  ");
-      else if (i < 100)
-        display(" " + i + ":  ");
-      else
-        display(i + ":  ");
-      nextIteration(i);
+    int[] allOutcomesPattern= new int[numOutcomes];
+    for (int oi = 0; oi < numOutcomes; oi++) 
+      allOutcomesPattern[oi] = oi;
-      // Need to do this for the full set to get a representative
-      // accuracy -- doing it while training is biased because the
-      // events are ordered according to their outcomes.
-      double currAccuracy = trainingStats(averageParams);
+    /** Stores the estimated parameter value of each predicate during iteration. */
+    MutableContext[] params = new MutableContext[numPreds];
+    for (int pi = 0; pi < numPreds; pi++) {
+      params[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
+      for (int aoi=0;aoi<numOutcomes;aoi++)
+        params[pi].setParameter(aoi, 0.0);
+    }
+
+    EvalParameters evalParams = new EvalParameters(params,numOutcomes);
+  
+    /** Stores the sum of parameter values of each predicate over many iterations. */
+    MutableContext[] summedParams = new MutableContext[numPreds];
+    if (useAverage) {
+      for (int pi = 0; pi < numPreds; pi++) {
+        summedParams[pi] = new MutableContext(allOutcomesPattern,new double[numOutcomes]);
+        for (int aoi=0;aoi<numOutcomes;aoi++)
+          summedParams[pi].setParameter(aoi, 0.0);
+      }
+    }
+
+    // If the change in training set accuracy is less than this, stop iterating.
+    double tolerance = .00001;
+
+    // Keep track of the previous three accuracies. The difference of
+    // the mean of these and the current training set accuracy is used
+    // with tolerance to decide whether to stop.
+    double prevAccuracy1 = 0.0;
+    double prevAccuracy2 = 0.0;
+    double prevAccuracy3 = 0.0;
+
+    // A counter for the denominator for averaging.
+    int numTimesSummed = 0;
+
+    double stepsize = 1.05;
+    for (int i = 1; i <= iterations; i++) {
+
+      // Decrease the stepsize by a small amount.
+      stepsize /= 1.05;
-      if (currAccuracy == prevAccuracy) {
-        numTimesSameAccuracy++;
-      } else {
-        prevAccuracy = currAccuracy;
-        numTimesSameAccuracy = 0;
+      displayIteration(i);
+
+      int numCorrect = 0;
+      int total = 0;
+
+      for (int ei = 0; ei < numUniqueEvents; ei++) {
+        int targetOutcome = outcomeList[ei];
+
+        for (int ni=0; ni<this.numTimesEventsSeen[ei]; ni++) {
+
+          // Compute the model's prediction according to the current parameters.
+          double[] modelDistribution = new double[numOutcomes];
+          if (values != null)
+            PerceptronModel.eval(contexts[ei], values[ei], modelDistribution, evalParams, false);
+          else
+            PerceptronModel.eval(contexts[ei], null, modelDistribution, evalParams, false);
+
+          int maxOutcome = maxIndex(modelDistribution);
+
+          // If the predicted outcome is different from the target
+          // outcome, do the standard update: boost the parameters
+          // associated with the target and reduce those associated
+          // with the incorrect predicted outcome.
+          if (maxOutcome != targetOutcome) {
+            for (int ci = 0; ci < contexts[ei].length; ci++) {
+              int pi = contexts[ei][ci];
+              if (values == null) {
+                params[pi].updateParameter(targetOutcome, stepsize);
+                params[pi].updateParameter(maxOutcome, -stepsize);
+              } else {
+                params[pi].updateParameter(targetOutcome, stepsize*values[ei][ci]);
+                params[pi].updateParameter(maxOutcome, -stepsize*values[ei][ci]);
+              }
+            }
+          }
+
+          // Update the counts for accuracy.
+          total++;
+          if (maxOutcome == targetOutcome) 
+            numCorrect++;
+        }
-      // If the accuracy hasn't changed for four iterations, stop training.
-      if (numTimesSameAccuracy == 4) {
-        display("Accuracy repeated 4 times, stopping training.\n");
+      // Calculate the training accuracy and display.
+      double trainingAccuracy = (double) numCorrect / numEvents;
+      if (i < 10 || (i%10) == 0)
+        display(". (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+          
+      // If we are doing averaging, and the current iteration is one
+      // of the first 20 or it is a perfect square, then updated the
+      // summed parameters. The reason we don't take all of them is
+      // that the parameters change less toward the end of training,
+      // so they drown out the contributions of the more volatile
+      // early iterations. The use of perfect squares allows us to
+      // sample from successively farther apart iterations.
+      if (useAverage && (i < 20 || isPerfectSquare(i))) {
+        numTimesSummed++;
+        for (int pi = 0; pi < numPreds; pi++) 
+          for (int aoi=0;aoi<numOutcomes;aoi++)
+            summedParams[pi].updateParameter(aoi, params[pi].getParameters()[aoi]);
+      }
+
+      // If the tolerance is greater than the difference between the
+      // current training accuracy and all of the previous three
+      // training accuracies, stop training.
+      if (Math.abs(prevAccuracy1-trainingAccuracy) < tolerance
+          && Math.abs(prevAccuracy2-trainingAccuracy) < tolerance
+          && Math.abs(prevAccuracy3-trainingAccuracy) < tolerance) {
+        display("Stopping: change in training set accuracy less than " + tolerance + "\n");
+      
+      // Update the previous training accuracies.
+      prevAccuracy1 = prevAccuracy2;
+      prevAccuracy2 = prevAccuracy3;
+      prevAccuracy3 = trainingAccuracy;
-    if (useAverage)
-      trainingStats(averageParams);
-    else
-      trainingStats(params);
-    // kill a bunch of these big objects now that we don't need them
-    numTimesEventsSeen = null;
-    contexts = null;
+    // Output the final training stats.
+    trainingStats(evalParams);
+
+    // Create averaged parameters
+    if (useAverage) {
+      for (int pi = 0; pi < numPreds; pi++) 
+        for (int aoi=0;aoi<numOutcomes;aoi++)
+          summedParams[pi].setParameter(aoi, summedParams[pi].getParameters()[aoi]/numTimesSummed);
+
+      return summedParams;
+
+    } else {
+
+      return params;
+
+    }
+        
-  /* Compute one iteration of Perceptron.*/
-  private void nextIteration(int iteration) {
-    iteration--; //move to 0-based index
-    int oei = 0;
-    for (int ei = 0; ei < numUniqueEvents; ei++, oei++) {
-      for (int ni=0;ni<this.numTimesEventsSeen[ei];ni++) {
-
-        for (int oi = 0; oi < numOutcomes; oi++)
-          modelDistribution[oi] = 0;
-
-        if (values != null)
-          PerceptronModel.eval(contexts[ei], values[ei], modelDistribution, evalParams,false);
-        else
-          PerceptronModel.eval(contexts[ei], null, modelDistribution, evalParams, false);
-
-        int max = 0;
-        for (int oi = 1; oi < numOutcomes; oi++) 
-          if (modelDistribution[oi] > modelDistribution[max]) 
-            max = oi;
-
-        for (int oi = 0;oi<numOutcomes;oi++) {
-          int updateValue = -1;
-          if (oi == outcomeList[oei])
-            updateValue = 1;
-
-    	  if (modelDistribution[oi]*updateValue <= 0) {
-    	    for (int ci = 0; ci < contexts[ei].length; ci++) {
-    	      int pi = contexts[ei][ci];
-    	      if (values == null)
-    	        params[pi].updateParameter(oi, updateValue);
-    	      else
-    	        params[pi].updateParameter(oi, updateValue*values[ei][ci]);
-    
-    	      if (useAverage) {
-    
-    	        if (updates[pi][oi][VALUE] != 0)
-    	          averageParams[pi].updateParameter(oi, updates[pi][oi][VALUE] *
-    	              (numEvents * (iteration-updates[pi][oi][ITER])
-    	              + (ei-updates[pi][oi][EVENT])));
-    	        
-    	        updates[pi][oi][VALUE] = (int) params[pi].getParameters()[oi];
-    	        updates[pi][oi][ITER] = iteration;
-    	        updates[pi][oi][EVENT] = ei;
-    	      }
-    	    }
-    	  }
-        }
-      }
-    }
-
-    //finish average computation
-    double totIterations = (double) iterations*numEvents;
-    if (useAverage && iteration == iterations-1) {
-      for (int pi = 0; pi < numPreds; pi++) {
-        double[] predParams = averageParams[pi].getParameters();
-        for (int oi = 0;oi<numOutcomes;oi++) {
-          if (updates[pi][oi][VALUE] != 0) 
-            predParams[oi] +=  updates[pi][oi][VALUE] *
-                (numEvents * (iterations-updates[pi][oi][ITER])
-                - updates[pi][oi][EVENT]);
-
-          if (predParams[oi] != 0) {
-            predParams[oi] /=totIterations;  
-            averageParams[pi].setParameter(oi, predParams[oi]);
-          }
-        }
-      }
-    }
-  }  
-  
-  private double trainingStats(MutableContext[] params) {
+  private double trainingStats (EvalParameters evalParams) {
-    int oei = 0;
-    for (int ei = 0; ei < numUniqueEvents; ei++, oei++) {
+
+    for (int ei = 0; ei < numUniqueEvents; ei++) {
-        for (int oi = 0; oi < numOutcomes; oi++)
-          modelDistribution[oi] = 0;
+
+        double[] modelDistribution = new double[numOutcomes];
+
-        int max = 0;
-        for (int oi = 1; oi < numOutcomes; oi++)
-          if (modelDistribution[oi] > modelDistribution[max])
-            max = oi;
-        if (max == outcomeList[oei])
+
+        int max = maxIndex(modelDistribution);
+        if (max == outcomeList[ei])
-    display(". (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+    display("Stats: (" + numCorrect + "/" + numEvents+") " + trainingAccuracy + "\n");
+
+
+  private int maxIndex (double[] values) {
+    int max = 0;
+    for (int i = 1; i < values.length; i++)
+      if (values[i] > values[max])
+        max = i;
+    return max;
+  }
+
+  private void display (String s) {
+    if (printMessages)
+      System.out.print(s);
+  }
+
+  private void displayIteration (int i) {
+    if (i > 10 && (i%10) != 0)
+      return;
+
+    if (i < 10)
+      display("  " + i + ":  ");
+    else if (i < 100)
+      display(" " + i + ":  ");
+    else
+      display(i + ":  ");
+  }
+
+  // See whether a number is a perfect square. Inefficient, but fine
+  // for our purposes.
+  private final static boolean isPerfectSquare (int n) {
+    int root = (int)Math.sqrt(n);
+    return root*root == n;
+  }
+

MOV31 INS31 INS31 INS31 INS31 INS83 MOV5 INS42 MOV44 INS44 INS8 MOV60 INS83 INS39 INS42 INS44 INS8 INS83 INS39 INS42 INS44 MOV8 INS83 INS83 INS83 INS39 INS42 INS44 INS8 INS60 INS41 INS39 INS42 MOV21 MOV60 MOV24 INS60 MOV24 INS60 INS60 INS25 INS60 INS60 INS60 INS60 MOV60 MOV60 INS24 INS21 INS25 INS43 UPD42 INS21 MOV5 INS42 MOV60 INS24 INS41 INS39 INS42 INS25 INS39 INS42 INS60 INS41 MOV5 INS59 MOV14 MOV21 INS5 INS59 MOV43 INS59 MOV5 INS59 INS42 INS8 INS39 INS59 INS39 INS59 INS39 INS59 INS39 INS59 MOV58 MOV27 MOV37 INS8 INS32 INS42 INS8 INS8 INS42 UPD39 INS32 INS58 INS27 INS37 INS25 INS42 INS27 INS41 INS39 INS59 INS27 INS42 INS32 UPD42 INS43 MOV85 UPD42 MOV42 MOV3 INS42 MOV14 INS42 MOV3 INS24 UPD42 MOV42 INS34 UPD42 MOV42 INS34 UPD42 MOV42 INS34 INS42 INS34 UPD42 UPD42 UPD34 INS21 INS21 MOV60 INS60 INS24 MOV60 INS25 INS25 INS25 INS21 MOV21 MOV21 INS42 INS42 INS24 INS41 INS41 UPD42 INS27 INS42 INS27 INS39 INS59 INS42 INS40 INS42 INS27 INS21 INS27 INS27 INS42 INS11 INS27 INS42 MOV42 MOV42 INS42 INS42 MOV21 INS58 INS27 INS37 INS8 INS7 MOV32 INS39 INS59 MOV58 MOV27 MOV37 INS8 INS27 MOV21 UPD27 MOV27 INS8 INS27 INS8 INS7 MOV58 MOV27 MOV37 INS24 INS42 INS42 INS11 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS45 INS42 INS34 INS2 MOV2 UPD7 MOV7 INS42 INS34 INS36 INS34 INS39 INS32 INS42 INS42 INS39 INS59 INS42 INS42 INS42 MOV21 INS24 INS42 INS34 UPD42 UPD42 UPD42 UPD42 MOV42 MOV34 INS60 INS24 INS27 INS27 INS42 INS36 INS21 INS24 INS27 INS27 INS21 INS10 INS42 INS42 INS42 INS42 INS42 INS42 MOV58 MOV27 MOV37 INS21 INS60 INS60 INS39 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 UPD42 INS42 INS42 INS27 INS42 UPD42 MOV42 UPD42 MOV42 UPD42 MOV42 MOV34 INS58 INS27 INS37 INS21 INS39 INS59 MOV58 MOV27 MOV37 INS8 INS42 INS34 INS36 INS34 INS27 INS37 MOV58 MOV27 MOV37 INS24 INS27 INS27 INS32 UPD42 MOV42 INS32 UPD42 UPD42 INS32 INS5 INS59 INS39 INS59 UPD42 MOV42 UPD34 MOV34 INS39 INS59 INS42 INS42 INS42 INS32 INS42 INS2 INS60 MOV25 MOV60 INS25 INS21 INS25 INS27 INS27 INS32 INS42 UPD42 UPD42 UPD42 INS58 INS27 INS37 MOV21 INS32 INS42 INS32 INS42 INS42 INS42 INS27 INS42 INS27 UPD42 INS2 INS42 INS42 INS27 INS39 INS85 UPD42 MOV42 INS3 INS42 INS32 UPD42 UPD42 MOV42 UPD34 MOV34 INS2 INS42 INS42 INS34 INS42 INS42 MOV5 INS59 INS27 INS8 INS37 INS27 INS21 INS42 INS34 INS42 INS34 INS42 INS42 UPD42 INS39 INS59 UPD42 MOV42 INS42 INS42 INS32 INS42 INS42 INS27 INS42 UPD42 MOV42 INS27 INS42 INS42 INS45 INS42 INS45 UPD42 MOV42 MOV42 INS2 INS42 INS5 INS42 INS42 INS42 UPD42 INS42 INS42 INS42 MOV3 INS42 INS32 INS42 INS42 INS24 INS42 UPD42 MOV42 UPD42 MOV42 INS37 UPD42 MOV42 INS34 INS2 INS42 INS42 MOV2 INS42 INS42 INS42 INS42 INS32 UPD42 MOV42 INS39 INS85 INS42 INS42 MOV58 MOV27 MOV37 INS8 UPD42 MOV42 UPD42 MOV42 MOV42 UPD42 INS2 INS42 MOV60 MOV25 UPD42 MOV42 MOV42 INS8 INS8 INS21 INS21 INS21 MOV21 INS32 INS32 MOV32 INS2 INS42 INS42 INS42 INS2 INS42 INS42 INS38 MOV2 INS42 INS27 MOV2 UPD42 INS42 INS42 INS42 INS42 INS42 INS42 INS2 INS38 INS2 INS42 INS42 INS42 INS42 DEL66 DEL65 DEL29 DEL83 DEL42 DEL59 DEL23 DEL83 DEL39 DEL85 DEL85 DEL5 DEL59 DEL23 DEL83 DEL39 DEL59 DEL23 DEL83 DEL39 DEL59 DEL23 DEL83 DEL39 DEL42 DEL34 DEL59 DEL23 DEL66 DEL65 DEL29 DEL83 DEL42 DEL59 DEL23 DEL83 DEL42 DEL59 DEL23 DEL59 DEL23 DEL83 DEL39 DEL59 DEL23 DEL83 DEL39 DEL59 DEL23 DEL52 DEL42 DEL22 DEL42 DEL7 DEL21 DEL52 DEL42 DEL22 DEL42 DEL7 DEL21 DEL52 DEL42 DEL22 DEL42 DEL7 DEL21 DEL42 DEL42 DEL39 DEL85 DEL85 DEL85 DEL5 DEL42 DEL42 DEL34 DEL3 DEL7 DEL21 DEL25 DEL42 DEL7 DEL21 DEL42 DEL42 DEL7 DEL21 DEL25 DEL42 DEL7 DEL21 DEL42 DEL7 DEL21 DEL32 DEL21 DEL42 DEL41 DEL42 DEL43 DEL42 DEL42 DEL42 DEL14 DEL41 DEL25 DEL8 DEL42 DEL25 DEL42 DEL42 DEL42 DEL2 DEL42 DEL42 DEL34 DEL32 DEL21 DEL25 DEL8 DEL42 DEL34 DEL42 DEL42 DEL42 DEL21 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL2 DEL42 DEL2 DEL42 DEL2 DEL39 DEL11 DEL7 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL42 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL42 DEL83 DEL39 DEL42 DEL24 DEL42 DEL42 DEL42 DEL32 DEL21 DEL21 DEL25 DEL42 DEL33 DEL7 DEL21 DEL42 DEL33 DEL7 DEL21 DEL8 DEL31 DEL83 DEL39 DEL42 DEL39 DEL42 DEL44 DEL42 DEL37 DEL21 DEL42 DEL37 DEL39 DEL59 DEL58 DEL42 DEL42 DEL27 DEL42 DEL37 DEL42 DEL42 DEL2 DEL34 DEL7 DEL21 DEL24 DEL39 DEL42 DEL34 DEL59 DEL58 DEL27 DEL37 DEL42 DEL42 DEL7 DEL21 DEL25 DEL24 DEL39 DEL34 DEL38 DEL59 DEL60 DEL42 DEL42 DEL2 DEL27 DEL42 DEL34 DEL7 DEL21 DEL25 DEL42 DEL42 DEL2 DEL42 DEL27 DEL34 DEL27 DEL42 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL34 DEL27 DEL42 DEL42 DEL2 DEL42 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL42 DEL42 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL27 DEL36 DEL27 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL27 DEL36 DEL27 DEL36 DEL27 DEL32 DEL21 DEL25 DEL8 DEL25 DEL8 DEL24 DEL8 DEL25 DEL8 DEL24 DEL8 DEL24 DEL8 DEL24 DEL39 DEL42 DEL39 DEL42 DEL11 DEL42 DEL27 DEL59 DEL60 DEL42 DEL42 DEL42 DEL34 DEL27 DEL27 DEL27 DEL42 DEL42 DEL42 DEL2 DEL42 DEL32 DEL59 DEL60 DEL2 DEL42 DEL2 DEL42 DEL2 DEL34 DEL27 DEL42 DEL42 DEL2 DEL2 DEL2 DEL42 DEL2 DEL42 DEL42 DEL42 DEL42 DEL2 DEL42 DEL2 DEL42 DEL2 DEL27 DEL36 DEL27 DEL2 DEL42 DEL2 DEL42 DEL2 DEL27 DEL36 DEL27 DEL7 DEL21 DEL25 DEL34 DEL27 DEL21 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL32 DEL21 DEL8 DEL25 DEL8 DEL24 DEL8 DEL24 DEL8 DEL25 DEL8 DEL31 DEL42 DEL37 DEL39 DEL34 DEL59 DEL58 DEL42 DEL42 DEL27 DEL42 DEL37 DEL42 DEL42 DEL2 DEL34 DEL7 DEL21 DEL24 DEL39 DEL42 DEL34 DEL59 DEL58 DEL42 DEL42 DEL27 DEL42 DEL37 DEL42 DEL42 DEL2 DEL42 DEL42 DEL2 DEL27 DEL42 DEL42 DEL7 DEL21 DEL25 DEL24 DEL34 DEL42 DEL42 DEL2 DEL42 DEL42 DEL42 DEL32 DEL21 DEL39 DEL42 DEL42 DEL42 DEL32 DEL59 DEL60 DEL42 DEL42 DEL27 DEL42 DEL37 DEL21 DEL8 DEL42 DEL42 DEL7 DEL21 DEL42 DEL34 DEL7 DEL21 DEL8 DEL25 DEL27 DEL42 DEL45 DEL32 DEL21 DEL10 DEL8 DEL25