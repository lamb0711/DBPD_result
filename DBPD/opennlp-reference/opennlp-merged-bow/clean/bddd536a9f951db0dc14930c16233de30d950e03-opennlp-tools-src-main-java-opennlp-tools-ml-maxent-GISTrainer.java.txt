OPENNLP-123: Feature cutoff should only be done by data indexers, this closes apache/opennlp#65

- *
+ * <p>
- *
+ * <p>
+  private static final double LLThreshold = 0.0001;
+  private final boolean printMessages;
-
-
-
-
-  private final boolean printMessages;
-
-
-
-
-
-
-
-
-  /**
-   * The number of times a predicate occured in the training data.
-   */
-  private int[] predicateCounts;
-
-  private int cutoff;
-
-
-
-
-
-
-
-  private static final double LLThreshold = 0.0001;
-
-   *
-   *
+   *
-   * @param iterations The number of iterations to use for GIS.
-   * @param cutoff The number of times a feature must occur to be included.
+   * @param iterations  The number of iterations to use for GIS.
+   * @param cutoff      The number of times a feature must occur to be included.
-  public GISModel trainModel(ObjectStream<Event> eventStream, int iterations, int cutoff) throws IOException {
+  public GISModel trainModel(ObjectStream<Event> eventStream, int iterations,
+                             int cutoff) throws IOException {
-    return trainModel(iterations, indexer, cutoff);
+    return trainModel(iterations, indexer);
-   * @param iterations  The number of GIS iterations to perform.
-   * @param di The data indexer used to compress events in memory.
+   * @param iterations The number of GIS iterations to perform.
+   * @param di         The data indexer used to compress events in memory.
-   *         to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
+   * to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
-  public GISModel trainModel(int iterations, DataIndexer di, int cutoff) {
-    return trainModel(iterations,di,new UniformPrior(),cutoff,1);
+  public GISModel trainModel(int iterations, DataIndexer di) {
+    return trainModel(iterations, di, new UniformPrior(), 1);
-   * @param iterations  The number of GIS iterations to perform.
-   * @param di The data indexer used to compress events in memory.
+   * @param iterations The number of GIS iterations to perform.
+   * @param di         The data indexer used to compress events in memory.
-   *         to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
+   * to disk using an opennlp.tools.ml.maxent.io.GISModelWriter object.
-  public GISModel trainModel(int iterations, DataIndexer di, Prior modelPrior, int cutoff, int threads) {
+  public GISModel trainModel(int iterations, DataIndexer di, Prior modelPrior, int threads) {
-    this.cutoff = cutoff;
-    predicateCounts = di.getPredCounts();
+    /*
+    The number of times a predicate occured in the training data.
+   */
+    int[] predicateCounts = di.getPredCounts();
-      }
-      else {
+      } else {
-    prior.setLabels(outcomeLabels,predLabels);
+    prior.setLabels(outcomeLabels, predLabels);
-        }
-        else {
+        } else {
-    //printTable(predCount);
-    di = null; // don't need it anymore
-
-    for (int i = 0; i < modelExpects.length; i++)
+    for (int i = 0; i < modelExpects.length; i++) {
+    }
-    evalParams = new EvalParameters(params,0,1,numOutcomes);
+    evalParams = new EvalParameters(params, 0, 1, numOutcomes);
-      }
-      else { //determine active outcomes
+      } else { //determine active outcomes
-          if (predCount[pi][oi] > 0 && predicateCounts[pi] >= cutoff) {
+          if (predCount[pi][oi] > 0) {
-        }
-        else {
+        } else {
-      params[pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      for (int i = 0; i < modelExpects.length; i++)
-        modelExpects[i][pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      observedExpects[pi] = new MutableContext(outcomePattern,new double[numActiveOutcomes]);
-      for (int aoi = 0;aoi < numActiveOutcomes; aoi++) {
+      params[pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      for (int i = 0; i < modelExpects.length; i++) {
+        modelExpects[i][pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      }
+      observedExpects[pi] = new MutableContext(outcomePattern, new double[numActiveOutcomes]);
+      for (int aoi = 0; aoi < numActiveOutcomes; aoi++) {
-        }
-        else if (useSimpleSmoothing) {
-          observedExpects[pi].setParameter(aoi,smoothingObservation);
+        } else if (useSimpleSmoothing) {
+          observedExpects[pi].setParameter(aoi, smoothingObservation);
-    predCount = null; // don't need it anymore
-
-    if (threads == 1)
+    if (threads == 1) {
-    else
+    } else {
+    }
-    CompletionService<ModelExpactationComputeTask> completionService =
+    CompletionService<ModelExpectationComputeTask> completionService =
-      if (i < 10)
+      if (i < 10) {
-      else if (i < 100)
+      } else if (i < 100) {
-      else
+      } else {
-      currLL = nextIteration(correctionConstant,completionService);
+      }
+      currLL = nextIteration(correctionConstant, completionService);
-  private double gaussianUpdate(int predicate, int oid, int n, double correctionConstant) {
+  private double gaussianUpdate(int predicate, int oid, double correctionConstant) {
-  private class ModelExpactationComputeTask implements Callable<ModelExpactationComputeTask> {
-
-    private final int startIndex;
-    private final int length;
-
-    private double loglikelihood = 0;
-
-    private int numEvents = 0;
-    private int numCorrect = 0;
-
-    final private int threadIndex;
-
-    // startIndex to compute, number of events to compute
-    ModelExpactationComputeTask(int threadIndex, int startIndex, int length) {
-      this.startIndex = startIndex;
-      this.length = length;
-      this.threadIndex = threadIndex;
-    }
-
-    public ModelExpactationComputeTask call() {
-
-      final double[] modelDistribution = new double[numOutcomes];
-
-
-      for (int ei = startIndex; ei < startIndex + length; ei++) {
-
-        // TODO: check interruption status here, if interrupted set a poisoned flag and return
-
-        if (values != null) {
-          prior.logPrior(modelDistribution, contexts[ei], values[ei]);
-          GISModel.eval(contexts[ei], values[ei], modelDistribution, evalParams);
-        }
-        else {
-          prior.logPrior(modelDistribution,contexts[ei]);
-          GISModel.eval(contexts[ei], modelDistribution, evalParams);
-        }
-        for (int j = 0; j < contexts[ei].length; j++) {
-          int pi = contexts[ei][j];
-          if (predicateCounts[pi] >= cutoff) {
-            int[] activeOutcomes = modelExpects[threadIndex][pi].getOutcomes();
-            for (int aoi = 0;aoi < activeOutcomes.length; aoi++) {
-              int oi = activeOutcomes[aoi];
-
-              // numTimesEventsSeen must also be thread safe
-              if (values != null && values[ei] != null) {
-                modelExpects[threadIndex][pi].updateParameter(aoi,modelDistribution[oi]
-                    * values[ei][j] * numTimesEventsSeen[ei]);
-              }
-              else {
-                modelExpects[threadIndex][pi].updateParameter(aoi,modelDistribution[oi]
-                    * numTimesEventsSeen[ei]);
-              }
-            }
-          }
-        }
-
-        loglikelihood += Math.log(modelDistribution[outcomeList[ei]]) * numTimesEventsSeen[ei];
-
-        numEvents += numTimesEventsSeen[ei];
-        if (printMessages) {
-          int max = 0;
-          for (int oi = 1; oi < numOutcomes; oi++) {
-            if (modelDistribution[oi] > modelDistribution[max]) {
-              max = oi;
-            }
-          }
-          if (max == outcomeList[ei]) {
-            numCorrect += numTimesEventsSeen[ei];
-          }
-        }
-
-      }
-
-      return this;
-    }
-
-    synchronized int getNumEvents() {
-      return numEvents;
-    }
-
-    synchronized int getNumCorrect() {
-      return numCorrect;
-    }
-
-    synchronized double getLoglikelihood() {
-      return loglikelihood;
-    }
-  }
-
-                               CompletionService<ModelExpactationComputeTask> completionService) {
+                               CompletionService<ModelExpectationComputeTask> completionService) {
-    // is not divisible by the number of threads, the first "leftOver" 
+    // is not divisible by the number of threads, the first "leftOver"
-      if (i < leftOver)
-        completionService.submit(new ModelExpactationComputeTask(i, i * taskSize + i, taskSize + 1));
-      else
-        completionService.submit(new ModelExpactationComputeTask(i, i * taskSize + leftOver, taskSize));
+      if (i < leftOver) {
+        completionService.submit(new ModelExpectationComputeTask(i, i * taskSize + i,
+            taskSize + 1));
+      } else {
+        completionService.submit(new ModelExpectationComputeTask(i,
+            i * taskSize + leftOver, taskSize));
+      }
-      ModelExpactationComputeTask finishedTask;
+      ModelExpectationComputeTask finishedTask;
-          params[pi].updateParameter(aoi,gaussianUpdate(pi,aoi,numEvents,correctionConstant));
-        }
-        else {
+          params[pi].updateParameter(aoi, gaussianUpdate(pi, aoi, correctionConstant));
+        } else {
-          params[pi].updateParameter(aoi,((Math.log(observed[aoi]) - Math.log(model[aoi]))
+          params[pi].updateParameter(aoi, ((Math.log(observed[aoi]) - Math.log(model[aoi]))
-    if (printMessages)
+    if (printMessages) {
+    }
+  }
+
+  private class ModelExpectationComputeTask implements Callable<ModelExpectationComputeTask> {
+
+    private final int startIndex;
+    private final int length;
+    final private int threadIndex;
+    private double loglikelihood = 0;
+    private int numEvents = 0;
+    private int numCorrect = 0;
+
+    // startIndex to compute, number of events to compute
+    ModelExpectationComputeTask(int threadIndex, int startIndex, int length) {
+      this.startIndex = startIndex;
+      this.length = length;
+      this.threadIndex = threadIndex;
+    }
+
+    public ModelExpectationComputeTask call() {
+
+      final double[] modelDistribution = new double[numOutcomes];
+
+
+      for (int ei = startIndex; ei < startIndex + length; ei++) {
+
+        // TODO: check interruption status here, if interrupted set a poisoned flag and return
+
+        if (values != null) {
+          prior.logPrior(modelDistribution, contexts[ei], values[ei]);
+          GISModel.eval(contexts[ei], values[ei], modelDistribution, evalParams);
+        } else {
+          prior.logPrior(modelDistribution, contexts[ei]);
+          GISModel.eval(contexts[ei], modelDistribution, evalParams);
+        }
+        for (int j = 0; j < contexts[ei].length; j++) {
+          int pi = contexts[ei][j];
+          int[] activeOutcomes = modelExpects[threadIndex][pi].getOutcomes();
+          for (int aoi = 0; aoi < activeOutcomes.length; aoi++) {
+            int oi = activeOutcomes[aoi];
+
+            // numTimesEventsSeen must also be thread safe
+            if (values != null && values[ei] != null) {
+              modelExpects[threadIndex][pi].updateParameter(aoi, modelDistribution[oi]
+                  * values[ei][j] * numTimesEventsSeen[ei]);
+            } else {
+              modelExpects[threadIndex][pi].updateParameter(aoi, modelDistribution[oi]
+                  * numTimesEventsSeen[ei]);
+            }
+          }
+        }
+
+        loglikelihood += Math.log(modelDistribution[outcomeList[ei]]) * numTimesEventsSeen[ei];
+
+        numEvents += numTimesEventsSeen[ei];
+        if (printMessages) {
+          int max = 0;
+          for (int oi = 1; oi < numOutcomes; oi++) {
+            if (modelDistribution[oi] > modelDistribution[max]) {
+              max = oi;
+            }
+          }
+          if (max == outcomeList[ei]) {
+            numCorrect += numTimesEventsSeen[ei];
+          }
+        }
+
+      }
+
+      return this;
+    }
+
+    synchronized int getNumEvents() {
+      return numEvents;
+    }
+
+    synchronized int getNumCorrect() {
+      return numCorrect;
+    }
+
+    synchronized double getLoglikelihood() {
+      return loglikelihood;
+    }

MOV23 MOV23 MOV55 MOV23 UPD42 UPD74 INS66 INS66 INS60 UPD74 UPD43 UPD42 UPD43 MOV8 UPD66 UPD66 UPD66 UPD66 UPD66 UPD66 MOV5 INS59 INS8 INS8 INS8 UPD74 UPD43 INS8 UPD42 UPD42 MOV60 MOV41 INS42 MOV32 MOV21 MOV21 MOV21 UPD43 UPD42 MOV21 MOV58 MOV27 MOV37 INS8 UPD42 INS8 INS8 INS8 UPD43 MOV25 INS24 MOV21 MOV21 MOV25 MOV21 MOV21 INS8 INS8 MOV21 MOV21 UPD42 MOV58 MOV27 MOV37 MOV8 MOV21 MOV21 MOV60 MOV27 UPD43 UPD43 UPD42 UPD42 MOV2 MOV42 MOV42 DEL66 DEL65 DEL29 DEL83 DEL42 DEL59 DEL23 DEL83 DEL39 DEL42 DEL59 DEL23 DEL42 DEL39 DEL42 DEL44 DEL42 DEL39 DEL42 DEL44 DEL52 DEL42 DEL22 DEL42 DEL7 DEL21 DEL42 DEL7 DEL21 DEL42 DEL33 DEL7 DEL21 DEL42 DEL42 DEL2 DEL42 DEL27 DEL27 DEL42 DEL33 DEL7 DEL21 DEL39 DEL42 DEL44 DEL42 DEL42 DEL24 DEL8